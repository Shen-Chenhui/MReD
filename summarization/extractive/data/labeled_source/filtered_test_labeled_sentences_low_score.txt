2018-500	This manuscript explores the idea of adding noise to the adversary's play in GAN dynamics over an RKHS.	abstract
2018-500	This is equivalent to adding noise to the gradient update, using the duality of reproducing kernels.	abstract
2018-500	Unfortunately, the evaluation here is wholly unsatisfactory to justify the manuscript's claims.	weakness
2018-500	No concrete practical algorithm specification is given (only a couple of ideas to inject noise listed), only a qualitative one on a 2-dimensional latent space in MNIST, and an inconclusive one using the much-doubted Parzen window KDE method.	weakness
2018-500	The idea as stated in the abstract and introduction may well be worth pursuing, but not on the evidence provided by the rest of the manuscript.	weakness
2018-500	In this paper, the authors propose doubly stochastic adversarial autoencoder, which is essentially applying the doubly stochastic gradient for the variational form of maximum mean discrepancy.	abstract
2018-500	The most severe issue is lacking novelty.	weakness
2018-500	It is a straightforward combination of existing work, therefore, the contribution of this work is rare.	strength
2018-500	Moreover, some of the claims in the paper are not appropriate.	weakness
2018-500	For example, using random features to approximate the kernel function does not bring extra stochasticity.	weakness
2018-500	The random features are fixed once sampled from the base measure of the corresponding kernel.	weakness
2018-500	Basically, you can view the random feature approximation as a linear combination of fixed nonlinear basis which are sampled from some distribution.	weakness
2018-500	Finally, the experiments are promising.	strength
2018-500	However, to be more convincing, more benchmarks, e.g., cifar10/100 and CelebA, are needed.	weakness
2018-500	Thank you for the feedback, and I have read it.	misc
2018-500	The authors claimed that they used techniques in [6] in which I am not an expert for this.	rebuttal_process
2018-500	However I cannot find the comparison that the authors mentioned in the feedback, so I am not sure if the claim is true.	rebuttal_process
2018-500	I still recommend rejection for the paper, and as I said in the first review, the paper is not mature enough.	decision
2018-500	==== original review === The paper describes a generative model that replaces the GAN loss in the adversarial auto-encoder with MMD loss.	abstract
2018-500	Although the author claim the novelty as adding noise to the discriminator, it seems to me that at least for the RBF case it just does the following: 1. write down MMD as an integral probability metric (IPM)	weakness
2018-500	2. say the test function, which originally should be in an RKHS, will be approximated using random feature approximations.	weakness
2018-500	Although the authors explained the intuition a bit and showed some empirical results, I still don't see why this method should work better than directly minimising MMD.	rebuttal_process
2018-500	Also it is not preferred to look at the generated images and claim diversity, instead it's better to have some kind of quantitative metric such as the inception score.	rebuttal_process
2018-500	Finally, given the fact that we have too many GAN related papers now, I don't think the innovation contained in the paper (which is using random features) is good enough to be published at *CONF*.	decision
2018-500	Also the paper is not clearly written, and I would suggest better not to copy-past paragraphs in the abstract and intro.	weakness
2018-500	That said, I would welcome for the authors feedback and see if I have misunderstood something.	misc

2018-623	The paper promises quite a few intriguing connections between information bottleneck, phase transitions and deep learning.	strength
2018-623	While we think that this is a worthwhile bridge to build between machine learning and statistical field theory, the exposition of the paper leaves much to be desired.	weakness
2018-623	Had it been a clean straightforward application of QFT, as well-trained theoretical physicists, we would have been able to evaluate the paper.	weakness
2018-623	Generally, it would help the reader to have an overall map and indication of the steps that would be taken formally.	weakness
2018-623	Specifically, starting from Section 2.3, especially around the transition to continuous layers, very little information is provided how one is dealing with the cost function and the results are derived.	weakness
2018-623	Section 2.3 would benefit from expanded discussion with examples and detailed explanations.	weakness
2018-623	Minor: The following sentence in third paragraph of the Introduction is incomplete: Because the ResNet does not contain such symmetry breaking layers in the architecture.	weakness
2018-623	In this paper, an number of very strong (even extraordinary) claims are made: * The abstract promises "a framework to understand the unprecedented performance and robustness of deep neural networks using field theory."	weakness
2018-623	* Page 8 states that this is "This is a first attempt to describe a neural network with a scalar quantum field theory."	weakness
2018-623	* Page 2 promises the use of the "Goldstone theorem" (no less) to understand phase transition in deep learning	weakness
2018-623	* It also claim that many "seemingly different experimental results can be explained by the presence of these zero eigenvalue weights."	weakness
2018-623	* Three important results are stated as "theorem", with a statement like "Deep feedforward networks learn by breaking symmetries" proven in 5 lines, with no formal mathematics.	weakness
2018-623	These are extraordinary claims, but  when reaching page 5, one sees that the basis of these claims seems to be the Lagrangian of a simple phi-4 theory, and Fig. 1 shows the standard behaviour of the so-called mexican hat in physics, the basis of the second-order transition.	weakness
2018-623	Given physicists have been working on neural network for more than three or four decades, I am surprise that this would enough to solve all these problems!	weakness
2018-623	I tried to understand these many results, but I am afraid I cannot really understand or see them.	misc
2018-623	In many case, the explanation seems to be a vague analogy.	weakness
2018-623	These are not without interest, and maybe there is indeed something deep in this paper, but it is so far hidden by the hype.	weakness
2018-623	Still, I fail to see how the fact that phase transitions and negative direction in the landscape is a new phenomena, and how it explains all the stated phenomenology.	weakness
2018-623	Beside, there are quite a lot of things known about the landscape of these problems	weakness
2018-623	Maybe I am indeed missing something, but i clearly suspect the authors are simply overselling physics results.	weakness
2018-623	I have been wrong many times, but I beleive that the authors should probably precise their claim, and clarify the relation between their results and both the physics AND statistics litterature, or better, with the theoretical physics litterature applied to learning, which is ---astonishing-- absent in the paper.	weakness
2018-623	About the content: The main problem for me is that the whole construction using field theory seems to be used to advocate for the appearence of a phase transition in neural nets and in learning.	weakness
2018-623	This rises three comments: (1) So we really need to use quantum field theory for this?	weakness
2018-623	I do not see what should be quantum here (despite the very vague remarks page 12 "WHY QUANTUM FIELD THEORY?")	weakness
2018-623	(2) This is not new.	weakness
2018-623	Phase transitions in learning in neural nets are being discussed since aboutn 40 years, see for instance all the pionnering work of Sompolinky et al. one can see for instance the nice review in https://arxiv.org/abs/1710.09553 In non aprticular order, phase transition and symmetry breaking are discussed in	weakness
2018-623	* "Statistical mechanics of learning from examples", Phys.	misc
2018-623	Rev. A 45, 6056 – Published 1 April 1992	misc
2018-623	* "The statistical mechanics of learning a rule", Rev. Mod.	misc
2018-623	Phys. 65, 499 – Published 1 April 1993	misc
2018-623	* Phase transitions in the generalization behaviour of multilayer neural networks http://iopscience.iop.org/article/10.1088/0305-4470/28/16/010/meta	misc
2018-623	* Note that some of these results are now rigourous, as shown in "Phase Transitions, Optimal Errors and Optimality of Message-Passing in Generalized Linear Models", https://arxiv.org/abs/1708.03395	misc
2018-623	* The landscape of these problems has been studied quite extensivly, see for instance "Identifying and attacking the saddle point problem in high-dimensional non-convex optimization", https://arxiv.org/abs/1406.2572	weakness
2018-623	(3) There is nothing particular about deep neural net and neural nets about this.	weakness
2018-623	Negative direction in the Hessian in learning problems appears in matrix and tensor factorizaion, where phase transition are well understood (even rigorously, see for instance, https://arxiv.org/abs/1711.05424 ) or in problems such as unsupervised learning, as e.g.: https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.86.2174 https://journals.aps.org/pre/pdf/10.1103/PhysRevE.50.1766 Here are additional comments: PAGE 1: * "It has been discovered that the training process ceases when it goes through an information bottleneck (ShwartzZiv & Tishby, 2017)".	weakness
2018-623	While this paper indeed make a nice suggestion, I would not call it a discovery yet as this has never been shown on a large network.	ac_disagreement
2018-623	Beside, another paper in the conference is claiming exacly the opposite, see : "On the Information Bottleneck Theory of Deep Learning".	weakness
2018-623	This is still subject of discussion.	misc
2018-623	* "In statistical terms, a quantum theory describes errors from the mean of random variables.	weakness
2018-623	Last time I studied quantum theory, it was a theory that aim to explain the physical behaviours at the molecular, atomic and sub-atomic levels, usinge either on the wave function (Schrodinger) or the Matrix operatir formalism (Hesienbger) (or if you want, the path integral formalism of Feynman).	weakness
2018-623	It is certainly NOT a theory that describes errors from the mean of random variables.	weakness
2018-623	This is, i beleive, the field of "statistics" or "probability" for correlated variables.	weakness
2018-623	It is certianly used in physics, and heavily both in statistical physics and in quantum thoery, but this is not what the theory is about in the first place.	weakness
2018-623	Beside, there is little quantum in this paper, I think most of what the authors say apply to a statistical field theory ( https://en.wikipedia.org/wiki/Statistical_field_theory )	weakness
2018-623	* "In the limit of a continuous sample space, the quantum theory becomes a quantum field theory."	misc
2018-623	Again, what is quantum about all this?	weakness
2018-623	This true for a field theory, as well for continous theories of, say, mechanics, fracture, etc...	weakness
2018-623	PAGE 2: * "Using a scalar field theory we show that a phase transition must exist towards the end of training based on empirical results."	weakness
2018-623	So it is a scalar classical field theory after all.	weakness
2018-623	This sounds a little bit less impressive that a quantum field theory.	weakness
2018-623	Note that the fact that phase transition arises in learning, and in a statistical theory applied to any learning process, is an old topic, with a classical litterature.	weakness
2018-623	The authors might be interested by the review "The statistical mechanics of learning a rule", Rev. Mod.	suggestion
2018-623	Phys. 65, 499 – Published 1 April 1993	misc
2018-623	PAGE 8: * "In this work we solved one of the most puzzling mysteries of deep learning by showing that deep neural networks undergo spontaneous symmetry breaking."	strength
2018-623	I am afraid I fail to see what is so mysterious about this nor what the authors showed about it.	weakness
2018-623	In any case, gradient descent break symmetry spontaneously in many systems, including phi-4, the Ising model or (in learning problems) the community detection problem (see eg https://journals.aps.org/prx/abstract/10.1103/PhysRevX.4.011047).	weakness
2018-623	I am afraid I miss what is new there...	weakness
2018-623	* "This is a first attempt to describe a neural network with a scalar quantum field theory."	weakness
2018-623	Given there seems to be little quantum in the paper, I fail to see the relevance of the statement.	weakness
2018-623	Secondly, I beleive that field theory has been used, many times and in greater lenght, both for statistical and dynamical problems in neural nets, see eg.	weakness
2018-623	* http://iopscience.iop.org/article/10.1088/0305-4470/27/6/016/meta * https://arxiv.org/pdf/q-bio/0701042.pdf * http://www.lps.ens.fr/~derrida/PAPIERS/1987/gardner-zippelius-87.pdf * http://iopscience.iop.org/article/10.1088/0305-4470/21/1/030/meta	misc
2018-623	* https://arxiv.org/pdf/cond-mat/9805073.pdf The paper makes a mathematical analogy between deep neural networks and quantum field theory, and claims that this explains a large number of empirically observed phenomena.	abstract
2018-623	I have a solid grasp of the relevant mathematics, and a superficial understanding of QFT, but I could not really make sense of this paper.	weakness
2018-623	The paper uses mathematics in a very loose manner.	weakness
2018-623	This is not always bad (an overly formal treatment can make a paper hard to read), but in this case it is not clear to me that the results are even "correct modulo technicalities" or have much to do with the reality of what goes on in deep nets.	weakness
2018-623	The first thing I'm confused about is the nature and significance of the symmetries considered in this paper.	weakness
2018-623	At a very high level, there are two kinds of symmetries one could consider in DL: transformations of the input space that leave invariant the desired output, and transformations of the weight space that leave invariant the input/output mapping.	weakness
2018-623	These are not necessarily related.	weakness
2018-623	For instance, a translation or rotation of an image is an example of the former, whereas an arbitrary permutation of hidden units (and corresponding rows/columns of weight matrices) is an example of the latter.	weakness
2018-623	This paper is apparently dealing with groups that act on the input as well as the weight space, seemingly conflating the two.	weakness
2018-623	Section 2.2 defines the action of symmetries on the input and weight space.	weakness
2018-623	For each layer t, we have a matrix Q_t in G, where G is an unspecified Lie group.	weakness
2018-623	Since all Q_t are elements of the same group, they have the same dimension, so all layers must have the same dimension as well.	weakness
2018-623	This is somewhat unrealistic. Furthermore, from the definitions in 2.2 it seems that in order to get covariance, the Q_t would have to be the same for all t, which is probably not what the authors had in mind.	weakness
2018-623	For symmetries like rotation/translation of images, a better setup would probably involve a single group with different group actions or linear group representations for each layer.	weakness
2018-623	In that case, covariance of the weight layers is not automatic, but only holds for certain subspaces of weight space.	weakness
2018-623	For permutation or scale symmetries in weight space, a more sensible setup would be to say that each layer has a different group of symmetries, and the symmetry group of the whole network is the direct product of these groups.	weakness
2018-623	It is stated that transformations in the affine group may not commute with nonlinearities, but rotations of feature maps do.	weakness
2018-623	This is correct (at least up to discretization errors), but the paper continues to talk about affine and orthogonal group symmetries.	weakness
2018-623	Later on an attempt is made to deal with this issue, by splitting the feature vectors into a part that is put to zero by a ReLU, and a part that is not, and the group is split accordingly.	weakness
2018-623	However, this does not make any sense because the pattern of zeros/non-zeros is different for each input, so one cannot speak of a "remnant symmetry" for a layer in general.	weakness
2018-623	The connection between DL and QFT described in 2.3 is based on some kind of "continuous limit" of units and layers, i.e. having an uncountably infinite number of them.	weakness
2018-623	Even setting aside the enormous amount of technical difficulty involved in doing this math properly, I'm a bit skeptical that this has anything to do with real networks.	weakness
2018-623	As an example of how loose the math is, "theorem 1" is only stated in natural language: "Deep feedforward networks learn by breaking symmetries".	weakness
2018-623	The proof involves assuming that the network is a sequence of affine transformations (no nonlinearities).	weakness
2018-623	Then it says that if we include a nonlinearity, it breaks the symmetry.	weakness
2018-623	Thus, since neural nets use nonlinearities, they break symmetries, and therefore learning works by breaking symmetries and the layers can learn a "more generalized representation" than an affine network could.	weakness
2018-623	The theorem is so vaguely stated that I don't know what it means, and the proof is inscrutable to me.	weakness
2018-623	Theorem 2 states "Let x^T x be an invariant under Aff(D)".	weakness
2018-623	Clearly x^T x is not invariant under Aff(D).	weakness
2018-623	The paper claims to explain many empirical facts, but it is not exactly clear which are the conspicuous and fundamental facts that need explaining.	weakness
2018-623	For instance, the IB phase transition claimed to happen in deep learning was recently called into question [1].	weakness
2018-623	It appears that this phenomenon does not occur in ReLU nets but only in sigmoid nets, but the current paper purports to explain the phenomenon while assuming ReLUs.	weakness
2018-623	I would further note that the paper claims to explain a suspiciously large number of previously observed phenomena (Appendix A), but as far as I can tell does not make novel testable predictions.	weakness
2018-623	The paper makes several strong claims, like "we [...] illustrate that spontaneous symmetry breaking of affine symmetries is the sufficient and necessary condition for a deep network to attain its unprecedented power", "This phenomenon has profound implications", "we have solved one of the most puzzling mysteries of deep learning", etc.	weakness
2018-623	In my opinion, unless it is completely obvious that this is indeed a breakthrough, one should refrain from making such statements.	weakness
2018-623	[1] On the information bottleneck theory of deep learning.	misc
2018-623	Anonymous *CONF*2018 submission.	misc

2018-730	This paper deals with early stopping but the contributions are limited.	weakness
2018-730	This work would fit better a workshop as a preliminary result, furthermore it is too short.	decision
2018-730	Following a short review section per section.	misc
2018-730	Intro: The name SFC is misleading as the method consists in stopping early the training with an optimized learning schedule scheme.	weakness
2018-730	Furthermore, the work is not compared to the appropriate baselines.	weakness
2018-730	Proposal: The first motivation is not clear.	weakness
2018-730	The training time of the feature extractor has never been a problem for transfer learning tasks for example: once it is trained, you can reuse the architecture in a wide range of tasks.	weakness
2018-730	Besides, the training time of a CNN on CIFAR10 or even ImageNet is now quite small(for reasonable architectures), which allows fast benchmarking.	weakness
2018-730	The second motivation, w.r.t. IB seems interesting but this should be empirically motivated(e.g. figures) in the subsection 2.1, and this is not done.	weakness
2018-730	The section 3 is quite long and could be compressed to improve the relevance of this experimental section.	weakness
2018-730	All the accuracies(unsup dict, unsup, etc) on CIFAR10/CIFAR100 are reported from the paper (Oyallon & Mallat, 2015), ignoring 2-3 years of research that leads to new numerical results.	weakness
2018-730	Furthermore, this supervised technique is only compared to unsupervised or predefined methods, which is is not fair and the training time of the Scattering Transform is not reported, for example.	weakness
2018-730	Finally, extracting features is mainly useful on ImageNet (for realistic images) and this is not reported here.	weakness
2018-730	I believe re-thinking new learning rate schedules is interesting, however I recommend the rejection of this paper.	decision
2018-730	This paper proposes a fast way to learn convolutional features that later can be used with any classifier.	abstract
2018-730	The acceleration of the training comes from a reduced number of training epocs and a specific schedule decay of the learning rate.	abstract
2018-730	In the evaluation the features are used with support vector machines (SVN) and extreme learning machines on MNIST and CIFAR10/100 datasets.	abstract
2018-730	Pros: The paper compares different classifiers on three datasets.	strength
2018-730	Cons: - Considering an adaptive schedule of the learning decay is common practice in modern machine learning.	weakness
2018-730	Showing that by varying the learning rate the authors can reduce the number of training epocs and still obtain good performance is not a contribution and it is actually implemented in most of the recent deep learning libraries, like Keras or Pytorch.	weakness
2018-730	- It is not clear why, once a CNN has been trained, one should want to change the last layer and use a SVN or other classifiers.	weakness
2018-730	- There are many spelling errors	weakness
2018-730	- Comparing CNN based methods with hand-crafted features as in Fig. 1 and Tab.3 is not interesting anymore.	weakness
2018-730	It is well known that CNN features are much better if enough data is available.	weakness
2018-730	I am not sure how to interpret this paper.	weakness
2018-730	The paper seems to be very thin technically, unless I missed some important details.	weakness
2018-730	Two proposals in the paper are: (1) Using a learning rate decay scheme that is fixed relative to the number of epochs used in training, and	weakness
2018-730	(2) Extract the penultimate layer output as features to train a conventional classifier such as SVM.	weakness
2018-730	I don't understand why (1) differs from other approaches, in the sense that one cannot simply reduce the number of epochs without hurting performance.	weakness
2018-730	And for (2), it is a relatively standard approach in utilizing CNN features.	weakness
2018-730	Essentially, if I understand correctly, this paper is proposing to prematurely stop training an use the intermediate feature to train a conventional classifier (which is not that away from the softmax classifier that CNNs usually use).	weakness
2018-730	I fail to see how this would lead to superior performance compared to conventional CNNs.	weakness

2018-731	This writeup describes an application of recurrent autoencoder to analysis of multidimensional time series.	abstract
2018-731	The quality of writing, experimentation and scholarship is clearly below than what is expected from a scientific article.	weakness
2018-731	The method is explained in a very unclear way, there is no mention of any related work.	weakness
2018-731	I would encourage the authors to take a look at other *CONF* submissions and see how rigorously written they are, how they position the reported research among comparable works.	suggestion
2018-731	The paper describes a sequence to sequence auto-encoder model which is used to learn sequence representations.	abstract
2018-731	The authors show that for their application, better performance is obtained when the network is only trained to reconstruct a subset of the data measurements.	abstract
2018-731	The paper also presents some visualizations the similarity structure of the learned representations and proposes a window-based method for processing the data.	abstract
2018-731	According to the paper, the experiments are done using a data set which is obtained from measurements of an industrial production process.	abstract
2018-731	Figure 2 indicates that reconstructing fewer dimensions of this dataset leads to lower MSE scores.	abstract
2018-731	I don't see how this is showing anything besides the obvious fact that reconstructing fewer dimensions is an easier task than reconstructing all of them.	weakness
2018-731	The only conclusions I can draw from the visual analysis is that the context vectors are more similar to each other when they are obtained from time steps in the data stream which are close to each other.	weakness
2018-731	Since the paper doesn't describe much about the privately owned data at all, there is no possibility to replicate the work.	weakness
2018-731	The paper doesn't frame the work in prior research at all and the six papers it cites are only referred to in the context of describing the architecture.	weakness
2018-731	I found it very hard to distil what the main contribution of this work was according to the paper.	weakness
2018-731	There were also not many details about the precise architecture used.	weakness
2018-731	It is implied that GRU networks and were used but the text doesn't actually state this explicitly.	weakness
2018-731	By saying so little about the data that was used, it was also not clear what the temporal correlations of the context vectors are supposed to tell us.	weakness
2018-731	The paper describes how existing methods are applied to a specific data set.	weakness
2018-731	The benefit of only reconstructing a subset of the input dimensions seems very data specific to me and I find it hard to consider this a novel idea by itself.	weakness
2018-731	Presenting sequential data in a windowed format is a standard procedure and not a new idea either.	weakness
2018-731	All in all I don't think that the paper presents any new ideas or interesting results.	weakness
2018-731	Pros: * The visualizations look nice.	strength
2018-731	Cons: * It is not clear what the main contribution is.	weakness
2018-731	* Very little information about the data.	weakness
2018-731	* No clear experiments from which conclusions can be drawn.	weakness
2018-731	* No new ideas. * Not well rooted in prior work.	weakness
2018-731	This paper proposes a strategy that is inspired by the recurrent auto-encoder model, such that clustering of multidimensional time series data can be performed based on the context vectors generated by the encoding process.	abstract
2018-731	Unfortunately, the paper in its current form is a bit thin on content.	weakness
2018-731	Main issues: No related works (such as those using RNN for time series analysis or clustering of time series data streams etc.) were described by the paper, no baselines were used in the comparison evaluations, and no settings/details were provided in the experiment section.	weakness
2018-731	As a result, it is quite difficult to judge the merits and novelty of the paper.	weakness
2018-731	Other issues: some contribution claims highlighted in the Discussion Section, i.e., Section 4, are arguable and should be further extended.	weakness
2018-731	For example, the authors claim that the proposed LSTM-based autoencoder networks can be natively scaled up to data with very high dimensionality.	weakness
2018-731	I would like the authors to explain it in more details or empirically demonstrate that, since a LSTM-based model could be computationally expensive.	suggestion
2018-731	As another example, the authors claim that reducing the dimensionality of the output sequence is one of the main contributions of the paper.	suggestion
2018-731	In this sense, further elaborations from that perspective would be very beneficial since some networks already employ such a mechanism.	suggestion
2018-731	In short, the paper in its current form does not provide sufficient details for the reviewer to judge its merits and contributions.	weakness

2019-798	This submission proposes a method for learning to follow instructions by splitting the policy into two stages: human instructions to robot-interpretable goals and goals to actions.	abstract
2019-798	The authors claim to achieve better data efficiency, adaptability, and generalization as compared to the baselines.	abstract
2019-798	Here are some comments/questions: - One of the biggest limitations of the proposed method is that it can only work for one-to-one or many-to-one mapping of instructions to goals.	weakness
2019-798	As I understand (please correct me if I am wrong), the method can not work for contextual instructions where the goal depends on the environment and the same instruction can map to different goals, such as 'Go to the largest/farthest object'.	weakness
2019-798	- Another limitation of the method is that it requires a set of goals G, which is not trivial to obtain especially in partially observable environments such as embodied navigation in 3D space.	weakness
2019-798	- The experimental setup is unclear and several crucial details are missing: - "An instruction for approaching one of the five targets in the arena is generated and passed to the agent at first." -> how is the instruction generated?	weakness
2019-798	- There's no example of the environment or the instruction in the submission	weakness
2019-798	- "Within the instruction become approaching more than one targets, one of two added targets is selected as internal targets pair with one of the remaining targets." I do not understand this sentence.	weakness
2019-798	How are the targets generated in the trajectory-oriented task?	weakness
2019-798	How are the instructions generated in this task?	weakness
2019-798	- Experimental results are not convincing: - The introduction motivates the need for understanding human instructions and the abstract says 'Given a human instruction', but I believe experiments do not have any human instructions.	weakness
2019-798	- All the environments seem to be fully-observable, it is not clear whether the method would work in partially-observable environments.	weakness
2019-798	- Only vanilla PPO and BC cloning are used as baselines.	weakness
2019-798	There are several competing methods for following instructions which the authors cite such as Hermann et al. 2017, Chaplot et al. 2017, Misra et al. 2017, etc.	weakness
2019-798	Why weren't any of these approaches used as a baseline?	weakness
2019-798	- The submission requires proof-reading, there are several typos in the manuscript (some are listed below), some of them make it very difficult to understand the setting.	weakness
2019-798	- Typos: - Sec 3.1 on Pg 4 mentions 'CEM' multiple times, it's not defined until 3.3.2 on Pg 6.	weakness
2019-798	- Pg 3 Theses sets -> These sets	weakness
2019-798	- Pg 7 where the Reacher pointing at -> where the Reacher is pointing at	weakness
2019-798	- Pg 7 What reacher observes the word is its fingertip's position, coordinates in two dimension.	weakness
2019-798	-> something is wrong in this sentence.	weakness
2019-798	- Pg 7 Then comes to the trajectory-oriented task, there are only a few differences from above -> something is wrong in this sentence.	weakness
2019-798	- Pg 7 Within the instruction become approaching more than one targets -> something is wrong here This paper presents an instruction-following model consisting of two modules: a goal-prediction model that maps commands to goal representations, and an execution model that maps goal representations to policies.	weakness
2019-798	The second module is trained without command supervision via a goal exploration process, while the first module is trained supervisedly in a metric learning framework.	weakness
2019-798	This paper contains an important core insight---much of what's hard about instruction following is generic planning behavior that doesn't depend on the semantics of instructions, and pre-learning this behavior makes it possible to use natural language supervision more effectively.	strength
2019-798	However, the paper also contains a number of serious evaluation and presentation issues.	weakness
2019-798	It is obviously not ready to publish (uncaptioned figures, paragraphs interrupted mid-sentence,	decision
2019-798	etc.) and should not have been submitted to *CONF* in its present form.	decision
2019-798	SUPERVISION AND COMPARISONS I found comparisons between supervision conditions in this paper difficult to understand.	weakness
2019-798	It is claimed that the natural language instruction following approaches described in the first paragraph "require a large amount of human supervision" in the form of action sequences.	weakness
2019-798	This is not exactly true, as some approaches (e.g. Artzi 2013), can be trained with only task completion signals.	weakness
2019-798	More problematically, all these approaches are contrasted with reinforcement and imitation learning approaches, which are claimed to use "little human supervision".	weakness
2019-798	In fact, most of the approaches listed in this section use exactly the same supervision---either action sequences (imitation learning) or task completion signals (reinforcement learning).	weakness
2019-798	Indeed, the primary distinction is that the "NLP-style" approaches are typically evaluated on their ability to generalize to new instructions, while the "RL-style" approaches are evaluated on the (easier) problem of fitting the complete instruction distribution as quickly as possible.	weakness
2019-798	This confusion carries into the evaluation of the approach proposed in this paper, which is compared to RL and IL baselines.	weakness
2019-798	It's hard to tell from the text, but it appears that this is an "RL-style" evaluation setting, where we only care about rapid convergence rather than generalization.	weakness
2019-798	But the baselines are inadequately described, and it's not clear to me that they condition on the commands at all.	weakness
2019-798	More significantly, it's not clear what an evaluation based on	weakness
2019-798	"timesteps" means for a behavior-cloning approach---is this the number of distinct trajectories observed?	weakness
2019-798	The number of gradient steps taken?	weakness
2019-798	Without these explanations it is impossible to interpret the experimental results.	weakness
2019-798	GENERALITY OF PROPOSED APPROACH Despite the advantages of the high-level two-phase model proposed, the specific implementation in this paper has two significant shortcomings: - No evidence that it works with real language: despite numerous claims throughout the paper that the model is designed to interpret "human instructions", it is revealed on p7 that these instructions consist of one or two	weakness
2019-798	5-way indicator features. This is an extremely impoverished instruction space,	weakness
2019-798	especially compared to the numerous papers cited in the introduction that make use of large datasets of complex natural-language strings generated by human annotators.	weakness
2019-798	The present experiments do not support the use of the word "human"	weakness
2019-798	anywhere in the paper. - No support for combinatorial action spaces.	weakness
2019-798	Even if we set aside the distinctions between human-generated instructions and synthetic command languages like used in Hermann Hill & al., the goal -> policy module is defined by a buffer of cached trajectories and goal representations.	weakness
2019-798	While this works for the simple environments considered in this paper, it cannot generalize to real-world instruction-following scenarios where the number of distinct goal configurations is too large to tractably enumerate.	weakness
2019-798	Again, this is a shortcoming that existing approaches do not suffer from (given appropriate assumptions about the structure of goal space), so the lack of comparisons is problematic.	weakness
2019-798	CLARITY The whole paper would benefit from copy-editing by an experienced English speaker, but a few sections are particularly problematic: - The first paragraph of 4.1.1 is extremely difficult to understand What does the fingertip do?	weakness
2019-798	What exactly is the action space?	weakness
2019-798	- The end of the second paragraph is also difficult to understand; after reading it I still don't know what the extra "position" targets do.	weakness
2019-798	- 4.1.4 is cut off mid-way through a sentence.	weakness
2019-798	- last sentence of 4.2	weakness
2019-798	The figures are also impossible to interpret: three of the four are captioned	weakness
2019-798	"overview of the proposed framework", and none are titled.	weakness
2019-798	The paper proposes a modular approach to the problem of mapping instructions to robot actions.	abstract
2019-798	The first of two modules is responsible for learning a goal embedding of a given instruction using a learned distance function.	abstract
2019-798	The second module is responsible for mapping goals from this embedding space to control policies.	weakness
2019-798	Such a modular approach has the advantage that the instruction-to-goal and goal-to-policy mappings can be trained separately and, in principle, allow for swapping in different modules.	strength
2019-798	The paper evaluates the method in various simulated domains and compares against RL and IL baselines.	abstract
2019-798	STRENGTHS + Decoupling instruction-to-action mapping by introducing goals as a learned intermediate representation has advantages, particularly for goal-directed instructions.	strength
2019-798	Notably, these together with the ability to train the components separately will generally increase the efficiency of learning.	strength
2019-798	WEAKNESSES - The algorithmic contribution is relatively minor, while the technical merits of the approach are questionable.	weakness
2019-798	- The goal-policy mapping approach would presumably restrict the robot to goals experienced during training, preventing generalization to new goals.	weakness
2019-798	This is in contrast to semantic parsing and symbol grounding models, which exploit the compositionality of language to generalize to new instructions.	weakness
2019-798	- The trajectory encoder operates differently for goal-oriented vs.	weakness
2019-798	trajectory-oriented instructions, however it is not clear how a given instruction is identified as being goal- vs.	weakness
2019-798	trajectory-oriented. - While there are advantages to training the modules separately, there is a risk that they are reasoning over different portions of the goal space.	weakness
2019-798	- A contrastive loss would seemingly be more appropriate for learning the instruction-goal distance function.	weakness
2019-798	- The goal search process relies on a number of user-defined parameters	weakness
2019-798	- The nature of the instructions used for experimental evaluations is unclear.	weakness
2019-798	Are they free-form instructions? How many are there?	weakness
2019-798	Where do they come from?	weakness
2019-798	How different are the familiar and unfamiliar instructions?	weakness
2019-798	- Similarly, what is the nature of the different action spaces?	weakness
2019-798	- The domains considered for experimental evaluation are particularly simple.	weakness
2019-798	It would be better to evaluate on one of the few common benchmarks for robot language understanding, e.g., the SAIL corpus, which considers trajectory-oriented instructions.	suggestion
2019-798	- The paper provides insufficient details regarding the RL and IL baselines, making it impossible to judge their merits.	weakness
2019-798	- The paper initially states that this distance function is computed from learned embeddings of human demonstrations, however these are presumably instructions rather than demonstrations.	weakness
2019-798	- I wouldn't consider the results reported in Section 4.5 to be ablative studies.	weakness
2019-798	- The paper incorrectly references Mei et al. 2016 when stating that methods require a large amount of human supervision (data annotation) and/or linguistic knowledge.	weakness
2019-798	In fact Mei et al. 2016 requires no human annotation or linguistic knowledge.	weakness
2019-798	- Relevant to the discussion of learning from demonstration for language understanding is the following paper by Duvallet et al. Duvalet, Kollar, and Stentz, "Imitation learning for natural language direction following through unknown environments," ICRA 2014	misc
2019-798	- The paper is overly verbose and redundant in places.	weakness
2019-798	- There are several grammatical errors	weakness
2019-798	- The captions for Figures 3 and 4 are copied from Figure 1.	weakness

2020-791	The paper "Beyond Classical Diffusion: Ballistic Graph Neural Network" tackles the problem of graph vertices representation.	abstract
2020-791	While most existing works rely on classical random walks on the graph, the paper proposes to cope with the "speed of diffusion" problem by introducing ballistic walk.	abstract
2020-791	I noticed the comment of the authors that gives a correction for the introduction.	rebuttal_process
2020-791	But even with it the paper remains very cryptic, with very few pointers to help the reader in understanding the contribution.	weakness
2020-791	The introduction (even corrected) is very abrupt and it is very difficult to understand the problem that the authors propose to attack.	weakness
2020-791	The problem is that authors start with mathematical discussions before presenting the manipulated concepts and formalizing the adressed problem.	weakness
2020-791	I only understood the adressed problem after seing which are the baselines the proposal is compared with in section 4.2.	weakness
2020-791	Also, the introduction does not introduce the proposal at all.	weakness
2020-791	A symptomatic example of the lack of paper positioning is the Related Works section which does not even give a single reference !	weakness
2020-791	A related work section with no related works in it appears to have a limited interest to me...	weakness
2020-791	This section should at least introduce other works in the field of graph embedding, such as those reported as baselines.	suggestion
2020-791	It would also greatly help to understand the contribution of the paper.	suggestion
2020-791	Also, the ballistic concept is not introduced at all in section 4.	weakness
2020-791	Where does this term comes from ?	weakness
2020-791	The proposed approach is completely cryptic, with clearly not enough definition of the notations the algorithm deals with.	weakness
2020-791	A global view of the approach, from the input graph to the final representation, would also be required to help the reader to understand the proposal.	weakness
2020-791	If the contribution is only a new kind of random walk on a graph, is *CONF* the good targeted venue ?	weakness
2020-791	If authors think so, they should present their contribution in a representation learning perspective, which would highlight the importance of this new walk for the graph representation learning process.	suggestion
2020-791	From my point of view, without a full re-writting of the paper, this work cannot be published in a conference like *CONF*.	decision
2020-791	This paper was extremely hard to read or comprehend.	weakness
2020-791	It's riddled with typos, inaccurate notations and undefined variables (see below for a sampling).	weakness
2020-791	The authors will need to significantly polish and improve the presentation of the paper.	weakness
2020-791	After a few forward and backward passes through the paper, I was able to gather the following high level ideas about the paper: (1) This paper is somewhat related to the Defferard et.	weakness
2020-791	al, 2016 in that the authors want to define a propagation filter for graph neural networks.	weakness
2020-791	2) This proposed filter known as "ballistic filter" should have the property of allowing fast diffusion through the network.	weakness
2020-791	(3) The authors claim that the ballistic kernel diffuses @ O(k) as compared to O(\\sqrt k) when compared to traditional GCNs, where k is the number of propagation steps.	weakness
2020-791	(4) The authors additionally claim that their approach needs one-third the number of parameters.	weakness
2020-791	(5) The authors provide some plots to visualize the linear diffusion rate of their proposed filter.	weakness
2020-791	--- Issues and clarifications ---	misc
2020-791	- Sec 3, Eq 1 seems to have been taken from Eq 1 in Defferard et.	weakness
2020-791	al, however there's no reference to it and the terms g, U, etc.	weakness
2020-791	are not defined. - Sec 4, Algo 1 contains the main core of the proposed algorithm, but it's only defined for the 2D grid case.	weakness
2020-791	The notation therein is extremely unclear.	weakness
2020-791	What is H_space, H_c? How does one sample \\hat{O}_coin.?	weakness
2020-791	The net result is that algorithm is undefined.	weakness
2020-791	Without a clear definition of the algorithm, it's completely unclear what the proposed method does.	weakness
2020-791	- Sec 4.2 is completely unparseable.	weakness
2020-791	What is problem setting? What is the metric?	weakness
2020-791	How have the baselines been implemented?	weakness
2020-791	How has data been split for training/testing?	weakness
2020-791	- Section 5 mentions that one-third params are used to get 97% but no details are provided as to how less params are consumed.	weakness
2020-791	- How is figure 7 generated?	weakness
2020-791	- Sec 8, feel totally unrelated to the paper.	weakness
2020-791	There are a whole bunch of random, unmotivated diffusion equations  Eq 6, mentions "..	weakness
2020-791	\\hat{g}(f) decreases as f increases and thus can be seen as a low pass filter…" .	weakness
2020-791	This is not true from the formula.	weakness
2020-791	--- A sampling of typos ---	weakness
2020-791	Sec 4.1, .. consisits … Sec 5 "REVISIT" -> "REVISITING"	weakness
2020-791	Figure 6, text, "cassical" Sec 6.2 title, "SUMMAY" Sec 8  "aggreated"	weakness
2020-791	Sec 8  t=\\-tau to -\\tau	weakness
2020-791	Several typos with Hardmard, Hadmard instead of Hadamard.	weakness
2020-791	Overall, the major criticisms of this paper: - The proposed algorithm is not clear.	weakness
2020-791	- The authors need much more experimentation to bolster their claims in the paper.	weakness
2020-791	It's completely unclear if fast diffusion even if it were possible will help GNNs perform better on a diverse set of tasks.	weakness
2020-791	- The paper needs a lot more polish and proof reading to make this paper presentable.	weakness
2020-791	This paper proposed a new diffusion operation for the graph neural network.	abstract
2020-791	Specifically, the ballistic graph neural network does not require to calculate any eigenvalue and can propagate exponentially faster comparing to traditional graph neural network.	abstract
2020-791	Extensive experiments have been conducted to verify the performance of the proposed method.	abstract
2020-791	1. The motivation of this method is to accelerate the diffusion speed in a graph.	weakness
2020-791	However, as we know, a very severe issue of graph neural network is the over-smoothness issue.	weakness
2020-791	The reason is that, in the high layer, the node feature is diffused to far neighbours.	weakness
2020-791	When using the proposed ballistic filter, node features diffuse much faster than the regular GNN.	weakness
2020-791	Thus, the over-smoothness will appear in the shallow layer very fast.	weakness
2020-791	As a result, we cannot use many layers so that the non-linearity of deep neural networks cannot be fully utilized.	weakness
2020-791	Thus, is it necessary to accelerate the diffusion speed for graph neural network?	weakness
2020-791	2. There is only one dataset for  the comparison of the performance of different graph neural networks.	weakness
2020-791	More datasets are needed to thoroughly verify the performance of the proposed ballistic graph neural network.	weakness
2020-791	3. Is it possible to slow down the diffusion speed with the proposed ballistic filter?	weakness

2020-794	The paper is concerned with the presence of isomorphism bias in commonly used graph learning benchmarks.	abstract
2020-794	In particular, the paper analyzes the amount of isomorphic graphs in 54 graph datasets and evaluates the performance of three graph classification methods under two isomorphism settings.	abstract
2020-794	Careful analyses of commonly used benchmarks can be important contributions that provide new insights into the performance of state-of-the-art models.	strength
2020-794	The present paper's results on graph isomorphism properties can indeed be valuable for the ablation of models and testing their performance with regard to this property.	strength
2020-794	I also found the relatively high label disagreements on some datasets (even under stronger isomorphism constraints) to be a surprising and useful result.	strength
2020-794	However, the main assumption of the paper -- which equates the quality of a graph learning benchmark with the amount of isomorphic graphs that it contains, i.e., the lower the better -- seems questionable.	weakness
2020-794	The paper argues that isomorphic graphs are akin to duplicate images in computer vision and should be removed from a dataset.	abstract
2020-794	While completely identical graphs are certainly problematic, the case seems different for isomorphic graphs.	abstract
2020-794	In the latter, a learning method is required to identify the correct bijection form V_1 to V_2 which is a non-trivial task.	abstract
2020-794	Testing on isomorphic graphs evaluates the ability of a model to infer these equivalence classes from data which is an important property.	weakness
2020-794	Moreover, being able to capture the equivalence relation can be important for various graph learning tasks, e.g., to facilitate that two topologically equivalent graphs are be classified similarly.	weakness
2020-794	Going back to the computer vision analogy: it seems a more adequate comparison for graph isomorphism would be translation and scale invariance which are certainly desirable properties for CV models.	weakness
2020-794	In addition, the dataset analysis could also be improved.	weakness
2020-794	For instance, the SYNTHETIC dataset includes continuous node attributes that are essential for classification and make the graphs non-isomorphic (when considering, for instance, each attribute vector as a unique node label).	weakness
2020-794	However, the attributes are not considered in the analysis what leads to a large number of isomorphic graphs.	weakness
2020-794	On a side note: the paper also incorrectly attributes the SYNTHETIC dataset to (Morris et al, 2016), but it is in fact from [1].	weakness
2020-794	The synthetic dataset of Morris et al (SYNTHIE) does not consist of isomorphic graphs, while the SYNTHETIC dataset of [1] does so intentionally.	weakness
2020-794	The results of Section 5 seem also not very surprising: After removing node labels, it is expected that the number of isomorphic graphs increases since a discriminating feature has been removed.	weakness
2020-794	Moreover, when accounting for node labels, many standard benchmarks seem to consist of significantly less isomorphic and mismatched graphs (as can be seen in the appendix).	weakness
2020-794	Since graph isomorphism != graph identity, the assumption Y_iso \\sub Y_train in Property 6 seems also not appropriate.	weakness
2020-794	The results of Theorem 6.1 on the other hand seems straightforward and would hold for any classification task for which the true label for an equivalence class of instances is known.	weakness
2020-794	The authors discuss here the problem of isomorphism bias in graph dataset, i.e. the overfitting effect in learning networks whenever graph isomorphism features are incorporated within the model.	abstract
2020-794	This is a bias which jeopardises the validity and the reproducibility of several studies, and it is theoretically analogous to data leakage effects.	weakness
2020-794	The authors fairly discuss the problem in the introduction, with a good coverage of the related literature; the background theory is reasonably discussed, although is not very deep.	rebuttal_process
2020-794	The experimental part is extensive and well described, and it shows the overfitting effect very clearly.	strength
2020-794	However, the novelty of the work is limited, and also the proposed solutions cannot be claimed as superior to other approaches, due to the small improvement in accuracy.	weakness
2020-794	This work probes graph classification datasets for isomorphism bias.	abstract
2020-794	They find substantial amount of bias in some datasets and show that they suffer from data leakage.	abstract
2020-794	They further perform a more fine-grained evaluation taking into consideration the node/edge types which reduce the perceived effects.	abstract
2020-794	They also provide some recommendations for measuring the 'right metrics' and release clean versions of the considered datasets.	abstract
2020-794	Strengths: - The methodology is rigorous and the datasets considered is extensive	strength
2020-794	- The paper is well written	strength
2020-794	Concerns: - Isomorphism is not necessarily a bad thing in graph classification tasks.	weakness
2020-794	Especially in chemistry where a bond decides if a compound is poisonous or not.	weakness
2020-794	Also, as the authors themselves mention, taking node/edge labels decrease the isomorphism in most datasets.	weakness
2020-794	- The results and recommendations presented in the paper are intuitive and somewhat trivial	weakness
2020-794	- I am not sure if *CONF* is the right venue for this work The paper presents three contributions: (a) the observation that there's train-to-test leakage in many graph classification datasets (under isomorphism equivalence), (b) what appears to be a theoretically motivated way of improving scores on such datasets, by focusing on solving the examples that are isomorphic with training instances, and (c) a recommendation to remove such leakage from test sets.	decision
2020-794	I don't think the paper meets the *CONF* bar.	decision
2020-794	While (a) is very interesting, and an important contribution, (b) and (c) are contradictory.	weakness
2020-794	The recommendation (c) is a bit of a no-brainer, and Property 6.1 and Theorem 6.1, providing the substance of (b), are near-trivial.	decision
2020-794	Missing reference: Bordes et al. (2013) and Toutanova et al. (2015) show there's train-to-test leakage (under isomorphism equivalence) in the FB15K dataset.	weakness

2020-802	PAPER SUMMARY: This paper proposes a fast inference method for Gaussian processes (GPs) that imposes a sparse decomposition on the VI approximation of the posterior GP (for computational efficiency) using the KNN set of each data point.	abstract
2020-802	This is further coupled with armortized inference for better scalability.	abstract
2020-802	NOVELTY & SIGNIFICANCE: This paper adopts a different approach of characterizing the VI approximation of a GP posterior than original VI approximation that was developed in Titsias (2009): Instead of characterizing the surrogate q(f_I) of p(f_I | Y) for a small collection of inducing inputs, the proposed method characterize q(f) directly where q(f) = int_f_I q(f_I) p(f | f_I)df_I.	abstract
2020-802	This is, however, a somewhat strange direction which, to me, seems to raise extra issues that could have been avoided if one follows the conventional VI approximation: (1) As the posterior surrogate is now directly over f instead of f_I, the number of variational parameters is now proportional to the data size which requires several (redundant) extra approximations including armortized inference & the lower-bound on the entropy term that admits a sparse decomposition.	weakness
2020-802	(2) This at least creates the armortized and entropy gaps that decrease the expressiveness of the original VI.	weakness
2020-802	While I understand that this is in exchange for the ability to encode local information (via KNN) within the surrogate posterior, it is not clear to me why do we need to incur all these computational issues to incorporate such local information.	weakness
2020-802	(3) For example, instead of forcing such local information in the posterior surrogate q(f), we could alternatively let it be reflected in the test conditional p(f_* | f_I, Y_n(*)) such that the test output depends on both the inducing output and a local partition of data (e.g., via K-mean), which has been previously explored in [*] and later incorporated in the conventional VI paradigm of Titsias (2009) without incurring extra intractability [**].	weakness
2020-802	(4) This maintains the dense correlation between data points within the same neighborhood while allowing the VI surrogate to be more concisely specified and independent of the no.	weakness
2020-802	of training data points. Furthermore, it also helps avoid the data-bound overhead of computing a KNN per test point.	weakness
2020-802	[*] Local and global sparse Gaussian process approximations (AISTAT-07)	misc
2020-802	[**] A distributed variational inference framework for unifying parallel sparse gaussian process regression models (ICML-16)	misc
2020-802	To summarize, the practical significance of placing such a VI approximation directly on q(f) to encode such (indirectional) local information is, given the above, questionable to me.	weakness
2020-802	Please note that I am not disputing the potential use of this VI form here, which could have been the only way to encode a different (directional) type of information.	weakness
2020-802	For encoding KNN information, however, it only seems to create more troubles than it solves.	weakness
2020-802	Minor point: The above references, especially [*], should have been cited.	weakness
2020-802	TECHNICAL SOUNDNESS: [A] Optimization of the ELBO: (1) The ordering of data (i.e., the directional information) was mentioned repeatedly in the paper but its importance to the fast approximation was neither explained nor discussed.	weakness
2020-802	(2) The decomposition form of Eq.	weakness
2020-802	(6) also raises a question: How do we know that the term inside the log is positive?	weakness
2020-802	There seems to be missing information on the constraint of R.	weakness
2020-802	[B] Amortized Inference: (1) The choice of the GCN seems arbitrary here.	weakness
2020-802	I am in fact not sure why GCN is necessary for the inference network & furthermore, GCN also brings to the table another heuristic choice of A.	weakness
2020-802	(2) How do we set the adjacency graph A?	weakness
2020-802	(3) How do we know what is the right complexity for the GCN?	weakness
2020-802	[C] Complexity: The complexity analysis is too informal and lacking fine-grained information.	weakness
2020-802	Please include a detailed complexity analysis of the training and inference cost in terms of the input dimension, the no.	suggestion
2020-802	of data points, the size of the neighborhood and the batch size.	suggestion
2020-802	It is also necessary to factor in the KNN overhead (e.g., the cost of building the K-D tree for low-dimensional embedding of data & the approximation cost of projecting that information to high-dimensional data)	weakness
2020-802	EXPERIMENT: The experiment results only show marginal improvement over the baselines, and the size of the dataset for regression is too small.	weakness
2020-802	If I read correctly, both have fewer than 20000 data points.	weakness
2020-802	SVGP in particular has been tested on a much larger datasets (AIRLINE, UK Housing) comprising millions of data points -- comparison on such dataset should have been reported.	weakness
2020-802	Note that the largest dataset used to evaluate the efficiency of fast approximation of GP is on the scale of 6M data points [****].	weakness
2020-802	On that note, eBird and precipitation should not even be considered mid-sized.	weakness
2020-802	To demonstrate the efficiency of local information encoding, comparison with [*] should be reported.	weakness
2020-802	There is another class of inducing-point methods that use expectation propagation that should have been discussed and/or compared with: [***] A Unifying Framework for Gaussian Process Pseudo-Point Approximations using Power Expectation Propagation (JMLR-18)	weakness
2020-802	[****] Distributed Gaussian Processes (ICML-15)	misc
2020-802	CLARITY: The paper is clearly written.	strength
2020-802	REVIEW SUMMARY: This paper adopts a VI approximation that deviates from the conventional form of (Titsias, 2009) to encode the KNN information, which causes extra computational issues (that incurs extra approximations).	abstract
2020-802	I find this deviation redundant seeing that the same information could have also been accounted for using the old VI form, which is a lot more computational efficient.	abstract
2020-802	I also find the experiment lacking as comparison with fast approximation method such as [*] that incorporate local information is not included.	weakness
2020-802	There are also a few technical ambiguities that need to be clarified.	weakness
2020-802	------ Post-Rebuttal Update ------ Thank you for the rebuttal & I have read it in detail.	rebuttal_process
2020-802	However, it still does not address my concern, which I re-summarize here: I do not dispute the beneficial of exploiting neighborhood information but my point is we could still leverage the same amount of neighborhood information without going through the trouble of incurring extra steps of approximation due to approximating q(f) instead of q(f_I)	ac_disagreement
2020-802	-- I think I have elaborated this in points	suggestion
2020-802	(1) - (4) in my original review	rebuttal_process
2020-802	-- which also creates the amortized gap.	weakness
2020-802	I am also not sure what model reuse means (in this context) and whether it is relevant since it appears somewhat noncentric to the objective of this paper.	weakness
2020-802	Also, apparently, the experiment is still lacking since to me, comparing with [*] is important in substantiating the contribution claim of this paper.	weakness
2020-802	1) Summary The manuscript proposes a k-nearest-neighbor (KNN) Gaussian process (GP) approximate inference scheme to render computations more scalable.	abstract
2020-802	2) Quality Although the application is clear and the methodology is well established, the quality of the submission can be improved by a more thourough empirical evaluation in particular a proper evaluation in terms of runtime, approximation accuracy and comparison to baseline methods.	weakness
2020-802	3) Clarity The manuscript is reasonably well written and most of the technical and experimental content is accessible.	weakness
2020-802	There are some typos and some glitches in the notation.	weakness
2020-802	See "Details". There are some open issues regarding the KNN computations.	weakness
2020-802	See Questions. 4) Originality The use of a localized (in the KNN sense) set of inducing inputs to improve GP inference but the impact needs to be better quantified empirically.	weakness
2020-802	5) Significance The proposed method is aiming at improving the established setting of GP inference.	weakness
2020-802	The modification is rather marginal and the empirical evaluation makes it hard to judge the relative merit of the proposal.	weakness
2020-802	6) Reproducibility The data is from published sources (toy, ebirds, precipitation, digits) and the code for the baseline methods and for the LAIM method itself is available.	weakness
2020-802	However, there is no code for the experiments, which makes the results slightly tricky to exactly reproduce.	weakness
2020-802	7) Evaluation The evaluation does not consider simple baselines like dense GPs or sparse approximations such as FITC and VFE.	weakness
2020-802	Also plain NN should be considered.	weakness
2020-802	8) Questions A) How do you set the parameter delta?	weakness
2020-802	B) How are the nearest-neighbors computed in the first place?	weakness
2020-802	Does it require computing the dense covariance matrix?	weakness
2020-802	C) How accurate is the NN computation?	weakness
2020-802	How much of the computational effort (percentage) of the overall pipeline is required for the NN computation?	weakness
2020-802	D) How much better is the proposed approach than directly using NN predictions?	weakness
2020-802	E) Does "most correlated" in the footnote on page 2 really mean correlation or is it about covariance?	weakness
2020-802	The latter would involve a diagonal rescaling of the covariance matrix.	weakness
2020-802	9) Details a) Abstract: "Gaussian Processes" -> "Gaussian processes"	misc
2020-802	b) Intro: "GP poses a Gaussian prior" -> funny sentence, "with some special "	weakness
2020-802	c) Intro: "with some special structures" -> fix d) Background: "q(f)~N(mu,V)" -> imprecise notation, rather "q(f)=N(mu,V)"	weakness
2020-802	e) Background, footnote: "distance metrics" -> Are you talking about "distance" or "metric"?	weakness
2020-802	f) "Experiment" -> "Experiments" g) References: capitalization not correct e.g. Gaussian, Fourier, Bayes In this paper, the authors propose a family of variational distributions in which the variational covariance matrix is parameterized as RR', with R_ij being nonzero only when j is a neighbor of i as defined by prior covariance.	weakness
2020-802	In other words, data points are only allowed to have nonzero posterior covariance if they are highly correlated a priori.	weakness
2020-802	This results in a sparse factor of the covariance matrix which can be used for efficient computation.	weakness
2020-802	Rather than being parameterized directly, the variational parameters \\mu_{i} and R_{i, n(i)} are parameterized using a GCN: the labels and prior covariance information are supplied to the GCN, which produces the mean for a data point x_i and the |n(i)| nonzero elements of the covariance factor R.	weakness
2020-802	Overall, the idea is interesting in the sense that a variational family with enforced sparsity likely leads to a reasonable probabilistic model.	strength
2020-802	However, I have a few concerns about the execution.	misc
2020-802	First, as a minor point, in my opinion, the approximations eqns.	weakness
2020-802	3-7 are not sufficiently motivated, and are essential to the method as they allow for stochastic optimization.	weakness
2020-802	It would be useful to see an empirical analysis of the tightness of the additional approximations, as well as a generally expanded discussion in this section.	suggestion
2020-802	Beyond this, the method is highly engineered but the only ablation study done of the various components is Figure 3, which merely offers an analysis of convergence speed, but not on final model performance.	weakness
2020-802	Both ideas introduced in the paper (localization and amortization) can be used independently of the other.	weakness
2020-802	More importantly, I believe the experimental evaluation should be substantially broadened.	weakness
2020-802	At present, three datasets are considered and on one of them (MNIST) three methods considered are within the error bars of each other: the bolding in Table 3 is inappropriate.	weakness
2020-802	Many popularly used benchmark datasets for sparse GP methods are widely available, and it seems particularly essential to include datasets larger than the ones considered here, since exact GPs can trivially be trained on these datasets in a matter of seconds (at least for the regression tasks).	weakness
2020-802	Again ignoring the single classification task, Variational GP methods are usually only considered for regression for much larger datasets.	weakness
2020-802	I suspect that, with proper hardware (e.g. a GPU) and truly large datasets much of the speed advantage enjoyed by LAIN as reported in the paper will be lost to overhead.	weakness

2020-805	In this paper, the authors propose the Homotopy Training Algorithm (HTA) for neural network optimization problems.	abstract
2020-805	They claim that HTA starts with several simplified problems and tracks the solution to the original problem via a continuous homotopy path.	abstract
2020-805	They give the theoretical analysis and conduct experiments on the synthetic data and the CIFAR-10 dataset.	abstract
2020-805	My major concerns are as follows.	misc
2020-805	1. The authors may want to give more detailed explanations of HTA.	weakness
2020-805	For example, they may want to give the pseudocode for HTA and explain its advantages compared to other optimization methods.	weakness
2020-805	2. The theoretical analysis is trivial.	weakness
2020-805	The proof of Theorem 3.1 is to verify Assumptions 4.1 and 4.3 in [1].	weakness
2020-805	Moreover, the proof of Theorem 3.2 is similar to the analysis for the convergence of SGD for convex problems in [2].	weakness
2020-805	3. The experiments do not show the efficiency of HTA, as the original quasi-newton method is faster than the quasi-newton method with the homotopy setup.	weakness
2020-805	4. The authors make a mistake in the proof of Theorem 3.1.	weakness
2020-805	The claim that "{\\theta_k} is contained in an open set which is bounded.	weakness
2020-805	Since that g is continuous, g is bounded." is incorrect.	weakness
2020-805	We can find a counterexample g(x) = \\frac{1}{x}, x\\in (0,1).	weakness
2020-805	[1] L. Bottou, F. Curtis, and J. Nocedal.	misc
2020-805	Optimization methods for large-scale machine learning.	misc
2020-805	SIAM Review, 60(2):223–311, 2018. [2] A. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro.	misc
2020-805	Robust stochastic approximation approach to stochastic programming.	misc
2020-805	SIAM Journal on Optimization, 19(4):1574–1609, 2009.	misc
2020-805	Summary This paper proposes an algorithm to address the issue of nonlinear optimization in high dimensions and applies it to convolutional neural networks (VGG models) on CIFAR 10.	abstract
2020-805	They show 11% relative reduction in error for this particular task with this particular network.	abstract
2020-805	In addition, they prove additional theoretical results on the convergence of SGD using their method in the convex case as well as convergence of SGD to a stationary point in the nonconvex case when the homotopy parameter is fixed which is not done in practice.	abstract
2020-805	Given an optimization problem, their method first solves multiple independent lower-dimensional optimization problems each with a subset of the parameters and then optimizes a new objective function controlled by a monotonically decreasing parameter L that interpolates the original objective function and the previously-solved lower dimensional problems.	abstract
2020-805	L can be seen as a regularization parameter that is gradually decreased as we optimize the new optimization function.	abstract
2020-805	When L = 0, we recover the original optimization problem.	abstract
2020-805	The authors prove that (1) SGD with their procedure will find a stationary point under the Robbins-Monro conditions for a fixed L and (2) SGD with their procedure will converge for convex problems as L is decreased to 0.	abstract
2020-805	Decision and reasoning This paper should be rejected because	decision
2020-805	(1) the proposed algorithm attempts to address the original issue of high dimensional nonlinear optimization of neural networks but violates the algorithm's assumption in practice,	weakness
2020-805	(2) the empirical evaluations are lacking	weakness
2020-805	- having only evaluated their method on a toy problem with up to only 6 dimensions and a relatively simple image classification task,	weakness
2020-805	and (3) the assumption of fixing the homotopy parameter in the theorem on the non-convex case directly violates the intention of the algorithm.	weakness
2020-805	Regarding (1): The proposed procedure requires initializing L at a large value and reducing L towards 0 in order to recover the original optimization problem.	weakness
2020-805	However, in practice for CIFAR 10, the authors initialize L to be 0.01 and gradually reduces it to 0.005 which is hardly the original intent of the algorithm.	weakness
2020-805	There is also no demonstration whether or not this gradual reduction in	weakness
2020-805	L actually has an effect on the optimization of the new objective function.	weakness
2020-805	For example, since the start and end values of L are similar, will we get similar results if we simply fix L to be 0.005 or 0.01?	weakness
2020-805	The authors also show that their method outperforms a quasi-newton method by combining the optimization with their procedure on a non-convex example by Chow et al. 2013.	weakness
2020-805	However, this example only goes up to n=6 dimensions, which is hardly comparable to the original problem of high dimensional non-convex optimization that this paper sought to address.	weakness
2020-805	Regarding (2): The authors evaluated their procedure on CIFAR10, a relatively simple image classification task that modern neural networks can solve easily and is not representative of the types of nonlinear optimization problems prevalent in deep learning.	weakness
2020-805	There's also an issue of using only VGG networks for their evaluations while VGGs are typically eschewed in favor of ResNets today.	weakness
2020-805	Given that the optimization is easier with residual connections, it may be the case that their procedure does not significantly improve the accuracy of ResNets.	weakness
2020-805	Regarding (3): By fixing L in Theorem 3.1, the authors essentially show that SGD	weakness
2020-805	converges to a stationary point for their new objective function which can be seen as a regularized version of the original objective function, which is not a strong result.	weakness
2020-805	Furthermore, fixing L goes against the original procedure's motivation of recovering the original optimization function as L decreases to 0.	weakness
2020-805	Additional comments and questions There are passages that are difficult to understand because not enough context is given.	weakness
2020-805	For example in the "remark" passage, it is not clear where the	weakness
2020-805	"necessary condition" comes from. In addition it seems like it doesn't even type-check since the first term is 2n dimensional while the second term is 4n dimensional.	weakness
2020-805	There are also many errors in the writing that hinder the presentation.	weakness
2020-805	A subset of them includes: - "nerual netowrks on roboticsKonda et al." -> "neural networks on robotics Konda et al."	weakness
2020-805	- "based on homotopy continuation method" -> "based on the homotopy continuation methods"	misc
2020-805	- "random chosen point" -> "randomly chosen point"	weakness
2020-805	- "we choose \\tilde{\\theta} = 0 in the dropout" -> reword	weakness
2020-805	- Fourth term in Equation 3 should be \\theta_2 - \\tilde{\\theta_2}	weakness
2020-805	- "By gradually increasing parameter L" -> "By gradually decreasing parameter L"	weakness
2020-805	- "where \\xi is a random variable due to random algorithms" -> reword and possibly say the randomness is from SGD	weakness
2020-805	- After equation 6, should have b_i instead of \\beta_i	weakness
2020-805	- In equation 20, should be g(\\theta_*^0) instead of g(\\theta_*^1)	weakness
2020-805	- In theorem 3.2 you never explained what \\theta_*^{L_k} is	weakness
2020-805	- "We compared the traditional optimization method (the quasi-Newton method)" -> which quasi-Newton method?	misc
2020-805	- Figures 2 and 3 label the x-axis with "epochs".	weakness
2020-805	However only 4 epochs were run, so I believe the x-axis should be "iterations"	weakness
2020-805	Besides improving the quality of writing in the paper, I would strongly suggest that the authors improve their empirical evaluation.	suggestion
2020-805	Possibilities include evaluating on CIFAR 100 or ImageNet, using a wider variety of networks including ResNets,	suggestion
2020-805	evaluating on tasks other than image classification.	suggestion
2020-805	The work proposes to learn neural networks using homotopy-based continuation method.	abstract
2020-805	The method divides the parameter space into two groups (extendable to multiple groups) and introduces a homotopy function which includes the original optimization problem as an extreme case.	abstract
2020-805	By varying the homotopy parameter, one can construct a continuous path from a supposedly easier to solve optimization problem to the problem of interest.	abstract
2020-805	The authors prove convergence in the non-convex case, the existence of solution path in the convex case and demonstrate the effectiveness of the proposed method on synthetic and real datasets.	abstract
2020-805	While the idea itself is rather intriguing and seems promising, the current presentation and experimentation does not meet the acceptance threshold.	decision
2020-805	The writing of the draft needs a lot of improvement, in particular the notations the authors used are not consistent throughout the paper, which is very confusing.	weakness
2020-805	The synthetic example the authors used in section 4.1 are naturally decoupled among the different dimensions of the parameters, which is no surprise the proposed method would achieve 100% convergence as shown in table 1.	weakness
2020-805	It seems the division of the parameter space would matter.	weakness
2020-805	One would imagine there exists certain division leading to much easier to solve subproblems.	weakness
2020-805	Do the authors have any insight or experiments comparing different division strategies?	weakness
2020-805	Here's a very closely-related work that should be cited and discussed: Wang, Xin.	misc
2020-805	"An efficient training algorithm for multilayer neural networks by homotopy continuation method." Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN'94).	misc
2020-805	Vol. 1. IEEE, 1994. Typos: 1) Equation following remark in page 2, should H() be replaced by G() or \\nabla H()?	weakness
2020-805	2) After equation (7), should G():= \\nabla H instead of F?	weakness

2020-850	This work examines the recently proposed randomized smoothing method for certifying the robustness of neural networks.	abstract
2020-850	The authors explain a theoretical framework for analyzing randomized smoothing as a certification method, propose two alternative definitions of robustness (D_MR and D_inf), and prove that using Gaussian noise for smoothing is near "optimal" for L2 robustness, while using exponential noise for smoothing is optimal for L_inf robustness (the authors do this by establishing a lower bound on the noise necessary for smoothing to work).	abstract
2020-850	This also leads the authors to the interesting conclusion that randomized smoothing may not be scalable to high dimensional data for L_inf robustness.	abstract
2020-850	In its current state, I would vote to weakly reject this paper for one key reason.	decision
2020-850	The notions of robustness defined by the authors (Definitions 3/7/8) is not the same as standard adversarial robustness (Definition 2), and the authors do not explain clearly how to translate their results back to adversarial robustness.	weakness
2020-850	Proving results about their own version of robustness is interesting, but it must be related back to the standard notion of adversarial robustness so that the broader machine learning community can understand how the authors' contributions fit in the literature.	weakness
2020-850	It may in fact be quite straightforward to relate the two notions, but I think the authors should explain how to do so clearly.	weakness
2020-850	I am happy to reconsider if the authors can address this (and other comments below) in a satisfactory manner.	suggestion
2020-850	I did not check the authors' theoretical proofs, but I find the statements of the theorems interesting, especially the results about the maximum certifiable radius for L_inf robustness.	strength
2020-850	This provides significant new insight about the fact that L_inf robustness may not be easy to certify using randomized smoothing methods.	strength
2020-850	However, it is not clear to me how best to translate the authors' results to a result for the standard notion of adversarial robustness, which I believe would be interesting to present clearly.	weakness
2020-850	I would encourage the authors' to clarify (and tone down) their statement about the "optimality" of Gaussian noise for L2 robustness.	suggestion
2020-850	Theorem 12 provides a lower bound on the L_inf norm of the noise added, and they show that Gaussian noise is close to "optimal" in terms of expected L_inf norm.	suggestion
2020-850	I am a bit confused as to why are we providing bounds on the L_inf norm of the added noise (especially since we are verifying L2 robustness) - in what other ways is Gaussian noise (near) optimal?	weakness
2020-850	Does it also have the expected lowest L2 norm?	weakness
2020-850	Also, why do we want the noise to have low norm?	weakness
2020-850	I feel that "optimal" should mean being able to prove the largest possible robust radius, and if that is not what you are proving, I would encourage you to try to avoid overclaiming.	weakness
2020-850	Finally, the experimental results should also not just be in terms of D_MR robustness.	weakness
2020-850	Otherwise, it is hard to compare with prior work like Cohen et.	weakness
2020-850	al. Some additional feedback: - "the Lp-normed robustness" can be replaced with "Lp-norm robustness" everywhere	weakness
2020-850	- Page 1, say "the Gaussian mechanism" instead of "Gaussian mechanism" (toward the end of the first paragraph)	weakness
2020-850	- Table 1's formatting can be improved (maybe have a box around the whole table)	weakness
2020-850	- Theorem 12 - use "In other words" instead of "In another word Summary of the paper's contributions: This paper introduces two new notions of robustness for randomized classifiers, which are based on the notions of differential privacy (DP) of randomized mechanisms.	abstract
2020-850	Specifically, the D_\\infty robustness and D_{MR} robustness of a random classifier are defined based on \\epsilon-DP and \\epsilon-zCDP, respectively.	abstract
2020-850	The paper proves lower bounds on the noise level of a random classifier for which it can be certified D_\\infty robust and D_{MR} robust.	abstract
2020-850	Further, it is shown that the lower bounds are achieved by random classifiers constructed using Gaussian noise and exponential noise for l_2 and l_\\infty robustness, respectively.	abstract
2020-850	Major criticisms: (1) The paper does not give sufficient motivation for studying D_\\infty robustness and D_{MR} robustness.	weakness
2020-850	(2) The paper makes several unsubstantiated claims regarding the optimality of different noise models for adversarial robustness.	weakness
2020-850	Detailed comments: - All the claims made in the paper regarding the optimality of different noise models  are specific to D_\\infty and D_{MR} robustness.	weakness
2020-850	However, they are written in a way to imply that the claims also hold for the standard l_2/l_\\infty robustness which is studied in adversarial ML literature (especially in the abstract and intro section).	weakness
2020-850	The authors should make clear the relation between D_\\infty and D_{MR} robustness and the standard notion of robustness of a classifier.	weakness
2020-850	Does one imply the other?	weakness
2020-850	- Does the relaxed notion of robustness of a random classifier g (Definition 3) imply a robustness guarantee for the final output of the random classifier, i.e., \\argmax_c P(g(x) = c) ?	weakness
2020-850	- The experiments use the same setup as in Cohen et al, but the results are not compared with those in Cohen et al. It is not clear how to judge the significance of these results without comparison to any other method of evaluating robustness.	weakness
2020-850	- "However, it is known that adding Gaussian noise often does not lead to \\epsilon-DP, but rather (\\epsilon; \\delta)-DP (Dwork et al., 2014) which has an additional parameter \\delta and thus is harder to be incorporated in our framework.	weakness
2020-850	To alleviate this issue, we employ Maximal Relative Renyi Divergence as the probability distance measurement to define another type of robustness, namely D_{MR} robustness." - This does not provide sufficient justification for studying D_{MR} robustness.	weakness
2020-850	- A comparison is made between Theorem 10 & Corollary 11 in the paper to Theorem 1 in Cohen et al. However, it is not clear how the result in the paper is better or even equivalent to the one in Cohen et al. D_{MR} robustness seems to be an approximate notion of robustness, while the result in Cohen et al gives perfect robustness within a ball of a certain radius.	weakness
2020-850	The radius r in both papers scales linearly with \\sigma.	weakness
2020-850	It is said that "a smaller c yields a larger r compared to Cohen et al." It is not clear why that is useful.	weakness
2020-850	- In Theorem 12, each entry in x is restricted to be in the range [0, r/\\sqrt{d}].	weakness
2020-850	This means the l_2 norm of x cannot be more than r.	weakness
2020-850	Then, how is it meaningful to discuss the (2r, D_{MR}, l_2, \\epsilon/2) robustness of an algorithm on this data, with the radius of the robust guarantee being 2r?	weakness
2020-850	- In Theorem 12, the lower bound on the expected l_\\infty norm of the random noise is shown to be independent of d, while the expected l_\\infty norm for Gaussian noise scales with \\sqrt{\\log d}.	weakness
2020-850	I don't think it is correct to claim that Gaussian noise is "near" optimal from this analysis.	weakness
2020-850	-  In Definition 23, it is not clear what Loss(Y||Y') is.	weakness
2020-850	Suggestions for improvement: - The authors should make it clear in the abstract that the optimality of the noise models is with regards to the newly defined notions of robustness.	suggestion
2020-850	- It would be worthwhile to discuss how D_\\infty and D_{MR} robustness differ from standard notions of minimax robustness.	suggestion
2020-850	- One possible way to motivate the relaxed robustness introduced in Definition 3 is to link it to the robustness of the randomized classifier in Definition 1.	suggestion
2020-850	- Please consider using \\left( \\right) instead of ( ).	suggestion
2020-850	- For experiments, it would help to compare D_\\infty and D_{MR} robustness alongside the standard l_2 robustness.	suggestion
2020-850	In addition to training the network on Gaussian augmented dataset, it might be worthwhile to compare it to other baseline approaches as done in Cohen et al. Summary.	suggestion
2020-850	The authors propose a new definition for robustness of random functions.	abstract
2020-850	This definition is ideal for analyzing the certified robustness under randomized smoothing techniques.	abstract
2020-850	They analyze and show that the Gaussian smoothing is near optimal for \\ell_2 smoothing as the mean maximum error is only off by a factor of log d where d is the dimension from the optimal mean maximum energy.	abstract
2020-850	This is the case even under a more strict definition of robustness defined as D_\\infty.	abstract
2020-850	Moreover, the authors show that indeed smoothing with an exponential family  is optimal under D_\\infty robustness metric with radius measured in \\ell_\\infty.	abstract
2020-850	I find the paper very interesting and the approach is novel and generic.	strength
2020-850	I do not have any major criticism.	misc
2020-850	Minor comments. 1) Equation 3 "D(A(x'),A(x))" >> "D_\\infty(A(x'),A(x))"	misc
2020-850	2) Page 6 third line below Theorem 16.	rebuttal_process
2020-850	Reference of Theorem 11 should be Corollary 11.	suggestion
2020-850	3) The authors should report the certified accuracy of the undefended baseline classifier over varying radius in Figures 1 and 2 and 3.	suggestion
2020-850	4) Running experiments on ImageNet following Cohen et al. should make the paper stronger.	suggestion
2020-850	4) Can the authors comment on is the certified accuracy for \\sigma=0.5 at radius = 0 is better than the unsmoothned classifier a sigma 1.0.	suggestion
2020-850	I expect that the radius of certification is larger for larger sigma.	suggestion
2020-850	5) The authors should explain how does the new definition of robustness relate to the common robustness definitions as the one by Cohen et al. More discussion is necessary for this and more justification.	suggestion
2020-850	6) Why is the D_MR defined as maximum over α?	weakness
2020-850	It seems it is only sufficient to define it as the ratio over α.	weakness
2020-850	It seems that this is only needed for Theorem 8 to hold.	suggestion
2020-850	------------------------------------------------------------------------ After further careful read of several relevant papers, e.g. Bun et.	misc
2020-850	al 2016 and the work of Dwork "Concentrated Differential Privacy", I have several questions I would like to ask for some further clarifications.	misc
2020-850	1) Showing that a network is robust under D∞ robustness, implies very strong results.	strength
2020-850	The type of results that are common in the literature.	strength
2020-850	This is since D∞ robustness, implies ϵ DP networks (see Lemma 3.2 and proposition 3.3 of Bun et al.).	strength
2020-850	Once ϵ DP is guaranteed identical results of Lecurer et al. can be derived immediately as this implies separation in expectation (Lecurer et al.) where one can study directly the deterministic classifier Eg(x) and not the random g studied in this work.	strength
2020-850	2) The authors rely on the lower bounds of Bun et al. to find the average maximum energy that preserves the D∞ robustness (Thm 15 and 16).	strength
2020-850	Authors show that indeed exponential smoothing is optimal.	weakness
2020-850	This is significant but the analysis was intensively based on Bun et al. 3) The relaxation to DMR robustness results into improvement of the dependency on the dimension to d instead of d for under ℓ∞.	weakness
2020-850	This should not be surprising at all and in fact is identical to the results of Bun et al. Note that the zCDP proposed by Bun et al, is a relaxed version of DP where ϵ-DP for some radius r implies zCDP with radius r2.	weakness
2020-850	See proposition 3.3. Therefore, Theorem 6 and 17 are not surprising nor are they new.	weakness
2020-850	4) My major concern was with the results relating to Gaussian smoothing.	weakness
2020-850	I do understand that since Gaussian smoothing only implies high probability result of DP which is often referred to as (ϵ,δ)-DP which happens to be a equivalent to zCDP proposed by Bun et.	weakness
2020-850	al. Therefore, I have no issues of using DMR to analyzing the robustness for Gaussian smoothing since it was always analyzed in the DP community with the ϵ,δ-DP and not the stronger ϵ-DP.	ac_disagreement
2020-850	However, the statement of the result (Theorem 12) confused me vastly.	weakness
2020-850	Let me clarify. Theorem 12 seems to be too good to be true.	weakness
2020-850	How is it possible that one can guarantee DMR robustness without any dimensionality dependence.	weakness
2020-850	Using Gaussian smoothing the DMR can depend on log⁡d.	weakness
2020-850	While log⁡d may seem small; improving this to a constant in dimension is still a very big gap from log⁡d.	weakness
2020-850	This may raise several questions whether one can actually find this optimal smoothing distribution.	weakness
2020-850	However, with a careful read of Theorem 12, the range of the input decreases as a function of d.	weakness
2020-850	That is for a given range of input (independent from d), the energy in fact is NOT constant but scales with d.	weakness
2020-850	In such a case, the Gaussian smoothing is now of order dlog⁡d.	weakness
2020-850	Now, the factor is still log⁡d, but now this is very different as indeed improving the Gaussian to d may not be of significant interest as the energy still depends in the optimal sense on d which does not allow it to scale for larger problems.	weakness
2020-850	Moreover, Cohen et al results show that with Gaussian smoothing the energy of the noise scales d since the noise energy ∥n∥=O(dσ) where σ is std of Gaussian.	weakness
2020-850	Therefore, it seems that there is nothing surprising about such a result at all.	weakness
2020-850	The statement of the Theorem is very misleading and confusing.	weakness
2020-850	Overall, I like this new approach of analyzing the random smoothed classifier; however, the poor presentation of the work and the mis-represented Theorems that seem to over claim are a major reason for my rating.	weakness
2020-850	In addition, the paper should be self-contained in which one should not need to read 2-3 other works to figure out the details in this work and the meaning of the several robustness metrics and their direct relations to DP and Lecuer et al. results.	weakness
2020-850	The statement of constant in dimension lower bound on the energy of the noise under D_MR was to me the major contribution;	strength
2020-850	however, I found now that the statement is misleading and that in fact it is d reduces the contribution of the paper particularly after learning that such lower bounds are already derived in Bun et al.	weakness

2020-879	The paper proposes to maximize improve generalization in meta-learning by learning discrete codes via a mutual information maximization objective.	abstract
2020-879	I liked the motivation and presentation of the paper but see some critical shortcomings: - In Theorem 1, shouldn't there be a term that accounts for the complexity of the hypothesis class (VC-dim, Rademacher complexity etc.).	weakness
2020-879	Can we actually verify Theorem 1 in practice on synthetic distributions to get a sense of the constant terms?	weakness
2020-879	- The experiments do not compare with any mutual information related baselines.	weakness
2020-879	Eg, VIB [Alemi et al.].	misc
2020-879	This comparison is critical to stress the importance of discrete codes as opposed to continuous.	weakness
2020-879	- Can the authors shed more light on the tradeoffs between p and d?	weakness
2020-879	Empirical insights would lend more intuition and understanding.	weakness
2020-879	- Discreteness in activations is one form of regularization to reduce |tilde(x)|.	weakness
2020-879	Would regularizing the weights of the stochastic encoder (say by variational inference or minimizing say l2 norm) have the same/better/worse regularization effect (as done in Bayes by Backprop)?	weakness
2020-879	- There are a few missing references on stochastic encoders trained based on variational information maximization [1, 2].	weakness
2020-879	References: [1] Uncertainty Autoencoders: Learning Compressed Representations via Variational Information Maximization.	misc
2020-879	AISTATS 2019. [2] Neural Joint Source-Channel Coding.	misc
2020-879	ICML 2019. This paper presents DIMCO, a meta-learner that is trained by maximizing mutual information between a discrete data representation and class labels across tasks.	abstract
2020-879	DIMCO is inspired by an information theoretic lower bound on the generalisation gap for meta-learning, which the authors argue identifies overfitting in the task learner as the bottleneck.	abstract
2020-879	This work proposes to constrain a learner to output discrete codes that are learned to capture the mutual information with class labels.	abstract
2020-879	While the idea of using discrete codes is interesting, its presentation in the manuscript is not well motivated and at times hard to follow.	weakness
2020-879	This makes it challenging to evaluate the novelty, validity, and generality of the proposed approach.	weakness
2020-879	Meanwhile, the empirical evaluation is somewhat lacking.	weakness
2020-879	Thus, I do not believe this work is ready for publication in its current form.	decision
2020-879	Detailed comments My main concern is with respect to the primary contribution of this paper, a generalisation bound on meta-learning.	weakness
2020-879	The bound appears to be on a multi-task loss without task adaptation, and thus the claims made with respect to the theorem seem somewhat over-reaching.	weakness
2020-879	I also believe the VC-dimensionality of the encoder is missing in Eq. 4?	weakness
2020-879	If so, this changes the interpretation since the length of the code and the expressivity of the encoder are interrelated.	weakness
2020-879	Further, I would welcome a deeper analysis of the theorem and its implications.	weakness
2020-879	The current interpretation states that the number of tasks is independent of the size of each task, hence given many tasks, using minimal representations is an effective approach to meta-generalisation.	weakness
2020-879	Yet minimal representations is a well-known idea and has features in several works that use mutual information as a regularizer, most notably works on the Information Bottleneck.	weakness
2020-879	Another reservation I have is the use of mutual information between encoder representations and class labels as a loss function (Eq. 1).	weakness
2020-879	It lacks context and a proper motivation, especially since the analysis of [1] shows that the loss function in Eq. 1 is the cross-entropy objective.	weakness
2020-879	The authors make a similar analysis in Appendix A and argue that Eq. 1 differs in that cross-entropy is an approximation because it adds a parametrized linear layer on top of \\tilde{X}.	weakness
2020-879	Thus, in the absence of that layer they collapse to the same objective.	weakness
2020-879	As DIMCO itself directly extract class label predictions from \\tilde{X}, I fail to see a difference between the loss in Eq. 1 and a cross-entropy objective.	weakness
2020-879	The main motivation behind their loss objective is that it does not require a support / query set.	weakness
2020-879	This does not seem to be a feature of the mutual information objective itself, but rather a choice made by the authors.	weakness
2020-879	I would have liked a deeper discussion of this seeing as the authors make it a central tenet of DIMCO.	weakness
2020-879	Prior works use a support set as a principled means of doing meta-learning: meta-training explicitly takes into account that at test time, the learner will be given a small support set from which to learn how to query points.	weakness
2020-879	As far as I understand, DIMCO does not take this into account during meta-training.	weakness
2020-879	At meta-test time however, DIMCO does use a support set to map query points (Eqs. 10 and 11).	weakness
2020-879	Why should we break protocols between meta training and testing?	weakness
2020-879	Are there any downsides to doing so?	weakness
2020-879	Empirically, I find the CUB experiment compelling but would welcome some ablations.	weakness
2020-879	What are the trade-offs between p and d?	weakness
2020-879	Can DIMCO outperform N-pair when number of bits are unconstrained?	weakness
2020-879	miniImagenet is a standard benchmark in few-shot learning, but I am unable to find a results table - could the authors please provide results on the standard setup so that the method can be compared against known baselines?	weakness
2020-879	Further, would the results currently presented hold in a N-way-5-shot setup?	weakness
2020-879	As for the constrained version of miniImagenet that the authors propose, I am not convinced this is an interesting protocol.	weakness
2020-879	In general, the miniImagenet task distribution is created by N-way permutations of the classes in the meta-set (e.g. meta-training tasks are combinations of the 64 classes in the meta-training set).	weakness
2020-879	By keeping the number of classes constant but reducing the number of images per class, this protocol is not reducing samples per task: a task is always defined as 5/20-way-1-shot (Fig. 4).	weakness
2020-879	Instead, the effect should be that tasks are in (greater) violation of the task i.i.d. assumption.	weakness
2020-879	Thus, I question whether this setup demonstrates the trade-offs the authors present in Theorem 1 and whether the results can be interpreted in light of it.	weakness
2020-879	Finally, that both experiments are image-based raises questions as to the generality of the method.	weakness
2020-879	The paper could be considerably strengthened by evaluating DIMCO on a non-image task, or if not discuss the method's limitations.	suggestion
2020-879	The idea of discrete codes for few-shot classification is interesting and sufficiently novel, I am likely to increase my score if my concerns are addressed and the experimental section is strengthened.	suggestion
2020-879	Further questions and comments: - I am unable to parse Eq. 11 - what does the notation \\prod_i p_{\\tilde{x}_i, i} mean?	weakness
2020-879	- It is unnecessarily hard to follow the proof of theorem 1.	weakness
2020-879	It would help the reader if you restated relevant definitions, such as Eq. 1, since the difference with Eq. 23 is very subtle.	suggestion
2020-879	It would also be helpful to explain how the summand in Eq. 25 differs from either, and Eq. 26 could be expanded or briefly explained after the derivation.	suggestion
2020-879	-  Because DIMCO is trained with backpropagation, the interpretation of Eq. 5 as d independent events seems invalid.	weakness
2020-879	How does it affect the method if they are not independent?	weakness
2020-879	- Overloading X and Y as both random variables and mini-batch samples creates unnecessary confusion.	weakness
2020-879	I believe the objective in Eq. 1 is approximated, not calculated exactly?	weakness
2020-879	For instance, the mutual information in Eq. 8 is with respect to a mini-batch, so should it not be \\hat{I}?	weakness
2020-879	- p^j_{ik} in Eq. 9 is undefined.	weakness
2020-879	- Eq. 9 is interpreted as an exact entropy, however it appears to be a mini-batch approximation to the true entropy?	weakness
2020-879	References [1] Achille and Soatto. Emergence of Invariance and Disentanglement in Deep Representations.	misc
2020-879	JMLR. 2018. This paper proposes a method to learn classifier outputs for meta learning in the form of factorized discrete codes by maximizing the mutual information between the model's outputs and the ground truth labels.	abstract
2020-879	The authors further present an information theoretic generalization bound for meta learning in terms of the number of tasks, number of training samples per task and the expressively of the model.	abstract
2020-879	They further show empirically that their approach does not need a separate query set during meta-training and can generalize better than a few of the other metric-learning based meta-learning approaches specifically at lower shot values.	abstract
2020-879	They show that their method requires less memory than the N-pair meta-learning method.	abstract
2020-879	The paper addresses an important problem of generalization with very low shot values and proposes an interesting theoretical treatment of the problem in terms of deriving an information theoretic lower bound for it.	abstract
2020-879	I liked the authors' theoretical treatment of relating various metrics to the mutual information between the models' outputs and their labels.	strength
2020-879	However, there have been many recent works attempting to address the problem of better generalization of meta learning models.	weakness
2020-879	Most notable among them is the work of Kim et al. "Bayesian Model-Agnostic Meta-Learning" (https://arxiv.org/pdf/1806.03836.pdf), which is not referenced or compared against in this paper at all.	weakness
2020-879	The proposed method is also limited in its scope to classification tasks only and the authors make no attempt to address regression or reinforcement learning problem, which limits is widespread applicability.	weakness
2020-879	While the authors address the generalization of meta-learning methods for small values of M, they do not address how their model behaves viz-a-viz others when the number of tasks N available for training is small.	weakness
2020-879	Theoretically having more compact representations should also help in situations where the number of tasks available for training are small.	weakness
2020-879	I would like to see an empirical analysis of that as well.	suggestion

2020-883	The authors give new generalization bounds for GANs.	abstract
2020-883	The argue for a new definition of generalization for GANs, which isolates the effect of sampling error arising from sampling from the real distribution.	abstract
2020-883	(Their argument, which I find convincing, may be paraphrased as saying that sampling from the generator should be viewed more as a computational cost than a data-gathering cost, since a procedure may sample from a generator as many times as it wants.)	abstract
2020-883	They give a bound that is uniform both over discriminators and generators.	abstract
2020-883	In my opinion, the mathematical writing is not up to the standard for publication in *CONF*.	weakness
2020-883	There are many cases where the paper is unclear, and, in many other cases, I have to guess what they mean, and I have limited confidence in my guess.	weakness
2020-883	Since the theorems of the paper are quite technical, it is very difficult to be confident what their exact statements are.	weakness
2020-883	One example is where they write	weakness
2020-883	"We define F with weight normalization as ...".	weakness
2020-883	The fact that the c in this definition has a subscript of f led me to think that the bound can depend on f, but this does not make sense.	weakness
2020-883	I assume that the bound is independent of f.	weakness
2020-883	Later, when they write "we define the Lipschitz constant of f", since they write that this Lipschitz constant is with respect to a norm on parameterizations, I take it that they are defining the Lipschitz constant of a mapping from parameters to functions (and not a Lipschitz constant of f).	weakness
2020-883	But they don't indicate what metric is used to define the distance between functions.	weakness
2020-883	When the compare their bound with previous work, they treat quantities as constants which can be large.	weakness
2020-883	For example, they treat the product of the operator norms of the layers as a constant.	weakness
2020-883	It also is not clear how they get the bound that they attribute to Bartlett, et al from the bound in that paper.	weakness
2020-883	Most of the technical heavy lifting appears to have been borrowed from the Chen, et al paper.	weakness
2020-883	A more detailed account of how they get their covering bound for their (p,q) norm from the	weakness
2020-883	Dumer paper is needed. Since the authors assume that phi is the identity, it seems unnecessary to keep subscript d with it.	weakness
2020-883	On the other hand, subscripting d with calF would make the theorems easier to interpret at a glance.	weakness
2020-883	(Edit on 11/14/19: I have read the response and checked the revision.	misc
2020-883	Some of the above criticisms have been addressed by the revision.	rebuttal_process
2020-883	I have increased my rating.) In this paper, the authors study the generalization bound for GANs based on a new definition of generalization error where the distribution corresponding to the generator is assumed to be known for each generator (i.e., there is no empirical distribution for generators).	abstract
2020-883	For this generalization error, the authors give both bounds for a fixed generator and a uniform bound for a class of generators.	abstract
2020-883	In my opinion, most of the theoretical results seem follow directly from standard tools in statistical learning theory and existing results on capacity bounds of neural networks.	weakness
2020-883	It seems that the authors do not introduce new ideas or techniques in the analysis.	weakness
2020-883	The authors made comparisons with the related results in Arora et al (2017).	weakness
2020-883	However, since the generalization bound in Arora et al (2017) is based on a different definition of generalization error where empirical distributions are considered for both discriminators and generators, the comparison seems not fair.	weakness
2020-883	---------------------- After rebuttal: I have read the authors' response.	misc
2020-883	The contribution seems not novel and enough.	weakness
2020-883	I would like to keep my original score.	weakness
2020-883	This paper proves generalization bounds for GANs. I think the paper can be improved significantly in several ways: 1- Writing: The first two sections are relatively well-written.	weakness
2020-883	The problem starts at section 3 and continues after that.	weakness
2020-883	Some of the things that can be improved: a) The discussion on the different definitions of generalizations is not really helpful in the current format.	weakness
2020-883	You might want to explain how these different definitions relate to each other.	suggestion
2020-883	For example, if generalization in one of them implies generalization in the other one, etc.	weakness
2020-883	b)Theorem 2.3 is a general statement but it is followed by Corollary 3.3 which is a very specific generalization bound.	weakness
2020-883	There is no explanation how one can show the corollary.	weakness
2020-883	Even worse is mixing these two in the proof of the theorem in the appendix.	weakness
2020-883	Please consider improving the use of Theorems, Lemmas and Corollaries.	suggestion
2020-883	c) Section 3 and 4 have bunch of theorems and collieries without much explanation.	weakness
2020-883	It is not clear that all of these are actually helpful for the main purpose of the paper.	weakness
2020-883	d) I don't completely understand the notation in Corollary 3.3.	weakness
2020-883	Eg. what is d_{f,\\ell}? 2) Related Work: I think authors need to do a more comprehensive literature review on generalization bounds.	weakness
2020-883	Since the generalization bounds presented here are built on the supervised learning bounds, authors discuss the generalization bounds in supervised learning.	weakness
2020-883	For example, authors heavily rely on Chen et al. (2019) for their generalization bounds while very similar results where shown before by [1] and [2].	weakness
2020-883	[1] Neyshabur, Behnam, Ryota Tomioka, and Nathan Srebro.	misc
2020-883	"Norm-based capacity control in neural networks." Conference on Learning Theory.	misc
2020-883	2015. [2] Golowich, Noah, Alexander Rakhlin, and Ohad Shamir.	misc
2020-883	"Size-independent sample complexity of neural networks." Conference on Learning Theory.	misc
2020-883	2018. 3) Definition of generalization: I don't think the definition of generalization suggested in this work is much different than Arora et.	weakness
2020-883	al. since f really doesn't depend on samples from D_g and hence the empirical and true distributions are not very different.	weakness
2020-883	In fact, I think the definition provided by Arora et.	weakness
2020-883	al. 2017 is preferred because at the end of the day, we have to estimate the distribution D_g by generating some samples.	weakness
2020-883	4) Generalization bound for fixed g: Unfortunately, the novelty of these generalization bounds are very limited as they are a direct application of known generalization bounds in the supervised settings.	weakness
2020-883	Therefore, the authors contributions are very limited here.	weakness
2020-883	5) Generalization bounds for all generators: Again, here the novelty and final result is very limited since the bounds achieved by a union bound arguments and does not really go beyond that.	weakness
2020-883	6) Experiments: Experiments can also be improved significantly.	weakness
2020-883	Currently, the correlation is reported for 5 trained networks and it is not clear to me that this result is statistically significant.	weakness
2020-883	Moreover, only one hyper-parameter is changed in the experiments which could be problematic.	weakness
2020-883	I suggest authors to change multiple hyper-parameters and train more networks to improve the evaluation.	suggestion
2020-883	****************************** After author rebuttals: I have read the authors response and looked at the revision.	misc
2020-883	Unfortunately, many of my concerns are not addressed adequately so my score remains the same.	rebuttal_process

2020-894	LDMGAN: Reducing Mode Collapse in GANs with Latent Distribution Matching	misc
2020-894	Summary: This paper proposes a modification to the VAE-GAN model where mode coverage is encouraged by passing samples G(Z) through the encoder and minimizing the forward KL between E(G(Z)) and the prior over Z.	abstract
2020-894	Results are presented on synthetic MoG datasets, MNIST variants, CIFAR and CelebA.	abstract
2020-894	My Take: This paper's only point of novelty over a vanilla VAE-GAN implementation is the inclusion of the KL(E(G(Z)) || p) term in the generator loss, which is very similar to the idea behind VEEGAN.	weakness
2020-894	The relative novelty over VEEGAN is also limited, the description of the method is exceptionally similar to the description used in the VEEGAN paper (going so far as to copy-paste a figure straight from VEEGAN without attribution), and the comparison to VEEGAN in the related work section is not sufficiently fleshed out.	weakness
2020-894	The difference in performance over a vanilla VAE-GAN on CIFAR and CelebA is negligible (6-9% relative reduction in FID on an already weak baseline), so there is no compelling empirical reason to adopt this method.	weakness
2020-894	I argue strongly in favor of rejection.	decision
2020-894	Notes: -Mode collapse (when many points in z map to an unexpectedly small region in G(z)) is a different phenomenon from mode dropping (when many points in x are not represented in G(z), i.e. no point in z maps to a cluster of x's, as is the case if e.g. a celebA model generates frowning and neutral faces but no smiling faces).	abstract
2020-894	While these phenomena often co-occur (especially during complete training collapse), they are not the same thing, and this paper conflates them throughout.	abstract
2020-894	-For the synthetic dataset examples the comparison against VEEGAN appears to be unfair—it's one thing to report robustness to hyperparameters, but this seems more like the authors have intentionally picked settings for which VEEGAN happens to fail (by halving the width).	weakness
2020-894	If the authors wish to use settings different from the standard ones used by most other papers which test on the MoG datasets they should justify it thoroughly and include this justification in their analysis—do we have a compelling reason to believe that the LDM method is better suited to learning lower capacity models in general?	suggestion
2020-894	Minor: Typos throughout, like "regularized autoencoer." Please thoroughly proofread your paper for grammar and spelling mistakes.	weakness
2020-894	There are formatting errors in the PDF, such as at the top of page 8.	weakness
2020-894	Please examine your paper for formatting mistakes.	suggestion
2020-894	The manuscript contains typing and grammatical errors.	weakness
2020-894	I also think that the presentation is not clear enough.	weakness
2020-894	The notation is not clearly defined also.	weakness
2020-894	I hope I am not missing it, but the function combination operation is not defined (e.g. f(x) o g(x), to denote f(g(x)), and used a lot.	weakness
2020-894	Just under equation 4, you are saying that comparing empirical distributions is difficult, and hence propose an alternative objective.	weakness
2020-894	But you could actually compare the two empirical distributions with a sample based divergence measure such maximum mean discrepancy, or Frechet Inception distance.	weakness
2020-894	Why don't you do this?	weakness
2020-894	In the algorithms section, I don't understand why you don't compare with widely used WGAN-GP model.	weakness
2020-894	DCGAN, and VAEGAN are relatively old models.	weakness
2020-894	Your only results in Celeb-A are compared against these relatively older models.	weakness
2020-894	Also by looking at the provided samples, I think the quality of the results are far away from what is obtained with state of the Generative models currently.	weakness
2020-894	Overall, I think the idea is sound and sensible, but I don't think that results are convincing enough for a conference paper.	weakness
2020-894	Furthermore, the writing needs to be improved.	weakness
2020-894	minor comments: In Figure 2, I think you should provide the explanations also in the caption to make the concept easier to follow for the reader.	suggestion
2020-894	In Algorithm 1, I think it would be easier for the reader to follow if you don't use shorthand notations defined in lines 5, 6, 7, 8.	suggestion
2020-894	It is argued in this paper that GANs often suffer from mode collapse, which means they are prone to characterize only a single or a few modes of the data distribution.	abstract
2020-894	In order to address this problem, the paper proposed a framework called LDMGAN which constrains the generator to align distribution of generated samples with that of real samples in latent space by introducing a regularized AutoEncoder that maps the data distribution to prior distribution in encoded space.	abstract
2020-894	The major difference of this paper from many traditional GANs is to constrain the distributions of generated data same as distributions of true data in latent space instead of constrain the ability of discriminator.	abstract
2020-894	The authors detailed their motivation, the algorithm, and also reported a series of evaluation results on several datasets.	abstract
2020-894	Generally, this paper was well written.	strength
2020-894	However, this paper has the following major concerns: （1） Though somewhat new, the novelty of this paper may be incremental to me.	weakness
2020-894	It looks like a combination of VEEGAN and AAE.	weakness
2020-894	Though the authors mentioned that VEEGAN autoencoded the noise vectors rather than data items, and AAE exploited the adversarial learning in the encoded space rather than using an explicit divergence,   it appears not significant to me between the proposed model and these two models.	weakness
2020-894	At least the authors did not  address sufficiently how significant the proposed method would be.	weakness
2020-894	（2） The paper tested the proposed algorithm with a 2D Synthetic dataset.	weakness
2020-894	However, I found a lot of discrepancies in the results presented in Table 1 with other published works.	weakness
2020-894	The authors show 1 of mode captured on 2D Grid and 2D Ring using the VEEGAN method.	weakness
2020-894	However, the VEEGAN paper shows they get 24.6 and 8 on 2D Ring and 2D Grid respectively.	weakness
2020-894	Such discrepancies were also observed in Figure 3.	weakness
2020-894	These discrepancies must be explained.	weakness
2020-894	（3） In Figure 4, the authors showed the distribution of MODE scores for GAN and LDMGAN.	weakness
2020-894	From the figure, it seemed that LDMGAN improved the sample quality and diversity compared to GANs, but it is still prone to characterizing only a single or a few modes of the data distribution.	weakness
2020-894	In another word,  this may alleviate the problem but may not fully solve the problem.	weakness
2020-894	Another minor point, the coordinate and legend are too small in this figure.	weakness
2020-894	It would be better if they become bigger.	suggestion
2020-894	（4） The results of Table 4 is not convincing because the comparative methods are truly out-of-date.	weakness
2020-894	It would be more convincing if more latest methods can be compared with LDMGAN method.	weakness
2020-894	Those results reported are far lower than the state-of-the-art performance in these datasets.	weakness
2020-894	(5) There is a mistake in the second term of equation 11, it should be ⋯〖-D〗_KL (p^* (y)||p(y))  )	weakness

2020-895	This paper tackles the Image-to-Image translation task via a simplified yet more effective training procedure.	abstract
2020-895	Compared to the direct baseline BicycleGAN, the training procedure proposed in this paper replaces the simultaneous training of the encoder E and the generator G with a staged training that alternatively trains on E and G and then finetune them together.	abstract
2020-895	Although this appears to be a simple modification, the empirical performance for generalization and reconstruction qualities prove the effectiveness of the proposal.	abstract
2020-895	It is better to provide more intuition on why this pretraining phase would help to make the results generalize better and yield better performance.	suggestion
2020-895	The current presentation of the paper mostly consists of detailed descriptions of the proposal training procedure, without some interesting discussions about why this pretraining makes the problem easier.	weakness
2020-895	For instance, I'm interested in seeing with some toy distributions, what is the training progress (measured quantitatively) comparing the proposed method and traditional BicycleGAN.	suggestion
2020-895	Although the results look nice, with the current presentation, there's not much inspiration one could get from the paper.	weakness
2020-895	I encourage the authors to make some adjustments, and I will reconsider the score.	suggestion
2020-895	Summary: The authors propose to use a non-end-to-end approach to the problem of multi-modal I2I.	abstract
2020-895	Firstly, a metric learning problem is solved to embed images into space, taking into account the pairwise style discrepancy (style is defined, e.g., based on VGG Gramians).	abstract
2020-895	As the notion of style is universal for similar datasets, this step further is shown to be generalizable.	abstract
2020-895	Secondly, the generator is trained on a supervised image translation tasks: the original image and the style, extracted from the target image, are fed to the generator, and the output is a translated image.	abstract
2020-895	Thirdly, style encoder and generator are simultaneously finetuned.	abstract
2020-895	Overall, this is an incremental work in the field of supervised I2I.	weakness
2020-895	Questions: 1. Is it true that the proposed approach requires semantically aligned datasets, as the style of the whole image is described with a comparatively low-dimensional vector, and the GAN objective is applied to paired outputs only?	weakness
2020-895	Compare, e.g., with Gramian-based style transfer, where segmentation masks are often desired for better results [1].	weakness
2020-895	2. Can the developed pipeline be generalized to the unsupervised setting, e.g., involving a cycle consistency loss and a non-conditional GAN objective?	weakness
2020-895	To my mind, such generalization can show the greater importance of the described method.	weakness
2020-895	Remarks: 1. Formula (1) is incorrect.	weakness
2020-895	I guess the first term should contain z instead of g.	weakness
2020-895	Otherwise, the encoder parameters are optimized using the regularizer only.	weakness
2020-895	[1] Jaejun Yoo, Youngjung Uh, Sanghyuk Chun, Byeongkyu Kang, Jung-Woo Ha. Photorealistic Style Transfer via Wavelet Transforms.	misc
2020-895	ICCV 2019. In this paper, the authors tackle the problem of multi-modal image-to-image translation by pre-training a style-based encoder.	abstract
2020-895	The style-based encoder is trained with a triplet loss that encourages similarity between images with similar styles and dissimilarity between images with different styles.	abstract
2020-895	The output of the encoder is a style embedding that helps differentiates different modes of image synthesis.	abstract
2020-895	When training the generator for image synthesis, the input combines an image in the source and a style embedding, and the loss is essentially the sum of image conditional GAN loss and perceptual loss.	abstract
2020-895	Additionally, the authors propose a mapping function to sample styles from a unit Gaussian distribution.	abstract
2020-895	I think the idea of pre-training a style-based encoder is straightforward.	strength
2020-895	I am mainly concerned about the performance of the presented approach.	weakness
2020-895	First, there are no many visual comparisons in the paper.	weakness
2020-895	The only visual comparison is in Figure 8, but results are only limited to faces.	weakness
2020-895	The visual results in Figure 5 do not look appealing to me.	weakness
2020-895	The change in the style mainly comes from the global change in color: no much change in the texture or local color.	weakness
2020-895	The "night2day" results look poor to me.	weakness
2020-895	I am concerned about the diversity of the styles learned in the model.	weakness
2020-895	On the other hand, I am convinced that the proposed model is better than BicycleGAN, and the approach is somehow novel.	strength
2020-895	The user study in Table 5 suggests that the proposed method is somehow better than BicyleGAN in visual quality on one task.	strength
2020-895	My overall rating is borderline.	rating_summary
2020-895	Minor comments: - In the first sentence of Section 3.2, I do not think "one-to-one correspondence" is the right description.	weakness
2020-895	The encoder is not expected to be invertible.	weakness
2020-895	- In Equation (3), "e_i" is a little bit misleading.	weakness
2020-895	It does not mean the i-th element in {"e_j"}.	weakness
2020-895	You may want to replace "e_i" with "s_i" to avoid confusion.	weakness
2020-895	- The explanation of ours v1, v2, v3, v4 is not clear.	weakness
2020-895	It is also difficult to find its definition.	weakness

2020-928	This paper investigates a list of methods to reduce the number of weights for deep RL architecture under the low-data regime.	abstract
2020-928	These methods include tensor regression, wavelet scattering, as well as second-order optimization (K-FAC).	abstract
2020-928	The experiments on the Atari games shows that by using tensor regression to replace the dense layer of the neural nets and using K-FAC for the optimization, one can reduce around 10 times of parameters without losing too much of performance.	abstract
2020-928	However, I have some concerns on the novelty of this work and therefore I'm giving this paper a weak reject.	decision
2020-928	Here are the reasons: To begin with, leveraging tensor structure of the neural nets to reduce number of parameters while maintaining similar level or getting even better results have been done before, for example: Tensorizing Neural Networks (Novikov et al, 2015), Learning compact recurrent neural networks with block-term tensor decomposition (Ye et al., 2018) etc.	weakness
2020-928	Although the use of tensor regression might be new, the core idea is still to leverage the low rank property of the tensor and obtain a compression of the weight tensors.	weakness
2020-928	Moreover, why use Tucker decomposition specifically for the tensor regression?	weakness
2020-928	It has been proposed that using tensor train (TT) decomposition can also get very good results (see Garipov et.	weakness
2020-928	al. Ultimate tensorization: compressing convolutional and FC layers alike).	misc
2020-928	Is it possible to investigate the use of TT decomposition for the dense layer of the deep RL architecture?	weakness
2020-928	Therefore the novelty for this aspect seems a bit weak for me.	weakness
2020-928	The second method the authors have attempted is to swap the convolution layer of the deep RL architecture with wavelet scattering.	weakness
2020-928	For one particular game (demon_attack), this approach seems to outperform every other methods by a large margin.	weakness
2020-928	However the experiment shows that for the rest of the Atari games, there is a huge drop (45%) of performance.	weakness
2020-928	Therefore the significance of this approach is rather thin for me.	weakness
2020-928	Maybe some further investigation of the game demon_attack is needed to understand why using scattering in this game in particular gives such a huge performance boost.	suggestion
2020-928	Thirdly, as an approximation of the second order optimization, K-FAC does not really concern with the main theme of the paper, which is an investigation of potential weights reduction methods.	weakness
2020-928	It is great that the authors applied this techniques and seems to have great results.	strength
2020-928	However, as the authors pointed out, K-FAC has been wildly applied in the deep RL literature, and the authors did not propose new extension for the K-FAC method, therefore the contribution of this matter is also quite thin.	weakness
2020-928	Last but not least, the writing of the paper is a bit clumsy, and I was having a hard time to figure out what exactly is the proposed method.	weakness
2020-928	I think this paper might need some rework on the writing to describe the idea of the authors in a more clear way for the publication.	suggestion
2020-928	Due to these reasons, I'm giving this paper a weak reject.	decision
2020-928	Some writing comments and potential writing errors (did not affect the decision): Page 3, first line of "Tensor regression layer", the shape of the tensor X seems to be a typo.	weakness
2020-928	Also here, the definition of <X, Y>_N in the paper is to sum over the dimension of I_1…I_N, then the shape of <X, Y>_N should be K_1*…*K_x*L_1*…*L_y, without the I_N in the middle.	weakness
2020-928	Also in this section, the authors mentioned Tucker decomposition for the tensor regression.	weakness
2020-928	However the phrasing of this sentence needs a bit rework.	weakness
2020-928	The usage of "For instance here", gives the readers a feeling that Tucker is just one possible way of doing this decomposition, but not necessarily the actual decomposition for the reported experiments.	weakness
2020-928	In 2.3, there is a lack of definition for  \\Lambda_1 and \\Lambda_2.	weakness
2020-928	In addition, it would be better for the general readers to add a few definitions for the terminologies in this section.	suggestion
2020-928	For example, "circular convolution", "wavelet filter banks" etc.	suggestion
2020-928	I guess people with corresponding background will understand it with no problem, however I do find myself a bit lost in this section with these terminologies.	weakness
2020-928	2.4 line 6, "with A and.	weakness
2020-928	B smaller, architecture-dependent matrices". I think it should be "with A and B being…"	weakness
2020-928	3.1, line 5, "This is all the more pressing that….", I did not understand this sentence.	weakness
2020-928	In page 6, line 3, there is a lack of definition for "compression rate".	weakness
2020-928	Is it the compression rate w.r.t only the last dense layer, or w.r.t the whole network?	weakness
2020-928	Figure 4 is lacking y-axis and x-axis labels.	weakness
2020-928	4.2, last bullet point, "However, one must not forget that the conv layers one learns must be somehow be well adapted…", I get what you are saying, but the sentence is a bit clumsy.	weakness
2020-928	Table 1 and 2, the row name "Average" is lacking definition.	weakness
2020-928	Overall it is a good attempt to reduce the number of weights in the deep RL architecture, but I do think the novelty of this work is a bit thin and the three contributions were not tied together with the main theme of the paper.	weakness
2020-928	Therefore, I'm giving this work a weak reject.	decision
2020-928	The paper aims at parsimonious reinforcement learning by employing 3	abstract
2020-928	different techniques: using tensor regression layers (Kossaifi et al.,	abstract
2020-928	2017b), wavelet scattering (Mallat 2011) and using K-FAC (Kingma & Ba,	abstract
2020-928	2014) as the optimization method.	abstract
2020-928	Learning models with fewer weights is important not only in reinforcement learning but also in all other machine learning areas.	abstract
2020-928	With the combination of tensor regression layers and K-FAC, the proposed methods give comparable performance on several Atari games against 2 other methods, SimpPLe and data-efficient Rainbow, while using 2 to 10 times fewer coefficients than data-efficient Rainbow.	abstract
2020-928	The use of wavelet scattering provides improvement on 1 out of 26 Atari games.	abstract
2020-928	The paper also points out an interesting concentration of eigenvalues of dense layer of a deep RL agent which provides motivation for low-rank presentations.	abstract
2020-928	While the savings in terms of coefficients is positive, the obtained results are of little surprise.	weakness
2020-928	Tensor regression layers and K-FAC are used as is without any modification while space savings and efficiency have been reported in corresponding references.	weakness
2020-928	The performances of wavelet scattering for the reported tasks are weak (better in only one game) and the space saving is not clear.	weakness
2020-928	The proposed improvements seem to be tailored to tasks with image inputs and hence reported results are only on Atari games (possibly with sparse and low-rank images).	weakness
2020-928	It is not clear if the proposed techniques can be applied to a wider set of reinforcement learning tasks	weakness
2020-928	(e.g. https://gym.openai.com/envs/#mujoco). It would be interesting to see if we can apply the proposed methods to other more diverse RL tasks.	suggestion
2020-928	The performance of wavelet scattering does indeed need more investigation and improvement.	suggestion
2020-928	It would also be interesting to compare the distributions of the eigenvalues of the tensor layers versus the dense layers in deep RL which may provide insights on the achieved savings and the compression trade-off.	suggestion
2020-928	I have read  the authors' rebuttals.	misc
2020-928	The reviews point to a number of directions where the contributions could be made more significant.	weakness
2020-928	This paper suggests three different disconnected ideas for improving the number of parameters of deep vision models for playing ATARI and to improve the training speed.	abstract
2020-928	- Tensor-regression layer to replace fully connected layers	abstract
2020-928	- Wavelet-scattering layer to replace the first convolutional layer	abstract
2020-928	- Second order optimization (K-FAC)	misc
2020-928	All the ideas mentioned in this paper are existing ones (although properly attributed), so the novelty of this work is relatively low.	weakness
2020-928	The paper mentions that this particular combination is "novel", but it is not clear is there is any significant synergy between these methods and why it should be considered interesting in this particular setup.	weakness
2020-928	Also the paper conflates sample-efficiency with parameter-efficiency.	weakness
2020-928	However, there is no indication that any of these methods address sample-efficiency which would be an interesting and useful contribution.	weakness
2020-928	Also the experiments are neither very conclusive nor are they easy to interpret.	weakness
2020-928	For example in the pong case, there is no discernable effect of the compression ratio as the highest and lowest compression give the best (and comparable) results.	weakness
2020-928	Also the results come without confidence intervals.	weakness
2020-928	So, in general, I would consider this paper to be an uninspired combination of pre-existing ideas with weak and inconclusive experimental results: a clear reject.	decision

2020-943	This work discusses how to set the projection size for each head (head size) in multi-head attention module, especially Transformer.	abstract
2020-943	Theorem 1 is interesting, which points out a lower bound for the head size.	abstract
2020-943	The proposed method is to decouple the dependency between the head size and the embedding size.	abstract
2020-943	The experiments show that the proposed method is able to achieve comparable performance to BERT with fewer training cost.	abstract
2020-943	The lower bound for the head size is a valuable result.	abstract
2020-943	However, the novelty is very limited.	weakness
2020-943	To decouple the dependency between the head size and the embedding size is not a novel point.	weakness
2020-943	In BERT/Transformer, it is set d_q=d_k=d_v=d, which is not a strict constraint.	weakness
2020-943	The only constraint in attention is to have d_q=d_k to allow dot product.	weakness
2020-943	Therefore, the proposed method is more like a tuning of hyper-parameters.	weakness
2020-943	This work studies the head size <--> head number tradeoff in multihead attention.	abstract
2020-943	It argues and formally establishes that (1) the expressivity of an attention head is determined by its dimension and (b) fixing the head dimension, one gains additional expressive power by using more heads.	abstract
2020-943	In response to such observations, the paper proposes Fixed Multihead Attention, where the constraint that `head_size * number_of_heads = embedding_size` in standard multihead attention is lifted; and it allows for using more attention heads without making each head smaller.	abstract
2020-943	One can control the total amount of parameters by using smaller embedding sizes, making it comparable (in terms of #parameters) to standard multihead attention.	abstract
2020-943	Empirical results on language modeling and NLI tasks confirms the arguments.	abstract
2020-943	Pros: - The arguments on head size and head number tradeoff could be inspiring to future works.	strength
2020-943	- A simple approach that proves strong in several NLP tasks.	strength
2020-943	Cons: - The theoretical discussion imposes too strong assumptions that might make it less interesting in practice.	weakness
2020-943	- No NMT experiments. - The takeaway seems a bit trivial.	weakness
2020-943	Details: - Theorem 1 presents a rank-based view of each attention head's capacity, which is nice.	strength
2020-943	Yet it is still unclear whether it is the case that the more expressive are the heads the better.	weakness
2020-943	For example, several recent works argues for specialized attention heads, i.e., each head has specific "job," which may not require it being very expressive [1, 2].	weakness
2020-943	Further, other works shows that a low-rank P matrix could be beneficial [3, 4, 5], which contradicts the argument in this work.	weakness
2020-943	It would be nice if the authors and discuss this in the revision	suggestion
2020-943	(To be clear, I do believe this is still an open question, and do not think presenting a different view from previous works hurts the contribution of this work in any way.)	ac_disagreement
2020-943	- Theorem 2. I didn't carefully check the proof.	weakness
2020-943	Why is it required that the V matrices for each head have the same product.	weakness
2020-943	For both Thm.1 and 2, it would be nice to see some discussion on how they translate into the models in practice.	suggestion
2020-943	- Can the authors compare the training/inference speed?	suggestion
2020-943	It probably will be the same as standard transformers, but it would be nice to confirm.	weakness
2020-943	- Figure 1: the caption says trying out embedding sizes from 256 to 512.	weakness
2020-943	But it seems that only 4 values are tried.	weakness
2020-943	Can the authors comment on this?	suggestion
2020-943	Also, it is a bit awkward to plot a line chart out of 4 points.	suggestion
2020-943	Same for Figure 2. - It would be nice to see some NMT experiments.	suggestion
2020-943	- The proposed method is so straightforward that I'm actually very surprised that this paper is the first trying this.	strength
2020-943	The authors might need justify the technical contribution more.	weakness
2020-943	(I'm on the fence for this one, but the system doesn't allow me to.	weakness
2020-943	I'm happy to revise the score if the authors can address my concerns.)	decision
2020-943	[1] Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned.	misc
2020-943	https://arxiv.org/abs/1905.09418 [2] Are Sixteen Heads Really Better than One?	misc
2020-943	https://arxiv.org/abs/1905.10650 [3] Generating Long Sequences with Sparse Transformers.	misc
2020-943	https://arxiv.org/abs/1904.10509 [4] Generating Long Sequences with Sparse Transformers.	misc
2020-943	https://arxiv.org/pdf/1904.10509.pdf. [5] Adaptively Sparse Transformers. https://arxiv.org/abs/1909.00015.	misc
2020-943	This paper proposes a "concise" version of the well-established Transformer model.	abstract
2020-943	The main proposal is to explicitly set the head size in the Transformer model instead of having to divide (share) representation ability amongst heads.	abstract
2020-943	This paper is poorly written and after an entire 2-page long-winded introduction, the reader is left wondering what is the main contribution of this work.	weakness
2020-943	The term "concise" is also not well-defined and left vague to readers.	weakness
2020-943	I re-read this paper multiple times and the only concluding finding I have is that this paper proposes an explicit way of setting the projection dimension regardless of the number of heads.	weakness
2020-943	After many mathematical formulations, theorems (seemingly ornamental, or handwavy actually), the final contribution seems to be to set the head size of BERT (size of each head) to 128.	weakness
2020-943	This is really trivial. The authors kept teasing a "different" way to do this, but this left the reader completely unsatisfied when the different way refers to explicitly setting each head to 128 and using a smaller model overall.	weakness
2020-943	The value 128 is derived from a theorem derived by the authors, which suggests that each head should at least be greater or equal than the sequence length (the sequence length here stated by the authors is 128).	weakness
2020-943	I'm not very convinced by the argument.	weakness
2020-943	While it is intuitive that each head has to be sufficiently large, being under-sized can be made up for with multiple heads.	weakness
2020-943	It is also not clear why every X and P must be expressed with transforms W_q and W_k.	weakness
2020-943	P here represents the affinity matrix between tokens in a sequence.	weakness
2020-943	It does not make any sense to me to ensure that every variation of P can be expressed because P is literally the pairwise scores between every token in the fully-connected attention graph.	weakness
2020-943	While I did not have the luxury of time to parse the Appendix to validate the legitimacy of the proof, I think the overall shortcomings of the paper (highly non-readable, bad presentation and perhaps a fair attempt at masking the lack of contribution) warrants a clear reject from me.	decision

2020-1002	In this work the authors studied the robust reinforcement learning problem in which the constraint on model uncertainty is captured by the Wasserstein distance.	abstract
2020-1002	Inspired by the analysis in the distribution-ally robust setting, they derived several sensitivity conditions to study how the radius of the wasserstein ball and the order of the wasserstein distance affect the conservativeness in model uncertainty.	abstract
2020-1002	Similar to the robust MDP work, they also show that this robust RL problem has a robust optimal Bellman operator, and the optimal value function can be computed using  robust policy iteration, which can be extended to model-free actor critic algorithm when state/action spaces are large/continuous.	abstract
2020-1002	This work extends the wasserstein uncertainty modeling  to the robust MDP setting.	abstract
2020-1002	However, I found the contribution rather limited/unclear.	weakness
2020-1002	First, the proposed robust Bellman optimality result is standard and can be found in many robust MDP work when the uncertainty set is state-action rectangular.	strength
2020-1002	The major novel part here is therefore the sensitivity analysis that is specifically tied to wasserstein distance, which has limited novelty.	weakness
2020-1002	Second, the robust actor critic algorithm is based on a multi-time scale minimax gradient approach, which is also quite standard in this field, and besides asymptotic convergence it is unclear how efficient this algorithm is.	weakness
2020-1002	Third, the experiment in this paper is very limited (only based on cartpole, and is only compared with the non-robust AC algorithm) and its illustration on the effectiveness of this algorithm is rather limited.	weakness
2020-1002	More comparisons with other robust MDP methods would be useful to understand how the value of the proposed wasserstein robust RL formulation.	suggestion
2020-1002	Summary: In this paper, the authors study the problem of robust MDP (RMDP), where the feasibility set is defined as a Wasserstein ball around the reference transition probability.	abstract
2020-1002	After formulating the problem, they first prove the contraction of the resulting operator and the existence of a deterministic stationary Markov optimal policy (Sec. 2.3).	abstract
2020-1002	Then, they provide a sensitivity analysis of the optimal value function w.r.t. the radius and order of the Wasserstein ball (Sec. 2.4).	abstract
2020-1002	Finally, they propose an actor-critic algorithm to solve the Wasserstein RMDP problem (Sec. 3) and evaluate its performance using simple experiments (Sec. 4).	abstract
2020-1002	Comments: - Section 2.3, which the authors call it Main Result, is not that novel.	weakness
2020-1002	The Wasserstein RMDP is just a state-action-rectangular RMDP with convex ambiguity set, and Lemma 1 and Theorem 1 are known to be true for such RMDPs.	weakness
2020-1002	- The sensitivity analysis section (Sec. 2.4) is interesting and useful, although it could have been written much better.	strength
2020-1002	- The algorithm is new, although its section (Sec. 3) is not well-written.	strength
2020-1002	There is no analysis for the convergence of the algorithm either.	weakness
2020-1002	It is a multi-time-scale stochastic approximation algorithm.	weakness
2020-1002	Similar policy gradient and actor-critic algorithms have been derived in risk-sensitive MDPs for mean-variance, mean-VaR, and mean-CVaR optimization (see the references below), but such algorithms for RMDPs is relatively new.	weakness
2020-1002	- The experimental results are very simple and not very convincing.	weakness
2020-1002	- I would suggest that the authors put their emphasis on the algorithm and try to explain it much better.	suggestion
2020-1002	And support it better with more comprehensive and convincing experimental results.	suggestion
2020-1002	This would definitely improve the quality of the paper.	suggestion
2020-1002	References on risk-sensitive MDPs: 1) A. Tamar, D. Di Castro, and S. Mannor.	suggestion
2020-1002	"Policy Gradients with Variance Related Risk Criteria".	misc
2020-1002	ICML-2012. 2) Prashanth L.A. and M.	misc
2020-1002	Ghavamzadeh. "Actor-Critic Algorithms for Risk-Sensitive MDPs".	misc
2020-1002	NIPS-2013. 3) Y. Chow and M. Ghavamzadeh.	misc
2020-1002	"Algorithms for CVaR Optimization in MDPs".	misc
2020-1002	NIPS-2014. 4) A. Tamar, Y. Glassner, and S. Mannor.	misc
2020-1002	"Optimizing the CVaR via Sampling".	misc
2020-1002	AAAI-2015. 5) A. Tamar, Y. Chow, M. Ghavamzadeh, and S. Mannor.	misc
2020-1002	"Policy Gradient for Coherent Risk Measures".	misc
2020-1002	NIPS-2015. This work aims to produce reinforcement learning methods that are 'distributionally robust'.	abstract
2020-1002	They approach this by assuming the transition function may vary between elements of the domain distribution and extend some recent results (Blanchet & Murthy, 2019) to give some theoretical results (contraction and optimal deterministic policy) and an actor-critic algorithm.	abstract
2020-1002	This is an important research area and the work takes a very nice approach.	strength
2020-1002	However, the clarity of the work and the empirical results could both use some work.	weakness
2020-1002	There are a great many grammatical errors throughout the paper.	weakness
2020-1002	The nature of the errors suggests a non-native speaker, which I really do not want to discourage, but this needs a proofread and edit.	weakness
2020-1002	One exception, there is an actual typo just after assumption 1 "dfnied", but actually better grammatically to just remove the word entirely.	weakness
2020-1002	In the intro, the citation of Mannor et al. 2004; 2007 for what is essentially a description of the gap between simulation to real transfer is a very strange choice.	weakness
2020-1002	Is it possible this was a mistake?	weakness
2020-1002	The description leading up to the main result could be made much clearer.	weakness
2020-1002	I went through this section, the main results, and the proofs in the appendix.	misc
2020-1002	Things look good, although I do feel like (as just said) it could be made much better/clearer.	weakness
2020-1002	One snag I hit was in the proof of Lemma 1, everything is good except I don't know why "u_1 \\le u_2 + \\gamma \\| u_1 - u_2 \\|_\\infty" must hold, but I might have simply missed something obvious so please help me out.	weakness
2020-1002	The experimental results are very minimal and not very convincing.	weakness
2020-1002	It is not immediately clear to me that Figures 1&2 actually show that the robustac algorithm is more robust than ac.	weakness
2020-1002	The performance is worse than ac, which is completely understandable, but for most of the environments ac is still significantly better.	weakness
2020-1002	Lastly, a small point to notice that this paper bleeds into the 9th page, and considering the amount of contributions (largely down to the two theoretical results and a very small experiment) I do not think the extra space is warranted.	weakness
2020-1002	This could be compressed and actually come out stronger as a result of being forced to be clearer and more concise.	weakness
2020-1002	Update: Thank you for your response, especially the fix to the proof.	rebuttal_process
2020-1002	I will keep my score, but do believe that further experiments and small adjustments to the writing will see a future version of this accepted.	decision

2020-1033	The main contributions of the submission are: 1. A comprehensive empirical comparison of deep learning optimizers, with their performance compared under different amount of hyper-parameter tuning (they perform hyper-parameter tuning using random search).	strength
2020-1033	2. The introduction of a novel metric that tries to capture the "tunability" of an optimizer.	strength
2020-1033	This metric attempts to trade off the performance of an optimizer when tuned only with a small number of hyper-parameter trials, and its performance when carefully tuned.	strength
2020-1033	The metric is defined as a weighted average of the performance after tuning with i random trials, with i that goes from 1 to K.	strength
2020-1033	The weights of this weighted average and K are "hyper-parameters" of the metric itself.	strength
2020-1033	They use K=100 and suggest 3 possible choices of weights.	strength
2020-1033	The paper appears to treat 2.	strength
2020-1033	as the main contribution. However, I do not think the metric they introduce is good enough to be recommended in future work, when comparing tunability of optimizers (or other algorithms with hyperparameters).	weakness
2020-1033	The reason is that simpler methods provide just as much information, and do not rely on the need of interpreting the choice of the weights and K.	strength
2020-1033	This point is proven in the paper itself, where for example Figure 2 provides a more concrete and easier to interpret information than the tunability metric, similar graphs could be easily provided per dataset.	strength
2020-1033	Similarly, figure 3 as well as figures 5-7 and 8 in the appendix provide very good information about the tunability of the various optimizers without using the introduced metrics.	strength
2020-1033	Information similar (although not identical) to that summarized in table 5 could be captured by substituting the 3 metrics with the best performance after tuning for 4, 16 and 64 iterations respectively (just as examples).	strength
2020-1033	A stronger contribution is 1., which however is somewhat incremental compared to similar comparisons made in the past.	weakness
2020-1033	Comparisons which, while mentioned, should perhaps have been discussed and compared more in detail in this work.	weakness
2020-1033	Overall, I do not feel the comparisons dramatically change the qualitative understanding the field has of the different optimizers and their tunability.	weakness
2020-1033	They also suggest that when the tuning budget is low, using Adam but tuning only the learning rate is beneficial, which could be a valuable and practical suggestion.	weakness
2020-1033	I enjoyed reading the submission, which is very clearly written, but due to the relatively limited value of the contributions, and excessive focus on the tunability metric which I do not feel is giustified, I slightly lean against acceptance here at *CONF*.	decision
2020-1033	I do think, however, that it would make a great submission to a smaller venue or workshop.	decision
2020-1033	Other comments/notes: * One aspects that is mostly left out of the discussion (except from one side comment) is the wallclock time, as some optimizers might be on average quicker to train (for example due to quicker convergence), this can easily lead it to be quicker to tune even though it requires a higher budget of trials.	weakness
2020-1033	I think it would be worth discussing this more.	weakness
2020-1033	* minor: in figure 8 in the appendix, the results after 100 iterations is, as far as I understand, over a single replication, so is not particularly reliable (and will always be 100% of a single optimizer)	weakness
2020-1033	* similarly to the above, if the configurations are always sampled from the same 100, confidence intervals in the graphs become less reliable as the budget increases.	weakness
2020-1033	This paper introduces a simple measure of tunability that allows to compare optimizers under varying resource constraints.	abstract
2020-1033	The tunability of the optimizer is a weighted sum of best performance at a given budget.	abstract
2020-1033	The authors found that in a setting with low budget for hyperparameter tuning, tuning only Adam optimizer's learning rate is likely to be a very good choice; it doesn't guarantee the best possible performance, but it is evidently the easiest to find well-performing hyperparameter configurations.	abstract
2020-1033	Comments: The paper is easy to follow.	strength
2020-1033	The motivation of defining tunability of optimizer is a very interesting question, however, the study seems to preliminary and the conclusion is not quite convencing due to several reasons: In section 3.2, to characterize its difficulties of finding best hyperparameters or tunability, the authors seem to try to connect the concept of "sharpness" of a minima in loss surface to the tunability of an optimizer, which is similar to comparing the loss landscape of minimums.	weakness
2020-1033	However, while the authors made intuitive explanation about the tunability in section 2.2, I did not see the actual plot of the true hyperpaparameter loss surface of each optimizer to verify these intuitions.	weakness
2020-1033	Can the author be more specific about the x-axis in the illustration 1.a and 1.b?	suggestion
2020-1033	If I understand correctly, they are not the number of trails.	weakness
2020-1033	In addition, the proposed stability metric seems not quite related with the above intuitions, as the illustrations (1.a and 1b) define the tunability to be the flatness of hyperparameter space around the best configurations, but the proposed definition is a weighted sum of the incumbents in terms of the HPO budgets.	weakness
2020-1033	The definition of the tuning budgets is not clear, is it the number of trials or the time/computation budgets?	weakness
2020-1033	The authors seems interchangeably using "runs" and "iterations", which makes the concept more confusable.	weakness
2020-1033	The authors further proposed three weighting schemes to emphasize the tunability of different stage of HPO.	weakness
2020-1033	My concern is that is highly dependent  on the order of hyperparameter searched, which could impact the tunability significantly.	weakness
2020-1033	For instance, in case of grid search HPO and 0.1 is the best learning rate, different search order such as [10, 1, 0.01, 0.1] and [0.1, 0.01, 1, 10] could results in dramatic different CPE and CPL.	weakness
2020-1033	My major concern is the hyperparameter distributions for each optimizer highly requires prior knowledge.	weakness
2020-1033	A good prior of one optimizer could significantly affect the HPO cost or increase the tunability, i.e., the better understanding the optimizer, the less tuning cost.	weakness
2020-1033	My major concern is that the authors assume the hyperparameters to be independent (section 3.2), which is not necessarily true.	weakness
2020-1033	Actually hyperparameters are highly correlated, such as momentum, batch size and learning rate are correlated in terms of effective learning rate [1,2], so as weight decay and learning rate are [3], which means using non-zero momentum is equivalent to using large learning rate as long as the effective learning rate is the same.	weakness
2020-1033	This could significantly increase the tunability of SGDM.	weakness
2020-1033	Another concurrent submission [4] verified this equivalence and showed one can also just tune learning rate for SGDM.	weakness
2020-1033	The assumption of independent hyperparameters might be fine for black box optimization or with the assumption that practitioners have no knowledge of the importance of each hyperparameter, then the tunability of the optimizer could be different based on the prior knowledge of hyperparameter and their correlations.	weakness
2020-1033	But it is not rigorous enough to make the conclusion that Adam is easier to tune than SGD.	weakness
2020-1033	The author states their method to determine the priors by training each task specified in the DEEPOBS with a large number of hyperparameter samplings and retain the hyperparameters which resulted in performance within 20% of the best performance obtained.	weakness
2020-1033	Could the authors be more specific on the hyperparameters searched?	weakness
2020-1033	Is this process counted in the tunability measurement?	weakness
2020-1033	[1] Smith and Le, A Bayesian Perspective on Generalization and Stochastic Gradient Descent, https://arxiv.org/abs/1710.06451	misc
2020-1033	[2] Smith et al, Don't Decay the Learning Rate, Increase the Batch Size, https://arxiv.org/abs/1711.00489	misc
2020-1033	[3] van Laarhoven et al, L2 Regularization versus Batch and Weight Normalization, https://arxiv.org/abs/1706.05350	misc
2020-1033	[4] Rethinking the Hyperparameters for Fine-tuning https://openreview.net/forum?id=B1g8VkHFPH	misc

2020-1038	[Overview] In this paper, the authors proposed a shuffle strategy for convolution layers in convolutional neural networks (CNNs).	abstract
2020-1038	Specifically, the authors argued that the receptive field (RF) of each convolutional filter should be not constrained in the small patch.	abstract
2020-1038	Instead, it should also cover other locations beyond the local patch and also the single channel.	abstract
2020-1038	Based on this motivation, the authors proposed a spatial shuffling layer which is aimed at shuffling the original feature responses.	abstract
2020-1038	In the experimental results, the authors evaluated the proposed ss convolutional layer on CIFAR-10 and ImageNet-1k and compared with various baseline architectures.	abstract
2020-1038	Besides, the authors further did some ablated analysis and visualizations for the proposed ss convolutional layer.	abstract
2020-1038	[Pros] 1. The authors proposed a new strategy for convolutional layers.	strength
2020-1038	The idea is borrowed from the biological domain, and then transformed to a spatial shuffling layer which can shuffle the feature response at each convolutional layer.	strength
2020-1038	2. The authors performed experiments on both small-scale dataset (CIFAR-10) and large-scale data (CIFAR-100) for evaluations.	strength
2020-1038	3. The authors further added some ablated analysis on the proposed model.	strength
2020-1038	Specifically, the authors visualize the receptive field which can be used in ss layer compared with the original convolutional layer, which indicates that ss layer can incorporate the global context at the very beginning.	strength
2020-1038	[Cons] 1. The motivation behind the proposed ss layer is not explained very well.	weakness
2020-1038	Though the authors mentioned that it is biologically inspired, I would not buy that since it is still a unclear phenomenon, and even it is true, using a randomized shuffling seems not align with the observations to some extent.	ac_disagreement
2020-1038	2. The paper is poorly written in general.	weakness
2020-1038	The motivation behind the proposed method, and the presentation of method section part are cluttered much.	weakness
2020-1038	In the model analysis in experiment section, the presentation and explanations are also vague and not clear to me.	weakness
2020-1038	3. The proposed model seems increase the baseline models' performance very marginally on all architectures.	weakness
2020-1038	It is hard to say that it is because the shuffling layer enable the neurons to incorporate the global context information.	weakness
2020-1038	Instead, it might just because the randomization which would increase the generalization ability of the trained model.	weakness
2020-1038	4. Finally, the comparison with previous models, such as SENet, ShuffleNet, etc are not systematically.	weakness
2020-1038	I would like to see a more comprehensive summarization of the differences between the proposed ss layer and other architectures, because all of them are trying to incorporate more contextual information from other channels or locations.	weakness
2020-1038	[Summary] Overall, I think the proposed ss layer is still a reasonable way to incorporate the contextual information in CNNs. However, the poor presentation and the weak experimental results and analysis make the paper overall a one under the bar of the venue.	decision
2020-1038	I would suggest the authors revise the paper with more well-motivated formula and more solid experiments and analysis in the next submission.	suggestion
2020-1038	This paper proposes a simple "spatial shuffling" operation for modifying CNNs based on a permutation matrix created at initialization time.	abstract
2020-1038	The approach is motivate by a very high-level discussion of biological brains.	abstract
2020-1038	Improvements are claimed on Cifar10 but results are not near the state of the art.	weakness
2020-1038	The results do seem to improve incrementally over the previous vanilla results on the particular architecures on which they are applied.	weakness
2020-1038	The authors dedicate some space to a qualitative analysis of why the models improve although it is at best intuition-y.	weakness
2020-1038	In the end I'm left with inconclusive results, a weakly motivated story,	weakness
2020-1038	and a paper that despite exceeding the page limit by a page lacks information density.	weakness
2020-1038	Minor: Convolutional neural networks achieve … "elegant performance in computer vision tasks"	misc
2020-1038	>>>  wrong adjective. Summary: The authors extended the regular convolution and proposed spatially shuffled convolution to use the information outside of its RF, which is inspired by the idea that horizontal connections are believed to be important for visual processing in the visual cortex in biological brain.	abstract
2020-1038	The authors proposed ss convolution for regular convolution and group convolution.	abstract
2020-1038	The authors tested the proposed ss convolution on multiple CNN models and show improvement of results.	abstract
2020-1038	Finally, detailed analysis of spatial shuffling and ablation study was conducted.	abstract
2020-1038	Strengths: The authors proposed spatially shuffled convolution to use the information outside of its RF.	strength
2020-1038	The operation only requires small amount of extra shuffling operations and without extra learnable parameters.	strength
2020-1038	The idea is straightforward and easy to understand.	strength
2020-1038	I especially like the visualization analysis of the receptive field and the layer ablation study suggested that all layers can benefit from the proposed operation, though more for middle and higher layers.	strength
2020-1038	Weakness: The proposed method seems to be a reasonable alternative for regular convolution, but  By fixing the permutation, not much insight is gained from this technique.	weakness
2020-1038	Suggestions: It would be good to include the standard deviation for the results as the final results were average of 5 runs and can help to see if it's consistently useful.	suggestion
2020-1038	In the current setting, the permutation matrix is generated randomly, considering the proposed method is based on shuffling, how would different permutation affect the performance?	suggestion
2020-1038	In addition, I think it could be helpful if the authors can show more utilities of the proposed method, for example, are the proposed method capable of doing tasks similar to this paper **Learning long-range spatial dependencies with horizontal gated recurrent units**, which argues that the ability of CNNs to learn long-range spatial dependencies is limited by their localized receptive fields.	suggestion
2020-1038	One minor thing, in the main paper, the abbreviation for spatial shuffled convolution (ss convolution) is mentioned multiple times.	weakness

2020-1087	The paper suggests to use temperature scaling in adversarial attack design for improving transferability under black-box attack setting.	abstract
2020-1087	Based on this, the paper proposes several new attacks: D-FGSM, D-MIFGSM, and their ensemble versions.	abstract
2020-1087	Experimental results found that the proposed methods improves transferability from VGG networks, compared to the non-distillated counterparts.	abstract
2020-1087	In overall, I liked its novel motivation and simplicity of the method, but it seems to me the manuscript should be improved to meet the *CONF* standard.	decision
2020-1087	Firstly, the presentation of the method is not that clear to me.	weakness
2020-1087	The mathematical notations are quite confusing for me as most of them are used without any definitions.	weakness
2020-1087	I am still not convinced that the arguments in Section 3.1 and 3.2 are indeed relevant to the actual practice of black-box adversarial attacks, which usually includes extremely non-smooth boundaries with multiple gradient steps.	weakness
2020-1087	Even though the experiments show effectiveness partially on VGGNets, but the overall improvements are not sufficient for me to claim the general effectiveness of the method unless the paper could provide additional results on broader range of architectures and  threat models.	weakness
2020-1087	- I feel Section 2.3 is too subjective with vague statements.	weakness
2020-1087	The following statement was particularly unclear to me: "The first problem with gradient based methods is that they lose their effectiveness after a certain number of iterations.": Does the term "effectiveness" indicate some relative effectiveness compared to other methods, e.g. optimization-based attacks?	weakness
2020-1087	Is this really a general phenomenon in gradient-based attacks?	weakness
2020-1087	Also, please elaborate more on "So, insufficient information acquisition for different categories and premature stop of gradient update are the reasons ..."	weakness
2020-1087	- Regarding that the softmax is the problem, one could try to directly minimize the logit layers skipping the softmax, i.e., gradient on logits?	suggestion
2020-1087	This is actually one of common techniques and there are many simple tricks in the context of adversarial attack, so the paper may include comparisons with such of tricks as well.	suggestion
2020-1087	- It is important to specify the exact threat model used throughout the experiments, e.g. perturbation constraints and attack details.	weakness
2020-1087	Demonstrating the effectiveness on a variety of threat models could also strengthen the manuscript.	suggestion
2020-1087	- Table 1 and 2 may include other baseline (black-box attack) methods for comparison.	suggestion
2020-1087	This would much help to understand the method better.	suggestion
2020-1087	This paper proposes distillation attacks to generate transferable targeted adversarial examples.	abstract
2020-1087	The technique itself is pretty simple: instead of only using the raw logits L(x) to compute the cross entropy loss for optimization, they also use the distilled logits L(x)/T to generate adversarial examples.	abstract
2020-1087	Their evaluation setup largely follows the style of Liu et al., but they construct a different subset of ILSVRC validation set, and some of the model architectures in their ensemble are different from Liu et al. Their results show that by including the distilled logits when computing the gradient, the generated adversarial examples can transfer better among different models using both single-model and ensemble-based attacks.	abstract
2020-1087	I think their proposed attack is interesting due to its simplicity and effectiveness.	strength
2020-1087	However, I would like to see clarification of some evaluation details, as well as more experiments to compare with Liu et al.: 1. To assess the effectiveness of targeted attacks, it is important to ensure that the semantic meaning of target label is far from the ground truth label.	suggestion
2020-1087	Some of the 1000 ImageNet labels have very similar meanings to each other, thus different choices of the target label would dramatically affect the difficulty of the attacks.	suggestion
2020-1087	In Liu et al., they manually inspect the image-target pairs to ensure that the target label is very different from the ground truth in its meaning.	suggestion
2020-1087	To enable a fair comparison, it would be helpful to provide results on the same image-target pairs constructed by Liu et al., which could be found in the public repo linked in their paper.	suggestion
2020-1087	2. For ensemble attacks, is including both the raw and the distilled logits crucial in obtaining a good performance?	suggestion
2020-1087	What is the performance of including distilled logits only?	suggestion
2020-1087	How do different values of \\lambda_1 and \\lambda_2 in (8) affect the attack performance?	suggestion
2020-1087	3. Could you visualize some generated adversarial examples, so that we can view the qualitative results?	suggestion
2020-1087	4. In general this paper lacks empirical analysis on why distillation helps improve the transferability.	weakness
2020-1087	Some more discussion would be helpful.	suggestion
2020-1087	------------- Post-rebuttal comments Thanks for your response!	misc
2020-1087	I think this paper still misses a more in-depth analysis, and thus I keep my original assessment.	weakness
2020-1087	------------- This paper proposes an attack method to improve the transferability of targeted adversarial examples.	abstract
2020-1087	The proposed method uses a temperature T to convert the logit of the network, and calculates the gradient based on the new logit, yielding the distillation-based attack method.	abstract
2020-1087	It has been integrated into FGSM and MI-FGSM.	abstract
2020-1087	Overall, this paper has the poor quality based on the writing, presentation, significance of the algorithm, insufficient experiments.	weakness
2020-1087	The detailed comments are provided below.	misc
2020-1087	1. The writing of this paper is poor.	weakness
2020-1087	There are a lot of typos in the paper.	weakness
2020-1087	The notations are used without definitions.	weakness
2020-1087	These make the paper hard to read and understand.	weakness
2020-1087	2. Based on my understanding of the paper, the motivation of the proposed method is that the softmax function on top of neural networks can make the gradient unable to accurately penetrate classification boundaries.	weakness
2020-1087	And the distillation-based method is proposed to reduce the magnitude of the logits to make the gradient more stable.	weakness
2020-1087	However, if the argument were true, we could use the C&W loss to perform the attack, which is defined on the logit layer without affected by the softmax function.	weakness
2020-1087	3. There are a lot of recent attack methods proposed to improve the transferability of adversarial example, e.g., "Improving transferability of adversarial examples with input diversity" (Xie et al., 2019); "Evading defenses to transferable adversarial example by translation-invariant attacks" (Dong et al., 2019).	weakness
2020-1087	The authors are encouraged to compare the proposed methods with previous works.	suggestion

2020-1095	In this paper, the authors propose a new adaptive gradient algorithm AdaX, which the authors claim results in better convergence and generalization properties compared to previous adaptive gradient methods.	abstract
2020-1095	The paper overall is fairly clear, although the writing can be improved in places.	strength
2020-1095	Section 3 is interesting, although calling the section the "nonconvergence of Adam" is a bit misleading, since the algorithm does converge to a local minimum.	strength
2020-1095	I have some concerns about the rest of the paper however.	misc
2020-1095	I am a bit confused about the changes proposed to Adam that gives rise to the AdaX algorithm.	weakness
2020-1095	1. Won't replacing beta2 with 1+beta2 keep increasing the magnitude of the denominator of the algorithm just like AdaGrad does?	weakness
2020-1095	In that case, is the algorithm expected to work better when having sparse gradients?	weakness
2020-1095	2. I also do not quite understand how to interpret using a separate hyperparameter for the momentum term (ie the beta3 hyperparameter that is introduced).	weakness
2020-1095	How is beta1 and beta3 related?	weakness
2020-1095	The numerator loses the interpretation of momentum, i.e., averaged past gradients, when using a separate beta3 parameter, and this does not feel like a principled change.	weakness
2020-1095	I have a number of questions about the experiments as well, which makes it hard for me to interpret the significance of the empirical results presented: 1. What is the minibatch size used?	weakness
2020-1095	Do any of the conclusions presented change if the minibatch size is changed?	weakness
2020-1095	2. Is the learning rate tuned?	weakness
2020-1095	The authors mention the initial learning rate used for the experiments, but it is not clear why those values are used?	weakness
2020-1095	Was the same initial learning rate used for all algorithms?	weakness
2020-1095	3. Were the beta1, beta2 and beta3 values tuned for AdaX?	weakness
2020-1095	What about beta1 and beta2 for Adam?	weakness
2020-1095	What are the optimal values of these parameters that were observed?	weakness
2020-1095	4. How sensitive is performance to the values of these hyperparameters?	weakness
2020-1095	Overall I think this work requires quite a bit of work before it is ready for publication, and would benefit from a much more thorough empirical evaluation of the algorithm.	decision
2020-1095	================================== Edit after rebutall: I thank the authors for their response.	misc
2020-1095	While the paper has definitely improved in the newer draft, after having read the other reviews and the updated draft, I believe the paper still requires a bit of work before being ready for publication.	decision
2020-1095	I am sticking to my score.	decision
2020-1095	This paper points out that existing adaptive methods (especially for the methods designing second-order momentum estimates in a exponentially moving average fashion) do not consider gradient decrease information and this might lead to suboptimal convergences via simple non-cvx toy example.	abstract
2020-1095	Based on this observation, the authors provide a novel optimization algorithm for long-term memory of past gradients by modifying second-order momentum design.	abstract
2020-1095	Also, they provide aconvex regret analysis and convergence analysis for non-convex optimization.	abstract
2020-1095	Finally, the authors evaluate their methods on various deep learning problems.	abstract
2020-1095	Significance/Novelty: While there have been many studies on non-convergence of Adam, raising an issue on ignoring the gradient decrease information seems novel.	strength
2020-1095	Pros: 1. The motivating toy example in Section 3 is useful for readers to get intuitions.	strength
2020-1095	2. By introducing long-term memory on past-gradients, the authors fix the Adam's issues and they can also improve the convergence rate in a non-convex optimization (Corollary 4.2).	strength
2020-1095	3. Empirical studies show superiority to original Adam (Section 5).	strength
2020-1095	Cons: While they provide a significant study on Adam's failure and a novel optimization algorithm, I have several concerns: 1. What is default hyperparameters for AdaX in Algorithm 1?	weakness
2020-1095	Is it the same as AdaX-W (Algorithm 3) in Appendix?	weakness
2020-1095	The bias correction term in the line 7 of Algorithm 1 will be very large even with small β2 since it is expoential (For example, (1 + 0.0001)^(100000) ~ 20000 for β2 = 10^(-4)).	weakness
2020-1095	So, it is not clear that the second momentum estimate of Ada-X is really stable.	weakness
2020-1095	For this, it would be interesting to see how the trajectories of second-order momentum estimates of Adam, AMSGrad, Ada-X are different.	weakness
2020-1095	I think this will help to understand Ada-X better.	weakness
2020-1095	2. In terms of theory, I think the Lemma 4.1 is inevitable for convergence guarantees in Theorem 4.1 and Theorem 4.2.	weakness
2020-1095	Although the authors effectively remove log T in the numerator in Corollary 3.2 of Chen et al. (2019) using their lemma 4.1 (I think this is the key point), the assumption that β2t=β2/t seems quite strong, and original Adam paper has no such assumptions.	weakness
2020-1095	For a real deep learning problems such as training ResNet on CIFAR-10, the β2t is almost zero after even one or two epochs where Ada-X behaves like vanilla SGD.	weakness
2020-1095	Is there no room for relaxing this assumption such as β2t=β2/t?	weakness
2020-1095	Also, it is not clear how the authors derive Corollary 4.2 from Theorem 4.2 since Theorem 4.2 assumes β2t=β2/t while Corollary 4.2 does not.	weakness
2020-1095	3. In the experiment, it is not clear that the authors use the same strategy for constructing first-order momentum for Adam with a newly introduced parameter β3.	weakness
2020-1095	In other words, the authors should use the same policy on constructing the first-order momentum estimate for both Adam and Ada-X.	weakness
2020-1095	Also, as the authors add an additional hyperparameter β3, the effect of β3 on performance should be discussed at least empirically.	weakness
2020-1095	4. There are many studies on fixing poor generalization of adaptive methods (such as AdaBound which the authors cited).	weakness
2020-1095	In this context, Zaheer et al. (2018, Adaptive methods for non-convex optimization) propose a large epsilon value (numerical stability parameter) such as ϵ=10−3 for better generalization.	weakness
2020-1095	It will be more interesting to see the comparisons in this regime.	suggestion
2020-1095	5. In my experience with Adam-W (Decoupled weight decay regularization), Adam-W requires a relatively large weight decay parameter λ.	suggestion
2020-1095	As an example, DenseNet-BC-100-12 shows a similar validation accuracy with Adam-W λ=0.05 under the learning rate scheduling in (Huang et al. 2016, DenseNet)  as vanilla SGD.	suggestion
2020-1095	Therefore, the authors should consider more broader range of weight decay parameters for at least image classification tasks.	suggestion
2020-1095	Minor: 1. In eq (2), the domain of x should be mentioned: according to Reddie et al, it is [-1,1].	weakness
2020-1095	2. In both theorem 4.1 and corollary 4.1, D∞2 should be D∞2?	weakness
2020-1095	This paper introduces a new step-size adaptation algorithm called AdaX.	abstract
2020-1095	AdaX builds on the ideas of the Adam algorithm to address instability and non-convergence issues.	abstract
2020-1095	Convergence of AdaX is proven in both convex and non-convex settings.	abstract
2020-1095	The paper also provides an empirical comparison of AdaX against its predecessors	abstract
2020-1095	(SGD, RMSProp, Adam, AMSGrad) on a variety of tasks.	abstract
2020-1095	I recommend the paper be rejected.	decision
2020-1095	I believe the convergence results could be a significant contribution, but the quality of the paper is hampered by its experimental design.	weakness
2020-1095	The paper felt generally unpolished, containing frequent grammatical errors, imprecise language, and uncited statements.	weakness
2020-1095	My main issue with the paper is the experimental design.	weakness
2020-1095	I am not convinced that we can draw valid conclusions from the experimental results for the following reasons: - The experiments are lacking important details.	weakness
2020-1095	How many independent runs of the experiment were the experimental results averaged over?	weakness
2020-1095	All of the experiments have random initial conditions	weakness
2020-1095	(e.g. initialization of the network), and should be ran multiple times, not just once.	weakness
2020-1095	There's no error bars in any of the plots, so it's unclear whether AdaX really does provide a statistically significant improvement over the baselines.	weakness
2020-1095	Similarly, the data in all the tables is quite similar, so without indicating the spread of these estimates its impossible to tell whether these results are significant or not.	weakness
2020-1095	- How were the hyperparameters and step-size schedules chosen?	weakness
2020-1095	The performance of Adam, AMSGrad, and	misc
2020-1095	RMSProp are quite sensitive to their hyperparameters, and the optimal hyperparameters are problem-dependent.	weakness
2020-1095	Some of the experiments just use the default hyperparameters; this is insufficient when trying to directly compare the performance of these methods, as their performance can vary greatly with different values of these parameters.	weakness
2020-1095	I'm not convinced that we should be drawing conclusions about the relative performance of these algorithms from any of the experiments for this reason.	weakness
2020-1095	Of course, meaningful empirical results are not necessarily characterized by statistically outperforming the baselines.	weakness
2020-1095	Well designed experiments can highlight important ways in which the performances differ, providing the community with a deeper understanding of the methods investigated.	weakness
2020-1095	I would argue that the experiments in the paper do not achieve this either; the experiments do not provide any new intuition or understanding of the methods, showing only the relative performances in terms of learning curves on a somewhat random collection of supervised learning problems.	weakness
2020-1095	Why were these specific problems chosen?	weakness
2020-1095	What makes these problems ideal for showcasing the performance of AdaX?	weakness
2020-1095	If AdaX is an improvement over Adam, why?	weakness
2020-1095	What exactly is happening with it's effective step-sizes that leads to the better performance?	weakness
2020-1095	Can you show how their step-sizes differ over time?	weakness
2020-1095	Statements that need citation or revision: - "Adaptive optimization algorithms such as RMSProp and Adam...	weakness
2020-1095	as well as weak performance compared to the first order gradient methods such as SGD" (Abstract).	weakness
2020-1095	This needs a citation. Similarly, "AdaX outperforms various tasks of computer vision and natural language processing and can catch up with SGD"; as above, I'm unaware of work (other than theoretical) that shows that SGD significantly outperforms Adam in deep neural networks.	weakness
2020-1095	-  "In the era of deep learning, SGD ...	misc
2020-1095	remains the most effective algorithm in training deep neural networks" (Introduction).	weakness
2020-1095	What are you referring to here?	misc
2020-1095	Vanilla SGD? Or are you including Adam etc here?	weakness
2020-1095	As above, this should have a citation.	weakness
2020-1095	Adam's popularity is largely due to its effectiveness in training deep neural networks.	weakness
2020-1095	- "However, Adam has worse performance (i.e. generalization ability in testing stage) compared with SGD"	weakness
2020-1095	(Introduction). Citation needed. - In the last paragraph of the Introduction, you introduced AdaX twice: "To address the above issues, we propose a new adaptive optimization method, termed AdaX, which guarantees convergence...", and, "To address the above problems, we introduce a novel AdaX algorithm and theoreetically prove that it converges..." This paper proposed a new adaptive gradient descent algorithm with exponential long term memory.	weakness
2020-1095	The authors analyzed the non-convergence issue in Adam into a simple non-convex case.	weakness
2020-1095	The authors also presented the convergence of the proposed AdaX in both convex and non-convex settings.	weakness
2020-1095	- The proposed algorithm revisited the non-convergence issue in Adam and proposed a new algorithm design to try to address this issue.	weakness
2020-1095	However, the new algorithm design is a bit strange to me, especially in Line 6 of Algorithm 2, the authors proposed to update v_t by (1+ \\beta_2) v_{t-1} + \\beta_2 g_t^2, where normally people would use (1-\\beta2) and \\beta2 as the coefficients.	weakness
2020-1095	I am not quite get the intuition of using such as strange design.	weakness
2020-1095	I wonder if the authors could further explain that.	weakness
2020-1095	- The authors also add change \\beta_1 in Line 5 of Algorithm 2 into \\beta_3.	weakness
2020-1095	And then in theory, the authors again choose \\beta_3 as \\beta_1.	weakness
2020-1095	It seems that \\beta_3 is not contributing to any theoretical result.	weakness
2020-1095	It seems to me to just have another parameter to tune in order to get better performances.	weakness
2020-1095	Can the authors gives more justification on why introducing such a term here?	suggestion
2020-1095	And also show how the different choice of \\beta_3 affects the final result?	suggestion
2020-1095	- Missing some important references closely related to this paper: Chen, Jinghui, and Quanquan Gu.	weakness
2020-1095	"Closing the generalization gap of adaptive gradient methods in training deep neural networks." arXiv preprint arXiv:1806.06763 (2018).	misc
2020-1095	Zaheer, Manzil, et al. "Adaptive methods for nonconvex optimization." Advances in Neural Information Processing Systems.	misc
2020-1095	2018. Zhou, Dongruo, et al. "On the convergence of adaptive gradient methods for nonconvex optimization." arXiv preprint arXiv:1808.05671 (2018).	misc
2020-1095	I would suggest the authors to also compare with the above mentioned baselines to better demonstrate its performances and theoretical results.	suggestion
2020-1095	- The authors include theoretical analysis in both convex and non-convex settings, which is appreciated, however, the theoretical result seems to show similar convergence guarantees with AMSGrad.	strength
2020-1095	I wonder if the authors could provide theoretical justifications on why the proposed method is better than prior arts, probably some sharper convergences or some generalization guarantees?	suggestion
2020-1095	- In the experiments part, I wonder why the authors did not compare with AMSGrad, RMSProp in later parts such as ImageNet, IoU and RNN parts?	weakness
2020-1095	I makes no sense to drop them for those experiments.	weakness
2020-1095	Also, are the authors fully tuned the hyper-parameters for other baselines such as step size and weight decay on SGDM?	weakness
2020-1095	================ after the rebuttal I thank the authors for their response but I still feel that the intuition of this paper is not clear enough and comparison with more baselines is needed.	rebuttal_process
2020-1095	Therefore I decided to keep my score unchanged.	rebuttal_process

2020-1116	This paper considers the effect of network width of the neural network and its ability to capture various intricate features of the data.	abstract
2020-1116	In particular, the central claim of this paper is what the title claims "Wider networks learn features that are better".	abstract
2020-1116	They make this claim using the visualization technique called "activation atlasses".	abstract
2020-1116	They find that wider networks learn features in the hidden neurons that are more "interpretable" in this visualization framework.	abstract
2020-1116	Additionally, they also notice that fine-tuning a _linear model_ using the learned features for the wider networks provide better accuracy for new (but related) tasks over the shallower counterparts.	abstract
2020-1116	For most experiments of this paper, "shallow network" refers to a width of 64 and "wide network" refers to a width of 2048.	abstract
2020-1116	The main datasets used for the experiments are MNIST, CIFAR 10/100 and a "translated" version of MNIST images.	abstract
2020-1116	Overall the paper is written well and the ideas and results are communicated crisply.	strength
2020-1116	I have a few comments.	misc
2020-1116	First, regarding the related work, I think that the reader would be served better if the authors also list the recent works related to effect of network width on convergence and generalization (e.g., [1] and references that cite this).	suggestion
2020-1116	The reason I say this is so that the reader should not (wrongly) interpret that this is the first work that finds "favorable" properties of wider networks (the paper does not make this claim, but it is easy for a reader to interpret it).	misc
2020-1116	Second, I find it slightly concerning that a lot of findings have been extrapolated from just one architecture.	weakness
2020-1116	In particular, I find the experiments in section 5 to be the most informative (and also objective), since it is a single number which is easy to think about.	weakness
2020-1116	To be clear, I like the visualization experiments and it gives credibility to the claim about interpretability.	strength
2020-1116	Given that there are many levers in a neural net (batch norm, architectural choices, hyper-params etc.) one could fiddle with, to make the claim made in the introduction one needs a more extensive set of experiments.	weakness
2020-1116	I acknowledge that the authors say they haven't explored the possibility of fine-tuning the hyper-params for instance, but I think considering some of these choices is really helpful.	weakness
2020-1116	This will help _isolate_ the effect of width independent of the architecture choice.	weakness
2020-1116	Given the above observations, my current decision of this paper is that it doesn't meet the bar.	decision
2020-1116	I find the results promising but the paper is not yet ready.	decision
2020-1116	[1] - https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf This paper investigates wider networks using a recent feature visualization technique named activation atlases.	abstract
2020-1116	By analyzing what the hidden layers of wider networks respond to, the authors showed that wider networks learn more transferable features.	abstract
2020-1116	However, I tend to reject this paper since it doesn't show very compelling evidence through experiments.	decision
2020-1116	1. This paper does not present any novel methods, and so the experiments need to be very solid.	weakness
2020-1116	But all the datasets and architectures used in this paper are quite simple from the view of deep learning.	strength
2020-1116	It is not clear whether the conclusions will still be valid for larger datasets or deeper networks.	weakness
2020-1116	2. The most important observation of this paper is to find that wider networks can be easily transferred to a new task.	strength
2020-1116	But in Section 5.1, all layers except the last classification layer are fixed when fine-tuning the networks for the second task.	strength
2020-1116	It is so obvious that wider networks with fewer previous layers can perform better.	strength
2020-1116	In Section 5.2, the authors did not show the network details, and also it is not fair to compare the networks with a linear classifier.	weakness
2020-1116	The authors should include more competitive baselines.	suggestion
2020-1116	3. I encourage the authors to show the training/validation curves to testify the data efficiency of the wider networks when training or fine-tuning on a new task.	suggestion
2020-1116	The authors observed that the wider deep neural networks can learn much rich representative features than shallower deep neural networks while both networks show similar level of the test performance.	suggestion
2020-1116	They show feature visualization about their observations using two different networks n=20/n=2048.	abstract
2020-1116	At the first, I feel that the visualizations on figure 1 about two different width are too marginal.	weakness
2020-1116	Almost they look similar, it's hard to say that significantly show difference.	weakness
2020-1116	Also there is no guarantee that the quality of the feature visualization follows linear relationship according to width.	weakness
2020-1116	Comparison with just two different width is not enough to analyze the situation.	weakness
2020-1116	I wonder if human-interpretable features are always better.	weakness
2020-1116	Machine-interpretable information also do important role, as adversarial attack.	weakness
2020-1116	Even the total number of parameter is preserved, the performance will be largely vary according to the network architecture, such as the number of the layers.	weakness
2020-1116	Then, I have a doubt whether experiments on Sec 5.1 are meaningful not.	weakness
2020-1116	More, the model can suffer from the gradient vanishing problem when the network has a number of layers.	weakness
2020-1116	I wonder that the results on figure 4 are caused from this problem.	suggestion

2020-1143	This paper proposes a very interesting idea of loss function optimization.	abstract
2020-1143	At first sight, loss function is the goal of optimization and can not be optimized directly.	abstract
2020-1143	However, the true goal of optimization is the final accuracy (for classification).	abstract
2020-1143	So lots of loss functions can be designed and combined to form a large search space.	abstract
2020-1143	In this paper, the authors adopt genetic programming to design loss functions hierarchically.	abstract
2020-1143	And experiments show that GLO (Genetic Loss-function Optimization) based loss function can achieve better results than cross entropy.	abstract
2020-1143	The paper is well written and easy to understand.	strength
2020-1143	I like the idea. Baikal loss is a form searched by GLO.	strength
2020-1143	Interestingly and counter intuitively , it is not a monotonically decreasing function.	strength
2020-1143	The authors explain it as a regularizer which can prevent the model to be too confident.	strength
2020-1143	Experiments on MNIST and Cifar10 are conducted to show the effectiveness of the proposed method.	strength
2020-1143	This part is very weak since MNIST and Cifar10 are very small datasets and the provided results are far from state-of-the-art results.	weakness
2020-1143	Experiments on larger datasets such as ImageNet and more analysis about the optimization details are suggested to make this work more promising.	suggestion
2020-1143	Since the optimization is rather complex, it's better to show if it is stable enough to generalize to various datasets and models.	suggestion
2020-1143	*Summary* The authors propose using evolutionary computation (EC) to perform meta learning over the set of symbolic expressions for loss functions.	abstract
2020-1143	It's a compelling idea that is well-motivated.	strength
2020-1143	They find that applying their EC method to mnist yields an interesting loss function that they name the 'Baikal loss.' Much of the paper is devoted to analyzing the properties and performance of the Baikal loss.	strength
2020-1143	*Overall Assessment* The paper's idea is very interesting.	strength
2020-1143	However, there are some important drawbacks of this work.	misc
2020-1143	These should be fixed and the paper should be resubmitted to a different conference soon.	misc
2020-1143	1) The experiments focus almost entirely on the Baikal loss (a particular loss function found once when running EC on mnist), and do not analyze the overall behavior of EC for loss functions.	weakness
2020-1143	Does EC consistently converge to the same loss, or do different ones emerge different times you run it?	weakness
2020-1143	What happens if you optimize convergence speed vs.	weakness
2020-1143	generalization accuracy with EC? How do these loss functions differ?	weakness
2020-1143	2) The experiments are largely on mnist, with a small study showing that the Baikal loss can be applied to cifar-10.	weakness
2020-1143	It would be good to show that loss functions meta-learned on mnist generalize to larger-scale problems than cifar.	suggestion
2020-1143	*Comments* I was surprised when you optimized in fig 3 for convergence speed, rather than final accuracy of something that runs for a while.	weakness
2020-1143	Why should our goal be to find loss functions that lead to fast optimization, instead of loss functions that lead to models that generalize best?	weakness
2020-1143	If these are two different goals, then you should have two sets of experiments analyzing how GLO can find interesting (and perhaps different) loss functions for each.	weakness
2020-1143	Mnist is possible to get basically 100% accuracy.	weakness
2020-1143	This means that the loss will only be evaluated in certain regimes of its inputs.	weakness
2020-1143	What happens when you transfer this to problems where the best achievable accuracy is something like 60% for binary classification?	weakness
2020-1143	You should cite the Focal loss as another alternative to the cross entropy loss.	suggestion
2020-1143	Is the focal loss achievable in your particular grammar over loss functions?	suggestion
2020-1143	You should also cite label smoothing as an additional way to achieve a very similar implicit regularization effect as the Baikal loss.	suggestion
2020-1143	You only analyze one loss function that came from your EC.	suggestion
2020-1143	What if you run it multiple times?	suggestion
2020-1143	Do you find different formulas?	suggestion
2020-1143	How do these perform? The beginning of the paper is very focused on EC, but then you transition suddenly to only discussing the Baikal loss.	suggestion
2020-1143	Can you present experiments demonstrating, for example, how the EC performance varies with the number of steps, with different ways to define the search space, etc?	suggestion
2020-1143	The authors present a framework to perform meta-learning on the loss used for training.	abstract
2020-1143	They introduce the Baikal loss, obtained using the MNIST dataset, and	abstract
2020-1143	BaikalCMA where the coefficients have been tuned.	suggestion
2020-1143	The evaluation of these loss functions is performed on the MNIST and CIFAR-10, and according to the results they converge faster, towards lower test error and need fewer samples to obtain results similar to the cross-entropy loss.	abstract
2020-1143	The claims are clearly stated and the framework is detailed, the experiments cover all the potential benefits of the Baikal loss.	strength
2020-1143	However it seems that some potentially critical points have been omitted.	strength
2020-1143	The cross-entropy loss is well known to be beneficial in dataset with severe class imbalance.	strength
2020-1143	The two datasets used for evaluation are perfectly balanced, it might beneficial to see how it performs in the unbalanced case.	strength
2020-1143	I have a couple of concerns about the method.	weakness
2020-1143	First about step "(1) loss function discovery": The initial population starts with trees of depth at most	weakness
2020-1143	2, and the final solution(Baikal) has either 2 or 3 (depending on which definition of depth is chosen).	weakness
2020-1143	It is unclear that the genetic optimization is superior to simply choosing random loss functions.	weakness
2020-1143	I think it would be relevant to add a figure that shows how the fitness of the leader of each generation evolves over time.	suggestion
2020-1143	The second step "(2) coefficient optimization", while objectively generating a loss function that was superior on the metrics evaluated, raised some questions.	weakness
2020-1143	In equation (2) the factor "1.5352" seems to be equivalent to adding a constant to the loss, which should not impact optimization.	weakness
2020-1143	Also the factor "2.7279" seems to be equivalent to a change in learning rate.	weakness
2020-1143	This may be an indication that the learning rate search was not done thoroughly.	weakness
2020-1143	It would be beneficial to clarify when it is happening: a) For each individual of the population during step (1), b) before performing CMA, c) after CMA.	suggestion
2020-1143	Also: Was learning rate search was performed on the network trained with Cross-Entropy?	suggestion
2020-1143	It was not entirely clear from the experiment details in Appendix A.2.1.	weakness
2020-1143	About the Baikal loss itself, I fear that it could produce models that have very poor calibration, it might be nice to evaluate that (even if it is only in the appendix).	weakness
2020-1143	While the paper does a great job at presenting the problem and its applications and propose a framework that generated a loss that can transfer to other datasets without any tuning required.	strength
2020-1143	I think it lacks a more thorough evaluation and description of the dynamics observed during the genetic evolution, and the performance of the Baikal loss on other datasets (my quick experients with it on ImageNet diverged I did not have the time necessary to tune the hyper-parameters).	weakness
2020-1143	Minor remarks: There might be a slight omission in section 3.1: according to Figure 1, exp(x)	weakness
2020-1143	is one of the potential unary operators explored by the GLO framework.	weakness
2020-1143	However it is not present it the list of operators.	weakness
2020-1143	Could you clarify this? To the best of my knowledge, in the machine learning literature, it seems that the letter x is used to denote the prediction and y for the ground truth.	weakness
2020-1143	The fact that this paper used the opposite convention confused me the first time I	weakness
2020-1143	read it.	misc

2020-1164	This paper tackles the out of distribution detection problem and utilizes the property that the calculation of batch-normalization is different between training and testing for detecting out-of-distribution data with generative models.	abstract
2020-1164	The paper first empirically demonstrates that the likelihood of out-of-distribution data has a larger difference between training mode and testing mode, then provides a possible theoretical explanation for the phenomenon.	abstract
2020-1164	The proposed scoring function utilizes such likelihood differences in a permutation test for detecting out-of-distribution data.	abstract
2020-1164	The evaluation is performed on two small in-distribution image datasets and four out-of-distribution datasets with three types of generative models.	abstract
2020-1164	We recommend a weak accept.	decision
2020-1164	Its clarity is good, and the strength of the paper has three parts.	strength
2020-1164	The first is the thorough observation of the likelihood changes between different modes of batch-normalization.	strength
2020-1164	Second, the theoretical explanation for the observed phenomenon is sound.	strength
2020-1164	The example in Figure 2 gives a good intuition of how mis-specification can happen.	strength
2020-1164	The last is the strong performance on the out-of-distribution detection with generative models.	strength
2020-1164	However, I have some concerns about the design of the scoring function (Section 5), which looks like it is carefully tuned: 1. Why do the authors use the permutation score (Tb,r1,r2) instead of likelihood difference (δb,r1,r2)?	weakness
2020-1164	The likelihood difference itself seems like it could be a good indication for OoD detection.	weakness
2020-1164	2. Why do the authors use interpolation between training and evaluation?	weakness
2020-1164	It introduces extra hyperparameters (r1, r2) for the method.	weakness
2020-1164	Is the performance sensitive to the choice of r1 and r2?	weakness
2020-1164	One minor issue: 3. The sentence at the bottom of page 7 should be removed ("related work still needs some work, but there seems to be some bug on overleaf right now") This paper attempts to address the problem of out-of-distribution detection with generative models.	weakness
2020-1164	To do this they assume they are given batches of OOD examples or batches of in-distribution examples, and they detect whether the batch is in- or out-of-distribution.	weakness
2020-1164	Normally we try to detect if an example is in- or out-of-distribution.	weakness
2020-1164	Unfortunately, this is not an interesting assumption and makes the problem significantly easier.	weakness
2020-1164	If we assume this, then averaging the anomaly scores of multi-class OOD detectors would result in performance near the ceiling.	weakness
2020-1164	It is not surprising that one can obtain a much better OOD detector given a batch of OOD samples.	weakness
2020-1164	Hence they're making progress on a problem we have the community has not been interested in, and they are not making progress on the standard OOD detection problem.	weakness
2020-1164	Small notes: > given their successful generalizing on a test dataset.	suggestion
2020-1164	What does this mean? Does this mean their BPP is good?	suggestion
2020-1164	By what standard? > unerlying underlying > CIFAR	suggestion
2020-1164	Include CIFAR-10 vs CIFAR-100 results in the table.	suggestion
2020-1164	The paper makes the observation that likelihood models trained with batch norm assign much lower likelihoods to "training batches" of OoD data (batch norm statistics computed over over minibatch) than evaluation batches of OoD data (batch norm statistics over entire training set).	abstract
2020-1164	One issue with comparing this method to most other OoD detection works is that it considers OoD detection on *batches* of (all OoD data) or (all in-distribution data).	weakness
2020-1164	As soon as the problem is changed to "classify between OoD batches" and not single samples, there are a large number of possible statistical tests one can perform to perform OoD (T-test between likelihoods of each batch) and the problem becomes *much* easier.	weakness
2020-1164	In some ways, this makes things more well-defined (hard to compare distributions when one of them is just a single sample from an arbitrary distribution).	weakness
2020-1164	However, that brings me to a big concern I have with the evaluation protocol.	weakness
2020-1164	The batch size used for train/evaluation is rather large (64, this detail is hidden in the Appendix and I would have appreciated the number put in the main experiments section).	weakness
2020-1164	If you take a likelihood model and evaluate on 64 samples from SVHN, you are all but guaranteed to sample a sample with *exceedingly* low likelihood, which dominates the mean statistic, making it possible to separate SVHN batch from CIFAR10 batches.	weakness
2020-1164	I suspect that OoD datasets have plenty of these "extremely low likelihood" examples that will drag the mean likelihood down a lot.	suggestion
2020-1164	This is consistent with your batch normalization experiments: in training mode, the likelihood is computed from mean activations over a batch of OoD samples, several of which probably contribute to the low likelihoods.	suggestion
2020-1164	In evaluation mode, likelihoods for each OoD sample are evaluated independently, which results in a similar observation to prior work showing that CIFAR10 likelihoods are inaccurate for SVHN.	suggestion
2020-1164	In other words, I think there is a mistake made here: it is the phenomenon that *batch likelihoods*, not *batch norm*, that is responsible for this method working well.	weakness
2020-1164	One experiment that is missing from your paper (and would prove my hypothesis wrong) would be if you adapted the OoD criteria to compare the *mean* likelihoods in the evaluation mode, and show that for OoD datasets, the difference between batches still remains small.	weakness
2020-1164	Nits: - "...such as learning a mixture of Gaussians", I believe this toy example was on univariate gaussians, not mixtures.	weakness
2020-1164	- Choi et al. 2018 and should also be included in the citation that "CIFAR10 gives higher likelihood estimates to SVHN than CIFAR10 ones" (this was a concurrent discovery between the two papers)	suggestion
2020-1164	- Choi et al. 2018 is not the right citation for "we evaluate the area under the ROC curve (AUC) and average precision (AP)" for each binary classification task, a more appropriate one would be Hendryks and Gimpel 2017.	weakness
2020-1164	- No doubt the authors realized already but Page 7 has some "related work still needs some work, but there...." which should be deleted.	weakness
2020-1164	- It took me awhile to find the batch size used in training and evaluation mode (64), which was on page 16.	weakness

2020-1172	Contributions: 1. This paper proposes an invertible flow-based method for the one-shot graph generation.	strength
2020-1172	2. The paper demonstrates their method on a molecular graph generation task.	strength
2020-1172	3. Empirical results show the effectiveness of the proposed method.	strength
2020-1172	The merit of the proposed invertible flow method is two folds.	strength
2020-1172	First, it can guarantee a one hundred percent reconstruction accuracy.	strength
2020-1172	Second, it can be adapted to generate graphs with various types (such as molecules) without incorporating much domain knowledge.	strength
2020-1172	Below are my concerns regarding this paper.	misc
2020-1172	[Page 7, Table 2] My first concern is: does the reconstruction performance matters in the graph generation case?	weakness
2020-1172	Typically a lower reconstruction error does not mean a worse model to generate reasonable new graphs.	weakness
2020-1172	So the reconstruction error should accompany with other criterions.	weakness
2020-1172	In Table 2, I can see CD-VAE and JT-VAE does better in generating valid, novel and unique graphs.	weakness
2020-1172	So I wonder whether it worth sacrificing novelty to pursue a perfect reconstruction.	weakness
2020-1172	[Page 7, Sec 4.2] The authors mention they cannot reproduce the decoder of CG-VAE and JT-VAE.	rebuttal_process
2020-1172	So I expect they mention somewhere in this paper that they will release their code once published.	misc
2020-1172	[Page 5, Sec 3.3.1] The authors should be explicit by saying we replace sliced matrices (z_X[l^-,:,] in Eq. 2 and z_A[l^-,:,:] in Eq. 4) with masked matrices rather than just saying "Eqs.	rebuttal_process
2020-1172	(2,4) are implemented with masking patterns".	rebuttal_process
2020-1172	[Page 5, Sec 3.3.1] Can you explain the gain of masking?	suggestion
2020-1172	To my understanding, even with masking you still need a sequence of N coupling layers to update each node once.	weakness
2020-1172	[Page 5, Sec 3.3.1] The second paragraph in Sec 3.3.1 is confusing to me.	weakness
2020-1172	The masking scheme indeed makes the whole process, not permutation invariant.	weakness
2020-1172	But I'm confusing about the way you fix it.	weakness
2020-1172	Can you explain your "permutation invariant coupling"?	weakness
2020-1172	E.g., why you need to change the indexing on the non-node axis?	weakness
2020-1172	Overall, I think the method proposed in this paper sacrifices some more import aspects in graph generation such as novelty and uniqueness by introducing an invertible flow architecture.	weakness
2020-1172	And some parts in the paper may require a significant re-writing, such as Sec 3.3.1.	weakness
2020-1172	This paper presents a new reversible flow-based graph generative model wherein the whole graph i.e., representative attributes such as node features and adjacency tensor is modeled using seperate streams of invertible flow model.	abstract
2020-1172	This allows training of generative model using exact likelihood maximization over the underlying graph dataset.The model avoids encoding any domain specific heuristics and thus can be applied to any structured graph data.	abstract
2020-1172	The paper focusses it applicability for molecular graphs.	abstract
2020-1172	Given that this approach avoids sequential generation of graph, it is faster by an order of magnitude than prior models for molecular generation.	abstract
2020-1172	Empirical experiments on couple of molecular graph data suggets that GraphNVP approach performs as well as prior approach but albeit without any rule checker.	weakness
2020-1172	My major concern with such invertible models is "scalability".	weakness
2020-1172	Given that flow-based model are required to retain the original dimension its applicability is limited to low dimensional feature vectors.	weakness
2020-1172	In the case of GraphNVP, this means limited number of node labels as well as edge labels.	weakness
2020-1172	Additionally, since it limits adjacency tensor, this would lead to modeling graphs with few nodes.	weakness
2020-1172	However, if integrated with encoder-decder model some of these limitation can be overcome.	suggestion
2020-1172	Given this major weakness and with limited novelty (i.e., extending to adjacency tensor), I am inclined to reject this paper.	decision
2020-1172	I shall improve my rating if GraphNVP is applied to general graph structures - synthetic / real.	suggestion
2020-1172	Few more limitations: 1. Although paper claims one-shot generation of graphs, in reality it seems otherwise.	weakness
2020-1172	Since every layer processes only on single node, overall it operates sequentially from one node to another.	weakness
2020-1172	2. Moreover, this same sequential processing yet again limits it applicability to small graphs.	weakness
2020-1172	3. As in MolGAN, the direct generation of adjacency tensor leads to training with fixed size graphs i.e., through the addition of virtual nodes.	weakness
2020-1172	It is not possible to train model with variable number of nodes.	weakness
2020-1172	4. As pointed by authors, their model is not node permutation invariant.	weakness
2020-1172	Clarification: 1. Are the function 's' and 't' fixed across time ?	weakness
2020-1172	For QM9 with max of 9 atoms and 27 layers, each atom attribute is processed multiple times.	weakness
2020-1172	Are they processed using same functionality of s and t ?	weakness
2020-1172	2. Is it possible to model permutation invariance by augmenting the training data using multiple permutation of nodes such as BFS, DFS, degree, k-node (see GRAN) ?	weakness
2020-1172	3. I understand GraphNVP can reconstruct perfectly.	weakness
2020-1172	But I fail to note the actual significance of such metric.	weakness
2020-1172	If it reconstruct 100% or not how does it matter ?	weakness
2020-1172	What matters is unniqueness, validity and novelty.	weakness
2020-1172	4. Can you please compare inference time ?	weakness
2020-1172	5. How difficult is it to integrate validity checker with your generation process ?	weakness
2020-1172	Can we have some comparison using it ?	weakness
2020-1172	Minor: 1. In eq (2) please use different notation for layer 'l' and node 'l'.	suggestion
2020-1172	2. Page 4, penultimate line: So as functions s and t -?	weakness
2020-1172	To model functions s and t In this paper, a GraphNVP framework for molecular graph generation is proposed.	abstract
2020-1172	The main difference from the previously proposed models is the use of the invertible normalizing flow idea for the generative model, which doesn't require a separate decoder for sampling.	abstract
2020-1172	This architecture is implemented with coupling layers combined with a multi-layer perceptron.	abstract
2020-1172	The model is evaluated and compared on QM9 and ZINC chemical molecular datasets.	abstract
2020-1172	This method combines a number of existing techniques to obtain a new model for the molecular graph generation problem.	abstract
2020-1172	The paper is very well written.	strength
2020-1172	I have several concerns with regards to this model and the proposed algorithm: 1. How many parameters does GraphNVP model have?	weakness
2020-1172	The coupling layers should have at least O(LN^2R) and that must be multiplied by the number of MLP parameters of the adjacency tensor which I suppose is of order O(N^2R), is this correct?	weakness
2020-1172	This number must be huge.	weakness
2020-1172	How can one ensure that such a model does not overfit?	weakness
2020-1172	Moreover, 100% reconstruction accuracy is rather an indicator that it actually does overfit, isn't it?	weakness
2020-1172	2. I'm concerned whether the use of dequantization for this particular application is valid.	weakness
2020-1172	Indeed, images are usually modeled as vectors taking values in [0, 255] and adding a uniform on [0,1] variable actually corresponds to noise.	weakness
2020-1172	However, the graph adjacency tensor takes either 0 or 1 values and adding a similar uniform variable (potentially scaled by 0.9) is actually more than simply adding noise.	weakness
2020-1172	Say one value is 0 and added 0.8, while the other is 1 and added 0.1; the transformed variables are now much closer to each other.	weakness
2020-1172	Therefore, the likelihood of the transformed variables is going to be significantly different from the original one.	weakness
2020-1172	Although one can indeed recover the original graph from the dequantized one, I doubt that there is a correspondence between two likelihoods extrema.	weakness
2020-1172	This also contradicts one of the motivations to this paper that this approach uses precise log-likelihood.	weakness
2020-1172	Could you please comment on this?	misc
2020-1172	3. I am confused by this sentence: "Our objective is maximizing the log likelihood (Eq. 1) of z over minibatches of training data." Does this mean that log(p_z(z)) is the objective?	weakness
2020-1172	If yes, how does this relate to maximum likelihood?	weakness
2020-1172	4. Given the high cost of wet-lab experiments, the runtime of a method for the drug discovery application is much less important than the quality of the obtained results.	weakness
2020-1172	Is it actually more important to have a sampling time decrease from 100/400s to 4s or does the higher quality of results should matter more?	weakness
2020-1172	If the latter, are there any other advantages of GraphNVP over other models?	weakness

2020-1178	Authors introduce TriMap based on triplet constraints that preserves the global accuracy of the data.	abstract
2020-1178	A measure of global accuracy is proposed to reflect the global accuracy of the embedding.	abstract
2020-1178	Experiments on various datasets the better performance than baselines.	abstract
2020-1178	Authors define the minimum reconstruction error from the embedding as the global measure in reflecting the global structure of the data similar to PCA.	abstract
2020-1178	From the definition, this measure has preferences to the linear projection model such as PCA, so the score becomes lower for non-linear projection methods such as t-SNE and UMAP.	abstract
2020-1178	The illustrated S-shape example in Figure 1 somehow demonstrate the difference of the proposed method with PCA, t-SNE and UMAP, but the usage of the embedding is not clear since Figure 1(d) looks like a 2-d visualizing of the original 3-d data visualized from certain angle.	weakness
2020-1178	In addition, the initialization of the proposed method is the PCA method, which prefers the GS measure.	weakness
2020-1178	It is interesting to see how the GS measure will change if the random initialization is used.	abstract
2020-1178	Authors demonstrate GS and AUS for all the tested data.	weakness
2020-1178	It might be interesting and more important to see how to get the better embedding with a balanced score for a given data since GS and AUC seems always opposite measures.	suggestion
2020-1178	The TriMap method defines the loss of triplet based on unnormalized weighting schema and the weights are adjusted by applying a non-linear transformation that emphasizes the small weights.	abstract
2020-1178	These formulations are quite heuristic and constructive.	weakness
2020-1178	It is better to have some formal explanation on the proposed method.	weakness
2020-1178	Authors suggest a new technique for embedding point to low-dimensional space.	abstract
2020-1178	The technique is reminiscent of t-SNE, with the difference that it get weighted triplets (i,j,k) as inputs (meaning that j is closer to i thank).	abstract
2020-1178	Further a loss function is defined which directly follows t-SNE ideology.	abstract
2020-1178	A paper is purely experimental.	weakness
2020-1178	The only way to judge the quality of its results is to compare 2D pictures of TriMap with other pictures.	weakness
2020-1178	I did not see any evidence that images of TriMap somehow give a new insight into data (in comparison with other methods).	weakness
2020-1178	The paper proposed ``TriMap''---a novel dimensionality reduction technique that learns to preserve relative distances among points in a triplet.	abstract
2020-1178	The paper has done extensive experiments and presents the results in very nice visualizations.	abstract
2020-1178	The paper is clearly written.	strength
2020-1178	Major merits of this paper are: 1. The proposed method seems effective.	strength
2020-1178	On some datasets (e.g., S-curve), the learned low-dimensional embeddings indeed look very good.	strength
2020-1178	And the proposed method has much less runtime than other baselines as shown in table-1.	strength
2020-1178	2. The paper is well written.	strength
2020-1178	However, I am still leaning towards rejecting this submission because the proposed method is lack of necessary justification.	decision
2020-1178	1. Many important technical decisions on this method seem arbitrary, including the parametrization of functions (e.g., s, \\omega, \\zeta, etc) and values of hyperparameters (e.g., \\gamma and \\delta).	weakness
2020-1178	For function forms, the authors should justify why particular parametrization has been chosen; for the hyperparameters, the authors should clearly explain how they are picked---maybe using domain knowledge or tuned on data?	weakness
2020-1178	2. The argument for ``global score'' is not clear enough.	weakness
2020-1178	There are at least two points that need clarification.	weakness
2020-1178	First, ``non-local'' is not equal to ``global''.	weakness
2020-1178	The proposed method indeed considers non-local (or non-near) points while learning embeddings, which helps preserve non-local information.	weakness
2020-1178	But I am not convinced that the preserved information is actually global.	weakness
2020-1178	Maybe what helps is to first define ``global'' in a dimensionality reduction context.	weakness
2020-1178	Second, the definition of ``global score'' depends on another baseline method (i.e. PCA), which seems odd.	weakness
2020-1178	A principled evaluation (or a score) should be method-independent.	weakness
2020-1178	What seems right to me is to compute global score (i.e. how much global information has been preserved) by comparing to some statistics in the (high-dim) x space, not to another method.	weakness
2020-1178	Moreover, the authors had a strong claim that the proposed ``GS is the only DR performance measure that can reflect this property''---it doesn't sound right and why one can't just use another score which is monotonic wrt the proposed score?	weakness
2020-1178	The authors mentioned that ``PCA has the lowest possible MRE''---but this is only right up to the use of a linear transformation and F-norm, so this shouldn't be a justification for my questions above.	weakness
2020-1178	3. What is the reason for the successful runtime?	weakness
2020-1178	The authors didn't clarify why the proposed method is theoretically faster than the baselines.	weakness
2020-1178	What I noted is: the authors chose a subset \\mathcal{T} for the TriMap method and used \\mathcal{T} throughout the paper---is it a typo or is a subset always chosen?	weakness
2020-1178	If the latter holds, then how was it chosen and how large is it compared to the training data used by other methods?	weakness
2020-1178	In the end, is the proposed method faster because it uses less data?	weakness
2020-1178	Besides the weakness above, I also suggest the authors evaluate their method with some extrinsic evaluations.	suggestion
2020-1178	What's currently used is only intrinsic---the embeddings are trained to preserve relative distances and are evaluated on a trade-off between local accuracy and the defined global score.	suggestion
2020-1178	It is fine because extensive visualizations are provided and readers can subjectively judge the quality of the learned embeddings.	strength
2020-1178	However, the experimental section can be stronger if the authors can show the learned embeddings are better at helping some downstream tasks than other baselines (by preserving non-local information?).	weakness

2020-1179	This paper proposes a flatness measure that is invariant to layer-wise reparametrizations in ReLU networks.	abstract
2020-1179	The notion of feature robustness, which is a notion the paper proposes, connects the flatness measure to generalization error.	abstract
2020-1179	This paper should be rejected because it is not well-placed in the literature.	decision
2020-1179	Similar notions with the proposed flatness measure have repeatedly appeared in the literature.	weakness
2020-1179	This paper needs to discuss novel insights.	weakness
2020-1179	Major comments: 1) Many studies proposed or mentioned the flatness measures listed in Table 1 [1, 2, 3, 4].	weakness
2020-1179	One of the most relevant work will be [1].	misc
2020-1179	It appears that the Fisher-Rao norm [1] has several advantages over the proposed measure in the submitted paper.	weakness
2020-1179	A) Fisher-Rao norm is invariant to a broader range of linear transformations.	weakness
2020-1179	B) Fisher-Rao norm does not rely on the Hessian, which is more suitable for non-smooth ReLU networks.	weakness
2020-1179	Additionally and importantly, the Fisher-Rao norm has a direct connection with the size of input gradients, which has a strong relationship with the feature robustness.	weakness
2020-1179	It is strongly encouraged to discuss the connections and comparisons with the Fisher-Rao norm.	suggestion
2020-1179	2) On the connection to the generalization error, Theorem 10 relies on the strong assumption defined in Definition 9.	weakness
2020-1179	Given the high ability of deep networks to express many functions, assuming that \\phi(S) is epsilon-representative seems difficult to justify.	weakness
2020-1179	This paper should discuss why the assumption is reasonable.	weakness
2020-1179	Otherwise, it is hard to claim that this paper connected the modified flatness measure to generalization error.	weakness
2020-1179	[1] Liang et al. "Fisher-Rao Metric, Geometry, and Complexity of Neural Networks." AISTATS 2019	misc
2020-1179	[2] Achille et al. "Emergence of Invariance and Disentanglement in Deep Representations." JMLR 19 (2018)	misc
2020-1179	[3] Neyshabur et al. "Exploring Generalization in Deep Learning." NeurIPS 2017	misc
2020-1179	[4] Tsuzuku et al. "Normalized Flat Minima: Exploring Scale Invariant Definition of Flat Minima for Neural Networks using PAC-Bayesian Analysis." arXiv:1901.04653	misc
2020-1179	===== Update: Thank you for the replies and the clarifications.	misc
2020-1179	They did address some of my concerns.	rebuttal_process
2020-1179	However, the theoretical result is limited, and I do not think it provides clear connections of flatness and the local loss landscape.	weakness
2020-1179	I think this paper is not ready for publication, and I keep my score.	decision
2020-1179	This paper describes a connection between flatness of minima and generalization in deep neural networks.	abstract
2020-1179	The authors define a concept called "feature-robustness" and show that it is related to flatness.	abstract
2020-1179	This is derived through a straightforward observation that perturbations in feature space can be recast as perturbations of the model in parameter space.	abstract
2020-1179	This allows the authors to define a (layerwise) flatness measure for minima in deep networks (this layerwise flatness measure is also invariant to rescalings of the layers in neural networks with positively homogenous activations).	abstract
2020-1179	The authors combine their notion of feature robustness with epsilon representativeness of a function to connect flatness to generalization.	abstract
2020-1179	They present a few empirical evaluations on CIFAR10 and MNIST.	abstract
2020-1179	I believe this paper is able to once again confirm the relationship between flatness and generalization in an empirical manner with their layerwise measure of flatness.	suggestion
2020-1179	I am not so convinced about the theoretical justification that they claim to provide and thus do not recommend acceptance.	decision
2020-1179	Theory - The key theorem relating generalization and flatness is Theorem 10 which says that if a compositional model is feature robust and the output of the first component is an epsilon-representative for the second component, then the compositional model will generalize.	weakness
2020-1179	While this is interesting, it is not clear to me that this guarantees generalization for deep neural networks.	weakness
2020-1179	This result only talks about feature robustness and representativeness for a particular layer.	weakness
2020-1179	If a deep network has many layers, will the feature robustness layers closer to the input guarantee feature robustness at deeper layers?	weakness
2020-1179	That might require a further unit operator norm constraint on the layer operator, which is a restriction on the types of weights that can be used.	weakness
2020-1179	If a sample is epsilon representative at one layer, what is required for the next layer to be epsilon representative for the rest of the deep network?	weakness
2020-1179	This seems to be a missing step in relating flatness/feature robustness of a layer to the generalization of the whole network.	weakness
2020-1179	Another idea that I think arises from Theorem 10 is that the flatness of loss landscapes is important when you have learning problems where the hypothesis class is compositional.	weakness
2020-1179	While flatness is only spoken of in the case of deep neural networks, can we identify the same phenomenon in other problems?	weakness
2020-1179	I would encourage the authors to try and identify another model in which the flatness-generalization relationship exists (even empirical evidence would suffice for now).	suggestion
2020-1179	This would strengthen the case for studying flatness and biasing optimization towards flatter solutions in the case of deep networks.	suggestion
2020-1179	Experiments - This section seems to be pretty rudimentary, I would like to see more results on different kinds of network architectures (VGG?	weakness
2020-1179	Inception? AlexNet?), more datasets (KMNIST? Fashion MNIST?	weakness
2020-1179	SVHN?), and possibly more repetitions.	weakness
2020-1179	At one point the authors mention that they declare a minimum has been reached if the training loss is < 0.07.	weakness
2020-1179	Atleast on CIFAR10 and MNIST it is possible to achieve training loss <1e-4 so am not sure if the networks that the authors are testing are minima at all (It is important for them to be minima since the flatness measure is only defined at minima).	weakness
2020-1179	Can the authors also identify more situations other than large batch vs small batch training that would lead them to obtain flatter/sharper minima?	weakness
2020-1179	The authors also claim that measuring generalization using test error is flawed, but do not provide details about their method of measuring generalization.	weakness
2020-1179	I would want to see these details and a more thorough discussion of why measuring generalization through test error is flawed.	weakness
2020-1179	While this is an interesting paper, I do not believe it is ready for acceptance at *CONF* 2020.	decision
2020-1179	This paper proposes a notion of feature robustness which is invariant with respect to rescaling the weight.	abstract
2020-1179	The authors discuss the relationship of this notion to generalization.	abstract
2020-1179	The definition of feature robustness is interesting and could potentially be useful.	strength
2020-1179	However, the paper has the following major issues: 1- Related work: It seems that authors are unaware of the related work in this area.	weakness
2020-1179	There are many relevant work in this area that connect feature or weight robustness to generalization look at [1,2,3,4] for some examples.	suggestion
2020-1179	I suggest authors to do a comprehensive literature review.	suggestion
2020-1179	2- Theoretical results: The theoretical results presented in the paper have very limited value.	weakness
2020-1179	For example, authors fail to really connect their suggested measure to generalization in any meaningful way.	weakness
2020-1179	Instead they end up decomposing the test error to the sum of their robustness measure and the gap between robustness and test error which is trivial.	weakness
2020-1179	I suggest authors to look at the literature on PAC-Bayesian and compression-based bounds to connect their suggested measure to generalization.	suggestion
2020-1179	3- Experiments: The experiments are not really convincing.	weakness
2020-1179	The empirical results show that the suggested measure can correlate with generalization when training with different batch-sizes.	weakness
2020-1179	When varying other things, the measure is not really correlated.	weakness
2020-1179	Therefore, this is not any better than the version suggested by Keskar et.	weakness
2020-1179	al. Moreover, the experiments are very limited and I suggest authors to look at more controlled setting to verify the relationship of their measure to generalization.	weakness
2020-1179	Also, when looking at the generalization, it is important to set the stopping criterion based on the cross-entropy instead of number of epochs.	weakness
2020-1179	[1] Dziugaite and Roy. "Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data".	misc
2020-1179	AAAI, 2017. [2] Neyshabur et. al.	misc
2020-1179	"Exploring Generalization in Deep Learning", NeurIPS 2017.	misc
2020-1179	[3] Arora et. al. "Stronger generalization bounds for deep nets via a compression approach".	misc
2020-1179	ICML 2018. [4] Wei and Ma.	misc
2020-1179	"Data-dependent Sample Complexity of Deep Neural Networks via Lipschitz Augmentation", NeurIPS 2019.	misc
2020-1179	**************************** After author rebuttals: Author have added discussion of related work which was missing in the original submission (thanks!).	rebuttal_process
2020-1179	However, the other two issues are still present.	rebuttal_process
2020-1179	On the theoretical side, I think the major issue is that the paper cannot connect the measure to generalization properly and ends up decomposing the test error to the sum of the robustness measure and the gap between test error and the robustness measure which is not informative.	weakness
2020-1179	However, this would have been still interesting if the measure could go beyond other empirical measures.	suggestion
2020-1179	Unfortunately, the correlation only happens in case of changing batch size (and learning rate which we know is empirically equivalent to changing batch size) and therefore cannot go beyond what is shown in Keskar et al. 2017.	weakness
2020-1179	Therefore, my evaluation remains the same.	weakness

2020-1290	[Overview] In this paper, the authors proposed a new method called knowledge acquisition (KA) for distilling the learned knowledge from the teacher model to the student model.	abstract
2020-1290	Unlike the conventional KL-divergence based knowledge distillation method, the authors take the reverse version which learns the student to increase the precision.	abstract
2020-1290	The paper gave a thorgough analysis on the proposed KA strategy and compared with other strategies like KL and JS divergence.	abstract
2020-1290	On the sequence generation task (translation), the authors showed that the proposed KA strategy achieved better performance compared with KD based methods when distilling the knowledge from a teacher model to a student model.	abstract
2020-1290	[Pros] 1. The authors proposed a new strategy to perform the knowledge distillation from a teacher model to student model for sequence generator.	strength
2020-1290	To improve the precision of the student model, the authors proposed to invert the formula of KL divergence, i.e., the position of prediction probability from teacher and student models.	strength
2020-1290	2. The authors presented a thorough analysis on the proposed KA strategy and compared it with KL strategy in terms of the precision and recall for the student models.	strength
2020-1290	I think it is very readable and understandable.	strength
2020-1290	This analysis align with those put on generative adversarial network.	strength
2020-1290	3. The authors performed the experiments on the translation tasks showing that the proposed KA strategy outperforms both KL and JS strategy in terms of the generation performance.	strength
2020-1290	Also, the authors ablated the number of top reference tokens from the teacher model and showed that using a reasonable number of top tokens is important to help alleviate the noised in the teacher model.	strength
2020-1290	[Cons] The main concern about the proposed method is whether it can be used as a generic strategy for transferring the knowledge from the teacher model to student model.	weakness
2020-1290	1. First, I have a doubt on the stability of the proposed strategy.	weakness
2020-1290	In my opinion, the improvements on the sequence generation tasks are mainly due to the tuned hyper parameters for the training, especially the lambda in Eq(12), which is tuned at the validation set.	strength
2020-1290	It controls how much to modulate the prediction distribution of student model toward that of teacher model.	strength
2020-1290	However, a less tuned lambda would cause either over curve fitting or under curve fitting.	strength
2020-1290	As a result, the authors should: 1) first show how the performance would be affected by varying the lambda in the formula; 2) from the reading, I did not see whether the lambda was tuned as well for KD or (KD + KA) / 2.	suggestion
2020-1290	If not, then for fair comparison, the authors should tune the lambda for the KD and (KD + KA) / 2 strategy as well.	suggestion
2020-1290	At some point, I would think the combination of KD and KA would be better than either of them.	suggestion
2020-1290	2. Second, some experimental results are somewhat counter-intuitive to me.	weakness
2020-1290	These are two folds: a) In Figure 4(b), we can see that the KA strategy has learned to generate more new tokens compared with KD.	weakness
2020-1290	This is a bit strange to me because, KA will focus on the precision instead of recall.	weakness
2020-1290	To me, pushing the precision will high likely sacrifice the recall and thus the number of novel tokens generated by the model.	weakness
2020-1290	b) similarly, in Figure 5, it is shown that KA has generally higher entropy than KD.	weakness
2020-1290	This is also a bit counter intuitive.	weakness
2020-1290	In Eq(6), it is obvious that the proposed strategy has a entropy term which will be reduced when we want to reduce the KL divergence during the training time.	weakness
2020-1290	From Figure 5, KA and KD start from the same point (I guess it is because the same pre-trained student model) is used.	weakness
2020-1290	However, for KA, the entropy start to increase and then converge to a stable number which is consistently higher than KD strategy.	weakness
2020-1290	3. Third, Figure 4(a) also indicates some thing.	weakness
2020-1290	When only the top few tokens are used to transfer the knowledge from teacher model to student model, KA focus on the precision of a small subspace, which tends to have few modes.	weakness
2020-1290	However, when the number of tokens is increased, the mode number would also increase drastically.	weakness
2020-1290	i guess that's why the both strategies finally become very close to each other, and the minor gap between them is probably due to the benefit from hyper-parameter fine-tuning.	weakness
2020-1290	Besides the above comments. there are some minor points which are missed in the paper: 1. As pointed above, it is not clear whether the same tuning is also applied to KD and (KD + KA) / 2.	weakness
2020-1290	the authors should mention this in the experiment section.	suggestion
2020-1290	2. It is also not clear how many tokens is used for reporting the numbers in Table 2.	weakness
2020-1290	Is it the whole vocabulary side?	weakness
2020-1290	If this is the case, the gap between KA and KD on validation set are pretty close while more significant on test set.	weakness
2020-1290	3. In Eq (11), should there be a minus sign before the expectation?	weakness
2020-1290	4. Also, is there any more comment on why it is hard to train the student model joint from scratch?	weakness
2020-1290	what will happen in this case?	weakness
2020-1290	[Summary] In this paper, the authors proposed a new strategy called Knowledge Acquisition which is used for distilling the knowledge learned from  teacher model to the student model.	abstract
2020-1290	Different from KD strategy, it inverted the position of probability distributions for teacher and student models.	abstract
2020-1290	By this way, the KA strategy learns a student model which can achieves higher precision.	abstract
2020-1290	The proposed strategy is evaluated on sequence generation, particularly translation task.	abstract
2020-1290	However, as pointed above, in my opinion, there are some counter-intutive observations in the experimental results.	weakness
2020-1290	It would be good if the authors can address these concerns in the rebuttal.	suggestion
2020-1290	This paper introduces Knowledge Acquisition (KA), i.e., KL-divergence in the reverse order as the loss function to train student models for sequence-to-sequence tasks, and experiments were done on WMT'17 De-En and IWSLT'15 Th-En translation tasks.	abstract
2020-1290	Pros: The paper is clearly written.	strength
2020-1290	The authors clearly show the reason to use KL-divergence in the reverse order.	strength
2020-1290	They provide a concrete analysis of the effects of minimizing the proposed KA loss function to alleviating exposure bias.	strength
2020-1290	Some figures like Fig. 1 and Fig. 2 helps to show the paper.	strength
2020-1290	Cons: As the analysis of the authors, KL-divergence in the reverse order is an alternative of KL-divergence for training student models on sequence generation tasks.	weakness
2020-1290	However, I have a little concern that the contribution is relatively limited since it is known that KL-divergence is not symmetric and the proposed KA (KL-divergence in the reverse order) may be thought a little straightforward.	weakness
2020-1290	In addition, KA is only investigated on token-level, as the authors said, "due to practical issues".	weakness
2020-1290	The experiments in this paper may be thought insufficient.	weakness
2020-1290	Specifically, the authors only establish teacher and student model baselines by themselves.	weakness
2020-1290	It is reasonable that the proposed method could be compared with other similar KD methods, like [1] mentioned in the paper.	weakness
2020-1290	Another concern is whether the proposed KA method can be applied in current sequence-to-sequence state-of-the-art teacher models, such as GPT-2 [2] and XLM [3], and whether it is still effective.	weakness
2020-1290	Reference [1] Yoon Kim, Alexander M.	misc
2020-1290	Rush. Sequence-Level Knowledge Distillation. EMNLP 2016	misc
2020-1290	[2] Alec, Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever.	misc
2020-1290	Language models are unsupervised multitask learners.	weakness
2020-1290	OpenAI Blog 2019. [3] Guillaume Lample, Alexis Conneau.	misc
2020-1290	Cross-lingual Language Model Pretraining. CoRR abs/1901.07291 This paper addresses the problem of training small models to mimic large models but, in constrast to knowledge distillation, minimize the reverse-KL between the teacher and the model instead of the forward-KL.	abstract
2020-1290	The authors notice that there is an interesting interaction between beam search (i.e. focusing only on the top-k tokens) and distillation.	abstract
2020-1290	By minimizing the forward-KL, distillation focuses the student on having the non-negative mass on all the words selected by the teacher.	abstract
2020-1290	However, the authors argue that minimizing the reverse-KL makes more sense: to only include tokens in the students that are present in the teacher.	abstract
2020-1290	The paper then spends time explaining the difference between minimizing the KL (KD) or the reverse KL (their proposed KA) and show some experiments validating their methods.	abstract
2020-1290	I think the paper is well-written, but can be sometimes difficult to follow.	strength
2020-1290	For example, they introduce the notation p_\\theta and q_\\phi without specifying who is the teacher and who is the student (I assumed that q was the teacher and p the student as in the introduction).	strength
2020-1290	The paper spend a bit of time explaining the qualitative difference between minimizing the KL or the reverse-KL.	weakness
2020-1290	Even though it is useful, I believe it is well known in the community and can be found in multiple standard references (e.g. (Murphy, 2012) or this online class on graphical models: https://ermongroup.github.io/cs228-notes/inference/variational/).	weakness
2020-1290	I don't think this constitutes a contribution yet the authors spend a fair amount of the paper on that particular topic.	weakness
2020-1290	The idea is quite simple but seems to be effective (up to +1.9 BLEU on German to English and +0.6 BLEU on Thai to English).	strength
2020-1290	I think it would have been useful to say how each model were tuned for fair comparison (e.g. how was the learning rate chosen?).	suggestion
2020-1290	I would have also like to see more tasks, like language modelling, question answering or text summarization.	suggestion
2020-1290	I also think the use of the term `actor-critic' is misleading given that, as far as I understand, there is no reinforcement learning in this paper.	weakness
2020-1290	Section 3.1.2 is really confusing: are you referring to the derivative of the KL between two finite-dimensional vectors?	weakness
2020-1290	Is there a lagrangian because you are somewhat taking the derivative on the simplex?	weakness
2020-1290	Overall, this paper proposes an interesting trick that seems to work in practice but the novelty remains limited.	weakness
2020-1290	(Murphy, 2012) Machine Learning: a Probabilistic Perspective.	misc
2020-1290	Murphy, Kevin. 2012.	misc

2020-1381	This paper studies the effect of quantization on training reinforcement learning tasks.	abstract
2020-1381	Specifically, the paper applies post-training quantization and quantization aware learning to various tasks and record the effects on accuracy and training speed.	abstract
2020-1381	Overall, the empirical evaluations suggest that quantization does not significantly hurt the performance of RL training among a wide range of tasks.	abstract
2020-1381	On several tasks, the authors showed that quantization can significantly reduce memory usage and speed up the inference time.	abstract
2020-1381	On the other hand, the improved efficiency comes at the cost of accuracy or lower rewards (2% - 5% error as shown in section 4) and (> 5% in terms of success rate as shown in Figure 5).	weakness
2020-1381	While it is expected that quantization should decrease the accuracy of the trained model, it is not entirely clear how one should evaluate the trade-off presented in the work.	weakness
2020-1381	Some natural questions that I believe deserve more discussions are: -- Are the kinds of accuracy cost the best one could hope for using these methods?	weakness
2020-1381	--  Is there still room for improvement in terms of reducing the cost of accuracy?	weakness
2020-1381	Detailed comments: -- In the definition of Q_n(W): isn't δ equal to |W| / 2^n?	weakness
2020-1381	-- In Figure 5: your results show that the "int8" method has a significantly lower success rate than "fp32".	weakness
2020-1381	Could you provide some discussion as to why this is the case?	suggestion
2020-1381	-- Typos: Page 4, "is a applied"; Page 5, "full connected weights"; Page 8, "of a accurate".	misc
2020-1381	This paper investigates the impact of using a reduced precision (i.e., quantization) in different deep reinforcement learning (DRL) algorithms.	abstract
2020-1381	It shows that overall, reducing the precision of the neural network in DRL algorithms from 32 bits to 16 or 8 bits doesn't have much effect on the quality of the learned policy.	abstract
2020-1381	It also shows how this quantization leads to a reduced memory cost and faster training and inference times.	abstract
2020-1381	I don't think this paper contributes with many novel results in the field, with most results being known or expected.	weakness
2020-1381	The result that is interesting, in my opinion, is not properly explored.	weakness
2020-1381	The paper is well-written but it is a bit repetitive.	weakness
2020-1381	It seems to me that the first 3 pages could be compressed in 1, as the same information is introduced over and over again.	weakness
2020-1381	With respect to the results being known, quantization is known to succeed in supervised learning tasks.	weakness
2020-1381	In a deep reinforcement learning algorithm, when you apply post-training quantization in a deep reinforcement learning algorithm, mainly when that algorithm uses a value function (e.g., A2C or DQN), the problem is reduced to a regression problem.	weakness
2020-1381	It is no different than a supervised learning problem.	weakness
2020-1381	One has the original network's prediction and they need to match that prediction.	weakness
2020-1381	The complexities introduced in the reinforcement learning problem (bootstrapping, exploration, stability) don't exist anymore as they arise during training.	weakness
2020-1381	Thus, it doesn't seem to me that these results are novel or surprising.	weakness
2020-1381	In a sense it is neat to see that eventual errors do not compound, but that's it.	weakness
2020-1381	If I were to write this paper I would make this set of experiments much shorter just as a sanity check.	weakness
2020-1381	One thing that I feel is missing is a notion of the impact of the quantization not in the rewards accumulated but in the policy/value function.	weakness
2020-1381	How often does the quantized agent take a different action than the original agent, for example?	weakness
2020-1381	Does it happen often but only when it doesn't matter, or is it rare?	weakness
2020-1381	The quantization during training is potentially interesting.	strength
2020-1381	It was not properly explored though.	weakness
2020-1381	I wonder if the quantization during training has a regularization effect, which is known to improve agent's performance in reinforcement learning (e.g., Cobbe et al., 2018, Farebrother et al., 2018).	weakness
2020-1381	Does the agent generalize better when using a network with fewer bits of precision?	weakness
2020-1381	How does this change impact training?	weakness
2020-1381	These are all questions that could potentially make the results in this paper novel (i.e., quantization as a form of regularization), but as it is now, the results are not that surprising.	weakness
2020-1381	Importantly, there are important details missing in the paper that make it hard for me to evaluate the validity of the results presented.	weakness
2020-1381	Are the results reported over multiple runs?	weakness
2020-1381	What is the version of the Atari games used, is it the one with stochasticity?	weakness
2020-1381	How much variance do we have if we replicate this process over different networks that perform well?	weakness
2020-1381	These are questions I would like to see answered because they also inform us about the impact of the proposed idea.	weakness
2020-1381	For example, if by repeating this experiment multiple times one observe a high variance, it might mean that different models might be impacted in different ways.	weakness
2020-1381	The results in the "real-world" (Pong is not real-world) are not that surprising as well.	weakness
2020-1381	Basically they show that if one uses a network with lower precision training and inference are faster, which, again, is not surprising.	weakness
2020-1381	There's also an important distinction in the results that is not discussed in the paper: DQN estimates a value function while methods such as PPO directly estimate a policy.	weakness
2020-1381	The reason DQN might have a wider distribution is exactly because it is estimating a different objective.	weakness
2020-1381	These are important details that should be acknowledged and discussed in the paper.	weakness
2020-1381	In my opinion, for this paper be relevant, it should have a very thorough evaluation of these different dimensions of reinforcement learning algorithms, with explicit discussions about it.	weakness
2020-1381	Variance, the impact of quantization during learning, the distinction between parametrizing policies versus value functions, etc.	weakness
2020-1381	Finally, there are some aspects of the presentation of this paper that could also be improved.	weakness
2020-1381	Aside from typos, below are some other comments on the presentation.	misc
2020-1381	- There's no such thing as Atari environment, it is either Arcade Learning Environment (Bellemare et al., 2013) or Atari games.	weakness
2020-1381	- I'd introduce/explain quantization in the beginning of the second paragraph of the Introduction for those not familiar with the term.	suggestion
2020-1381	- No references are provided for the environments used.	weakness
2020-1381	You should refer to Bellemare et al.'s (2013) work as well as Brockman et al.'s (2016).	suggestion
2020-1381	- Is it really necessary to explain Fp16 quantization as it is done now, with even a picture of two bytes?	weakness
2020-1381	I'd expect most readers are familiar with how numbers are represented in a computer.	weakness
2020-1381	- The equation for Uniform Affine Quantization is pretty much the same as the one in the Section Quantization Aware Training.	weakness
2020-1381	All these "repetitions", or discussions that are common-knowledge give the impression that the paper is trying to fill all the pages without necessarily having enough content.	weakness
2020-1381	- The references are not standardized (e.g., sometimes names are shortened, sometimes they are not) and the paper "Efficient inference engine on compressed deep neural network" is cited twice.	weakness
2020-1381	References: Marc G. Bellemare, Yavar Naddaf, Joel Veness, Michael Bowling: The Arcade Learning Environment: An Evaluation Platform for General Agents.	misc
2020-1381	J. Artif. Intell. Res. 47: 253-279 (2013)	misc
2020-1381	Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, Wojciech Zaremba: OpenAI Gym. CoRR abs/1606.01540 (2016)	misc
2020-1381	Karl Cobbe, Oleg Klimov, Christopher Hesse, Taehoon Kim, John Schulman: Quantifying Generalization in Reinforcement Learning.	misc
2020-1381	CoRR abs/1812.02341 (2018) Jesse Farebrother, Marlos C.	misc
2020-1381	Machado, Michael Bowling: Generalization and Regularization in DQN.	misc
2020-1381	CoRR abs/1810.00123 (2018) ------ >>> Update after rebuttal: I stand by my score after the rebuttal.	rebuttal_process
2020-1381	The rebuttal did acknowledge some points I made to me the paper took a gradient update towards the right direction.	rebuttal_process
2020-1381	I don't think the paper is quite there yet though.	decision
2020-1381	It is repetitive, spending too much time with basic concepts, and it still ignores small details that matter (e.g., calling it Atari Arcade Learning).	weakness
2020-1381	I strongly recommend the authors to follow my recommendations closely and then submit the paper again to a next conference.	decision
2020-1381	The discussion about generalization is potentially interesting, going beyond the regularization for exploration aspect.	strength
2020-1381	A better discussion about quantization during learning is also essential.	strength
2020-1381	The first three pages could probably be compressed by half.	weakness
2020-1381	Training and deployment of DRL models is expensive.	weakness
2020-1381	Quantization has proven useful in supervised learning, however it is yet to be tested thoroughly in DRL.	weakness
2020-1381	This paper investigates whether quantization can be applied in DRL towards better resource usage (compute, energy) without harming the model quality.	abstract
2020-1381	Both quantization-aware training (via fake quantization) and post-training quantization is investigated.	abstract
2020-1381	The work demonstrates that policies can be reduced to 6-8 bits without quality loss.	abstract
2020-1381	The paper indicates that quantization can indeed lower resource consumption without quality decline in realistic DRL tasks and for various algorithms.	abstract
2020-1381	The researchers propose a benchmark called QUARL that allows them to evaluate the effectiveness of quantization as well as the impact of quantization across a set of established DRL algorithms (e.g., DQN, DDPG, PPO) and environments (e.g., OpenAI Gym, ALE).	abstract
2020-1381	Quantizations tested: fp32 -> fp16, int8, uniform affine.	abstract
2020-1381	The idea is simple and carries over from (image-based) supervised learning.	abstract
2020-1381	The experiments are exhaustive and have to the best of my knowledge not yet been conducted.	abstract
2020-1381	The conclusions indicate the advantage of quantization, however it is unclear how these results would generalize to real environments (the environments used are after all still simple benchmarks, e.g., half-cheetah or pong).	weakness
2020-1381	The results are also not entirely surprising or impactful: how is quantization impacting reinforcement learning in a different way than supervised learning?	weakness
2020-1381	E.g., DQN is supervised learning of a Q-value function against a target.	weakness
2020-1381	What secondary effects does quantization have on the learning procedure: e.g., does it boost exploration behavior or does it regularize training?	weakness
2020-1381	We also know that some of these tasks can be solved by extremely small models (https://arxiv.org/abs/1806.01363), while the models used in this work are significantly larger: is quantization working simply because the network capacity is large enough to allow it?	weakness
2020-1381	These could be investigated in more detail.	weakness
2020-1381	Furthermore, I'm also missing some experimental setup details: e.g., how many seeds were used for all of the experiments (which is known to greatly affect the results on the benchmarks used in this paper)?	weakness

2020-1387	This paper proposes a model that learns to disentangle visual scene into objects (slots), and simultaneously learns a dynamics model to capture how these objects interact with each other.	abstract
2020-1387	The authors demonstrated that the proposed model has the potentials to discover objects without supervision, and also enables an exploration strategy that maximizes the number of objects changed in the agents' trajectories.	abstract
2020-1387	This paper is for sure studying an important problem.	strength
2020-1387	The approach presented in the manuscript makes intuitive sense.	strength
2020-1387	The experimental results are reasonable but can be strengthened.	weakness
2020-1387	However, I was shocked that the authors seem to be unaware of the abundant related work in this area (see below).	weakness
2020-1387	I'd like to see the authors' responses regarding the missing related work.	misc
2020-1387	As of now, my recommendation is a clear reject.	decision
2020-1387	As the authors mentioned, objects play a key role in human perception, and the problem of discovering objects from visual input is for sure an important problem.	suggestion
2020-1387	I commend the authors for pursuing research in this direction.	misc
2020-1387	The experimental evaluations are however a little limited: it's restricted to games, where the visual appearance of objects is almost identical.	weakness
2020-1387	In those cases, it'd be hard to access how the model may generalize to real-world data, where object appearances and texture can be complex.	weakness
2020-1387	There are also no comparisons with published, SOTA methods.	weakness
2020-1387	The major problem of this manuscript, to me, is its ignorance of related work and, therefore, overclaiming at a few places.	weakness
2020-1387	Most importantly, I suggest the authors cite, discuss, and ideally compare with many related works from Josh Tenenbaum's group and Sergey Levine's group.	suggestion
2020-1387	A few papers listed below, in particular [A] and [B], also formulated the problem in a similar fashion, where they decompose the scene into object-centric representations and learn the interactions among objects.	suggestion
2020-1387	[B] and [C] also explored how the model can be used in an RL setting.	misc
2020-1387	Further, [D] studied learning an object-oriented dynamics predictor in a similar context as presented in this paper.	suggestion
2020-1387	The sparse effects have also been explored by Xia et al. [E].	misc
2020-1387	Similarly, the work has built upon object-centric representations.	weakness
2020-1387	I, therefore, wonder how the proposed method compares with all those published papers, both at the conceptual level and at the experimental level.	suggestion
2020-1387	[A] Wu et al. Learning to See Physics via Visual De-animation.	misc
2020-1387	NeurIPS 2017 [B] Janner et al. Reasoning About Physical Interactions with Object-Oriented Prediction and Planning.	misc
2020-1387	*CONF* 2019 [C] Co-Reyes et al. Discovering, Predicting, and Planning with Objects.	misc
2020-1387	ICML 2019 Workshop, https://sites.google.com/view/dpppo/ [D] Zhu et al. Object-Oriented Dynamics Predictor. NeurIPS 2018 [E] Xia et al. Learning sparse relational transition models.	misc
2020-1387	*CONF* 2019 This paper proposes to use a 'slot-based' (factored) representation of a 'scene' s.t. a forward model learned over some observed transitions only requires sparse updates to the current representation.	abstract
2020-1387	The results show that jointly learning the forward model and the scene representation encourages meaningful 'entities' to emerge in each slot.	abstract
2020-1387	Additionally, the paper argues that this representation allows for better generalization and can also guide exploration by rewarding actions that change multiple entities	abstract
2020-1387	I really like the overall idea i.e. jointly learning the scene representation and the transition model, while enforcing sparse transitions.	strength
2020-1387	The experiments in Sec 4.2 and the visual results in Fig 3 do clearly highlight the benefits of joint learning, and show that the emergent representations are more meaningful compared to learning representations independently.	strength
2020-1387	However, while the overall approach is intuitive and seems to yield desirable results, I have concerns regarding the experiments, comparisons to prior work, and the exact contributions of this work.	weakness
2020-1387	Specifically: 1) It is unclear what this paper is claiming to improve over prior work: is the goal to a) learn a good forward model, or b) show that emergent entities allow better downstream tasks.	weakness
2020-1387	If it is 'a' , then there are several other ways of learning good forward models e.g. convolution flow-based [1], and simply showing comparisons to a naive baseline is not sufficient.	weakness
2020-1387	Similarly, the only downstream task examined is exploration, and again the only comparison is against a variant of the method.	weakness
2020-1387	Therefore, while the results regarding the emergent representation are good compared to a variant without joint training, they are not shown to be useful in context of any task when compared to the approaches in literature.	weakness
2020-1387	2) Despite the motivation in the introduction regarding applications to RL, the paper essentially learns a specific form of factored forward model.	weakness
2020-1387	There have been several prior works which also pursue a similar approach (though mainly in context of video prediction) e.g. [2], and I don't think this paper's approach is novel in context of these.	weakness
2020-1387	In any case, some comparisons should be made to these form of models which also show emergent entities with a graph-structured transition model.	suggestion
2020-1387	3) While the experiments in Sec 4.2 clearly demonstrate the benefits of the approach, the ones in Sec 4.1 and 4.3 are less convincing: 3a) Sec 4.1 shows that the slot based transition model generalizes better, but this is only in comparison to a naive fully-connected baseline.	weakness
2020-1387	I feel any prediction model with some structure e.g. graph-based forward model, convolutional forward model etc.	suggestion
2020-1387	would also similarly generalize. 3b) Sec 4.2 argues that this slot-based representation can help exploration, but this is in fact a chicken-and-egg problem, as one needs to have collected interesting transition samples for a good representation to emerge.	weakness
2020-1387	In fact, the results shown in Fig 6b) show that actions affecting 3 blocks were not explored, perhaps because the random transitions did not sample these to begin with.	weakness
2020-1387	Overall, the approach proposed is desirable, but there are closely related alternatives that exist in literature, and there need to be more concrete comparisons against these for either prediction quality or success in downstream task.	weakness
2020-1387	--- References: [1] Self-Supervised Visual Planning with Temporal Skip Connections, Ebert et.	misc
2020-1387	al, CORL 17 [2] Learning to decompose and disentangle representations for video prediction, Hsieh et.	misc
2020-1387	al., NeurIPS 18 This paper introduces a model that learns a slot-based representation, along with a transition model to predict the evolution of these representations in a sparse fashion, all in a fully unsupervised way.	abstract
2020-1387	This is done by leveraging a self-attention mechanism to decide which slots should be updated in a given transition, leaving the others untouched.	abstract
2020-1387	The model learns to encode in a slot-wise and is trained on single step transitions.	abstract
2020-1387	This work tackles an important problem, and is very well motivated and presented in a very clear fashion.	strength
2020-1387	It reuses some known ideas and components, but combines them in a nice way.	strength
2020-1387	I especially liked the use of attention to select what to update, which is a good prior to have.	strength
2020-1387	However, the results presented unfortunately seem to fall a bit short in this current version, and some decisions might have had too much of an effect on some of these shortcomings.	weakness
2020-1387	Given some improvements, this work might become quite promising, but for the time being I am leaning against publication.	decision
2020-1387	1. Most modeling decisions are clear and well-motivated, however the choice to make the transition model f_trans always be applied only "slot-wise" might be too restrictive.	weakness
2020-1387	Indeed, for a given action, this means that 2 slots have to independently learn the effect of that action (e.g. as shown in the example in Figure 2.	weakness
2020-1387	right), and that some interactions are ~impossible to learn (e.g. in Sokoban, pushing a box requires knowing about the location of both the agent and the box).	weakness
2020-1387	This could have been alleviated if the transition had access to "interactions outcomes" (e.g. if using a GraphNet, or in your model, if \\tilde{s} was provided to the transition function f_theta).	suggestion
2020-1387	Other works (including Zambaldi et al 2018, which is cited several times), handle this appropriately.	suggestion
2020-1387	Did you try to provide \\tilde{s} to the transformation operator (e.g. in Figure 7 left)?	suggestion
2020-1387	2. Adding a direct comparison to pure non-slotted versions of the model/baselines would have been quite useful, as currently it is unclear why certain things are failing.	suggestion
2020-1387	3. Similarly, finding what was the output of the CNN encoder for pixel inputs was a bit too difficult.	suggestion
2020-1387	It is explained in the Appendix that one maps into 4x4 feature maps, but that might be too large for the current environments?	weakness
2020-1387	Indeed for Sokoban, this means that any grid is partially supported by several "slots", which may hurt the results more than they should (especially combined with the slot-wise transition constraints expressed above).	weakness
2020-1387	4. The early state of the current results are quite visible in all examples of the "Separate training" model predictions (Figure 3, 5, 8, 9, 10 and 11).	weakness
2020-1387	None of these actually show this model performing a "correct" prediction for t+1?	weakness
2020-1387	They only predict no changes, or nonsensical interpolations… This is not sufficient to try to make an argument about the "joint training" helping, and most discussions about "what information they contain" is strenuous at best.	weakness
2020-1387	5. The paper keeps mentioning that it "implicitly imposes transitions to be sparse", however it is never explained how that would come about?	weakness
2020-1387	I understand that the softmax in the self-attention may tend to become "peaky" and hence only affect a few slots (and the results do seem to confirm this observation), but I was expecting an explicit loss to enforce this fact.	weakness
2020-1387	The current emphasis seems a bit ill-funded, so I would present more evidence to it or downplay it.	weakness
2020-1387	6. Some of the results shown seem hard to interpret or provide only weak evidence for the proposed model: a. Figure 2.	weakness
2020-1387	Left does seem to indicate a benefit in using the self-attention module, but it is hard to know how much of an effect the gap between the orange and red curves actually imply.	weakness
2020-1387	This figure is overall a bit too small to interpret, and it might be better to split the 2 conditions into sub-plots.	weakness
2020-1387	The names of the curves in the legend do not correspond to anything described in the text/caption (but I could understand them…).	weakness
2020-1387	I was expecting more discussion of the results in Figure 2, for example at the end of Section 4.1.	suggestion
2020-1387	b. As explained above, Figure 3 only shows that the Joint Training can perform a 1-step prediction, which is ok but is the bare minimum.	weakness
2020-1387	Does it handle multi-step rollouts?	weakness
2020-1387	c. Figure 4 does not seem to provide any significant results or insights.	weakness
2020-1387	I would interpret them as showing no significant difference between the curves, and they are too small to extract any information out of them.	weakness
2020-1387	I would remove this figure fully.	suggestion
2020-1387	d. Figure 5 is unclear about what f_k=0 really is, and once again just shows that Separate training does nothing.	weakness
2020-1387	I expected it to be exactly reconstructing s_t (given that the others are trying to predict s_t+1)?	suggestion
2020-1387	But this is only the case for the joint training, and without knowing what x_t actually was, it is hard to trust.	weakness
2020-1387	The fact that f_k changes what it does as it is being increased makes the whole point hard to interpret.	weakness
2020-1387	7. Figure 6 was quite interesting, and I feel like this could be pushed forward in a quite interesting manner.	weakness
2020-1387	The choice of "maximizing the number of entities selected" was fair as a first try, but I could imagine it failing to generalize to more complex environments, or to be easily exploited if one ever decides to pass gradients back into the representation from the policy.	weakness
2020-1387	It was unfortunate that the legends do not correspond to anything expressed in the main text or caption (e.g. why do you not reuse the "valid_move", …, "blocked_push" names that you thoroughly introduce?).	weakness
2020-1387	What is "random_XX"? Could you comment on why the curves seem to have a large increase in variance along the 80000-100000 updates region?	weakness
2020-1387	Details: 8. Figure 2 (right) was good to explain how the model worked, but I would actually change its location and try to move it into Figure 1.	weakness
2020-1387	Similarly, Figure 7 in the Appendix seemed rather necessary to understand the model, and belongs in the main text in my opinion.	weakness
2020-1387	9. When presenting the self-attention block, it would be good to directly state that these are MLPs receiving [s_t, a_t] (as done in the Appendix).	weakness
2020-1387	10. Is sigma^2 in the decoder fixed?	weakness
2020-1387	To which value? 11. When presenting the "sparse" and "full" settings, having access to Figure 7 and the rest of the Appendix might be beneficial, it would be good to point forward to it.	suggestion

2020-1395	Summary --- (motivation) CNN image classifiers tend to overfit to distractor patterns.	abstract
2020-1395	Perhaps these patterns are spatially local, such that in most images signal is at one location while the noise models tend to overfit to is somewhere else.	abstract
2020-1395	If so, then generalization should improve if models are given additional supervision (i.e., a mask identifying salient regions) that specifies where the signal is and is not.	abstract
2020-1395	This paper designs the Actdiff loss to realize this intuition.	abstract
2020-1395	(approach) Actdiff: 1) The Actdiff loss requires a mask that highlights areas of the input image which have signal and not distractor regions.	abstract
2020-1395	It extracts features from the original input image and its masked version then encourages the two features to be similar at every layer of the CNN using an L2 loss.	abstract
2020-1395	Actdiff is compared to 5 other methods including a reconstruction loss and Gradmask (previous work).	abstract
2020-1395	(evaluation - synthetic dataset) A synthetic dataset is constructed for a simple binary classification task based on the presence of simple shapes.	abstract
2020-1395	Two patterns can predict the correct class at train time, but one of the patterns is removed at test time so additional information (masks in this case)	abstract
2020-1395	is required to specify which pattern the classifier should use.	abstract
2020-1395	All the losses except Actdiff achieve at best 50% accuracy on the val set, but Actdiff gets 80% or more accuracy on 3 of 4 tested model variations.	abstract
2020-1395	This shows that Actdiff can effectively introduce the relevant masking information.	abstract
2020-1395	(evaluation - Medical Segmentation Decathalon)	misc
2020-1395	This dataset provides 3 segmentation tasks (Liver, Cardiac, Pancreas), including ground truth masks for those images.	abstract
2020-1395	All 6 methods outperform all the others at least some of the time.	abstract
2020-1395	The conclusion is that adding mask information using Actdiff doesn't improve segmentation performance.	abstract
2020-1395	(evaluation - Multi-Site dataset) A final task tries to construct another synthetic dataset out of real X-ray images collected at two different places.	abstract
2020-1395	The train set is largely from one place and the test set is mostly from the other place, and masks are constructed so Actdiff can try to eliminate this bias.	abstract
2020-1395	Actdiff causes a negligible increase in performance.	abstract
2020-1395	The paper concludes that signals CNNs tend to fit to in this type of data are not very spatially distinct.	abstract
2020-1395	Strengths --- There is some novelty in the approach.	strength
2020-1395	The actdiff loss makes sense and masking + activation mapping have not been tried together before to my knowledge.	strength
2020-1395	Experiments follow a logical progression, starting by verifying the idea on a synthetic dataset, then moving to real data, and then evaluating on a half-synthetic dataset designed to debug the approach.	strength
2020-1395	Experiments average over many random initializations.	strength
2020-1395	The paper embraces its negative result.	strength
2020-1395	Weaknesses --- The approach is not very compelling to me: * Implicit in this paper is that any information outside the mask is a distractor and any information inside is not a distractor.	weakness
2020-1395	Why should the particular masks chosen for the experiments have this property?	weakness
2020-1395	How can an expert know which features a model will find useful?	weakness
2020-1395	The paper's novelty is somewhat limited.	weakness
2020-1395	The idea of regularizing using saliency maps has been explored and even applied to medical data like the MSD used here in Gradmask (one of the strong baselines this paper compares to).	weakness
2020-1395	Activation matching is also common (e.g. [1]), though it has not been combined with masking before.	weakness
2020-1395	While the weights applied to the various losses are provided, it's not clear how they were tuned.	weakness
2020-1395	In this case there may be lots of competing losses, so it's important to tune the weights somehow to ensure the tradeoff between losses is optimal.	weakness
2020-1395	The results (and the conclusions) suggest Actdiff is not very effective at increasing generalization.	weakness
2020-1395	Table 2 reports test results on all datasets.	weakness
2020-1395	In that table, each loss outperforms all the other losses in at least two cases (a case is a model-dataset pair).	weakness
2020-1395	[1]: Gatys, Leon A. et al. "A Neural Algorithm of Artistic Style." ArXiv abs/1508.06576 (2015): n.	misc
2020-1395	pag. Missing experiments: * In the Multi-Site experiment, compare to what happens when the circular mask is applied to all images and not just those from one site.	weakness
2020-1395	This is a necessary control to be sure that any benefits from masking are due to domain transfer and not other regularization effects.	suggestion
2020-1395	Either conclusion could be useful, but it would be nice to know.	suggestion
2020-1395	Presentation weaknesses: * In the synthetic dataset the model cannot tell the difference between correct and incorrect signals at train time.	weakness
2020-1395	Therefore, I think there's no way for some of the baselines (plain classifier, autoencoder) to generalize correctly.	weakness
2020-1395	Is that right? If so, it should be clear that comparisons to these baselines are not fair when discussing the synthetic evaluation in section 4.	weakness
2020-1395	Missing details / points of clarification: * What is the Conv AE?	weakness
2020-1395	I assume it is a CNN based autoencoder of some sort.	weakness
2020-1395	A detailed description of the non-standard architectures would be useful for reproducibility, though probably only in the appendix.	suggestion
2020-1395	* What are the lambda hyperparameters?	suggestion
2020-1395	I assume these are weights on the corresponding loss terms, but this is never made explicit.	weakness
2020-1395	* How does f(.) relate to the function o_l(.)?	weakness
2020-1395	Is o_l(.) an intermediate step in f(.)?	weakness
2020-1395	* The MSD dataset is not clearly described.	weakness
2020-1395	Is this a classification dataset where classes are different diseases?	weakness
2020-1395	What do the ground truth masks capture?	weakness
2020-1395	* I think only Conv AE and UNet contain reconstruction losses.	weakness
2020-1395	This presentation is a bit confusing since reconstruction loss was presented as another loss and it shows up in the tables implicitly based on the architecture being compared.	weakness
2020-1395	Suggestions --- * This paper would be a bit more convincing if it started with a concrete example of the problem illustrated on some dataset (e.g., maybe an example from Gradmask).	suggestion
2020-1395	That may also help drive intuitions later on in the paper.	suggestion
2020-1395	Preliminary Evaluation --- Clarity: The paper is fairly clear.	strength
2020-1395	Quality: Quality is mixed. Lots of relevant experiments are reported but they don't support clear conclusions and I'm not sure how well the models were tuned.	weakness
2020-1395	Originality: There is some novelty, but it is limited as discussed above.	weakness
2020-1395	Significance: I see limited significance.	weakness
2020-1395	For me this paper requires special scruitiny because it presents a negative result.	weakness
2020-1395	Here are some factors that come to mind when thinking about whether to publish a negative result: * Is the approach compelling?	weakness
2020-1395	- This approach is not very compelling (e.g., comments about limited novelty and lack of concrete examples to boost intuition).	weakness
2020-1395	* Are the experiments thorough?	weakness
2020-1395	- The experiments could be significantly more thorough (e.g., comments about tuning lambda).	weakness
2020-1395	* Will readers learn something useful?	weakness
2020-1395	- This paper may help researchers trying to leverage similar intuitions, but it won't be very useful outside this audience.	weakness
2020-1395	* Does the paper present experiments that promote deeper understanding of why the approach failed?	weakness
2020-1395	- This paper makes significant reasonable steps in that direction with sections 4 and 6, but I was still a bit dissapointed with the conclusions of these sections.	weakness
2020-1395	* Does the paper discuss alternative approaches that were investigated?	weakness
2020-1395	- Many alterantive approaches were considered and their performance reported.	weakness
2020-1395	Overall I think this paper is close but fails to meet the bar because it does a bit worse than expected on most criteria above.	decision
2020-1395	This paper attempts to tackle the overfitting problem due to the focusing on the distracting information.	abstract
2020-1395	By utilizing the dataset with masks, the authors propose a simple method to ignore the distracting features.	abstract
2020-1395	By designing actdiff loss and reconstruction loss, the authors demonstrate that classifiers are likely to predict using features unrelated to the task and their losses can mitigate this problem.	abstract
2020-1395	Pros: This kind of study can make us understand deeply what is going on in deep learning and thus to make it better, which shows this work's high significance.	strength
2020-1395	Cons: 1. The presentation of this paper is not clear.	weakness
2020-1395	For example, in Table 1, the experiment name is so confusing.	weakness
2020-1395	The authors mention that "Conv AE Actdiff" is the one using both actdiff loss and reconstruction loss.	weakness
2020-1395	Then what does "Conv AE Reconstruct Masked" mean?	weakness
2020-1395	Does Conv AE means they implicitly contain reconstruction loss?	weakness
2020-1395	The authors should elaborate them clearly.	weakness
2020-1395	The corresponding double quotation marks should be revised.	weakness
2020-1395	Figure 3 is also confusing.	weakness
2020-1395	At first, I thought different lines represent different input data (one without mask and one with mask) and different columns represent different methods.	weakness
2020-1395	However, this is not the case.	weakness
2020-1395	Furthermore, the fourth column is more confusing.	weakness
2020-1395	I do not see any red circles in the fourth column.	weakness
2020-1395	Why the reconstruction of distractor is far away from the original one.	weakness
2020-1395	Does the right top picture show the advantages of UNet Reconstruction or its drawbacks?	weakness
2020-1395	2. In fact, the training data with masking is not sufficient (may only available in some medical images).	weakness
2020-1395	It is hard to utilize these data to generalize to various other tasks including large amounts of images without masking.	weakness
2020-1395	3. From the experiments on real tasks, I barely see improvements by the proposed method, which makes the conclusion unconvincing.	weakness
2020-1395	This paper considers how we can train image classification models so that they can ignore task irrelevant features.	abstract
2020-1395	For this purpose, the authors considered a situation where task relevant parts of the images are annotated as masks by the human experts.	abstract
2020-1395	The authors then proposed using Actdiff loss, Reconstruction loss, and Gradmask loss that are designed to suppress the effect of irrelevant features.	abstract
2020-1395	I think the problem considered in this paper is interesting and important.	strength
2020-1395	As the authors pointed out, the medical images taken from different hospitals may contain hospital-specific features which is irrelevant to the targeting task.	strength
2020-1395	Thus, we need a way to train image classifiers that can ignore such irrelevant features.	strength
2020-1395	My major concern on this study is the experiments.	weakness
2020-1395	The authors mention that part of their methods sometimes did not work (see below).	weakness
2020-1395	This makes the effectiveness of the proposed losses a bit questionable.	weakness
2020-1395	If I understad correctly, in practice, the users need to tune the weights of several losses carefully until they can obtain a good model.	weakness
2020-1395	If this is the case, I am not very sure if the proposed losses are essential, or tuning a right weight can occasionally provide good models.	weakness
2020-1395	* (Sec4) "Gradmask proves to be too powerful a regularizer for this task, and never produces a model with good generalization performance."	weakness
2020-1395	* (Sec5) "For the Cardiac dataset, the best performing method was classification with gradmask for the Convolutional AutoEncoder and with actdiff for the UNet, and each achieve similar performance."	weakness
2020-1395	* (Sec5) "The gradmask and combination actdiff and gradmask models improved over baseline, but there is no clear reason why this would be true from the saliency maps."	weakness
2020-1395	* (Sec6) "Both actdiff and gradmask improve performance of the model, but only actdiff scores above chance, and performs similarly to a model trained with the areas outside of the mask completely removed."	weakness
2020-1395	### Updated after author response ###	rebuttal_process
2020-1395	The authors have tried to address my concern by re-running the experiments, which I greatly appreciate.	rebuttal_process
2020-1395	However, the effectiveness of the proposed approach is not convincing enough.	weakness
2020-1395	I expect the authors to design the more effective experiments in the future version.	suggestion
2020-1395	It would be great if the authors can clarify and demonstrate which regularization is helpful under which circumstances and why, and when it is not.	suggestion

2020-1420	This article studies the similarities between the learned representations for different tasks when trained using reinforcement learning algorithms.	abstract
2020-1420	The ultimate question that this study tries to answer is an interesting one.	strength
2020-1420	Namely, how much can representations learned by training on one task be beneficial for learning other tasks?	strength
2020-1420	A high interdependence between the representations can lead to a more successful transfer of knowledge between tasks.	strength
2020-1420	The authors are further interested in studying the properties that influence this relationship, which depends on the elements of training as well as attributes of the tasks themselves.	strength
2020-1420	However, I believe that the results are not strong enough to support the claims that are stated in the paper and the limited scope of the environments tested does not make a convincing case that the results will be generalizable much beyond these scenarios.	weakness
2020-1420	Therefore, in the current state, I think this paper should be rejected.	decision
2020-1420	Firstly, the paper states that: > "..	weakness
2020-1420	if the distance between models trained on different tasks is the same as that between models trained on the same task, representations are task-agnostic."	weakness
2020-1420	This seems to be a key argument in the paper.	weakness
2020-1420	However, I believe that this argument is based on the assumption that representations learned for a single task are indeed highly similar.	weakness
2020-1420	I think this assumption requires some sort of support as reinforcement learning algorithms are known to be highly inconsistent even in reaching similar solutions.	weakness
2020-1420	Therefore, one cannot take for granted that the learned representations would be similar in any way.	weakness
2020-1420	Second, the authors claim in Section 5 that the random splits have little impact on the learned representation, but in Section 6 claim that the spatially disjoint splits have a noticeable impact on the representations.	weakness
2020-1420	Without any measure of the impact, looking at figures 1b and 3a, I'm not convinced that this distinction is so obvious.	weakness
2020-1420	The situation is worse when looking at the figures in the appendix, namely figures A3 and A5.	weakness
2020-1420	If someone were to swap these two figures, my untrained eye would not be able to tell the difference.	weakness
2020-1420	I suggest that the authors spend more time explaining their reasoning as to why these results are significant enough to support the claims.	suggestion
2020-1420	Also, the text should be improved if it is to be accepted.	weakness
2020-1420	There exist many problems ranging from small typos (simlate -> simulate, reuse-ability -> reusability, and "?." -> "?") to sentences that need to be reworked.	weakness
2020-1420	Some figure legends/captions can also be improved to include more information, such as explaining what exactly the shaded regions represent (I'm guessing one standard deviation from the mean over some unknown replicates), or in Fig 3b making clear whether "A -> B" is done with "New Policy" or "Fine-tuned Policy".	weakness
2020-1420	I am also curious as to why only one of these scenarios was experimented with in sections 6 and 7.	weakness
2020-1420	This paper tests generality and transfer in visual navigation tasks.	abstract
2020-1420	It's an interesting question and a well-executed study.	strength
2020-1420	I applaud the use of a complex high-dimensional environment.	strength
2020-1420	The experiments are well done, but I am not sure what we learn.	weakness
2020-1420	Each experiment compares two highly similar tasks - as the authors themselves acknowledge - in ways that do not obviously connect to realistic transfer scenarios, such as transferring to a new environment.	weakness
2020-1420	I would have liked to see experiments that compare networks trained on different environments or on different sets of environments.	suggestion
2020-1420	The paper is called "Insights on visual representations for embodied navigation tasks," but I am left wondering what those insights are.	weakness
2020-1420	The authors state that "Our work provides valuable and actionable insight into how the task influences the representation for embodied navigation tasks," but it is light on specifics and on the general discussion of the results.	weakness
2020-1420	Not much is offered beyond a suggestion to use ResNets.	weakness
2020-1420	I would consider revising my assessment if the authors write a more thorough discussion and specify clear implications of their findings.	suggestion
2020-1420	The paper is generally well-written although important details are left out: - I think the target objects have fixed rather than randomized locations in the environments, but this isn't stated in the paper.	strength
2020-1420	Please specify. - Where does the agent start during an episode?	suggestion
2020-1420	- How large are the environments?	weakness
2020-1420	e.g., one room or multiple rooms?	weakness
2020-1420	- How many objects per environment are there e.g., in sets A and B?	weakness
2020-1420	- The "permutations of an environment" setting isn't very clearly written and it took me a few readings to understand what you mean.	weakness
2020-1420	- Finally, I suggest revising the very vague title to the paper This paper tries to analyze the similarities and transferring abilities of learned visual representations for embodied navigation tasks.	suggestion
2020-1420	It uses PWCCA to measure the similarity.	suggestion
2020-1420	There are some interesting observations by smart experimental designing.	strength
2020-1420	I have several concerns. - for the non-disjoint experiments, the difference between A and B is that the subsets contain different instances.	weakness
2020-1420	The objects in subsets A and B may have the same category.	weakness
2020-1420	The objects with the same category may share similar surrounding environment.	weakness
2020-1420	Thus, the visual inputs for the training model on A and B may just have minor differences.	weakness
2020-1420	This point is also related to the spatial coverage used in the paper.	weakness
2020-1420	Since the visual input is similar, why is the conclusion in Figure1(b) non-trivial?	weakness
2020-1420	- for the transferring experiments, in the beginning, the finetuning way is better than the new training makes sense.	weakness
2020-1420	But, why do the results of learning a new policy from scratch will inferior to the finetuning way when training to convergence?	weakness
2020-1420	The two experiments are both performed on the same fixed visual encoder.	weakness
2020-1420	- I think the experiments can not support the argument that residual connections help networks learn more similar representations.	weakness
2020-1420	Will other structures such as VGG also learn similar representations?	weakness
2020-1420	Will the degrees of similar representations be proportional to the accuracy of the classification tasks and the modified residual network still outperforms the squeezenet?	weakness
2020-1420	The more straightforward ablation studies might be that we remove all shortcuts of the ResNet as the plain version.	suggestion
2020-1420	========================================================= After Rebuttal: I thank the author for the response.	misc
2020-1420	I still think the evaluations and experimental settings cannot fully support the conclusions.	rebuttal_process
2020-1420	So I keep the original score.	rebuttal_process
2020-1420	I hope the comments are useful for preparing a future version of this work.	misc

2020-1435	This paper introduces directional adversarial training (DAT) and UMixUP, which are extension methods of MixUp. DAT and UMixUp use the same method of MixUp for generating samples but use different label mixing ratios where DAT retains the sample's original label.	abstract
2020-1435	In contrast, UMixUp uses a function of the input mixing ratio.	abstract
2020-1435	This paper shows that UMixUp and DAT are equivalent when the number of samples tends to infinity.	abstract
2020-1435	In the experiments, UMixUp provides an improvement over MixUp. This paper should be rejected because the originality of the proposed method over MixUp is marginal, and the improvement of classification accuracy is not surprising, although the explanation of the relationship among DAT, UMixUp, and the original MixUp is nice.	decision
2020-1435	The modification of label mixing ratios is not enough contribution.	weakness
2020-1435	A more precise description of why DAT and UMixUp work better over the original MixUp is required.	suggestion
2020-1435	The same idea of MixUp was proposed at the same conference (*CONF*2018).	weakness
2020-1435	It should be cited. Tokozume et al., Learning from Between-class Examples for Deep Sound Recognition.	suggestion
2020-1435	*CONF*, 2018. Tokozume et al. explain why the mixture of examples works well from the different perspectives of adversarial examples.	misc
2020-1435	Also, BC learning uses a KL loss, not a cross-entropy loss.	weakness
2020-1435	Therefore, the reviewer doubts the following statement: "MixUp is only applicable to baseline models that use cross entropy loss" on page 2.	weakness
2020-1435	Minor comments 1) In page 8, "negative-cosine (CE)" might be "negative-cosine　(NC)".	weakness
2020-1435	First of all, the concept of 'Directional Adversarial Training (DAT)' is not appropriate.	weakness
2020-1435	Actually similar method has been proposed in Hiroshi Inoue (2018) as a data augmentation method.	weakness
2020-1435	What surprised me the most is that after trying to connect UMixUp with adversarial training in the whole paper, there is no evaluation of adversarial robustness in the experiments?	weakness
2020-1435	The main character of adversarial training is an improvement in robustness and degeneration on clean accuracy, which is different from the performance of UMixup or Mixup.	weakness
2020-1435	The authors should do a major modification on their motivation and experiments before the paper is able to be published.	decision
2020-1435	Reference: [1] Hiroshi Inoue. Data Augmentation by Pairing Samples for Images Classification.	misc
2020-1435	arXiv 1801.02929 This paper proposes a novel data augmentation method, untied MixUp (UMixUp), which is a general case of both MixUp and Directional Adversarial Traning (DAT).	abstract
2020-1435	DAT is referred to in this paper as a scheme that only input feature vectors are mixed, while MixUp also incorporates their corresponding labels.	abstract
2020-1435	The authors provide a theoretical discussion that both DAT and UMixUp converges to be equivalent to each other when the number of training samples becomes infinity.	abstract
2020-1435	Experimental results on Cifar 10, Cifar 100, MNIST, and Fashion MNIST show quantitative comparisons among the baseline, MixUp, and UMixUp. According to the author guideline,	abstract
2020-1435	> There will be a strict upper limit of 10 pages for the main text.	weakness
2020-1435	Reviewers will be instructed to apply a higher standard to papers in excess of 8 pages.	suggestion
2020-1435	The authors use nine pages.	weakness
2020-1435	Therefore, the review should be more careful about its quality.	weakness
2020-1435	Currently, I have three major concerns that keep me from judging this paper acceptable in *CONF* 2020.	decision
2020-1435	First, the authors failed to cite two closely related papers below: - Tokozume et al., LEARNING FROM BETWEEN-CLASS EXAMPLES FOR DEEP SOUND RECOGNITION.	weakness
2020-1435	*CONF*, 2018. - Tokozume et al., Between-class Learning for Image Classification.	misc
2020-1435	CVPR, 2018. The first one is published in the previous *CONF* and mixing two samples belonging to different classes.	weakness
2020-1435	The second one is an application to image classification using ImageNet dataset, which is larger than the dataset used in this paper.	misc
2020-1435	What's more important is that both papers propose that the mixing ratio of two samples is not linearly but depending on the strength of their signals.	weakness
2020-1435	Since UMixUp is also focusing on the mixing ratio between two training samples, Between-Class Learning should have been compared to the proposed method.	weakness
2020-1435	Secondly, the theoretical discussion is not so fascinating.	weakness
2020-1435	Actually, both MixUp and UMixUp are shown to converge to DAT when the number of training samples tends to infinity.	weakness
2020-1435	Data augmentation is, however, performed to remedy the lack of training samples in general.	weakness
2020-1435	The discussion that the number of training samples is assumed to be large is the opposite situation.	weakness
2020-1435	Thirdly, the experimental results show that the performance gain by UMixUp is relatively small in comparison to that of the original MixUp.	weakness
2020-1435	There are no ablation studies using different values for alpha and beta, which are parameters for the policy of UMixUp.	weakness
2020-1435	The authors reported that these values are defined using a heuristic search.	weakness
2020-1435	Thus, we cannot see if the performance is sensitive to the parameter selection.	weakness
2020-1435	I lean to reject this paper because of these concerns.	decision
2020-1435	I'm looking forward to seeing the revised version in another conference.	decision

2020-1436	[Summary] This paper proposes a GAN with an attention-based discriminator for I2I translation, GuideGAN.	abstract
2020-1436	The proposed discriminator provides the probability of real /fake and an attention map which reflects the salience for image generation.	abstract
2020-1436	They apply their method to CycleGAN.	abstract
2020-1436	GuideGAN is evaluated on the Cityscape dataset, horse2zibra, apple2orange, and day2night, compared to UNIT, CycleGAN, StarGAN, cGAN, and pix2pix.	abstract
2020-1436	[Pros] - Quantitative results [Cons] - Novelty is restricted.	weakness
2020-1436	Even if there is no work using attention in the discriminator, it is hard to tell that the use of attention is not novel.	weakness
2020-1436	- The used datasets are not challenging.	weakness
2020-1436	Why the quantitative results are evaluated on the Cityscape?	weakness
2020-1436	How about FID on other datasets such as CelebA and Summer2Winter, or higher-resolution data?	suggestion
2020-1436	- The quantitative scores are not impressive.	weakness
2020-1436	The gaps look insignificant. - How large are additional parameters?	weakness
2020-1436	and How long does it spend training compared to CycleGAN?	weakness
2020-1436	- The authors describe two concatenation methods.	weakness
2020-1436	How about the results of simple RGBA?	weakness
2020-1436	- Why post hoc and RAM are evaluated on different datasets from each other in qualitative results?	weakness
2020-1436	- User study will be helpful.	weakness
2020-1436	- Basically, this architecture can be applied to various GANs. Do the authors have any result on other GANs?	weakness
2020-1436	[Minor] In Figure 1, M is used without the definition.	weakness
2020-1436	In row 2 of page 3, follows --> follow This paper introduces a feedback mechanism in the GAN framework which improves the quality of generated images in the context of image-to-image translation.	abstract
2020-1436	The key contribution is that the discriminator not only predicts the probability of an image being real or fake, but also outputs a map which indicates where the generator should focus in the next iteration in order to make its results more convincing.	abstract
2020-1436	The paper explores ways of obtaining such a map 1) by summing feature activations of the discriminator on a specific or group of layers  2) by predicting it via augmenting the capacity of the discriminator.	abstract
2020-1436	After such a map is obtained, it is concatenated with the input image and fed iteratively to the generator.	abstract
2020-1436	The proposed setting have been tested on the setting of supervised and unsupervised image translation on 4 datasets.	abstract
2020-1436	Quantitative experiments show that the proposed approach improves over other baselines.	abstract
2020-1436	I think this paper introduces an interesting and important new GAN framework.	strength
2020-1436	However, I feel that the paper requires a major revision strengthening the experiments, before it can be reconsidered for *CONF*: More qualitative results showing comparisons with other algorithms should be shown for Day-Night, Apple-Orange, Horse-Zebra.	decision
2020-1436	The only comparison available in the paper is on the well constrained problem of segmentation maps to images.	weakness
2020-1436	More quantitative experiments should be provided for other datasets (perhaps using FID and KID).	suggestion
2020-1436	It is not entirely clear if the produced results are better than cycleGAN's (my subjective analysis is that the results of cycleGAM look better on Fig. 2).	weakness
2020-1436	The paper is closely related to [Huh et al: Feedback Adversarial Learning: Spatial Feedback for Improving Generative Adversarial Networks] in that they share the idea of a feedback mechanism from the discriminator.	weakness
2020-1436	It hence seems reasonable to compare with this approach.	weakness
2020-1436	I was struggling to understand precisely how the StarGAN results were obtained on CityScapes: As a multi-modal image-to-image translation model, StarGan takes as input, an image and a binary vector pointing to which modality to transform the image into.	weakness
2020-1436	In the case of CityScape, there is no such multi-modality (at least none that is provided as ground truths, via for example, a binary vector).	weakness
2020-1436	More details on this process would make the experimental section clearer.	weakness
2020-1436	Table 4.1 is often used however such a Table does not exist (probably Table 1,2 was meant here).	weakness
2020-1436	This paper proposes an extension of the conditional GAN objective, where the generator conditions on an attention map produced by the discriminator in addition to the input image.	abstract
2020-1436	The motivation is that the discriminator is usually too powerful, and so the gradient the generator receives is often too small in magnitude.	abstract
2020-1436	By conditioning on the attention map, the generator could leverage information about the regions in the image that the discriminator attends to and use it to generate a new image that better fools the discriminator.	weakness
2020-1436	My main concern is about whether the proposed extension achieves the desired goal.	weakness
2020-1436	The intuitive motivation provided in the paper aims to add a cooperative component to the two-player game, but the min-max objective corresponds to a zero-sum adversarial game.	weakness
2020-1436	As a result, when training the discriminator, the discriminator is encouraged to reveal as little information as possible via the attention map, so that the loss maximized.	weakness
2020-1436	This appears to be the opposite of the desired behavior, so the objective needs to be reformulated.	weakness
2020-1436	Also, it is unclear how inference is performed: at test time, the attention map is unknown and so some placeholder must be used in its place.	weakness
2020-1436	The paper should clarify what is done at test time, and clearly state the shortcomings as a result of this, i.e. different procedures are used for training and testing, which is not principled.	weakness
2020-1436	I imagine the generator could rely too much on the attention map as a result - how this is alleviated/prevented should be explained.	weakness
2020-1436	Figure 2: Only the qualitative results for unsupervised image-to-image translation are available; qualitative results for supervised image-to-image translation should also be provided.	weakness
2020-1436	While the quantitative improvement over existing methods is somewhat insignificant, I appreciate the authors discussing their hypotheses why this might be the case.	rebuttal_process
2020-1436	It would be more useful to empirically validate these hypotheses as well.	suggestion
2020-1436	For example, for the claim that "maybe the attention map only focuses on a few domain specific classes so the generator works too hard on those classes and ignores others", it might be good to compute the average per-class attention map intensity to show that some classes appear rarely in the attention map.	suggestion
2020-1436	The evaluation protocol should be explained in greater detail (perhaps in the appendix); the segmentation model (which I assume is FCN) should be described and each of the evaluation metrics (per-pixel acc., per-class acc.	suggestion
2020-1436	and IoU) should be described for the benefit of researchers outside the area.	suggestion
2020-1436	pg. 4: "in their implementation contains several Resblock (He et al., 2016), which makes it infeasible in our framework".	weakness
2020-1436	Why is it infeasible? pg. 6: What are the architectures used by the baselines?	suggestion
2020-1436	Are they comparable to the architecture the proposed method used?	suggestion
2020-1436	Minor Issues: pg. 3: "differences between P_x and G_Y \\cdot P_y, P_y and G_X \\cdot P_x are minimized" - confusing; should rephrase as "the difference between P_x and G_Y \\cdot P_y and the difference between P_y and G_X \\cdot P_x are minimized".	weakness
2020-1436	Also should replace \\cdot with \\circ.	suggestion
2020-1436	pg. 4: "like random noisy" -> "like random noise"	misc
2020-1436	pg. 4, last paragraph: "Our trainable attention module follows the same structure of the attention block in RAM (Wang et al., 2017).	weakness
2020-1436	They built a very deep network with several such blocks, each containing two branches: mask branch and trunk branch.	weakness
2020-1436	Mask branch cascades the input features through a bottom-up top- down architecture that mimics human attention.	weakness
2020-1436	Trunk branch is applied as feature processing." - this is very confusing; it would be easier to refer readers to the appendix.	weakness
2020-1436	pg. 5 - "Attention mask can potentially break good property of the raw input." - what does this mean?	weakness
2020-1436	pg. 6 - "as showed in Table 4.1" -> "as shown in Table 4.1"	weakness

2020-1440	The motivation of this work is to address the issue of inconsistent and missing data in longitudinal clinical studies.	abstract
2020-1440	The main goal of this work is to learn a dimensionality reduction representation by combining locality preserving projection (LPP) and and the global pattern by principal component analysis (PCA).	abstract
2020-1440	The balance between these two components is modulated by a hyperparameter alfa.	abstract
2020-1440	The authors proposed a method to overcome the issue of a direct computation of alfa.	abstract
2020-1440	The main contribution of this work is to prove that a quotient formulation between LPP and PCA is equivalent to a weighted difference of these two terms.	abstract
2020-1440	It is not straightforward to understand whether the proposed method is effective in reducing the time consuming effort required by the computation of alfa hyperparameter, as stated in the premises as motivation of this work.	weakness
2020-1440	The presentation of theorems is misleading.	weakness
2020-1440	Theorems 1 and 4 seem to claim opposite statements, while theorems 2 and 5 have the same claim.	weakness
2020-1440	Minor comments. After equation 5 there is a typos in the ratio LPP/LPP.	weakness
2020-1440	This manuscript develops a metric-learning with non-Euclidean error terms for robustness and applies in to data reduction to learn diagnostic models of Alzheimer's disease from brain images.	abstract
2020-1440	The manuscript discusses a metric-learning formulation as a quotient for reconstruction-error terms, how to optimize the quotient based on results from Wang et 2014, an iterated reweighted approach to circumvent the non-smooth part of the l1 loss in zero, and experiments on brain images of Alzeimer's disease.	abstract
2020-1440	My two main issues with the manuscript is that the theoretical part is written very imprecisely and that the experiments are not convincing due to the lack of good baselines and of statistical power.	weakness
2020-1440	With regards to the theoretical contributions, a fraction of the results in the present manuscript are trivial consequences or Wang2014, and yet it comes with errors in the statements.	weakness
2020-1440	For instance, in equation (9), the present manuscript writes greater or equal, while I believe that it should be strictly greater, as in Wang.	weakness
2020-1440	Theorem 1 and 4 seem almost the same thing, though with a contradiction between the two.	weakness
2020-1440	Other statements are inaccurate: the authors claim some results on reaching global optima, while I believe that they can only claim that they reach stationary points.	weakness
2020-1440	Theorem 2 and 5 seem to be the same thing.	weakness
2020-1440	Concerning the iterated reweighted approach, I believe that this is non smooth only for g(x)=0, which is not covered by the theorems of Wang 2014.	weakness
2020-1440	Is this algorithm needed? Note that Wang apply their algorithm with an l1 norm, ie non-smooth in zero, and do not report problems with out.	weakness
2020-1440	The manuscript mentions that "to inverted matrices that divide 0s, which routinely lead to inferior learning performance.".	weakness
2020-1440	I am not exactly sure what that means and I would need to understand better the problem.	weakness
2020-1440	Also, the theoretical contribution that with the added the delta the algortihm converges, seems quite trivial: it seems to me that it is the eta trick.	weakness
2020-1440	Minor comments: in algorithm 3, it would be useful to write the full expression of the equations, rather than just reference the numbers.	suggestion
2020-1440	Also, the computational cost of the eigenvectors at each iteration seems quite prohibitive.	weakness
2020-1440	How was the value r=3 selected?	weakness
2020-1440	Figure 2 seem to choose that approaches have not converged: they final value is larger than intermediate values?	weakness
2020-1440	How were the p-values between cross-validation assessment of estimators computed?	weakness
2020-1440	If it was done using standard paired t-test, this is incorrect are the folds are not independent.	weakness
2020-1440	With regards to the experiments, I worry that the model is not compared against simple baselines, such as a PCA.	weakness
2020-1440	This paper proposed an unsupervised method to make better usage of the inconsistent longitudinal data by minimizing the ratio of Principal Components Analysis and Locality Preserving Projections.	abstract
2020-1440	Comments: 1. It is out of the area of my expertise, but the innovation of combining the PCA and LPP to produce the dimensionally reduced representation of the longitudinal data seems not significant enough, especially when the author did not mention why they chose these two methods out of all the available projection/hashing approaches.	weakness
2020-1440	2. The paper is poorly written.	weakness
2020-1440	Theorem 1 and Theorem 4 state the opposite conditions for v.	weakness
2020-1440	Theorem  2 and Theorem 5 are exactly the same.	weakness
2020-1440	If the same theorem has already been proved by previous work [Wang et al., 2014], it is not necessary to prove it again in this paper.	weakness
2020-1440	The most important theorem which is claimed as the theoretical contribution of this paper (i.e. Theorem 6) did not even appear in the main contents but only in the appendix.	weakness
2020-1440	The proof of theorems in appendix, Proof A.1, A.2, A.3 did not state which theorem they are corresponding to and are organized in different order as Theorem 3-5, make it hard to read.	weakness
2020-1440	3. There are many grammar errors and sentences which are not consistent with English writing conventions.	weakness
2020-1440	E.g. "This problem is heavily studied with (Wang et al., 2012;	weakness
2020-1440	Brand et al., 2018; Lu et al., 2018) as example approaches which, despite their effectiveness, present an added complexity to the problem." is better written as "This problem is excessively studied by (Wang et al., 2012;	weakness
2020-1440	Brand et al., 2018; Lu et al., 2018) as example approaches which, despite their effectiveness, present an additional complexity to the problem";	weakness
2020-1440	"... to provide value in predicting patients' diagnosis." is better written as "...	weakness
2020-1440	to provide valuable information in ..."; "...	weakness
2020-1440	, we focus AD diagnosis from MRI scans ..." should be "...	weakness
2020-1440	, we focus on AD diagnosis from MRI scans ..."; "consider outliers" is better as "handle outliers"; etc.	weakness
2020-1440	4. In the sentence below equation (5), "J_LPP/J_LPP" should be "J_LPP/J_PCA".	weakness

2020-1442	[Update after rebuttal period] I am sorry that the response cannot address my confusion.	rebuttal_process
2020-1442	I still doubt the motivation of this paper and the actual experimental performance compared with state-of-the-art methods are still ignored.	rebuttal_process
2020-1442	Thus I decrease my score.	rebuttal_process
2020-1442	[Original reviews] This paper proposed to modeling image as the combination of a GAN with a Deep Decoder, to remove the representation error of a GAN when used as a prior in inverse problems.	abstract
2020-1442	The proposed methods are evaluated on two image restoration tasks, including compressive sensing and image super-resolution.	abstract
2020-1442	The effectiveness of the combination is also presented.	abstract
2020-1442	Authors devote themselves to remove the representation error of the GAN image prior.	misc
2020-1442	Intuitively, the manner of the proposed linear combination model is rough and less reasonable.	weakness
2020-1442	In Alg.1, the detailed algorithmic process is presented, it is clear that authors need to pre-train the used GAN and Deep Decoder, then combine them to train one network.	weakness
2020-1442	If the motivation of this paper is to remove the representation error of GAN, GAN should be viewed as the main body.	weakness
2020-1442	However, the authors view GAN and Deep Decoder as the same position against the original intention.	weakness
2020-1442	Additionally, in the experimental part, the ablation studies indeed reflect the effectiveness of the proposed algorithm, but it looks like the Deep Decoder plays a key role in all cases.	weakness
2020-1442	In other words, the GAN image prior just plays a supporting role.	weakness
2020-1442	This is also far away from motivation.	weakness
2020-1442	More importantly, I cannot see the surprising results because of this work only compare themselves with some basic version or naïve methods.	weakness
2020-1442	All state-of-the-art approaches to different tasks are ignored, which is the other big disadvantage.	weakness
2020-1442	In Table 2, what is the meaning of 'CSGM'？ The authors should describe it.	weakness
2020-1442	In a word, from the algorithmic and experimental perspective, this paper cannot achieve satisfying performance.	weakness
2020-1442	This paper presents a method for reducing the representation error generative convolutional neural networks by combining them with untrained deep decoder.	abstract
2020-1442	The method is evaluated on compressive sensing and super-resolution, where a better performance than the isolated use of Deep Decoders and GAN priors.	abstract
2020-1442	The main contribution of the paper is not the performance, but the simplicity of this approach.	strength
2020-1442	For the title, I would suggest to replace the word Removing with Reducing.	suggestion
2020-1442	Furthermore, the clarification of "GAN prior" is very nice in the introduction, maybe you could already clarify it in the abstract.	rebuttal_process
2020-1442	You should perform a critical grammar check.	suggestion
2020-1442	There are too many commas, for example: "At sufficiently difficult superresolution problems, the Hybrid model outperforms, the Deep	suggestion
2020-1442	Decoder, Bicubic upsampling, the BEGAN prior, and the BEGAN as DIP prior." -> there should be no comma after "outperforms"	weakness
2020-1442	The sentence from Page 3 to 4 reads strangely, probably a word is missing after "For our GAN prior, we use the BEGAN architecture, and we demonstrate similar results"	weakness
2020-1442	"Philosophically, they hybrid" -> "Philosophically, the hybrid"	weakness
2020-1442	Fig 6 caption - shouldn't it be 49152 instead of 49512?	weakness
2020-1442	You perform various very good analysis experiments, which is well appreciated.	strength
2020-1442	Still, it would be good to think about some more experiments (and include at least one of them in the paper): 1. You compare to IGAN and show that you achieve similar performance.	suggestion
2020-1442	You describe that a state-of-the-art approach are invertible generative models and that they are very time consuming (e.g., 15 minutes for a 64x64 image).	suggestion
2020-1442	How good would the invertible models be in terms of performance?	suggestion
2020-1442	Could you perform tests as well?	suggestion
2020-1442	2. It would be great if you report the runtime of all experiments as well - maybe also the memory usage.	suggestion
2020-1442	Summary: This paper proposes to use a combination of a pretrained GAN and an untrained deep decoder as the image prior for image restoration problem.	abstract
2020-1442	The combined model jointly infers the latent code for the trained GAN and the parameters in the untrained deep decoder.	abstract
2020-1442	It also jointly infers the mixing coefficient alpha and beta during test time for each image, thus learning how much we should rely on GAN.	abstract
2020-1442	The proposed hybrid model is helpful on compressed sensing experiments on the CelebA dataset; however, it is only marginally better than deep decoder on image super resolution and out-of-distribution compressed sensing.	abstract
2020-1442	Detailed comments: - The writing is clear and I was able to understand the model part of the paper.	strength
2020-1442	The algorithm box is helpful.	strength
2020-1442	However, I would still appreciate if the authors can provide an overall model figure in the model section to help understanding.	strength
2020-1442	- Jointly learning the mixing coefficient is an interesting part of the model.	strength
2020-1442	- The motivation in the abstract and intro could be strengthened.	weakness
2020-1442	A smaller version of Figure 1 can be probably moved to the beginning of the paper to illustrate the problem of GAN.	suggestion
2020-1442	But even with the help of Figure 1, it is still unclear what is the fundamental problem for GAN.	weakness
2020-1442	Simply combining a GAN with an untrained decoder model doesn't help elucidate the source of the problem.	weakness
2020-1442	- The proposed Hybrid model seems to help on compressed sensing experiments on CelebA.	weakness
2020-1442	However, it doesn't help much on out-of-distribution experiments.	weakness
2020-1442	Moreover, in the super-resolution task, as shown in Figure 5, the improvement over deep decoder is also not significant.	weakness
2020-1442	- The out-of-distribution experiments seems lack of thorough study.	weakness
2020-1442	In particular, the paper only studies the transfer between CelebA -> Caltech-UCSD Bird dataset.	weakness
2020-1442	It would be better if the paper can study a variety of other image datasets as well.	suggestion
2020-1442	Also some visualization on the Bird dataset should also be included.	suggestion
2020-1442	- Effect of n_pre needs to be further investigated.	weakness
2020-1442	Why not directly train both models together?	suggestion
2020-1442	It would be good if the authors could comment on how sensitive the n_pre is and what is the intuition.	weakness
2020-1442	- For figures, I would recommend rename "Hybrid" to "Hybrid (Ours)" to highlight the paper's contribution, and use a brighter color.	suggestion
2020-1442	- Figure 5 should be renamed as a Table.	weakness
2020-1442	- Hyperparameter details should be moved to the Experiment section.	weakness
2020-1442	Conclusion: The paper proposes a simple combination of a trained GAN and an untrained decoder model for the task of image restoration.	abstract
2020-1442	Although the method is clear and straightforward, in the experiments, the influence of the new model component seems marginal.	weakness
2020-1442	Moreover, the motivation is not strong enough.	weakness
2020-1442	Therefore, I recommend weak reject.	decision

2020-1480	The paper looks into the problem of training agents that can interact with their environments to verify hypotheses about it.	abstract
2020-1480	It first formulates the problem as a MDP, where the agent takes actions to explore the environment and has two special actions (Answer_True, and Answer_False) to indicate that the agent has made a prediction about the validity of the hypothesis.	abstract
2020-1480	The reward depends on how correct the agent's prediction is.	abstract
2020-1480	A second formulation uses MDP to explore the states and has a special action (Answer), which predicts the validity of the hypothesis based on the last sequence of N states visited.	abstract
2020-1480	This is one side of the problem.	abstract
2020-1480	The authors carry out such experiments and conclude that this doesn't work.	abstract
2020-1480	Then, the authors exploit the structure of some hypotheses (such as triplet hypotheses of the form pre_condition, action_sequence, post_condition), which are easier to test.	abstract
2020-1480	They conclude that taking this structure into account helps.	abstract
2020-1480	Overall, the paper is well-written and the literature review section is quite excellent.	strength
2020-1480	However, I have reservations against the formulations that the authors used.	weakness
2020-1480	I would appreciate it if the authors present their argument in the rebuttal.	rebuttal_process
2020-1480	First, in the plain formulation of MDP, a policy produces an action according to the current state only.	weakness
2020-1480	The authors add (Answer_True, and Answer_False) to the list of actions in MDP.	weakness
2020-1480	So, if the agent is trained on some hypotheses, the agent will essentially learn to identify for each h which state s that can be used to to verify h (either prove or disprove it).	weakness
2020-1480	To me, this is essentially memorization, and the agent cannot learn to predict the validity of new hypotheses.	weakness
2020-1480	So, it seems that formulating the problem using MDP is not reasonable to begin with.	weakness
2020-1480	Second, when the agent exploits the structure of the hypotheses, the problem becomes nearly trivial.	weakness
2020-1480	It would have been interesting if, somehow, the agent learned the strategy of trying to alter the preconditions or postconditions on its own, but this is not the case in the paper.	weakness
2020-1480	The formulation essentially tells the agent that it should alter the preconditions and postconditions so that we have enough information about the validity of h that can be fed into a prediction network.	weakness
2020-1480	I think that the fact this works is not that interesting.	weakness
2020-1480	Some minor comments: - I suggest that all acronyms be defined in the paper before they are used.	suggestion
2020-1480	- In the reward functions, why did the authors use C instead of just using 1.	suggestion
2020-1480	- In Page 4, "The agent is is spawned" has a typo.	weakness
2020-1480	- In Page 5, "so we can in principal only" has a typo.	weakness
2020-1480	- In Page 7, "as it paves the towards" has a typo.	weakness
2020-1480	================== #Post Rebuttal Remark I have gone through the authors' response and I thank them for it, particularly for making some of the suggested enhancements.	rebuttal_process
2020-1480	However, my score remains unchanged.	rebuttal_process
2020-1480	The authors present a framework for testing a set of structured hypotheses about environment dynamics by learning an exploratory policy using Reinforcement Learning and a evaluator through supervised learning.	abstract
2020-1480	They propose a formulation that decomposes environment hypotheses into sets of pre-conditions, required actions, and post-conditions.	abstract
2020-1480	They then exploit this decomposition to (a) decouple the problem into both RL and supervised learning, and (b) provide localised pre-training to make the problem more tractable.	abstract
2020-1480	Overall, I really wanted to like this paper.	misc
2020-1480	The problem is interesting, and it certainly provides a great venue for interesting and impactful research in RL, language-conditioned decision making, structured / symbolic learning, and so on.	strength
2020-1480	However, I've found it relatively difficult to understand good parts of the methods and part of the experimental section, due to missing or misleading details.	weakness
2020-1480	In particular: 1. the justification for splitting the problem in a _exploratory_ / verification policy and a predictor is sound in principle, however it's unclear to me whether the problem is after all that intractable.	weakness
2020-1480	In the experiment section a "RL Baseline" is mentioned in principle, however	weakness
2020-1480	(1) it is unclear whether it was pre-trained similarly to the proposed methods, and	weakness
2020-1480	(2) if the policy has learnt enough about the problems that its poking methodology provides enough signal to the predictor, I would expect the same policy to be able to learn the same function given enough memory and training steps.	weakness
2020-1480	2. I'm confused by the way the authors decomposed the action space for the policy and the predictor in section 3.1.	weakness
2020-1480	Does the policy use ans_T and ans_F at any point during training?	weakness
2020-1480	Does the actor effectively decide (i.e. by choosing "ans") when to query the prediction network?	weakness
2020-1480	3. The way the authors split the templates is confusing to me.	weakness
2020-1480	Up to section 3.3.1 (and - really - until I read the appendix...), the writing sort of led me to assume that (1) the "(pre-condition, action sequence) -> post-condition" split was a fairly standard manner of compose a hypothesis, and that (2) the templates were mostly symbolic.	weakness
2020-1480	However after reading the appendix, I found the imposed structure to be fairly arbitrary, and the usage of natural language overkill and not necessarily well justified.	weakness
2020-1480	Ideally, I would like to see some comparisons between this type of hypothesis and other decompositions used in previous literature, since it seems like the method exploits this particular structure quite heavily and I don't quite understand how it generalises to other tasks.	suggestion
2020-1480	4. The environments seem to be all fairly similar, both in terms of overall complexity, size, and features.	weakness
2020-1480	It would have been better to also present problems with fairly different settings (e.g. much different - sparser and/or denser - types of reward function), rather than evaluating multiple times on effectively the same grid-world.	weakness
2020-1480	I was though encouraged to see that one of the environment seemed to require slightly different setting in the pre-training reward setup, however the authors didn't follow up with some analysis on why there was such a difference.	weakness
2020-1480	5. I'm confused by how the pre-training is done.	weakness
2020-1480	I understand that R_{pre} is used by itself in one environment, but I couldn't figure out whether it's both reward functions at the same time that are used in the rest of them, or just R_{ppost}.	weakness
2020-1480	Looking at the scale of the (average?) reward, the former seems to be the case, but it would be good to be certain about such things.	weakness
2020-1480	6. The final accuracy of all the experiments are shown using the max of top-5, however appendix D shows quite a significant variance for the methods.	weakness
2020-1480	Thus I'm not sure the analysis and final considerations are reasonable.	weakness
2020-1480	What happens if the methods are trained on more seeds?	weakness
2020-1480	6. [nit] the title is somewhat misleading: in the introduction, a scientist is defined as being both a proposer and a verifier of hypotheses, which is a reasonable, however the authors fundamentally propose to solve only arguably the more straightforward of the two problems.	weakness
2020-1480	A less _flashy_ title would go a long way towards providing reasonable expectations for the reader.	suggestion
2020-1480	To improve this paper, I would like to see: - Better clarity on how the hypothesis setup stands to previous literature.	suggestion
2020-1480	- The difference in performance on each environment with different pre-training reward function (only one in show in the paper right now)	suggestion
2020-1480	- At least one more environments with significantly different dynamics, or an explanation of how the existing settings differ in qualitative terms.	suggestion
2020-1480	- A baseline employing some form of memory (such as heavy usage of frame stacking or recurrency), to attempt at figuring out whether it's really not reasonable to learn the whole problem simply using RL, with ablation of pre-training (which I suspect might make a significant difference).	suggestion
2020-1480	At this point, I cannot recommend the article for acceptance, but I'd be willing to change my rating if the authors were to address some of the above points.	decision
2020-1480	This paper trains agents which are able to verify hypotheses, such as "the blue switch causes the door to open".	abstract
2020-1480	It does this by first pretraining the agent to perform interventions in the environment which change the states of the objects of interest, and then finetuning the agent to actually make a decision about whether the given hypothesis is correct.	abstract
2020-1480	The paper shows that agents trained using this procedure are able to not only verify the types of hypotheses seen during pre-training, but also learn to verify more complex hypotheses.	abstract
2020-1480	In contrast, an agent which is trained directly on the hypothesis verification task is unable to learn to do it.	abstract
2020-1480	Overall, I enjoyed reading this paper and thought that it provided an interesting take on the question of how to train agents that can appropriately gather information about their environments.	strength
2020-1480	However, (1) the paper lacks any discussion of related work in terms of causal reasoning and partial observability, and (2) the experiments and analysis seem weak.	weakness
2020-1480	I thus am giving a score of "weak reject", though it is possible I could increase my score is some of my concerns can be addressed.	decision
2020-1480	First, I was very surprised to see that the paper included no discussion at all about either causal reasoning or partial observability.	weakness
2020-1480	The whole notion of verifying hypotheses—particularly those in the triplet form as presented in the paper—is equivalent to the idea of performing inference about the structure of a causal graph with three variables.	weakness
2020-1480	The choice of which interventions to perform in order to make these inferences is a well-studied problem [1] and has been recently explored in the context of RL as well [2].	weakness
2020-1480	The novelty here seems to be in embedding the problem of causal reasoning in harder credit assignment problems (i.e. longer time horizon), though see [3].	weakness
2020-1480	Similarly, the setup of the MDP in the paper is actually a POMDP, where the state includes the truth value of the hypothesis but where observations do not include this information.	weakness
2020-1480	Yet, there is no mention of POMDPs or discussion of the literature on partial observability in the paper.	weakness
2020-1480	Second, I felt that the setup was overly complex in places making it difficult to draw conclusions, that there were a lack of comparisons, and that the analysis was not as in depth as it could have been.	weakness
2020-1480	For example, why is it necessary to represent the hypothesis with natural language?	weakness
2020-1480	Why not use a symbolic representation?	weakness
2020-1480	It seems like including the pseudo-natural language adds unnecessary complexity and makes it difficult to distentangle what about the problem is hard (Understanding the hypothesis?	weakness
2020-1480	Choosing the right interventions? Parsing the observations correctly?).	weakness
2020-1480	The utility of having it be closer to language is that you might see generalization between related hypotheses, but this isn't really something that is actually tested for since all hypotheses are trained on either during pretraining or finetuning.	weakness
2020-1480	I also feel like the choice of pretraining reward feels somewhat arbitrary, and it would have been nice to see comparisons to other alternatives (and even better, to other forms of intrinsic motivation).	weakness
2020-1480	For example, here are a few alternate ways of rewarding the agent that seem intuitively like they could also work: Reward the agent for changing the state of any of the objects in the environment	suggestion
2020-1480	Reward the agent for changing the state of any object referenced in the hypothesis	suggestion
2020-1480	Reward the agent for observing a state of the world it has not seen before (i.e. count-based exploration)	weakness
2020-1480	In other words, how important is the fact that the reward is given based on the pre and postconditions?	weakness
2020-1480	I thought the paper would benefit from more detailed analyses to tease apart the behavior of the agent.	suggestion
2020-1480	For example, I am curious how many errors are a result of errors in the predictor versus poor exploration behavior by the policy.	weakness
2020-1480	Could you report (1) how frequently the policy's behavior results in the right observations necessary to make a decision, and	suggestion
2020-1480	(2) results with a policy which uses an oracle predictor (i.e. which will always report the correct answer, if there was enough data in the last N frames to detect that answer)?	weakness
2020-1480	On the more practical side, I also thought the quality of the evaluations was not very thorough.	weakness
2020-1480	For instance, it looks like the pretraining proceeds for 1e8 steps and finetuning for 5e7 steps, based on the plots (these values should be stated more explicitly in the paper).	weakness
2020-1480	However, this is a bit of an unfair comparison for the "RL Baseline", as it only is trained for 5e7 steps while the other agents are trained for 1.5e8 steps.	weakness
2020-1480	I would like to see a comparison where the RL Baseline agent is trained for 1.5e8 steps as well.	suggestion
2020-1480	Similarly, on the bottom of page 6 the paper says "we show the max out of five for each of the methods shown".	suggestion
2020-1480	However, only reporting the max value is considered bad practice and can result in misleading comparisons (see Joelle Pineau's talk on "Reproducible, Reusable, and Robust Reinforcement Learning" at NeurIPS 2018).	weakness
2020-1480	I'd like to see the data in all figures and tables reported with means or medians across seeds, rather than best seeds.	suggestion
2020-1480	A few minor comments: - Please state in the main text which RL algorithm you use.	suggestion
2020-1480	- Can you clarify whether Figure 2 show the proxy rewards or the true rewards?	suggestion
2020-1480	- For R_pre and R_ppost, what values do you use for C and N?	suggestion
2020-1480	[1] Pearl, J. (2000). Causality: models, reasoning and inference (Vol. 29).	misc
2020-1480	Cambridge: MIT press. [2] Dasgupta, I., Wang, J., Chiappa, S., Mitrovic, J., Ortega, P., Raposo, D., ...	misc
2020-1480	& Kurth-Nelson, Z. (2019). Causal reasoning from meta-reinforcement learning.	misc
2020-1480	arXiv preprint arXiv:1901.08162. [3] Denil, M., Agrawal, P., Kulkarni, T.	misc
2020-1480	D., Erez, T., Battaglia, P., & de Freitas, N.	misc
2020-1480	(2016). Learning to perform physics experiments via deep reinforcement learning.	misc
2020-1480	arXiv preprint arXiv:1611.01843. -- Update after rebuttal: Thank you very much for your response.	misc
2020-1480	However, I do not feel that all of my concerns have been addressed and thus will keep my score as it is.	rebuttal_process
2020-1480	In particular, I still feel the paper lacks sufficient discussion of the literature on causal reasoning.	rebuttal_process
2020-1480	I also do not think it is sufficient to add an appendix with the results across multiple seeds: these results should be in the main paper.	rebuttal_process
2020-1480	I'm not sure I follow the justification that max seeds make sense because "the reward distribution is quite binary in nature"---the plots shown in Figure 3 and 4, for example, span a range of values from 0 to 1.	weakness
2020-1480	I find the plots that have both variance and max seed very hard to interpret---in some cases the mean is so much lower than the max seed that the variance region doesn't overlap at all.	weakness
2020-1480	More broadly, it might be easier to compare using bar plots showing final performance, rather than training curves	weakness
2020-1480	I appreciate the additional results, especially with different pretraining schemes---thanks for adding these!	strength
2020-1480	I have a bit of hard time interpreting the results though since there are no direct comparisons with the triplet pretraining scheme; it would be helpful if these results could be included in these figures too.	weakness

2020-1522	This paper proposes to address the problem of spatio-temporal forecasting in urban data, in a way that can accommodate regions with highly distinct characteristics.	abstract
2020-1522	On the spatial side, they make use of Graph Attention Networks (GAT), a very recent technique for spatial feature extraction using graph attention as a form of reweighting.	abstract
2020-1522	The authors modify the GAT to accommodate a masking that allows for selection.	abstract
2020-1522	For some parameter K, a collection of K GATs is then combined with the masking used so that only one of them can be active at any given time.	abstract
2020-1522	This architecture (called MGAAT) then encourages a form of clustering,	abstract
2020-1522	with each cluster associated with a single GAT.	abstract
2020-1522	This modification one of the two essential contributions of the paper.	abstract
2020-1522	Although the description is not easy to follow, it does appear to have the potential to encourage clustering as claimed by the authors.	strength
2020-1522	On the temporal side, the autoencoder-based Transformer architecture of Vaswani et al is imposed on top of the MGAAT architecture.	strength
2020-1522	Very few details are given in the main paper - as it stands now, without the hints on Transformer that appear only in the supplement, the overall workings of the paper cannot be easily understood.	weakness
2020-1522	No insight is given as to how the overall architecture solves the main motivating problem for this paper.	weakness
2020-1522	For their experimentation, the authors compare against a good number of competing methods.	weakness
2020-1522	However, three of them - DCRNN, GeoMAN, and ASTGCN - use important elements of the authors' own design, namely attention-based  models and encoder-decoder architectures (GeoMan uses both).	weakness
2020-1522	However, the authors fail to differentiate their design from these approaches.	weakness
2020-1522	Overall, the machinery is rather complex, underexplained, and undermotivated.	weakness
2020-1522	The paper has major omissions and other serious presentational issues that make it very difficult to follow.	weakness
2020-1522	The authors do not take care to point out which parts of their design are original and which are borrowed - it took much sleuthing to determine that the MGAAT differs from the GAT only in its introduction of a masking factor.	weakness
2020-1522	As someone not previously familiar with GATs and atrous graph attention (as I suspect most of the audience would be), I found the paper very difficult going.	weakness
2020-1522	A total overhaul of the paper would be needed in order to properly explain and motivate this work.	suggestion
2020-1522	Overall, in its current state (not least due to presentational issues) the paper appears to be significantly below the acceptance threshold.	decision
2020-1522	Summary: This paper proposes a clustering attention-based approach to handle the problem of unsmoothness while modeling spatio-temporal data, which may be divided into several regions with unsmooth boundaries.	abstract
2020-1522	With the help of a graph attention mechanism between vertices (which correspond to different regions), the CGT model is able to model the (originally unsmooth) cross-region interactions just like how Transformers are applied in NLP tasks (where words are discrete).	abstract
2020-1522	Experiments seem to suggest a big improvement when compared to baselines.	abstract
2020-1522	Pros: +This should be one of the first works that apply a graph transformer alike method in this domain, and specifically on the unsmoothness problem.	strength
2020-1522	+ Since the dataset is not publically available, there aren't many prior works to compare the CGT to.	weakness
2020-1522	However, at least compared to the one prior work [1] that the authors point to in Section 4, the RMSE results achieved CGT does seem to be significantly better.	rebuttal_process
2020-1522	======================================== However, I still have some questions/concerns on the paper, detailed below.	misc
2020-1522	1) The current organization of the paper, as well as its clarity, can (and should) be significantly improved.	weakness
2020-1522	I didn't completely understand the approach on my first two passes, and I **had** to read the code published by the authors.	weakness
2020-1522	Here are some issues that I found: - For one, Figure 2 is not quite helpful as it's too messy with font size too small.	weakness
2020-1522	A similar problem is with Figure 4 which, without further clarification (e.g., of what "atrous aggregation" exactly mean), is very hard to interpret.	weakness
2020-1522	- The notations are very inconsistent and messy: i) In Eq.	weakness
2020-1522	(1), you should use a symbol different from X to refer to the "predictions".	weakness
2020-1522	Since you are applying f(⋅) on Xt−Tx+1:t, you should not get the "exact same" target sequence.	weakness
2020-1522	That's your target. Maybe use y^, which you used in Eq. (8).	weakness
2020-1522	ii) In Figure 3, what is the orange line?	weakness
2020-1522	In addition, I only saw two blue lines in the figure, but the legend seems to suggest there are four of them...	weakness
2020-1522	iii) The notations used in Figure 4 are somewhat confusing.	weakness
2020-1522	For example, what does "f->1" mean?	weakness
2020-1522	(I later found through Eq. (2) that it means transform to 1 dimension; but the small plots in Figure 4 suggest f is a "magnitude" of the feature.) In addition, there are two H1 in Figure 4 with clearly different definitions.	weakness
2020-1522	iv) The authors used Gθk(xi) in Eq. (3) without defining it. The definition actually came much later in the text in Eq. (6). I suggest moving the usage of the clustering assignment (i.e., Eq. (3)) to after Eq. (6).	weakness
2020-1522	v) What does [⋅||⋅] mean (cf.	weakness
2020-1522	Eq. (4))? (The code seems to suggest it's concatenation?)	weakness
2020-1522	vi) The authors first used hxi in Eq.	weakness
2020-1522	(3) to denote the output of the CAB module.	weakness
2020-1522	Then letter h is then re-used in Eq.	weakness
2020-1522	(4) and (5) with completely different meanings.	weakness
2020-1522	For instance, the Wkhi in Eq.	weakness
2020-1522	(4) correspond to line 48 of the code "model.py".	weakness
2020-1522	(By the way, nowhere around Eq.	weakness
2020-1522	(4) did the authors explain how hi is produced, such as taking the mean over the batch dimension, etc.).	weakness
2020-1522	vii) In Section 2.6, you denote the "optimal vertex cluster scheme" with letter C, which is used in Eq. (2).	weakness
2020-1522	Similar for parameter ak and atrous offset a.	weakness
2020-1522	- This not a very big problem (as it seems somewhat inevitable), but I think there are too many acronyms in the paper.	weakness
2020-1522	I think it'd be great if the authors can take care of these issues, as clarity in math and descriptions are critical to the presentation of such an involuted method.	weakness
2020-1522	It would also be useful to clearly define the dimensionality of all the variables (e.g., you defined V in Section 2.1, but never used it again in later subsections).	suggestion
2020-1522	2) Regarding the usage of the multi-view position encoding, the authors claimed that it "provides unique identifiers for all time-steps in temporal sequences".	suggestion
2020-1522	However, if you consider x=7 and x=14, then PEi(7)=PEi(14) for all i=1,2,3,4 with PE5(7)≈PE5(14).	weakness
2020-1522	Doesn't this invalidate the authors' claim?	suggestion
2020-1522	Also, doesn't this mean that the proposed MVPE only works on sequences with length <= 7?	rebuttal_process
2020-1522	(In comparison, the design of positional encoding in the original Transformer doesn't have this problem.)	suggestion
2020-1522	(You didn't show how you implemented and initialized the position encoding in the uploaded code, so I may be missing some assumptions here.)	suggestion
2020-1522	3) In line 48 of the code (https://github.com/CGT-*CONF*2020/CGT-*CONF*2020/blob/master/model.py#L48), why did you take the mean over the batch dimension?	weakness
2020-1522	Shouldn't different samples in a minibatch be very different?	weakness
2020-1522	Does a (potentially completely independent) sample in a batch affect another sample?	weakness
2020-1522	A similar problem occurs for Eq.	weakness
2020-1522	(9): Why do you require clusterings of two different samples b1,b2 to be similar?	weakness
2020-1522	(Where these samples can come from quite different times and years of the data?)	weakness
2020-1522	4) In the experiments, you "sampled 10 input time-steps" due to computational resources.	weakness
2020-1522	Typically, in Transformer-based NLP tasks the sequence lengths can be over 500, with much higher dimensionality (e.g., 512); but you are only using sequence length 10 and dimensions <= 16 (in your code, you used "self.dec_io_list = [[5,8,16,16],[16,16,16,16],[16,8,8,8]]").	weakness
2020-1522	What is the bottleneck for the computation of your approach?	weakness
2020-1522	(I noticed there are more than 1K vertices in city A, which may be a costly factor indeed.) How much memory/compute does the CGT method consume?	weakness
2020-1522	How does using a longer sequence affect the performance of CGT?	weakness
2020-1522	5) You performed an ablation study on MVPE.	weakness
2020-1522	Did you simply remove MVPE, or did you use the conventional PE from the original Transformer paper (Vaswani et al. 2017)?	weakness
2020-1522	(If the latter, I'm very surprised that MVPE is so much better than PE.	suggestion
2020-1522	In that case, you may want to try MVPE on NLP tasks to see if it also improves SOTA.)	suggestion
2020-1522	6) How did you measure unsmoothness in Figure 6?	suggestion
2020-1522	It doesn't seem like a quantifiable property to me.	weakness
2020-1522	You should discuss this in the experiment section.	suggestion
2020-1522	----------------------------------- Minor questions/issues that did not affect the score: 7) There are some strange phrases/sentences in the paper.	weakness
2020-1522	For example, the first sentence of the 2nd paragraph of Section 1: "we will show **throughout the paper** that urban spatiotemporal prediction task suffers from..."	weakness
2020-1522	8) Why use an encoder-decoder architecture at all?	weakness
2020-1522	Why can't we train the model like in language modeling tasks, where we want to predict the next token?	suggestion
2020-1522	In other words, you can simply use a decoder-side CGT, and mask the temporal self-attention as in the Transformers.	suggestion
2020-1522	----------------------------------- In general, I think this paper proposed a valuable approach that seems to work very well on the spatio-temporal dataset they used (which unfortunately is private).	strength
2020-1522	However, as I pointed out above, I still have numerous issues with the paper's organization and clarity, as well as some doubts over the methodology and the experiment.	weakness
2020-1522	I'm happy to consider adjusting my score if the authors can resolve my concerns satisfactorily.	suggestion
2020-1522	[1] http://www-scf.usc.edu/~yaguang/papers/aaai19_multi_graph_convolution.pdf In this paper, the authors developed a neural network architecture to address the spacial and temporal unsmoothness problem, which was claimed to be neglected by existing works.	abstract
2020-1522	The proposed model, CGT, has an encoder-decoder structure, and is characterized by clustering modules for spacial regions based on their temporal patterns.	abstract
2020-1522	To handle temporal unsmoothness, additivity-preserved multi-view position encoding was proposed to characterize different temporal relationships.	abstract
2020-1522	The experimental results on real ride-hailing datasets demonstrate the effectiveness of the proposed method to some extent.	abstract
2020-1522	The major concern is the presentation of this paper.	weakness
2020-1522	There are many unclear points by going through the current paper, which prevents full judgement of the merits of the proposed method.	weakness
2020-1522	First, the key problem to address is claimed to be the spacial and temporal unsmoothness.	weakness
2020-1522	From the introduction, it is hard to see how important the problem is.	weakness
2020-1522	It is better to use real data statistics to show the prevalence and concrete examples of such unsmoothness.	suggestion
2020-1522	Second, the technical sections presents the methods with few intuition on how does each component solve the unsmoothness problem.	weakness
2020-1522	Figures such as fig 2 and 4 are very dense with few annotations, neither in captions nor main texts, thus are hard to understand.	weakness
2020-1522	Finally, in the experiments, it is good to see some results for model interpretation.	weakness
2020-1522	However, it is not clear on how to measure the spatial and temporal unsmoothness in fig 6 on the x axis.	weakness

2020-1533	--------- AFTER rebuttal 1) "We identify issues with current masking procedures as proposed in other papers"	rebuttal_process
2020-1533	One of the major issues with the current masking procedure is that the resulting image is out of the data distribution.	rebuttal_process
2020-1533	Even though your method achieved high accuracy in Table 2 for correctness, the generates images is still out of the data distribution.	rebuttal_process
2020-1533	2) "We propose a cost-effective masking technique that doesn't require retraining of the underlying classifier"	rebuttal_process
2020-1533	The authors compared against zero and gray masking for correctness.	rebuttal_process
2020-1533	None of those masking methods require retraining of the underlying classifier.	rebuttal_process
2020-1533	It is not clear, which previous masking technique required retraining of the underlying classifier?	rebuttal_process
2020-1533	3) We also further show that when performing a comprehensive evaluation, there is no one clearly better explainer and thus practitioners need to be careful about which explainer they choose.	rebuttal_process
2020-1533	This is an observation made upon through exploratory analysis and is not a technical novelty.	rebuttal_process
2020-1533	4) " Confidence on the other hand, also informs us about the per-instance behavior."	rebuttal_process
2020-1533	The confidence measures the change in probability assigned to the ground truth class.	rebuttal_process
2020-1533	Table 3 should also show the variance in the confidence to understand the instance-level behavior.	rebuttal_process
2020-1533	The experiments given in the paper, it looks like confidence and correctness are positively correlated.	rebuttal_process
2020-1533	An example of the model where they are not positively correlated will help the reader understand the importance of each of these terms.	rebuttal_process
2020-1533	5) " Effect of Thresholding on results"	rebuttal_process
2020-1533	Thank you for the explanation and new experimental results.	misc
2020-1533	------------------------- BEFORE rebuttal The paper proposed different metrics for comparing explainers based on their correctness (ability to find most relevant features in an input, used in prediction), consistency (ability to capture the relevant components while input is transformed), and the confidence of the generated explanations.	rebuttal_process
2020-1533	To evaluate correctness, the authors proposed to study the change in the classification accuracy of the target model, under a perturbed dataset where the most relevant regions (as given by explainer) of the image is preserved and the remaining content is replaced with non-informative backgrounds for the target class.	rebuttal_process
2020-1533	For consistency evaluation, the authors proposed to apply transformations like rotation, translation and flip that doesn't semantically change the input image.	rebuttal_process
2020-1533	For confidence evaluation, they compared the prediction performance on the original image, masked image (only salient regions) and inverted masked image (only non-salient regions).	rebuttal_process
2020-1533	Major • The paper lack technical novelty.	weakness
2020-1533	• The confidence component looks redundant and can be incorporated in the correctness component.	weakness
2020-1533	• The inverse saliency map idea is already proposed in "Evaluating the visualization of what a deep neural network has learned" for evaluating saliency maps.	weakness
2020-1533	There the authors gradually replace the most salient regions with random noise and observe a decrease in prediction accuracy.	weakness
2020-1533	• Most of the saliency maps producing methods, generate continuous maps.	weakness
2020-1533	For making, we need to convert the continuous map to binary by using a threshold.	weakness
2020-1533	An analysis of choosing different values as threshold is missing.	weakness
2020-1533	By choosing an appropriate threshold, the size of the most salient region can be controlled.	weakness
2020-1533	Thus, although Grad-Cam spread saliency over large area, we can use a higher threshold to define the binary mask.	weakness
2020-1533	• Grad-CAM, integrated grad and smooth grad are all gradient-based saliency maps.	weakness
2020-1533	There are perturbation-based saliency maps, which aims to find most salient regions such that removing those regions produce a maximum drop in prediction accuracy.	weakness
2020-1533	Example "Interpretable Explanations of Black Boxes by Meaningful Perturbation.", "Object detectors emerge in deep scene cnns" .	weakness
2020-1533	An evaluation of such methods is missing.	weakness
2020-1533	Minor: • The text in the figures has very small font size and is not readable.	weakness
2020-1533	• See post-rebuttal updates below!	misc
2020-1533	Summary --- (motivation) There are lots of heat map/saliency/visual explanation approaches that try to deep image classifiers more interpretable.	weakness
2020-1533	It's hard to tell which ones are good, so we need better ways of evaluating explanations.	weakness
2020-1533	This paper proposes 3 such explanation evaluation metrics, correctness, consistency, and confidence.	weakness
2020-1533	(approach - correctness) An explanation is correct if it highlights enough of an image for a classifier to tell the correct class with only the highlight parts of the image.	weakness
2020-1533	The default way to evaluate on only highlighted portions is to set the non-highlighted bckground to black/grey.	weakness
2020-1533	Instead, this method finds images with the same ground truth class which the classifier scored the lowest of all such images, forming a low-confidence baseline.	weakness
2020-1533	It copies the background from one of these images instead of using a black/grey background to try and put the masked image back into the distribution of images from the ground truth class.	weakness
2020-1533	This style of masking is used to compute correctness.	weakness
2020-1533	(approach - consistency) An explanation is consistent if it is invariance w.r.t. a number of mostly semantically invariant transformations.	weakness
2020-1533	These include small affine transformations, horizontal flips, vertical flips, and adding noise.	abstract
2020-1533	(approach - confidence) An explanation is confident if the masked images it produces still have high condidence under the classifier.	abstract
2020-1533	Masked images are produced as for correctness, by copying a distractor from the same class into the background.	abstract
2020-1533	(experiments) The experiments compare existing explanations (LIME, Grad-CAM, Integrated Gradients, SmoothGrad) using the proposed metrics.	abstract
2020-1533	1. Correctness: Classifiers have higher accuracy on explanation-masked images than on images they were least confident on (the ones used to fill in the background).	abstract
2020-1533	2. Grad-CAM is most correct, followed by SmoothGrad, Integrated Gradients, and LIME.	abstract
2020-1533	3. Consistency: Grad-CAM explanations are most resilient to the proposed transformations with Integrated Gradients, SmoothGrad, and LIME being successively less invariant.	abstract
2020-1533	4. Confidence: Explanation-masked images have higher scores for their ground truth class than the low-confidence baseline images.	abstract
2020-1533	5. Hyperparameter variations in the correcness/confidence metrics mostly preserve the ranking of methods, though the absolute values of performance do change substantially.	weakness
2020-1533	(conclusion) The paper concludes that Grad-CAM is usually the best of the methods tested according to the new metrics and that LIME is the worst.	weakness
2020-1533	Strengths --- I really like the related work section.	strength
2020-1533	It could be a valuable resource going forward.	strength
2020-1533	I like the research direction of this paper very much.	misc
2020-1533	I think that enumerating a suite of complementary benchmarks is a good way to measure explanation quality because we can only come up with benchmarks that capture a small part of what we want so far.	strength
2020-1533	Weaknesses --- I see some major conceptual flaws with these metrics: * In section 3.1 it seems like the first reasons that normal masking failed is not solved by the proposed approach.	weakness
2020-1533	The generated images are still out of distribution because the "foreground" and the "background" don't match.	weakness
2020-1533	* I'm concerned about the low-confidence distractor images used in the background.	weakness
2020-1533	They are from the same ground truth class as the high confidence images they are pasted into the background of, correct?	weakness
2020-1533	The correctness metric is supposed to capture whether or not an explanation highlights all the class-relevant content in an image and no more.	weakness
2020-1533	However, information that the explanation did not highlight (the background) can inform the classifier of the ground truth class because the background came from an image of that class (even if a low confidence one).	weakness
2020-1533	This is especially true because the relevant objects might be in differrent positions in the two images.	weakness
2020-1533	Thus it could be that the explanation did not highlight informative content but the classifier still gets the corresponding masked image correct because of the background.	weakness
2020-1533	How often does this happen?	weakness
2020-1533	* Consistency is supposed to measure "the ability of the explainer to capture the relevant components" under semantically invariant transformations.	weakness
2020-1533	The reported metric is mimized when the explanation is the same before and after a variety of transformations.	weakness
2020-1533	If this were the case then at least one of them must be wrong in the sense that it would not have captured some relevant components	weakness
2020-1533	(unless perhaps it just highlighted everything and was thus useless).	weakness
2020-1533	Because of the transformation (e.g. 15 degree rotation) the relevant components would have been at a different position, but the best explanation according to this metric would have been at the same position.	weakness
2020-1533	Thus this metric seems to reward explanations for not capturing relevant components.	weakness
2020-1533	Parts I Didn't Understand: * In section 3.1, I don't understand the second reason that masking failed.	weakness
2020-1533	In what sense is masking made meaningless?	weakness
2020-1533	How is that sense different from the out of distribution concern from the first point?	weakness
2020-1533	Missing Details / Presentation Weaknesses: * Missing reference to [1] which provides more metrics.	weakness
2020-1533	* The meaning of confidence is different than it normally is and this may be confusing.	weakness
2020-1533	Neural networks should be well calibrated, not necessarily confident (in the commonly used sense of [3]).	weakness
2020-1533	Minor flaws: * Masking by replacing the background with grey (i.e., the bias of the first conv layer) rather than black is more common (e.g., [2] and Grad-CAM).	weakness
2020-1533	A grey background negates the bias.	weakness
2020-1533	It's not clear that the background should cancel the bias, but it would be nice to compare to both grey and black masking in Table 7.	suggestion
2020-1533	[1]: Adebayo, Julius et al. "Sanity Checks for Saliency Maps." NeurIPS (2018).	misc
2020-1533	[2]: Zeiler, Matthew D. and Rob Fergus.	misc
2020-1533	"Visualizing and Understanding Convolutional Networks." ECCV (2013).	misc
2020-1533	[3]: Guo, Chuan et al. "On Calibration of Modern Neural Networks." ICML (2017).	misc
2020-1533	Final Evaluation --- This paper relies solely on theoretical arguments to show its metrics capture meaningful information.	weakness
2020-1533	Empirically, it only shows that the proposed metrics can differentiate between some popular explanations.	weakness
2020-1533	It does not empirically show that the differentiation is meaningful (e.g., by measuring agreement with human judgement).	weakness
2020-1533	This by itself isn't a problem.	weakness
2020-1533	However, above I detailed significant flaws in the theoretical justification for the metrics, so I can't recommend these metrics (this paper) on either a theoretical or an empirical basis.	weakness
2020-1533	Quality: Per above, I do not think the arguments/evidence in the paper support its conclusions.	weakness
2020-1533	Clarity: The paper could be clearer, but can be understood without too much effort.	weakness
2020-1533	Originality: These metrics are new enough, being novel variations on prior approaches.	strength
2020-1533	Significance: If I was convinced the metrics made sense then I would guess this paper would be very impactful.	strength
2020-1533	As is, I don't think it will have much impact.	weakness
2020-1533	The quality of the paper is my reason for the low rating.	misc
2020-1533	I'm interested to see whether what others think to make sure I've understood the paper correctly and analyzed it accurately.	misc
2020-1533	If my understanding is incorrect I could definitely raise my rating.	misc
2020-1533	Post-Rebuttal Evaluation --- After reading the other reviews and the author responses and taking a brief look at the updated paper I still think this paper should be rejected.	decision
2020-1533	The authors' response to my comments clarified my understanding of the consistency metric.	rebuttal_process
2020-1533	Now I understand it and think it is a useful metric.	strength
2020-1533	However, I did not find clarification about the confidence or correctness metrics, though I agree they are not redundant.	rebuttal_process
2020-1533	They still don't really quite make sense to me.	weakness
2020-1533	This puts me in about the same position as R3, who also doubts those metrics.	weakness
2020-1533	In the end, this leaves my initial evaluation essentially unchanged.	weakness
2020-1533	I still recommend rejection because the paper relies on a theoretical understanding of what makes confidence and correctness metrics useful and that understanding is not provided.	decision
2020-1533	This paper studies the interesting question of comparing the deep network visualization algorithms quantitatively.	abstract
2020-1533	Several metrics are proposed, including correctness, consistency and confidence.	abstract
2020-1533	I like the notion of consistency, where an explainer should produce the same explanation under transformations of the image that does not change its "semantic content".	abstract
2020-1533	However, I am confused or unconvinced by several arguments made in the paper, and if the authors can clarify them I am willing to increase my review.	weakness
2020-1533	I think the major issue is that most metrics are justified with flimsy arguments, not compared with prior work, and do not lead to consistent ranking of the models.	weakness
2020-1533	Correctness: I am not convinced by the correctness evaluation for several reasons	weakness
2020-1533	1. The combined image is still out of distribution, and it is unclear why this is better compared to e.g. using a white background.	weakness
2020-1533	2. Does it favor visualization methods with a blob-shaped saliency map vs.	weakness
2020-1533	scattered dots shaped saliency map?	weakness
2020-1533	Does it favor methods with a larger salient region?	weakness
2020-1533	For example, just from visual appeal, I do not think smoothgrad is worse than gradCAM, but the number says otherwise.	weakness
2020-1533	I think the arbitrariness of this metric makes the numbers hard to believe.	weakness
2020-1533	3. If the original image is already incorrectly classified (since they are the ones where the classifier assigns the lowest probability) it is hard to imagine that adding random background can make the performance worse.	weakness
2020-1533	Therefore, it is also unclear what to make of the numbers in e.g. Table 2.	weakness
2020-1533	There are so many metrics, precision, recall, F1, and none of them seem particularly well justified.	weakness
2020-1533	They also do not rank the model in the same way.	weakness
2020-1533	Which result should a practitioner believe?	weakness
2020-1533	Confidence: I am not sure the confidence vs.	weakness
2020-1533	number of pixels comparison are useful.	weakness
2020-1533	Across all methods, it seems to be more pixels -> increased confidence, which is unsurprising.	weakness
2020-1533	I think the results are only useful if one method pareto dominates another, which is not what is observed in the experiments.	weakness
2020-1533	I do not understand the difference between confidence and correctness.	weakness
2020-1533	It seems like both measure how well a model can predict the correct class given only the salient region.	weakness
2020-1533	For example, if method A has higher confidence and lower correctness compared to method B, what does that mean?	weakness
2020-1533	Under which situation should one choose method A over method B?	weakness

2020-1583	Summary: This paper investigates the choice of noise distributions for smoothing an arbitrary classifier for defending against adversarial attacks.	abstract
2020-1583	The paper focuses on the two major adversaries: \\ell_2 adversaries and \\ell_\\infty adversaries.	abstract
2020-1583	Theorem 1 quantifies the tradeoff between the choice of smoothing distribution which (1) has clean accuracy close to the original classifier and (2) promotes the smoothness of smoothed classifier (and hence adversarial accuracy).	abstract
2020-1583	For the \\ell_2 adversary, the paper argues that Gaussian distribution is not the right choice, because the distribution is concentrated on the spherical shell around the x.	abstract
2020-1583	Instead, the authors propose using a new family of distributions, with the norm square  (p_{|z|_2^2}) following the scaled \\chi^2 distribution with degree d-k (Eq. 8).	abstract
2020-1583	This allows an extra degree of freedom, and setting k=0 recovers the Gaussian distribution.	abstract
2020-1583	For \\ell_\\infty perturbations, the paper suggests another family of distributions combining the \\ell_2 and \\ell_\\infty norm (Eq. 9), and argues that it outperforms the natural choice of \\ell_\\infty norm-based distributions (Eq. 10).	abstract
2020-1583	I think the paper should be rejected because (1) For \\ell_2 perturbations, there is no major difference between this new family of distributions (d-k \\chi^2) and a Gaussian with different variance.	decision
2020-1583	(2) For \\ell_\\infty distributions, the motivation of mixed norm distributions (Eq. 9) over \\ell_\\infty based distributions (Eq. 10) is not very clear.	weakness
2020-1583	(3) The experimental evidence is also weak (see below).	weakness
2020-1583	Main arguments: 1. The distribution of the norm \\|z\\|_2 in Eq.	weakness
2020-1583	(8) would be concentrated on a thin spherical shell of radius about \\sqrt{d-k}\\sigma.	weakness
2020-1583	As the Gaussian distribution with standard deviation \\sigma' is supported on a shell of radius about \\sqrt{d} \\sigma', for each (k,\\sigma) in the family of Eq. 8, there is an equivalent Gaussian with appropriate \\sigma' (Theorem 3 now just compares the radius of the spherical shell).	weakness
2020-1583	Therefore, I don't see the benefit of this extra degree of freedom of k: the noise distribution is again a "soap bubble" of a different radius.	weakness
2020-1583	Thus, a grid search over \\sigma' for a Gaussian should be the same as a grid search over (k,\\sigma) in Eq. 8.	weakness
2020-1583	Even the experimental experiments are a marginal improvement over Cohen et al. I don't see why the value of (k,\\sigma) was not provided in Table 1 and only \\sigma was provided.	weakness
2020-1583	Also, the table of Cohen et al. was only calculated for specific values of \\sigma for Gaussian distributions (0.12, 0.25, 0.5, 1.00).	weakness
2020-1583	For a fair comparison, comparable values of \\sigma's must be calculated, and then the best choice should be selected.	weakness
2020-1583	2. In the light of previous arguments, I don't think the choice of Eq. (9) or Eq. (10) is well motivated.	weakness
2020-1583	Why not smooth it with a cube of appropriate radius?	weakness
2020-1583	Also, not enough experimental details are provided for Table 3.	weakness
2020-1583	Salman et al. (2019) reports the accuracy of 68.2% for \\ell_infty perturbations (Table 3, Salman et al. (2019)), whereas the value reported in your Table 3 for at the same radius is 58%.	weakness
2020-1583	Is it a typo? In any case, the values reported for the proposed model in Table 3 are only a marginal improvement over Figure 1 (left) in Salman et al. (2019), just going by the trivial \\ell_2 to \\ell_\\infty certificate.	weakness
2020-1583	Other areas for improvement: 1. The paper contains numerous grammatical errors, confusing statements, and nonstandard phrases.	weakness
2020-1583	For example: (i) more less robust, (ii) black start, (iii) pointy points, etc.	weakness
2020-1583	I suggest that the authors spend more time clarifying their manuscript.	suggestion
2020-1583	2. The paragraph starting with "Trade-off between Accuracy and Robustness": I think this paragraph should be reworded for clarification.	suggestion
2020-1583	It is not robustness but rather the lack thereof -- say, sensitivity.	suggestion
2020-1583	3. On p.5, why was the toy classifier sphere-based?	rebuttal_process
2020-1583	The toughest classifier for Gaussian smoothing (the one achieving the lower bound for Gaussian smoothing) is actually a linear classifier.	suggestion
2020-1583	This paper presents a new method for adversarial certification using non-Gaussian noise.	abstract
2020-1583	A new framework for certification is proposed, which allows to use different distributions compared to previous work based on Gaussian noise.	abstract
2020-1583	From this framework, a trade-off between accuracy and robustness is identified and new distributions are proposed to obtain a better trade-off than with Gaussian noise.	abstract
2020-1583	Using these new distributions, they re-certify models obtained in previous work.	abstract
2020-1583	I am hesitating between a weak reject and a weak accept.	decision
2020-1583	The theoretical results are interesting, showing a clear trade-off between robustness and accuracy with a new lower bound and deriving better smoothing distributions.	strength
2020-1583	However, the experimental results are lacking, and do not support much the proposed method.	weakness
2020-1583	Training with this new distribution would have been a natural experiment given the argument.	weakness
2020-1583	Moreover, the results for L_inf are partial and it would be expected to have some results for ImageNet as claimed in the introduction.	weakness
2020-1583	I would have given an accept if the previous points had been addressed and I feel that with some more work on it, it would become an excellent paper.	decision
2020-1583	Main arguments: My main concern is about the experiments: Why were Cohen et al.'s models used instead of Salman et al.'s?	weakness
2020-1583	Salman et al.'s have achieved better certified accuracy under the L_2 norm so it would only seem natural to use their model.	weakness
2020-1583	About the main results: there seems to be a discrepancy between the results reported for Cohen et al. and the original paper for both CIFAR-10 and ImageNet L2 certification.	weakness
2020-1583	Also, the reported certified accuracy for Salman et al.'s model for L_inf on CIFAR-10 reported in the original paper is 68.2 at 2/255, which is very far from the 58 in Table 3.	weakness
2020-1583	What is the reason for these differences?	weakness
2020-1583	Minor comments: In the third paragraph, it is claimed that L_inf attacks are a stronger and more relevant type of attacks than L_2 attacks.	weakness
2020-1583	These two different objectives cannot be compared in those terms.	weakness
2020-1583	Defenses such as adversarial training have not been "broken" as claimed in section 2 in the sense that the claims made in the original paper still hold true.	weakness
2020-1583	The term broken is used for defenses in which the claimed accuracy against stronger attacks were found to be much lower than what was claimed in the original paper.	weakness
2020-1583	It is claimed that "if ||z||_inf is too large to exceed the region of natural images, the accuracy will be obviously rather poor"; however, the common practice is to clip to the input space bounds.	weakness
2020-1583	How would that affect the method?	weakness
2020-1583	Things to improve the paper that did not impact the score: In the first paragraph, Goodfellow et al., 2015 is cited, however, papers on adversarial attacks were published earlier than that such as Szegedy et al., 2014 or Biggio et al., 2013.	weakness
2020-1583	Vershynin, 2018 is cited about the distribution of a gaussian in high-dimensional spaces.	weakness
2020-1583	However, this is a very well known result and does not need any citation (or if any, Bellman, 1961).	weakness
2020-1583	Typo after equation 4: ||f||_{L_p}	weakness
2020-1583	Typo in "Black-box Certification with Randomness" paragraph: "by convovling"	weakness
2020-1583	Typos in Table 2.: the columns 2.0 to 3.5 are mislabeled The paper introduces an improvement to the randomized smoothing analysis in Cohen et al. (2019), using Lagrangian relaxation to achieve a more general lower bound.	weakness
2020-1583	Using this, it considers different adversarial smoothing distributions that yield some increase in certified adversarial accuracy.	weakness
2020-1583	Overall assessment: While the Lagrangian relaxation idea is interesting and could yield interesting follow-up work, the paper is sloppy in several respects and needs to be tightened before it can be considered for publication.	decision
2020-1583	Key issues: 1. Proof of main theorem (strong duality) is incorrect.	weakness
2020-1583	Likely the statement itself is also incorrect.	weakness
2020-1583	Fortunately the most important direction (lower bound) is still true, so this isn't a fatal flaw to the approach.	weakness
2020-1583	2. The paper makes several references (in italics) to a "fundamental trade-off between accuracy and robustness".	weakness
2020-1583	But a fundamental trade-off means that *any* method that attains good accuracy must sacrifice robustness and vice versa; this requires a "for all" statement, i.e. a lower bound.	weakness
2020-1583	All the paper shows is that the *particular upper bound* exhibits a trade-off (and even then, the notions of "accuracy" and "robustness" are merely interpretations of quantities in the bound; it's not clear why the robustness term in particular is tied to more standard notions of robustness).	weakness
2020-1583	3. The justification for why the particular smoothing distributions are good ideas is sketchy.	weakness
2020-1583	I elaborate on 1 and 3 below.	misc
2020-1583	Addressing 1-3 effectively will improve my score.	suggestion
2020-1583	#1 (main theorem is incorrect): Claim 3 in the appendix is wrong.	weakness
2020-1583	The fact that (delta', f') outperforms (delta-bar, f-bar) with respect to lambda* does not imply that (delta', f', lambda*) is a better solution to the primal problem, because we must take max over lambda and the maximizing lambda need not be lambda*.	weakness
2020-1583	In particular if f' doesn't satisfy the constraint we would instead take lambda to infinity.	weakness
2020-1583	#3 (sketchy justification): The paper justifies a smoothing distribution that concentrates more mass around the center as follows: "This phenomenon makes it problematic to use standard Gaussian distribution for adversarial certification, because one would expect that the smoothing distribution should concentrate around the center (the original image) in order to make the smoothed classifier close to the original classifier (and hence accurate)."	weakness
2020-1583	I don't see why we should want more mass near the center---in the limit as we move all the mass towards the center and get the original classifier, our certified bound will be terrible, so it's not clear why moving in that direction should be expected to help.	weakness
2020-1583	Indeed, the experimental gains are minimal (1 to 3 percentage points) and on methods that were not carefully tuned, so one could imagine that the baseline method could be improved by that much just with careful tuning.	weakness
2020-1583	I similarly didn't understand the justification for the mixed L-inf / L-2 distribution for L-infinity verification.	weakness
2020-1583	The main justification was "The motivation is that this allows us to allocate more probability mass along the "pointy" directions with larger`∞norm, and hence decrease the maximum distance term max δ∈B`∞,rDF(λπ0‖πδ)."	weakness
2020-1583	This is at the very least too brief for justifying the main experimental innovation in the paper (here at least the empirical improvements are bigger, although still not huge).	weakness
2020-1583	Minor but related: Why is the x-axis in Figure 4 so compressed?	weakness
2020-1583	This is also in a regime where all 3 methods fail to certify so not clear it's meaningful.	weakness
2020-1583	Writing comment: Change some of the Theorems to Propositions.	weakness
2020-1583	Theorems should be for key claims in paper (there shouldn't be 4 of them in one 8-page paper).	weakness

2020-1610	This paper describes a sensor placement strategy based on information gain on an unknown quantity of interest, which already exists in the active learning literature.	abstract
2020-1610	As is well-known in the literature, this is equivalent to minimizing the expected remaining entropy.	abstract
2020-1610	What the authors have done differently is to consider the use of neural nets (as opposed to the widely-used Gaussian process) as the learning models in this sensor placement problem, specifically to (a) approximate the expectation using a set of samples generated from a generator neural net and to (b) estimate the probability term in the entropy by a deterministic/inspector neural net.	abstract
2020-1610	The authors have performed some simple synthetic experiments to elucidate the behavior and performance of their proposed strategy.	abstract
2020-1610	Conventionally, the sensor placement strategy is tasked to gather the most informative observations (given a limited sensing budget) for maximimally improving the model(s) of choice (in the context of this paper, the neural networks) so as to maximize the information gain.	abstract
2020-1610	The authors seem to have adopted a different paradigm in this paper: Large training datasets are needed for the prior training of both neural nets (in the order of thousands as reported in the experiments).	abstract
2020-1610	This seems to be defeating the original aim/objective of sensor placement, as described above.	abstract
2020-1610	Consequently, it is not clear to me whether their proposed strategy would be general enough for use in sensor placement for a wide variety of environmental monitoring applications.	weakness
2020-1610	Random sampling and GP-based sensor placement strategies do not face such a severe practical limitation.	weakness
2020-1610	The paper is also missing several important technical details and clarity of presentation is poor.	weakness
2020-1610	For example, (a) The configurations and training procedure of generator NN G and deterministic NN D for the experiments are not sufficiently described for each experiment.	weakness
2020-1610	(b) What do the authors do with the new observations obtained from placing the sensors in the last experiment?	weakness
2020-1610	Do they adopt an open-loop sensor placement strategy?	weakness
2020-1610	(c) The setup for the last experiment is not clear.	weakness
2020-1610	Is it still the same object classification task?	weakness
2020-1610	Is the GP receiving an exclusive set of 4D features that are different from the other two methods?	weakness
2020-1610	I get the impression that the classifiers are trained a priori.	weakness
2020-1610	For the GP classifier, isn't it the case that one should gather the most informative observations to maximally improve its classification accuracy?	weakness
2020-1610	Though I like the authors' motivation of the setup of the x-ray baggage scanning system in security screening, what has really been done in their experiments appears to be still quite far from this real-world setup.	weakness
2020-1610	Furthermore, their proposed strategy has been used to gather only 1 to 4 observations.	weakness
2020-1610	More extensive empirical evaluation with real-world datasets (inspired by realistic problem motivation) is necessary.	weakness
2020-1610	Fig. 2: I find it surprising that with a single observation, it is possible to generate the instance/imagined spectrum in orange that resembles that of the true spectrum.	weakness
2020-1610	Similarly, with 3 observations, all 10 instances/imagined spectrums can exhibit the first spike (without observations on it).	weakness
2020-1610	Can the authors explain this phenomena?	weakness
2020-1610	Minor issues The authors need to put a space in front of all opening round bracket.	weakness
2020-1610	Other formatting issues exist. Equation 3: v_k is missing from the conditioned part on the lefthand side of the equation.	weakness
2020-1610	Page 3: to estimates? Page 3: evidence lower bond?	weakness
2020-1610	Figure 2 appears on page 3 and is only referenced on page 4.	weakness
2020-1610	Algorithm 1: The use of subscript j in x^m_j to represent an unobserved location confuses with that of subscript k in x^m_k to denote the time step.	weakness
2020-1610	Figure 3 captions: adapted on the measurements?	weakness
2020-1610	Figure 4 captions: corner feature occurred?	weakness
2020-1610	Summary: This paper addresses the issue of how to optimize sensor placement.	abstract
2020-1610	The authors propose a framework for sensor placement called Two-step Uncertainty Network (TUN) based on the idea of information gain maximization.	abstract
2020-1610	More concretely, the proposed method encodes an arbitrary number of measurements, models the conditional distribution of high dimensional data, and estimates the task-specific information gain at unobserved locations.	abstract
2020-1610	Experimental results on the synthetic data clearly show that TUN outperforms current state-of-the-art methods, such as random sampling strategy and Gaussian Process-based strategy.	abstract
2020-1610	Comments: - On page 1, the phrase "… on high dimensional data such as images as generative models" seems unclear.	weakness
2020-1610	- The lhs of Eq 3.	weakness
2020-1610	should be MI(y,x_k|v_k, Obs)? - In Fig. 1a, the "red arrows" for indicating TUM look like brown?	weakness
2020-1610	- In Fig. 1b, only the variable x_k is mentioned in the caption.	weakness
2020-1610	- If I understand correctly, on page 3 in Sect.	weakness
2020-1610	2.1, the imagination step is basically the same as VAE?	weakness
2020-1610	After all, there does not seem to be any discussion on the choice of variational approximation q_{\\phi} and prior p_{\\theta}(z), where is crucial for performing variational inference.	weakness
2020-1610	Though I am not an expert in this domain, I find the basic idea is simple and easy to understand.	strength
2020-1610	However, my major concern is about the novelty of this work, given the fact that the theoretical contribution is quite limited.	weakness

2020-1631	This paper proposes a layer on top of BERT which is motivated by a desire to disentangle content (meaning of the tokens) and form (structural roles of the tokens).	abstract
2020-1631	Figure 1 shows this clearly.	abstract
2020-1631	The paper considers two variants of the disentangling layer (TPR), one with LSTMs (figure 2) and the other with attention (figure 3).	abstract
2020-1631	The aim in both is to obtain a decomposition of the form x(t) = S a_s(v_t) a_r(v_t) R where S and R are shared matrices of parameters and v is the output of BERT.	abstract
2020-1631	The model is well motivated and includes clear reasonable design ideas, including choosing hyper-parameters so that the number of symbols (s) is greater than the number of roles (r), and forcing only the roles to be independent (eqn 6).	strength
2020-1631	Minor: I would have preferred that figure 1 appeared earlier in page 3.	strength
2020-1631	This would help as the authors forgot to define v in eqn 2.	strength
2020-1631	One has to wait for the figure.	rebuttal_process
2020-1631	Having said this, the paper is extremely clear in the notation and does an excellent job at defining dimensions for all the quantities of interest.	strength
2020-1631	I read the paper eagerly and with excitement until I got to the results.	misc
2020-1631	First, it wasn't clear to me how well motivated is the idea of fine-tuning on intermediate tasks.	weakness
2020-1631	I understand the authors are just trying to make a point that BERT does worse than their model in this case and that this is not good for transfer, but still I find this to be artificially constructed.	weakness
2020-1631	The variations in the numbers seem small and possibly attributable to other factors.	weakness
2020-1631	For this reason, I feel the authors should have continued showing results for the other baselines from the first experiment.	suggestion
2020-1631	I would also have loved to see some visualizations for a, r, A and R in the appendix.	suggestion
2020-1631	Some visualization and anecdotal results might have helped me see that the motivation is backed up by the results.	suggestion
2020-1631	I hope the authors have the time to do this and consider the extra experiments.	suggestion
2020-1631	This paper proposes an alternative way of reusing pretrained BERT for downstream tasks rather than the traditional method of fine-tuning the embeddings equivalent to the CLS token.	abstract
2020-1631	For each bert embedded token, the proposed method aims at disentangling semantic information of the word from its structural role.	abstract
2020-1631	Authors provide two ways to provide this disentagling using LSTM or transformer blocks.	abstract
2020-1631	with several design choices such as: *  a regularization term to encourages the roles matrix to be orthogonal and hence each role carry independent information *  design the roles and symbols matrices so that the number of symbols is greater than the number of roles	abstract
2020-1631	In evaluation authors design several experiments to show that: * Does transferring disentangled role & symbol embeddings improve transfer learning	abstract
2020-1631	* the effectiveness of the TPR layer on performance?	abstract
2020-1631	* Transfer beyond Glue tasks?	weakness
2020-1631	While those experiments provide empirical gains of the design choices, authors don't show enough study to attribute those  empirical gains to the presented design choices: One large claim in the paper is that empirical gains in the ability of transfer between similar tasks MNLI and GLUE is because of disentangling the semantics from the role representations.	weakness
2020-1631	We don't know if the TPR layer really manages to do that, this could have been easily verified using for example clustering word senses of the same word.	weakness
2020-1631	The empirical gains in transfer learning can be simply attributed to: - More params it seems adding an LSTM over bert embeddings already does some improvement, I would have loved to see this more exploited but it wasn't.	weakness
2020-1631	This aligns with some recent findings that BERT is undertrained (Liu et al. 2019) https://arxiv.org/abs/1907.11692	weakness
2020-1631	- Variance in the results (authors report only results of one single run not mean and std of several runs).	weakness
2020-1631	- More budget given to hyper-parameter search for the models proposed in the paper.	weakness
2020-1631	Hyper param budget isn't also reported in the paper.	weakness
2020-1631	- other factors, not the ones associated with the claims in the paper: for example what authors claim is an ablation study was comparing several different models together.	weakness
2020-1631	It would have been more interesting to see for example the effect of making the # symbols = # roles or removing the orthogonality loss from the roles matrix.	suggestion
2020-1631	Conclusion: The paper introduces large claims and empirical results that correlate with, however the provided experiments are not done with enough control to attribute gains to the design choices provided in the paper.	weakness
2020-1631	This paper proposes a fine-tune technique to help BERT models to learn & capture form and content information on textual data (without any form of structural parsing needed).	abstract
2020-1631	They key addition to the classic BERT model is the introduction of the R and S embeddings.	abstract
2020-1631	R &S are supposed to learn the information in text that is traditionally represented as the structural positions and the content-bearing  symbols in those positions.	abstract
2020-1631	In order to effectively learn R and S embeddings, the authors propose two possible ways to do so: LSTM (Fig 2) and 1-layer Transformer (Fig 3).	abstract
2020-1631	The main experiments are based on 1-layer transformer HUBERT b/c from a single test in Table 1, the transformer variant appears to be working better than the LSTM variant.	abstract
2020-1631	My main concern regarding this paper is two-fold: limited novelty and insignificant performance gain.	weakness
2020-1631	The authors did a great job motivating the need for separating role and filler in the intro.	strength
2020-1631	However, in neither implementation of HUBERT, I do not see how the structural information (e.g., a parse tree) is directly incorporated into the learning of HUBERT.	weakness
2020-1631	Regarding the performance, it seems HUBERT is gaining very little over the BERT baseline.	weakness
2020-1631	please refer to my specific question below.	misc
2020-1631	Questions: What are the numeric values for d_S, d_R, n_S, n_R (defined under Section 3 on page 2) in experiment ?	weakness
2020-1631	I think d_S, d_R are determined at author's discretion (just like the dimensionality of, say, the LSTM hidden layer).	misc
2020-1631	But how are n_S and n_R determined?	weakness
2020-1631	Page 7, first paragraph: what is Filler embeddings F?	weakness
2020-1631	F is not defined in either version the proposed HUBERT( Figure 2 or Figure 3).	weakness
2020-1631	Did the authors mean S?	weakness
2020-1631	Table 2. Why do the first 5 rows and the bottom 5 rows have different baseline Acc.	weakness
2020-1631	? Shouldn't we always use the best accuracy as baseline for comparison?	weakness
2020-1631	If we look at the HUBERT Fine-tuned Acc., in many cases, they are actually worse than the best baseline acc.	weakness
2020-1631	available. (i.e., QNLI , QQP, and SST).	weakness
2020-1631	Other comments: Typo on page one: "[] To strengthen the generality of …."	weakness
2020-1631	Figure 1 is never referred in main text.	weakness

2020-1637	There are major problems with this paper.	misc
2020-1637	It is concerned with the examination of pruning experiments for a LeNet on the MNIST dataset.	weakness
2020-1637	I fail to see how anything useful can be derived from this, as MNIST is a completely trivial dataset and LeNet is a very old, small architecture which does not at all resemble the massive overparameterised models that we care about.	weakness
2020-1637	From a narrative perspective, I am not sure what the key point is, what should the reader take home?	weakness
2020-1637	What should they take account of when performing network pruning?	weakness
2020-1637	In terms of presentation, some of the figures are unreadable (figure 4).	weakness
2020-1637	Figure 15 looks like noise.	weakness
2020-1637	The writing is good however, if a bit grandiloquent.	strength
2020-1637	I dislike writing short reviews, but I fear this paper falls too far short of *CONF* standard.	decision
2020-1637	Pros: - Well written Cons: - Experiments are weak	weakness
2020-1637	- Unclear narrative; what's the one key message?	weakness
2020-1637	I have to give this paper a reject as the experiments conducted are far too weak, and there is little evidence anything found here will, say, generalise to a ResNet/DenseNet on ImageNet. This paper study the lottery ticket hypothesis by observing the properties of lottery tickets.	decision
2020-1637	In particular, the authors tested several different pruning techniques by varying evaluation criteria (L_1, L_2, L_-\\infty and random) and pruning structures (structured, unstructured and hybrid).	decision
2020-1637	The authors perform experiments mainly on LeNet with the MNIST dataset and analyze the observations.	weakness
2020-1637	Overall, I think that the observations presented in the paper are not significant due to the following reasons.	weakness
2020-1637	First, the paper consists of the list of observations but how the observations extend to is not clearly described.	weakness
2020-1637	There are no guidelines how to utilize the observations in future research (e.g., how they can be used for verifying the lottery ticket hypothesis or how they affect to existing pruning techniques) while some observations might be trivial or not very interesting (e.g., contribution 1 and contribution 2) for me.	weakness
2020-1637	Second, the observations are only presented for LeNet and MNIST and it is non-trivial whether they extend to large scale models.	weakness
2020-1637	The authors present VGG11 and AlexNet results in Appendix but they are not large enough to verify their hypothesis for practice.	weakness
2020-1637	The authors mentioned that larger models are not their subject, but this significantly reduces the confidence of the observations.	rebuttal_process
2020-1637	Other comments: I think that Figure 5 is not well described.	weakness
2020-1637	Explicitly noting the meaning of color in the figure would be better.	weakness
2020-1637	Texts in Figure 7 are too small to read.	weakness
2020-1637	*Summary* This paper compares network pruning masks learned via different iterative pruning methods.	abstract
2020-1637	Experiments on LeNet + MNIST show (a) different methods can achieve similar accuracy, (b) pruned sub-networks may differ significantly despite identical initialization, (c) weight reinitialization between pruning iterations yields more structured convolutional layer pruning than not reinitializing, and (d) pruning methods may differ in the stability of weights over pruning iterations.	abstract
2020-1637	*Rating* There are interesting bits of data in this paper, but the overall story is somewhat muddled and some inferences seem to be insufficiently supported by data (1-2 below).	weakness
2020-1637	In addition, the text would benefit from better organization and presentation (3-4 below) and replications on other datasets and architectures (5 below).	weakness
2020-1637	As a result, my rating is currently weak reject.	rating_summary
2020-1637	(1) *Overlap in pruned sub-networks*: In the middle of Sec. 4, Fig 3-5 examine the similarity of pruning masks between methods.	suggestion
2020-1637	It seems clear from several of the plots that multiple methods produce identical layer-wise masks, e.g. Fig 3(a), while others show a wide variance.	weakness
2020-1637	The overlap in lines makes this difficult to assess at times: perhaps a table would communicate it better?	weakness
2020-1637	Also, are Fig 3-4 depicting the Jaccard distance between masks of unpruned or pruned weights?	weakness
2020-1637	Is the ordering of training samples fixed in addition to network initialization?	weakness
2020-1637	Is reinitialization used between iterations?	weakness
2020-1637	Also, Fig 5 seems to contradict the conclusion that methods tend to learn different masks, since the structures are noticeably similar.	weakness
2020-1637	(2) *Weight stability during pruning*: It is difficult to discern a conclusion in Sec 5.	weakness
2020-1637	First, a clarification on the figures: are lines for pruned weights terminated where they are pruned?	suggestion
2020-1637	If so, this would be helpful to state.	suggestion
2020-1637	The 4th paragraph claims, "we empirically find a correlation between weight stability and performance", but this is not at all obvious from Figures 6-7.	weakness
2020-1637	I'm not sure what a more stable evolution looks like.	weakness
2020-1637	Hybrid is shown to be accurate in Fig 1, but the conv.	weakness
2020-1637	weights in 6(a) are a spaghetti tangle and the FC weights in 7(a) are constantly increasing in magnitude.	weakness
2020-1637	Perhaps a mathematical formulation for stability (perhaps based on average standard deviation of each weight's values over training) with a table of values for each method/layer would help to clarify.	suggestion
2020-1637	(3) *Organization*: Since the paper has many intertwined observations, a better organization would be helpful.	weakness
2020-1637	Consider mirroring the structure of Sec 1.1 in a combined Sec. 4-5 with clear paragraph headers summarizing each conclusion.	suggestion
2020-1637	(4) *Presentation*: Figure is too small throughout to read from a printed copy (or even on a screen without significant zooming).	weakness
2020-1637	Several results could be presented with less ambiguity in tabular form, as noted above.	weakness
2020-1637	(5) *Replications*: The paper presents results only a single set of experiments using the MNIST dataset with the LeNet architecture.	weakness
2020-1637	While this isn't a fatal issue, it is a significant weakness.	weakness
2020-1637	*Notes* Fig 1 and 2: What spacing is used for the x- and y- axes?	weakness
2020-1637	Fig 8: Perhaps scale vertically by the standard deviation of the weights?	weakness

2020-1686	The paper proposes an approach for image generation that relies on an autoregressive model for the image pixels.	abstract
2020-1686	These models are popularly used in image coding and compression settings, and have been used in generative models like PixelCNN.	abstract
2020-1686	In contrast to this prior work, the proposed model is based on the selection of a previously available pixel and the modeling of the differences between the old pixel and the new one.	abstract
2020-1686	The copy and adjustment models, i.e., eqs (3) and (5-6), are straightforward.	abstract
2020-1686	Applications to image-to-image translation are also presented.	abstract
2020-1686	I am rating the paper "weak reject" mostly due to the limited set of comparisons in experimental results.	decision
2020-1686	There is no qualitative comparison to other algorithms for two of the problems considered (colorization, super-resolution) and the comparison with other algorithms for unconditional image generation is limited to CIFAR-10; thus, the impact of this contribution is not clear.	weakness
2020-1686	Furthermore there is no discussion of these comparison results - i.e., what the proposed algorithm contributes given that it's outperformed by the sparse transformer.	weakness
2020-1686	It is not clear at first what the authors mean by "sub-pixel", which appears to be one of the color/spectrum channels of a pixel of the image?	weakness
2020-1686	Also not clear what "outcome masking" refers to.	weakness
2020-1686	The explanation of the hidden states (g,h) used for each mechanism are not always clear or explicit.	weakness
2020-1686	For example, can you write an equation for h_{i,c-1} which is more explicit than "composing the history of generated sub-pixels"?	weakness
2020-1686	Can you define Ui when it is first used in (6)?	weakness
2020-1686	What is the difference between the pixel state h_{r,C} and its values x_r?	weakness
2020-1686	Minor comments The second equation in Section 2.3 is missing =	weakness
2020-1686	In Section 5.1, it is not clear what is meant by "discrediting" the image.	weakness
2020-1686	The table in Fig. 3 could use full names for the problems instead of initials.	weakness
2020-1686	In this paper the authors present a new way to use autoregressive modeling to generate images pixel by pixel where each pixel is generated by modeling the difference between the current pixel value and  the preexistent ones.	abstract
2020-1686	In order to achieve that, the authors propose a copy and adjustment mechanism that select an existing pixel, and then adjust its sub-pixel (channel values) to generate the new pixel.	abstract
2020-1686	The proposed model is demonstrated with a suite of experiments in classic image generation benchmark.	abstract
2020-1686	The authors also demonstrate the use of their technique in Image to Image translation.	abstract
2020-1686	Overall, although the paper explain clearly the intuition and the motivation of the proposed technique, I think that the paper in its present state have low novelty, weak related work analysis review and insufficient experiments to support a publication at *CONF*.	decision
2020-1686	**Novelty, contribution and related work**	weakness
2020-1686	The authors should highlight better their main contribution novelty of the proposed method compared to their baseline.	suggestion
2020-1686	**Result and conducted experiments** the correctness of the proposed approach is not proved by the conducted experiment  in fact: The experiments do not provide the details of the used architecture compared to your baseline.	weakness
2020-1686	In Table 1 you report the results using your technique on several computer vision tasks (generation, colorization and super-resolution) but you're not comparing with the SoA of each of these tasks.	weakness
2020-1686	The  results reported in Tables 1 and 2 are not convincing  when compared to existing approaches (using only CIFAR10 in Table2).	weakness
2020-1686	There are so many missing details specially to validate Image-To-image translation	weakness
2020-1686	Figure 3 is confusing and  not clear	weakness
2020-1686	**Minor comments** In  references section : (Kingma & Dhariwal, 2018) is not in a proper format (nips 2018)	weakness
2020-1686	Bad quality of illustrations and images	weakness
2020-1686	Be coherent with the position of captions (figure 3) The paper bases its methodology on well known developments in image analysis/synthesis about similarity of pixel values in adjacent locations.	weakness
2020-1686	Many techniques have been used for modelling this similarity, including predictive models, cliques and graphs.	weakness
2020-1686	The paper uses a simple autoregressive model for generating pixel values based on the values of previously processed pixels, estimating the differences between these neighboring pixel values.	abstract
2020-1686	The method is implemented through copying the pixel values and adjusting the differences.	abstract
2020-1686	Three types of prediction, based on absolute, or relative values are examined, for image generation, colorization, super-resolution.	abstract
2020-1686	The problems are significant, but the approach rather superficial.	weakness
2020-1686	A small experimental study is presented, based on CIFAR-10 and downsampled ImageNet datsaets.	weakness
2020-1686	Much more experiments, including quantitative and qualitative results are reuired, to validate the prospects of the method in different types of (complex) problems and contexts.	weakness
2020-1686	Marginal improvements are observed in the presented results.	weakness
2020-1686	Since image generation and image to image translation are targeted, comparison and/or combined use with Sota methods, i.e., GANs should be examined.	weakness
2020-1686	Moreover, the paper presentation needs improvement; for example, symbols are undefined when used for the first time in the text (see eq.	weakness
2020-1686	3), etc.	weakness

2020-1688	The paper explores a transformer for reinforcement learning.	abstract
2020-1688	The authors demonstrate that Canonical Transformer is unstable.	abstract
2020-1688	The authors introduce two modifications to the Canonical Transformer.	abstract
2020-1688	The first is to move the layer normalization layer to the input stream.	abstract
2020-1688	The second is to replace residual connections with gating layers.	abstract
2020-1688	The experimental results show that (1) the first modification, i.e., moving the layer normalization layer to the input stream significantly stabilizes the training; (2) Gated Recurrent Unit (GRU) gating seems to be most effective gating mechanism.	abstract
2020-1688	My decision is Weak Reject, considering the following aspects.	decision
2020-1688	Positive points: (1) The experiments seem solid.	strength
2020-1688	The authors have evaluated the overall performance, as well as hyperparameters, seeds, and ablations.	strength
2020-1688	(2) Moving the layer normalization layer to the input stream seems to be surprisingly effective.	strength
2020-1688	This could be an interesting finding.	strength
2020-1688	(3) The paper is well organized.	strength
2020-1688	Negative points: (1) Lack of experiments on benchmark and large environments.	weakness
2020-1688	The authors did not evaluate their model on the widely used benchmark Atari-57.	weakness
2020-1688	Also, it is unclear whether the proposed transformer can scale to large environments.	weakness
2020-1688	(2) Lack of understanding of the layer normalization.	weakness
2020-1688	The authors provide some explanations about why the reordering works, but they seem not intuitive.	rebuttal_process
2020-1688	More analysis about why the reordering works would significantly enhance this paper.	rebuttal_process
2020-1688	Specific questions: (1) Have you tried simply removing the layer normalization layer?	rebuttal_process
2020-1688	(2) TrXL-I moves two layer-normalization layers together.	rebuttal_process
2020-1688	Have you tried only moving one of them?	suggestion
2020-1688	Which modification contributes more? (3) Could you provide more explanations about why the modification of the layer normalization layer works?	suggestion
2020-1688	(4) Have you experimentally validated the proposed hypothesis as to why the Identity Map Reordering, such as recording the evolution of the produced values in the submodules?	suggestion
2020-1688	This paper is motivated by the unstable performance of Transformer in reinforcement learning, and tried several variants of Transformer to see whether some of them can stabilize the Transformer.	abstract
2020-1688	The experimental results look good, however, I have problems in understanding the motivation, the intuition of the proposed methods, the experimental design, and the general implication to the research community that is using the Transformer in their day-to-day research.	weakness
2020-1688	First, the paper was based on the hypothesis of the authors that the Transformer is not stable, however, there is no comprehensive study on the unstability, and deep understanding on the root cause of it.	weakness
2020-1688	It would be much more convincing to give a form definition of unstability and to add experimental study and theoretical analysis to the motivation part, instead of just based on a hypothesis.	suggestion
2020-1688	Second, the proposal of the new structures (e.g., reordering the layer normalization, adding the gating layer) are quite ad hoc.	weakness
2020-1688	There is not very solid motivation and theoretical analysis on why they could solve the unstable problem of the Transformer.	weakness
2020-1688	For example, by changing the order of layer normalization, there are direct identity mapping from the first layer to the last layer, making the information flow smoother.	weakness
2020-1688	However, why this will make the Transformer more stable?	weakness
2020-1688	The hypothesis and intuitive analysis are not very convincing.	weakness
2020-1688	For another example, why replacing the residual connection with the gating layer can make the Transformer more stable?	weakness
2020-1688	It seems to me that these are mostly heuristics, but not verified or strongly motivated solutions.	weakness
2020-1688	Third, if the proposal is sound, it should not be effective only for reinforcement learning.	weakness
2020-1688	It should be able to improve the performance or stability of the Transformer in general (e.g., in NLP tasks).	weakness
2020-1688	However, there is no experiments and discussions regarding this.	weakness
2020-1688	Fourth, the experiments on the reinforcement learning is a little narrow, and many famous RL benchmarks and environments were not tested.	weakness
2020-1688	This makes it unclear whether the proposed approach is generally effective.	weakness
2020-1688	**I read the author responses, however, they do not really change my assessment on the paper.	rebuttal_process
2020-1688	* Summary This paper introduces architecture modifications for self-attention to stabilize transformers in reinforcement learning.	abstract
2020-1688	The new architecture, Gated Transformer-XL, replaces the order of the layer norm blocks to preserve an identity mapping.	abstract
2020-1688	Multiple existing gating layers are proposed to replace the residual connections of transformer.	abstract
2020-1688	The new architecture is compared against MERLIN and LSTM on DMlab-30, and further ablation studies are done on Numpad and Memory Maze.	abstract
2020-1688	It is noted that they use the recent V-MPO objective to train LSTM and transformer.	abstract
2020-1688	Their results show that transformers are able to learn in memory-intensive environments, with some gating combinations surpassing LSTM.	abstract
2020-1688	* Decision This paper presents promising empirical results, however the experiments are limited, making it difficult to place in the broader work.	weakness
2020-1688	In addition, the contribution is incremental and not well-motivated.	weakness
2020-1688	I would recommend a weak rejection.	decision
2020-1688	Still, I think the paper is well written and could be improved upon.	weakness
2020-1688	* Reasons While the empirical results are impressive, they are not put into context.	weakness
2020-1688	DMlab-30 is still a relatively new environment suite and it is difficult to place the result of this paper in the context of broader work.	weakness
2020-1688	In addition, the comparison is against LSTM on a new objective.	weakness
2020-1688	While Transformer is able to beat LSTM on the same objective, it is unclear whether that is a success of the objective or the architecture.	weakness
2020-1688	In Numpad, the transformer architecture shows an improvement over LSTM, but no comparisons are made to any other memory-based agents.	weakness
2020-1688	The hyperparameter studies on Memory Maze also show improvements in memory-related tasks, but do not help in understanding of the proposed work.	weakness
2020-1688	The choice of architecture modification is also not well motivated.	weakness
2020-1688	As the paper mentions, initializing near identity has been shown to be important in the supervised learning literature.	weakness
2020-1688	For the topic of this paper however, I do not think this adequetly explains the instability of transformers in reinforcement learning.	weakness
2020-1688	In the related work section for example, the paper notes that gating mechanisms have been used to handle the vanishing gradients problem.	weakness
2020-1688	The paper also notes that vanishing gradients is not an issue in transformers.	weakness
2020-1688	Hence, it is unclear why gating would stabilize transformers for reinforcement learning.	weakness
2020-1688	The paper is overall well written and the ideas developed are clear.	strength
2020-1688	Unfortunately, the impressive results on DMlab are not sufficient for both the lack of deeper empirical study and better theoretical motivation for the architecture modifications.	weakness

2020-1720	This paper presents a modification to policy gradient methods that are computed from advantage function estimates.	abstract
2020-1720	For a given trajectory of n steps, there are n different advantage function estimates: from 1-step to n-step.	abstract
2020-1720	GAE (Schulman, 2016) proposes to take an exponentially weighted average of these estimates to compute the policy gradients.	abstract
2020-1720	This paper proposes instead to use order statistics to compute the policy gradient; e.g. the most optimistic estimate, the most pessimistic estimate, or the most extreme estimate.	abstract
2020-1720	The paper introduces a regulatory ratio: the probability of using the averaged advantage estimate vs using the order statistic, for computing the policy gradients.	abstract
2020-1720	This hyper-parameter is justified on the optimistic case (max advantage), as a way to prevent overtly optimistic estimates.	abstract
2020-1720	The paper conducts experiments on  different domains (sparse and dense rewards, discrete and continuous actions, fully observable and partially observable environments) which show the effect of choosing different order statistics and regulatory ratio on the policy performance.	abstract
2020-1720	This paper could be accepted as it presents an interesting idea with extensive experiments showing where it works and where it fails, along with some justification for the hyperparameter choices.	decision
2020-1720	But there are a couple concerns about the validity of the method.	weakness
2020-1720	One concern is that the regulatory ratio is only justified for the max case, but not for the min or max-abs case.	weakness
2020-1720	In addition, the choice of regulatory ratio seems to have a wildly varying impact depending on the choice of the order statistic and environment, for which we get little insights from the paper.	weakness
2020-1720	Another concern is that most of the results are reported only for an ensemble of 4 n-step estimators.	weakness
2020-1720	In the appendix, the papers reports a comparison with a larger ensemble (12 n-steps estimators), which results in lower performance.	weakness
2020-1720	This is a bit confusing: using the order statistics (max, min and max-abs), and following the reasoning presented in the paper, I would expect that increasing the ensemble size would result in better performance ( the max/min of the 4 ensemble is n upper/lower bound of the max/min of the 12 ensemble).	weakness
2020-1720	This paper could be improved with more detailed results on the effect of the ensemble size.	weakness
2020-1720	While the paper provides arguments for why small ensembles might suffice, it does not explain how the ensemble should be chosen, and what would happen as the ensemble size increases.	weakness
2020-1720	Finally, the parallels to human psychology are  bit superfluous.	weakness
2020-1720	I understand how it might serve as an inspiration for algorithm design, but it is a bit distracting from the technical contribution of the paper.	weakness
2020-1720	Things to improve: Why is max-abs missing from Figure 2?	weakness
2020-1720	Did you try a Rainbow-style training (changing the regulatory focus periodically over training)?	weakness
2020-1720	In some sentences, it looks as if insure was written in place of ensure.	weakness
2020-1720	In general, this paper would benefit from proof reading by a proficient English speaker.	suggestion
2020-1720	This paper focuses on risk-aware reinforcement learning, where an agent could be encouraged to take more risk (high reward, high variance states) or avoid risk (low variance states).	abstract
2020-1720	Risk control is instantiated by different ways of estimating the advantage of a state (max/min instead of average).	abstract
2020-1720	Experiments on several environments show good performance of the proposed algorithm.	abstract
2020-1720	The paper is written clearly and the approach is straightforward.	strength
2020-1720	However, it's unclear what is the objective function the algorithm is optimizing by using a biased estimation of the advantage.	weakness
2020-1720	It seems to work pretty well in practice, but I wonder how it compares to other risk-sensitive RL algorithms (e.g. those cited in the related work section).	weakness
2020-1720	Overall, this paper presents a simple heuristic to steer the policy towards risk-seeking / risk-avoiding directions, but could benefit from either more theoretical analysis or more empirical comparison with other methods.	weakness
2020-1720	The paper studies the problem of advantage estimation for actor-critic RL algorithms.	abstract
2020-1720	The key observation is that the advantage can be computed using 1-step returns, 2-step returns, etc.	abstract
2020-1720	The paper suggests that, instead of choosing a fixed n, we should aggregate these advantageous together.	abstract
2020-1720	If the maximum is taken, the resulting policy will be exploratory (i.e., have a "promotion focus"); if the minimum advantage is taken, the resulting policy will be risk sensitive (i.e., have a "regulatory focus").	abstract
2020-1720	The paper presents results on a number of tasks.	abstract
2020-1720	A few toy examples show instances where the proposed method works better.	abstract
2020-1720	Experiments on sparse reward environments show that taking the max advantage provides for exploration that outperforms a baseline (EX2).	abstract
2020-1720	On a walking talk show that the min-approach can outperform state-of-the-art on-policy RL (PPO); the paper suggests this is because the min-approach is implicitly risk sensitive.	abstract
2020-1720	Experiments on some of the Mujoco control tasks and some of the Atari games show that taking the advantage with the maximum absolute value performs well, as compared to PPO.	abstract
2020-1720	Overall, I think the main contribution of this paper is the finding that there exist smarter ways of computing the advantage.	strength
2020-1720	A second contribution is connecting the ideas of risk-sensitive and risk-seeking control with ideas from psychology (regulatory fit theory).	strength
2020-1720	I am leaning towards rejecting this paper.	decision
2020-1720	On the one hand, the paper is well written, well motivated, and the experiments quite thorough.	strength
2020-1720	On the other hand, I don't think the paper is particularly useful, either from a theory or algorithmic perspective.	weakness
2020-1720	It is not surprising that if we add an additional hyperparater to an existing RL algorithm and tune that hyperparameter, we'll do better than the existing RL algorithm.	weakness
2020-1720	The ablation experiments in Fig 6 and Fig 7 suggest that how the advantage estimates are combined, and how they are "mixed" with a standard advantage estimate, matter a lot.	weakness
2020-1720	Further, the fact that using a smaller number of advantage estimates worked better (point #2 on pg 5, Effect of Ensemble Size in Appendix A) suggests that the ensemble size is an important hyperparameter, and that risk-seeking / risk-aversion (i.e., regulatory vs promotion focus) cannot alone explain why the proposed method works.	weakness
2020-1720	I think that, for this idea to be useful, it must be equipped with a fixed value for these hyperparameters that works well across a wide range of tasks (e.g., a learning rate of 3e-4 works well for Adam on most tasks), or an automated strategy for choosing this hyperparameter (e.g., the automatic entropy tuning in SAC).	suggestion
2020-1720	I would consider increasing my review if either of these were included.	suggestion
2020-1720	A second concern is that, despite the close connections with risk-sensitive and risk-seeking control (discussed in Section 2), none of these prior works are compared against.	weakness
2020-1720	Many of these prior works include a temperature parameter for trading off risk-seeking vs risk-aversion (e.g., \\beta in Eq 11 of [Mihatsch 2002]), which is arguably a more transparent (to the user) and easier to analyze (for the RL researcher) than the order statistics used in this paper.	strength
2020-1720	Given the wealth of prior work on risk-sensitive and risk-seeking control, I think it's important to know whether these prior methods already solve the problem at hand (choosing between risk-seeking and risk-aversion).	weakness
2020-1720	I would consider increasing my review if one of these methods were included as a baseline.	suggestion
2020-1720	Minor comments * "that humans own" -> "that humans' own"	suggestion
2020-1720	* The max strategy seems quite closely related to UCB-based exploration.	weakness
2020-1720	I'd be curious to learn about some discussion on the similarities/differences	weakness
2020-1720	* Fig 6 -- Can you add error bars to show the variance across random seeds?	weakness
2020-1720	* Appendix D -- How does this approach and the results shown in Fig 9 differ from standard GAE?	weakness
2020-1720	----------------------- UPDATE AFTER (NO) AUTHOR RESPONSE ----------------------------	misc
2020-1720	The authors did not post a response, so I will maintain my vote to "weak reject" this paper.	rebuttal_process
2020-1720	I would encourage the authors to incorporate the feedback in all reviews and submit the paper to a future conference.	decision

2020-1730	The paper proposes a framework for learning with rejection using ideas from adversarial examples.	abstract
2020-1730	The essential idea is, while predicting on a point x, we can reject classifying the point if it has an adversarial example very close to it.	abstract
2020-1730	So, the algorithm can be simply summarized as,	abstract
2020-1730	1. Learn a classifier function f	abstract
2020-1730	2. On the test set, predict on a point, only if it doesn't have an adversarial example close by.	abstract
2020-1730	I am inclined to reject the paper for the following reasons: 1. The proposed approach is a variation of a fairly well-known heuristic.	weakness
2020-1730	Having a close adversarial example is same as saying that the current point is very close to the decision boundary.	weakness
2020-1730	Being close to the decision boundary is a heuristic that has been applied in multiple scenarios in machine learning.	weakness
2020-1730	2. The proposed approach is not novel.	weakness
2020-1730	For example, [1] uses adversarial example style detection to augment their training data and improve their end-to-end model.	suggestion
2020-1730	3. There have been approaches which attempt to learn rejection function [2], so it would have been good to at least do a comparison of the proposed approach with such methods.	suggestion
2020-1730	[1] Adversarial Examples For Improving End-to-End Attention-based Small-Footprint Keyword Spotting, ICASSP 2019	misc
2020-1730	[2] SelectiveNet: A Deep Neural Network with an Integrated Reject Option, ICML 2019	misc
2020-1730	--- Thanks for the rebuttal. I have raised my scores, but I still believe that this paper falls short of acceptance.	decision
2020-1730	This paper wants to study the problem of "learning with rejection under adversarial attacks".	abstract
2020-1730	It first naively extends the learning with rejection framework for handling adversarial examples.	abstract
2020-1730	It then considers the classical cost-sensitive learning by transfer the multi-class problem into binary classification problem through one-vs-all and using the technique they proposed to reject predictions on non-important labels, and name such technique as "learning with protection".	abstract
2020-1730	Finally, they do some experimental studies.	abstract
2020-1730	The paper does not show any connection between "learning with rejection" and "adversarial learning".	abstract
2020-1730	The method it proposes is also a naïve extension of existing methods.	abstract
2020-1730	Both the problem setting and the technique does not have novelty.	weakness
2020-1730	The paper fails to realize that the motivated application is actually called "cost-sensitive learning" and has been studied long time before.	weakness
2020-1730	The paper also has problems in writing.	weakness
2020-1730	Finally, there is no comparison with any baseline.	weakness
2020-1730	Only empirical results of the proposed methods are shown.	weakness
2020-1730	Due to all these reasons, there is still a long way to go before the paper can be published.	decision
2020-1730	I will rate it a clear rejection.	decision
2020-1730	More specially, The definition of "suspicious example" in Sec.3.1 has no relationship with adversary examples.	weakness
2020-1730	Does the paper focus on adversary examples?	weakness
2020-1730	If the definition has no relationship, it is classical learning with rejection.	decision
2020-1730	In the last equation of Page 3, there is no definition of \\tilde L.	weakness
2020-1730	Actually, according to Figure 1, x's is more close to the decision boundary, it is an example more hard to classify, which could also be "suspicious".	weakness
2020-1730	In the definition of "suspicious example" at the beginning of Sec.3.1, is both x and x' defined as suspicious examples in this way?	weakness
2020-1730	In the last equation of page 2, there is a rejection function, so minimizing this loss is a "separation-based approach".	weakness
2020-1730	However, at the end of Sec.2 the paper states they "follow a confidence-based approach".	weakness
2020-1730	Any comment on the inconsistency?	weakness
2020-1730	The motivated problem is not new.	weakness
2020-1730	It is called cost-sensitive learning in machine learning and can date back to 2001: Charles Elkan.	weakness
2020-1730	The Foundations of Cost-Sensitive Learning.	misc
2020-1730	IJCAI 2001: 973-978. Where they study the same problem when misclassifying one class of data may cost a lot than misclassifying another class of data.	misc
2020-1730	The current paper has not discussed any related work of cost-sensitive learning although they want to study a problem in its field.	weakness
2020-1730	The paper should be also improved in writing in the following aspects.	weakness
2020-1730	There is a lot of inaccurate statements in the paper.	weakness
2020-1730	For example,  "In Sections 3 and 4, we propose and describe our algorithm", what is the difference between propose and describe?	weakness
2020-1730	"an estimator \\hat h might return result that differ greatly from h^* in a case with finite samples".	weakness
2020-1730	Actually there are rigorous theoretical results describing how the number of finite samples will impact the estimator \\hat h on unseen data.	weakness
2020-1730	For example, Peter L. Bartlett, Shahar Mendelson.	weakness
2020-1730	Rademacher and Gaussian Complexities: Risk Bounds and Structural Results.	misc
2020-1730	JMLR, 2002. So inaccurate/unclear statements that will mislead readers should be avoided.	suggestion
2020-1730	In writing, the paper also lacks the necessary references in many places.	weakness
2020-1730	For example, "Learning with rejection is a classification scenario where the learner is given the option to reject an instance instead of predicting its label.", "…classifies adversary attacks to two types of attacks, white-box attack and black-box attack.", "Methods for protecting against these adversarial examples are also being proposed.".	weakness
2020-1730	Necessary references are needed for these places.	misc
2020-1730	The organization is also problematic.	weakness
2020-1730	For example, in the second half of Sec.2 introducing two kinds of learning with rejection models, it should be included in a "related work" part.	suggestion
2020-1730	------------------------------------------ Thank you for the rebuttal.	misc
2020-1730	I raised my score a little bit.	rebuttal_process
2020-1730	But I still think this paper has not been ready to be published yet.	decision
2020-1730	There is still no universal method to deal with adversarial examples, and introducing a reject option to flag potential attacks seems a sensitive choice for many applications.	weakness
2020-1730	The considered problem is well-motivated and introduced, and I'm unaware of prior work studying classification with reject option in the context of adversarial examples.	strength
2020-1730	However, I think there are different dimensions along which the paper could be improved: - My understanding of classification with a reject option is that the rejection cost c(x) is a design choice that can depend on the specific application.	weakness
2020-1730	While c(x) is introduced as part of the framework it is then derived in a very specific way, removing the design aspect or at least not explaining very clearly how one would design it.	weakness
2020-1730	Also, Algorithm 1 doesn't have corresponding parameters.	weakness
2020-1730	- The rejection function r(x) relies on z^* which essentially amounts to computing an adversarial perturbation for a given testing point, see (2).	weakness
2020-1730	The authors state that they use a 30-step of the PGD algorithm to find z^*.	weakness
2020-1730	The attacks on which the method is tested only uses 10 PGD steps.	weakness
2020-1730	What if the attacker is stronger in the sense that it runs significantly more PGD iterations than used to compute the rejection function?	weakness
2020-1730	How sensitive is the rejection function to different initializations?	weakness
2020-1730	- Similarly, what happens if the attacker and the rejection function rely on different norms to compute the attack and the rejection score, respectively?	weakness
2020-1730	I think it is important to investigate this aspect.	weakness
2020-1730	- In Tables 1 and 2, I don't understand why the precision is the same for all rows corresponding to the same attack (strength), while the other metrics vary.	weakness
2020-1730	Overall, I think the paper explores an interesting direction, but would greatly benefit from a revision along the lines outlined above.	suggestion
2020-1730	Minor comments: - P3 3.1 2nd paragraph: "Let B^p..." rather than "Let B^\\infty..."	weakness
2020-1730	- P4 bottom: ")" is missing before "..., where"	weakness
2020-1730	- P6 bottom: (FR) should be (TR).	weakness
2020-1730	The acronyms FA and FR don't seem to be introduced.	weakness
2020-1730	### Reply to rebuttal: I thank the reviewers for their detailed reply.	misc
2020-1730	It seems that the authors agree that some of the issues I raised should be addressed and improved.	rebuttal_process
2020-1730	My assessment that the paper should be revised (and accordingly the rating) therefore remains unchanged.	rebuttal_process

2020-1772	============ comments after rebuttal I would like to thank the authors for addressing some of my concerns.	rebuttal_process
2020-1772	I believe the new results under Q2 and Q3 are useful additions to strengthen the paper.	rebuttal_process
2020-1772	As for the authors' comments for Q1, I'd like to point out that a "larger" search space is not necessarily more difficult (a more meaningful metric would be the average accuracy of random architectures).	rebuttal_process
2020-1772	It is still possible that the current search space is putting the proposed method at advantage, especially if having dense connections is a useful prior.	rebuttal_process
2020-1772	Given the above, I would like to increase my score from 1 to 3 (weak reject).	rating_summary
2020-1772	============ previous comments Neural architecture search can be formulated as learning a distribution of promising architectures (the sampling policy).	rebuttal_process
2020-1772	Such a distribution is usually represented in a fully factorized fashion (e.g., as a set of multinational distributions as in DARTS).	rebuttal_process
2020-1772	This paper proposes to model the architecture distribution using a VAE instead, where the encoder and decoder are implemented using LSTMs.	abstract
2020-1772	The authors argue that the increased flexibility of the sampling policy leads to improved performance on CIFAR-10, NASBench and ImageNet.	abstract
2020-1772	The idea of representing the architecture distribution using VAEs is very natural, which in principle could offer better coverage over interesting regions in the search space as compared to traditional factorized distribution representation (which has a single mode only).	strength
2020-1772	While the method itself is interesting, I do not think it has been properly backed up by controlled experiments.	strength
2020-1772	This is largely due to the fact that the authors are comparing their method against baselines in fundamentally different search spaces.	strength
2020-1772	For instance: * For CIFAR-10 experiments, the authors mentioned in the appendix: "Different from DARTS, in our search space, one node could have more than two predecessors in one cell".	weakness
2020-1772	This makes the search space very different from the existing ones as used by NASNet/AmoebaNet/DARTS/SNAS, and it hence remains unclear to what degree the resulting architecture has benefited from the increased in-degrees per node.	weakness
2020-1772	Note the searched densely connected cells in Figure 4 & 5 in Appendix A.4 are clearly not part of the search space for many of the baselines.	weakness
2020-1772	* For ImageNet experiments, the authors are using a ShuffleNet-like search space which has fundamentally different building blocks than other architecture search baselines (commonly built on top of inverted bottleneck layers).	weakness
2020-1772	It is unclear to what degree the 77.4 top-1 accuracy @ 365 MFlops results have benefited from this different search space.	weakness
2020-1772	Without fair comparisons in a controlled setup, it is impossible for readers to draw any solid conclusion about the true empirical advantages of the method.	weakness
2020-1772	I'm therefore unable to recommend acceptance for the paper at the moment, but am willing to raise my score if the authors can properly address those issues in the rebuttal.	decision
2020-1772	Additional question: How can we isolate it to tell whether the gains come from the LSTMs or the VAEs?	suggestion
2020-1772	Is there any intuition why incorporating a generative sampler based on VAEs is potentially superior to method like ENAS (which involves LSTMs decoders only)?	rebuttal_process
2020-1772	This paper proposed to use VAE to learn a sampling strategy in neural architecture search.	abstract
2020-1772	The main idea is to use the currently high-performing networks to train a VAE from which the sampled architectures for the next iteration will likely supply both high-performing networks and better diversity coverage.	abstract
2020-1772	The experiments are extensive, including results under various settings.	abstract
2020-1772	The idea is straightforward and reasonable.	strength
2020-1772	I do not work on neural architecture search myself, so I'm not sure how significant the experimental results are.	strength
2020-1772	Would the 0.1% (1.1%) absolute improvement over the second best in Table 2 (Table 3) be considered significant enough to justify the effectiveness of the proposed approach?	weakness
2020-1772	I'm a little concerned about the fairness of the comparison experiments.	weakness
2020-1772	A fairly heavy computation overhead is required to train the VAE models in the proposed method.	weakness
2020-1772	Instead of taking this overhead, wouldn't it be easier to randomly sample more architectures?	weakness
2020-1772	Intuitively, if we spend the cost of training a VAE model instead on sampling more architectures, the end  effects could be the same.	weakness
2020-1772	Are the numbers in Table 2 and Table 3 swapped?	weakness
2020-1772	This paper proposes to use the variational auto-encoder (VAE) to sample the network architectures.	abstract
2020-1772	The VAE is applied to both one-short and gradient descent scenarios, and shows consistent improvement on different NAS tasks.	abstract
2020-1772	The proposed method is reasonable, but I have two major concerns: - I wonder whether the VAE based approach will consistently converge to a good local minimum.	weakness
2020-1772	It will be very helpful if the authors could provide robust analysis or at least the variations of testing errors.	suggestion
2020-1772	- I understand the motivation of VAE + one shot, but I am not very convinced by VAE + gradient-based.	weakness
2020-1772	In the last paragraph in Section 4, the paper claims (1) VAENAS-G can increase the diversity of architectures, which can be also achieved by sampling the data set.	suggestion
2020-1772	Also, it claims (2) VAENAS-G helps to search for large models, which  I do not see experimental supports.	weakness
2020-1772	Detailed comments: - Algorithm 1: it is confusing to use S_K and S_k without explanation	weakness
2020-1772	- Table 1: most of the other methods provide test error with standard variations.	weakness
2020-1772	To be fair, I'd see VAENAS's test error variation.	weakness
2020-1772	- Tables 2 and 3: Why is VAENASNet (table 3) different from VAENAS-G and VAENAS-OS?	weakness

2020-1804	The paper proposed an interesting continual learning approach for sequential data processing with recurrent neural network architecture.	abstract
2020-1804	The authors provide a general application on sequential data for continual learning, and show their proposed model outperforms baseline.	abstract
2020-1804	It is natural that their naive baseline shows poor performance since they do not consider any continual learning issues like the catastrophic forgetting problem.	abstract
2020-1804	Then, I hesitate to evaluate the model in terms of performance.	abstract
2020-1804	In that sense, it would be much crucial to show more meaningful ablation studies and analysis for proposed model.	weakness
2020-1804	However, there is a few of thing about them.	misc
2020-1804	Then, I decide to give a lower score that even the authors suggest that the main contribution is a definition of problem setting.	ac_disagreement
2020-1804	It requires more detailed and sophisticated analysis.	weakness
2020-1804	The goal of this work is to best understand the performance and benchmarking of continual learning algorithms when applied to sequential data processing problems like language or sequence data sets.	abstract
2020-1804	The contributions of the paper are 3 fold - new benchmarks for CL with sequential data for RNN processing, new architecture introduced for more effective processing and a thorough empirical evaluation.	strength
2020-1804	Introduction: I think a little more insight into why the sequential data processing CL scenario is any different than the vision scenario would be quite helpful.	suggestion
2020-1804	Specifically, it would be quite impactful to tell us more about what the additional challenges with RNNs for CL vs feedforward for CL are in the intro.	suggestion
2020-1804	The paper is written as if the benchmark is the main contribution and the architecture improvement is just a delta on top of this, but it gets confusing when the methods section starts off with just directly stating the new architecture.	weakness
2020-1804	The algorithm seems like a straightforward combination of recurrent progressive nets and gated autoencoders for CL.	weakness
2020-1804	Can the authors provide more justification if that is the contribution or there is more to the insight than has been previously suggested in prior work?	weakness
2020-1804	Figure 1 has a very uninformative caption.	weakness
2020-1804	It also doesn't show how modules feed into one another properly.	weakness
2020-1804	The motivation for why one needs GIM after one already has A-LSTM or A-LMN is not very clear?	weakness
2020-1804	Overall the contribution does seem a bit incremental based on prior work and the description lacks enough detail to properly indicate why this is a very important contribution?	weakness
2020-1804	Experiments: What does it mean to be application agnostic but restricted to particular datasets and losses?	weakness
2020-1804	This doesn't quite parse to me.	weakness
2020-1804	The description of the tasks is very informal and hard to follow.	weakness
2020-1804	It's not clear what exactly the tasks and datasets look like	weakness
2020-1804	"using morehidden units can bridge this gap" -> why not just do it?	weakness
2020-1804	Its a benchmark after all.	weakness
2020-1804	Overall the task descriptions should be in a separate section where the setup is described in a lot of detail and motivated properly.	weakness
2020-1804	The results in the experiments section are very hard to parse.	weakness
2020-1804	The captions need much more detail for eg Table 2.	weakness
2020-1804	Could we also possibly have more baselines from continual learning?	weakness
2020-1804	For instance EWC (Kirkpatrick) or generative replay might be competitive baselines.	weakness
2020-1804	Overall I think that the GIM and A-LMN and A-LSTM methods are reasonable although somewhat incremental.	strength
2020-1804	But the proposed benchmarks are pretty unclear and the results are a bit hard to really interpret well.	weakness
2020-1804	It would also be important to run comparisons with more baselines and to provide more ablation/analysis experiments to really see the benefit of GIM/A-LMN or A-LSTM.	suggestion
2020-1804	I also think that the task descriptions should be much earlier in the paper and desribed in much more rigorous detail.	suggestion
2020-1804	Summary: In this paper, the authors propose a new method to apply continual learning on sequential data.	abstract
2020-1804	The model is constructed by combining an Autoencoder and LSTM/LMN for each task.	abstract
2020-1804	The experiments on several datasets show the proposed model outperforms basic LSTM/LMN.	abstract
2020-1804	Strength: + Sequential data widely exist in the real world, e.g., text, health records.	strength
2020-1804	Thus, It is interesting to see that continual learning is used in sequential data.	strength
2020-1804	+ The motivation of the proposed model is clear.	strength
2020-1804	The authors save the learned knowledge in the hidden representation of LSTM/LMN.	strength
2020-1804	Weakness: - In this paper, the model size linearly increases since the number of LSTM/LMN and AE increases when a new task comes in.	weakness
2020-1804	Thus, if the number of tasks is too large, the model size is quite big.	weakness
2020-1804	In traditional continual learning settings, researchers may not always increase the model size for overcoming catastrophic forgetting.	weakness
2020-1804	For example, if task 1 and task 2 sample from the same distribution, they can share the same LSTM/LMN and AE.	weakness
2020-1804	Thus, it would be better if the authors can consider how to reduce the model size in the future version.	weakness
2020-1804	- In the experiments, the authors only compare the proposed model with simple LSTM or LMN.	weakness
2020-1804	However, most continual learning methods can still be applied in this scenario, at least regularization based methods [1,2] can be simply applied in this scenario.	weakness
2020-1804	The authors may need to compare the proposed method with them in the future version.	suggestion
2020-1804	- It is better to compare it with a larger dataset.	weakness
2020-1804	For example, in the natural language processing field, we can regard sentiment analysis on one language as one task.	weakness
2020-1804	Then, we can construct the continual learning dataset for sentiment analysis.	suggestion
2020-1804	Minor Comments: It is better to improve Figure 3 by adding the x-axis label and y-axis label.	suggestion
2020-1804	[1] Kirkpatrick, James, et al. "Overcoming catastrophic forgetting in neural networks." Proceedings of the national academy of sciences 114.13 (2017): 3521-3526.	misc
2020-1804	[2] Zenke, Friedemann, Ben Poole, and Surya Ganguli.	misc
2020-1804	"Continual learning through synaptic intelligence." Proceedings of the 34th International Conference on Machine Learning-Volume 70.	misc
2020-1804	JMLR. org, 2017.	misc

2020-1810	This paper proposes a black box adversarial attacks to deep neural networks.	abstract
2020-1810	The proposed approaches consist of tiling technique proposed by Ilyas et al (2018) and derivative free approaches.	abstract
2020-1810	The proposed approaches have been applied to targeted and untargeted adversarial attacks against modern neural network architectures such as VGG16, ResNet50, and InceptionV3 trained on ImageNet and CIFAR10 datasets.	abstract
2020-1810	Experimental results show higher attack success rate with a smaller number of queries.	abstract
2020-1810	The experimental results look quite promising, i.e., revealing the vulnerability of the deep neural network against black-box adversarial attacks.	strength
2020-1810	A possible weakness in the experimental design is that the authors haven't apply any defense methodology to the classification models to be attacked.	weakness
2020-1810	Yet the results are promising.	strength
2020-1810	From the viewpoint of technical soundness, the approach is a simple combination of the existing approaches.	strength
2020-1810	The tiling technique is used in Ilyas et al (2018) combined with a bandit approach.	strength
2020-1810	The current paper simply replaces the bandit with evolution strategies.	strength
2020-1810	The introduction of the evolution strategies is motivated by their good performance as a zeroth order optimization algorithm.	strength
2020-1810	A small novelty appears in a way to handle a bounded search space.	strength
2020-1810	The authors claim that many DFO algorithms are designed for unbounded real search space and need some constraint handling.	strength
2020-1810	The authors proposed two ways of transforming the bounded search space to the unbounded real search space.	strength
2020-1810	However, there must be existing approaches for this type fo constraint (rectangle constraint) in DFO settings.	abstract
2020-1810	I can not list such approaches here as there are huge number of papers addressing the constraint of this type.	abstract
2020-1810	There is not enough discussion in the paper why these two proposed approaches are promising.	weakness
2020-1810	Formulation (2) makes the problem ill-posed and technically the optimal point may not exist.	weakness
2020-1810	Formulation (3) with softmax representation makes the optimization problem noisy, hence it may annoy the optimizer.	weakness
2020-1810	Nonetheless, I believe the combination of these constraint handling technique and evolutionary approaches are not new.	weakness
2020-1810	Some minor comments / questions below: P5: How are the original images to be attacked selected for Fig 2?	weakness
2020-1810	P6:  "we highlight that neural neural networks are not robust to l∞ tiled random noise.	weakness
2020-1810	" Isn't it the contribution of (Ilyas et al., 2018b)?	weakness
2020-1810	P7: What are the number of queries in Figure 3 and Table 1?	weakness
2020-1810	Are they the number of queries spent until these algorithms found an adversarial example which is categorized to a wrong class for the first time?	weakness
2020-1810	This paper proposed a DFO framework to generate black-box adversarial examples.	abstract
2020-1810	By comparing with Parsimonious and Bandits, the proposed approach achieves lower query complexity and higher attack success rate (ASR).	abstract
2020-1810	I have two main concerns about the current version: 1)  Some important baselines might be missing.	weakness
2020-1810	In addition to (Ilyas et al., 2018b) and (Moon et al., 2019), the methods built on zeroth-order optimization (namely, gradient estimation via function differences) were not compared.	weakness
2020-1810	Examples include [1] There are No Bit Parts for Sign Bits in Black-Box Attacks	suggestion
2020-1810	[2] AutoZOOM: Autoencoder-based Zeroth Order Optimization Method for Attacking Black-box Neural Networks	misc
2020-1810	[3] SIGNSGD VIA ZEROTH-ORDER ORACLE	misc
2020-1810	2) In addition to attack success rate and query complexity, it might be useful to compare different attacks in terms of ℓp distortion, where p≠∞.	suggestion
2020-1810	This could provide a clearer picture on whether or not the query efficiency and the attack performance are at the cost of increasing the ℓ1 and ℓ2 distortion significantly.	suggestion
2020-1810	########### Post-feedback ############## Thanks for the response and the additional experiments to address my first question.	misc
2020-1810	However, I am not satisfied with the response "But clearly our methods aim to reach the boundary of linf ball, so the distortion might be large" to the second question.	rebuttal_process
2020-1810	I am Okay with the design of ℓ∞ attack.	strength
2020-1810	However, if the reduction in query complexity is at a large cost of perturbation power, e.g., measured by ℓ2 norm, then it is better to demonstrate this tradeoff.	weakness
2020-1810	Furthermore, if the ℓ2 norm is constrained, will the proposed ℓ∞ attack outperform the others?	weakness
2020-1810	This is also not clear to me.	weakness
2020-1810	Thus, I decide to keep my score.	weakness
2020-1810	This paper proposed a new query efficient black-box attack algorithm using better evolution strategies.	abstract
2020-1810	The authors also add tiling trick to make the attack even more efficient.	abstract
2020-1810	The experimental results show that the proposed method achieves state-of-the-art attack efficiency in black-box setting.	abstract
2020-1810	The paper indeed presented slightly better results than the current state-of-the-art black-box attacks.	abstract
2020-1810	It is clearly written and easy to follow, however, the paper itself does not bring much insightful information.	weakness
2020-1810	The major components of the proposed method are two things: using better evolution strategies and using tiling trick.	weakness
2020-1810	The tiling trick is not something new, it is introduced in (Ilyas et al., 2018) and also discussed in (Moon et al., 2019).	weakness
2020-1810	The authors further empirically studied the best choice of tiling size.	weakness
2020-1810	I appreciated that, but will not count it as a major contribution.	weakness
2020-1810	In terms of better evolution strategies, the authors show that (1+1) and CMA-EA can achieve better attack result but it lacks intuition/explanations why these helps, what is the difference.	weakness
2020-1810	It would be best if the authors could provide some theories to show the advantages of the proposed method, if not, at least the authors should give more intuition/explanation/demonstrative experiments to show the advantages.	weakness
2020-1810	Detailed comments: - In section 3.2, is the form of the discretized problem a standard way to transform from continuous to discrete one?	weakness
2020-1810	What is the intuition of using a and b?	weakness
2020-1810	Have you considered using only one variable to do it?	weakness
2020-1810	- In section 3.3.2 what do you mean by "with or without softmax, the optimum is at infinity"?	weakness
2020-1810	I hope the authors could further explain it.	suggestion
2020-1810	- In eq (2), do you mean  max_{\\tau} L(f(x + \\epsilon tanh(\\tau)), y) ?	weakness
2020-1810	- In section 3.3.1, the authors said (1+1)-ES and CMA-ES can be seen as an instantiation of NES.	weakness
2020-1810	Can the authors further elaborate on this?	weakness
2020-1810	- Can the authors provide algorithm for DiagonalCMA?	weakness
2020-1810	- It is better to put the evolution strategy algorithms in the main paper and discuss it.	weakness
2020-1810	- Can the authors also comment/compare the results with the following relevant paper?	weakness
2020-1810	Li, Yandong, et al. "NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks." ICML 2019.	misc
2020-1810	Chen, Jinghui, Jinfeng Yi, and Quanquan Gu.	misc
2020-1810	"A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks." arXiv preprint arXiv:1811.10828 (2018).	misc
2020-1810	-  In Table 1, why for Parsimonious and Bandit methods, # of tiles parts are missing?	weakness
2020-1810	I think both of the baselines use tilting trick?	weakness
2020-1810	And they should also run using the optimal tiling size?	weakness
2020-1810	The result seems directly copied from the Parsimonious paper?	weakness
2020-1810	It makes more sense to rerun it in your setting and environment cause the sampled data points may not be the same.	weakness
2020-1810	Since CMA costs significantly more time, it makes a fair comparison to also report the attack time needed for each method.	weakness
2020-1810	- In Table 3, why did not compare with Bandit and Parsimonious attacks?	weakness
2020-1810	====================== after the rebuttal I thank the authors for their response but I still feel that there is a lot more to improve for this paper in terms of intuition and experiments.	rebuttal_process
2020-1810	Therefore I decided to keep my score unchanged.	rebuttal_process

2020-1813	This paper proposes a scheme for incorporating compressed (sparsified) gradients with momentum in distributed SGD.	abstract
2020-1813	The approach differs from others in the literature, comes with theoretical guarantees, and improved performance.	abstract
2020-1813	The results are correct, and the experiments illustrate that the proposed approach can make a difference (albeit, modest) in the quality of the resulting model.	strength
2020-1813	The main point I find dissatisfying about the theoretical results of the paper are the use of Assumption 2.	weakness
2020-1813	The memory vector is a parameter of the algorithm.	weakness
2020-1813	I realize that one can enforce this with a projection, as argued in the paragraph rationalizing this assumption.	weakness
2020-1813	However, that specific case isn't analyzed and it isn't clear how incorporating that projection would affect the accuracy, since it would essentially be countering the effect of error feedback.	weakness
2020-1813	I also find Assumption 3 to be strange.	weakness
2020-1813	In the convex setting, one can typically show that this follows from Assumption 1 alone under the additional assumption of a suitably small step size.	weakness
2020-1813	In the non-convex setting it isn't clear what this means, since w^* is not well defined (if there are multiple global minimizers).	weakness
2020-1813	Assumption 1 is also strong.	weakness
2020-1813	Typically one assumes that the stochastic gradients are unbiased, and either that the expected gradient is Lipschitz continuous (in the smooth case), or the expected gradient is bounded (in the non-smooth case).	weakness
2020-1813	Assuming that the stochastic gradients are uniformly bounded essentially implies that the noise vanishes when the gradient gets large.	weakness
2020-1813	Can you provide examples of functions/problems satisfying these assumptions?	weakness
2020-1813	Even an example as simple as the case where F is a finite sum of quadratic functions, and one randomly samples one of the terms in the finite sum to compute the gradient (i.e., using SGD to solve a large linear least squares problem) doesn't appear to satisfy Assumption 1.	weakness
2020-1813	Overall the results are potentially interesting.	strength
2020-1813	I would have given a higher rating if the assumptions didn't appear to be so strong, and if the experimental results demonstrated a more substantial difference with DGC.	suggestion
2020-1813	The author propose a method called global momentum compression for sparse communication setting.	abstract
2020-1813	The contributtions can be summarized into 3 parts: switching DGC setting from local momentum to global momentumm, theortical proof of the convergence, empirical results showing performance.	abstract
2020-1813	However there have several issues: 1. No significant contribution.	weakness
2020-1813	Although they theoretically prove a new version of DGC, it's just a minor modification and no significant performance improvement as shown from their empirical results.	weakness
2020-1813	2. In the experiment session, as shown in the results,  their method seems more stable during training but there achieves minor improvement in terms of the test accurarcy.	weakness
2020-1813	Second, they only compare with DGC and it's counterpart baseline.	weakness
2020-1813	It's better to include more related algorithms for comparison (like quantization methond: QSGD or signSGD).	suggestion
2020-1813	3. Comparing with DGC, there is no improvement in saving communication as shown in their results.	suggestion
2020-1813	Since GMC only changes DGC setting from local momentum to global momentum, no modification is involved in the compression part of DGC.	abstract
2020-1813	Overall, I appreciate the authors for their theoretical contribution for DGC and well written paper.	strength
2020-1813	However, it would be great to show a better improvement and include more related methods for comparison.	suggestion
2020-1813	Gradient sparsification is an important technique to reduce the communication overhead in distributed training.	abstract
2020-1813	In this paper, the authors proposed a training method called global momentum compression (GMC) for distributed momentum SGD with sparse gradient.	abstract
2020-1813	Following existing gradient sparsification techniques such DGC, GMC is also built up on the memory gradient approach; the major distinction between GMC and existing techniques is that GMC keeps track of global gradient to maintain the memory gradient, while the existing technique keeps track of worker-local gradients for memory gradient.	abstract
2020-1813	The primary contributions in the paper are as the following: 1. The authors propose GMC, a training method for distributed momentum SGD with sparse gradient communication.	abstract
2020-1813	It uses global gradient (but still achieve sparse communication) to maintain the gradient memory while existing approaches such as DGC use worker-local gradient to do so.	abstract
2020-1813	2. The authors prove the convergence rate of GMC for 1.	abstract
2020-1813	strongly convex and smooth functions 2.	abstract
2020-1813	convex functions and 3. Non-convex Lipschitz smooth functions.	abstract
2020-1813	This is the first work on proving the convergence rate of distributed momentum SGD using sparse communication techniques based on memory gradient.	abstract
2020-1813	3. Empirically, the authors show that GMC can empirically attain the same model accuracy as conventional distributed momentum SGD with ~100x reduction in communication overhead.	abstract
2020-1813	It can also match the performance of DGC at the same communication compression rate.	abstract
2020-1813	I think in general the ideas and efforts of the authors in proving the convergence rate of distributed momentum SGD with *gradient sparsification* is interesting and important.	strength
2020-1813	However, I have the some questions and concerns on validating the claims in the paper.	weakness
2020-1813	I currently give weak reject but I am happy to raise the score if the authors can clarify or improve in their rebuttal / future drafts.	decision
2020-1813	The primary questions and concerns (critical to the rating) are: 1. One important claimed advantage of GMC over existing method is that it uses global gradient for memory gradient, while existing methods such as DGC uses local-work gradient to do so.	weakness
2020-1813	But I did not find convincing support of this advantage in the paper: Empirically, in the experiment results, I don't think GMC demonstrate better performance than DGC in a statistical meaningful way; instead they are basically demonstrating matching performance.	weakness
2020-1813	Theoretically, I am not sure if only the global gradient enables the proof of convergence rate while the worker-local gradient cannot.	weakness
2020-1813	My preliminary feeling is that by bounding the gradient variance, it should also be possible to prove a rate for DGC using worker-local gradient; this is because the difference between the global gradient and the local gradient might be bounded via the gradient variance.	weakness
2020-1813	2. In the experiments, the authors focus on momentum SGD for image classification tasks.	weakness
2020-1813	To better support the versatility and efficacy of GMC, it would be interesting to include some experiments for other domains (e.g. using the STOA transformer style models for NLP tasks).	suggestion
2020-1813	In these models, momentum-like components are also used in the optimizer (e.g. Adam for fairseq for machine translations), it will be interesting to see if the efficacy of GMC also empirically transfer to these settings.	suggestion
2020-1813	Minor questions (influencing the rating in a secondary way)	suggestion
2020-1813	1. Regarding the assumptions in the paper, I think assumption 2 need some validation / support to show that it is a proper one.	weakness
2020-1813	My preliminary feeling is that assumption 2 is intuitive as the sparsification procedures only zero out small values so that the error introduced in the gradient is small and bounded.	suggestion
2020-1813	But it should be more convincing to empirically show the magnitude of u comparing to the magnitude of gradient g in Equ. 8.	suggestion
2020-1813	2. I notice that the experiments uses conventional momentum SGD for a few epochs as warm up, is there any specific reasoning on using this warmup approach instead of the sparsity level warmup as used in DGC?	weakness
2020-1813	3. In the experiments, GMC does not use the factor masking trick while DGC uses.	weakness
2020-1813	If it is for demonstrating the benefits of global gradient for gradient memory, I think it is more proper to also include the results of DGC without factor masking?	weakness
2020-1813	In this way, this question can be directly answered in an ablation study way by eliminating the possible contribution of using/not using factor masking.	weakness
2020-1813	NITS to improve the paper (not related to the rating): 1. The last contribution bullet forgets to mention that it is about comparing to DGC.	weakness
2020-1813	2. In algorithm 1, it is clearer to mention how the mask m is generated (e.g. based on magnitude).	weakness
2020-1813	3. In the second paragraph in section 3.2, the vector inner product is not properly written between coefficients and w.	weakness
2020-1813	4. Above theorem 1, in the text, the condition for the discussion on the two cases are confusing.	weakness
2020-1813	5. In the definition of CR in the first paragraph of section 5, why the summation starts from 5.	weakness
2020-1813	The text describes as warm up with 5 *epochs* while in the equation it is saying warm up with 4 *steps*.	weakness

2020-1823	Thank you for your rebuttal.	misc
2020-1823	The paper improved after the rebuttal but I still think point 5 in the rebuttal is problematic since using d'=d, may not guarantee that we have a proper metric as claimed by the authors.	rebuttal_process
2020-1823	I m updating  my score as a weak reject for this paper.	rebuttal_process
2020-1823	Summary of the paper: The paper proposes to train implicit  model such as gan and an explicit model (Energy Based ) jointly .	abstract
2020-1823	The GAN is trained using WGAN-GP objective or the original JS objective (we have a discriminator D and Generator G).	abstract
2020-1823	The energy based model (E) is trained using Stein Divergence with a fixed kernel k or a learned critic who's parameters are denoted pi in the paper.	abstract
2020-1823	Note that the critic of the stein divergence is vector valued.	abstract
2020-1823	This paper propose to add a regularization loss on the stein divergence between the generator G (implicit model ) and the explicit model (E).	abstract
2020-1823	This gives a training objective minG,EW(Pr,G)+λ1S(Pr,PE)+λ2S(PG,PE)	abstract
2020-1823	In the paper the stein critic is shared between the two stein divergence which means that the authors are rather considering : S(λ1Pr+λ2PG,PE)	abstract
2020-1823	Paper shows the effect of this additional coupling between the two models as a regularization on the Discriminator D and on the critic of the stein divergence.	abstract
2020-1823	Then  the effect of the regularization is also show in terms of convergence in the optimization on a bilinear game, and in the convex concave case.	abstract
2020-1823	Experiments are given showing the benefits of the joint training.	abstract
2020-1823	Review: The paper has a lot of typos and needs a lot of proofreading and is not in shape for being reviewed.	rating_summary
2020-1823	There are too many concerns with this papers: 1- The first one was mentioned above if the critic is shared then you better be considering :  S(λ1Pr+λ2PG,PE)	weakness
2020-1823	2- In equation 4,  the problem is minGmaxD it is swapped.	weakness
2020-1823	3- There a lot of gaps in the proofs of Theorems 1 and 2.	weakness
2020-1823	The transition from equation 14 to the infP...	weakness
2020-1823	is not explained and seems flawed.	weakness
2020-1823	In theorem 2 , the proof is too short and swapping of min and E is not backed rigoursly.	weakness
2020-1823	4- Again in Equation 8, it is not clear how the Stein terms were computed , the appendix does not give the derivations either.	weakness
2020-1823	5 - Authors say that the Stein critic have similar architecture to the GAN critic , which indicates an error in the implementation in the neural case for stein critic.	weakness
2020-1823	Stein critic has to be vector valued, after checking the code of this paper on GitHub, stein critic maps to a real value in the code , which is flawed.	weakness
2020-1823	The critic of stein needs to map the image to an image , which actually quite expensive.	weakness
2020-1823	Typos: abstract : without explicitly defines -> defining multimodal data .	weakness
2020-1823	has been -> have without explicit defines -> defining This paper proposes a training objective that combines three terms: * A Stein discrepancy for learning a energy model with intractable normalizing constant	abstract
2020-1823	* A Wasserstein GAN objective for learning an implicit neural sampler.	misc
2020-1823	* A Stein discrepancy for minimizing the distance between distributions defined by the energy model and the GAN.	misc
2020-1823	The third term is called "Stein bridging" by the authors.	weakness
2020-1823	It seems pretty difficult to motivate such a bridging term because from the first glance this term does not add anything to learning the two models from data.	weakness
2020-1823	So I'm wondering how the authors motivate themselves to study this modification.	weakness
2020-1823	This is my main concern about the paper if this term appears simply because that energy model has an unnormalized density while from GANs we can sample, and Stein discrepancy is best applicable to such pair of distributions.	weakness
2020-1823	Apart from the concern on motivations, I tried to follow the arguments in Section 3, as the bridging term is justified as regularization to both models.	weakness
2020-1823	However, I think the proof of Theorem 1 is incorrect: * I don't think it makes sense from \\nabla \\log (1 + h(x)) to (1 + h(x))\\nabla h(x), even if the taylor expansion suggested by the authors is applied.	weakness
2020-1823	* In the next step, "Consider a further approximation", this approximation basically sets 1 + h(x) to 1, if h(x) is approximately 0, then P=P_E..	weakness
2020-1823	Minor: * IN proof of Theorem 1, the expectation should be always over x,x'~P_E instead of x~P, right?	weakness
2020-1823	This paper proposes to train a GAN and an EBM jointly, and bridge them using a Stein discrepancy.	abstract
2020-1823	The paper claims it leads to novel regularization effect on both models, and stablizes the optimization process.	abstract
2020-1823	Experiments on MNIST and CIFAR-10 show improvement in sample quality and outlier detection.	abstract
2020-1823	Both the idea and the experiment results are interesting.	strength
2020-1823	However, the derivations contain too many typos and are in general confusing, and I cannot confirm their correctness.	weakness
2020-1823	Therefore I cannot recommend acceptance.	decision
2020-1823	Specifically the proof of Theorem 1 seems problematic: 1. In the proof you claim (15) equals −14λ2‖D−t‖H−1.	weakness
2020-1823	But (15) could only simplify to	weakness
2020-1823	1λ2(E[D⋅(λ2h)]+Ex,x′[∇(λ2h(x))Tk(x,x′)∇(λ2h(x′))], where h is unconstrained. Compare this with the definition of the H−1 norm,	weakness
2020-1823	suph{E[D⋅h]:Ex,x′[∇h(x)Tk(x,x′)∇h(x′)]≤1}, how did you drop the inequality constraint on h?	weakness
2020-1823	2. The transformation from the original objective (14) to (15) is strange as well.	weakness
2020-1823	In the proof you claim the minimization problem below "invoking Lagrangian duality gives" could only turn to (15) after "applying the approximation log(1+a)=a+O(a^2)" and "a further approximation".	weakness
2020-1823	But you can turn it into	weakness
2020-1823	E[(D-t)h]+λ E_{x,x'~P_E}[∇h(x)^T k(x,x') ∇h(x')] simply by simplifying the gradient terms.	weakness
2020-1823	Also, why did the t disappear in (15)?	weakness
2020-1823	There are also typos and issues elsewhere.	weakness
2020-1823	To list a few: 3. Energy-based models are not generally referred to as "explicit models", since the normalization constant is intractable.	weakness
2020-1823	I would suggest to replace the occurrences of (log) "density" with "energy" to avoid confusion.	suggestion
2020-1823	4. The GD update rule of (6) is incorrect; the optima should also be (0, 1), instead of (1, 0).	weakness
2020-1823	5. On the second line on Page 8, the unnormalized log density cannot be x^2+\\phi x, as the normalization constant would then be infinity.	weakness
2020-1823	For these reasons, I believe this paper needs a thorough proofreading before it can be reviewed efficiently.	weakness

2020-1833	This paper studies the connection between sensitivity and generalization where sensitivity is roughly defined as the variance of the output of the network when gaussian noise is added to the input data (generated from the same distribution as the training error).	abstract
2020-1833	The paper is well-written and the experiments are very comprehensive.	strength
2020-1833	There are however 3 major issues with the current approach: 1- Novelty: Novak et al. 2018 suggests a very similar notation of sensitivity and they show correlation with generalization.	weakness
2020-1833	Even though the authors site this work, they don't discuss the connection very clearly.	weakness
2020-1833	In light of that work, there is very limited novelty in this paper.	weakness
2020-1833	2- Definition of test loss: Authors define the test loss to be cross-entropy but in almost all these tasks, what we care about is the task-loss which is 0/1 classification error on the test data and not the cross-entropy loss.	weakness
2020-1833	These two loss behave very differently.	weakness
2020-1833	In particular, the cross-entropy loss is very sensitive to the of variance of the output while 0/1 classification loss does not depend on it.	weakness
2020-1833	Therefore, it is not surprising that there is high correlation between the output variance and the cross-entropy loss but it is not clear if this has anything to do with the test error.	weakness
2020-1833	3- Using test data in the complexity measure: The goal of understanding generalization is not just to get correlation with the test error.	weakness
2020-1833	One can always use a validation set to get a very good correlation.	weakness
2020-1833	Even when we have limited data, we can always put a small portion of the data for validation without loosing much in the final performance.	weakness
2020-1833	The main goal is to predict generalization without using any access to the distribution.	weakness
2020-1833	In particular, we need properties that show how networks behave on new data instead of simply measuring a property on the new data.	weakness
2020-1833	Therefore, using a measure that is evaluated on new data is not really helpful.	weakness
2020-1833	******************************** After author rebuttals: Authors have addressed one of my concerns (no 3) but the other two concerns are not addressed adequately.	rebuttal_process
2020-1833	I increase my score to "weak reject" but not higher because of my concern about the novelty of the work in light of Novak et al. 2018.	rebuttal_process
2020-1833	This paper examines generalization performance of various neural network architectures in terms of a sensitivity metric that approximates how the error responds to perturbations of the input.	abstract
2020-1833	A crude argument is presented for how the proposed sensitivity metric captures the variance term in the standard bias-variance decomposition of the loss.	abstract
2020-1833	A number of experimental results are presented that show strong correlation between the sensitivity metric and the empirical test loss.	abstract
2020-1833	Understanding the distinguishing characteristics of networks that generalize well versus networks that generalize poorly is a central challenge in modern deep learning research, so the topic and analyses presented in this paper are salient and will be of interest to most of the community.	strength
2020-1833	The experimental results are intriguing and the presentation is clear and easy to read.	strength
2020-1833	While some may object to the egregious simplifications utilized in "deriving" the sensitivity metric, I believe this kind of analysis should be welcomed if it produces new insights and helps explain otherwise opaque empirical phenomena.	ac_disagreement
2020-1833	All told, if taken in isolation from prior work, I think the insights and empirical results presented in this paper are quite interesting and certainly sufficient for acceptance to *CONF*.	decision
2020-1833	However, there is significant overlap with prior work that severely detracts from the novelty of the results presented here, and I think the community is already familiar with the paper's main conclusions.	weakness
2020-1833	From the empirical viewpoint, [1] performs a very similar (and actually quite a bit more thorough) analysis, and reaches very similar conclusions.	weakness
2020-1833	The authors do cite [1], but unless I missed something, their main argument for uniqueness is basically "in experiments, we prefer S to the Jacobian, because in order to compute S it is enough to look at the network as a black box that given an input, generates an output, without requiring further knowledge of the model."	rebuttal_process
2020-1833	While this may be useful from the practical standpoint for some non-differentiable models, I'm not convinced that this distinction is really significant in terms of building insights or new understanding.	weakness
2020-1833	One additional way this paper is distinct from [1] is that it includes a theoretical "derivation" for the sensitivity metric.	weakness
2020-1833	While I found the argument interesting, from the theoretical perspective, [2] gives much more rigorous and insightful arguments that help explain the observed phenomena.	weakness
2020-1833	Overall, I'm just not convinced this paper is novel enough to merit publication.	decision
2020-1833	But perhaps I've overlooked something, in which case I hope the author's response can highlight their unique contributions relative to prior work.	misc
2020-1833	[1] Novak, Roman, et al. "Sensitivity and generalization in neural networks: an empirical study." arXiv preprint arXiv:1802.08760 (2018).	misc
2020-1833	[2] Arora, Sanjeev, et al. "Stronger Generalization Bounds for Deep Nets via a Compression Approach." International Conference on Machine Learning.	misc
2020-1833	2018.	misc

2020-1855	This paper suggests a method for detecting adversarial attacks known as EXAID, which leverages deep learning explainability techniques to detect adversarial examples.	abstract
2020-1855	The method works by looking at the prediction made by the classifier as well as the output of the explainability method, and labelling the input as an adversarial example if the predicted class is inconsistent with the model explanation.	abstract
2020-1855	EXAID uses Shapley values as the explanation technique, and is shown to successfully detect many standard first-order attacks.	abstract
2020-1855	Though method is well-presented and the evaluation is substantial, the threat model of the oblivious adversary is unconvincing.	weakness
2020-1855	The paper makes the argument that oblivious adversaries are more prevalent in the real world, but several works [1,2,3,etc.] have shown that with only query access to input-label pairs from a deep learning-based system, it is possible to construct black-box adversarial attacks.	weakness
2020-1855	Thus, it is unclear why an attacker cannot just treat the detection mechanism as part of this black box, and mount a successful query-based attack.	weakness
2020-1855	Though I recognize that the task of detection is separate from the task of robust classification, in both cases the defender should at least operate in the case where the attacker has input-output access to the end-to-end system (including whatever detection mechanisms are present).	weakness
2020-1855	In particular, it seems impossible to "hide" a detector from an end user (when the method detects an adversarial example, it will alert the user somehow that the input was rejected), and so the user will be able to use this information to fool the system.	weakness
2020-1855	The authors should investigate the white-box accuracy of their detection system, or at the very least try black-box attacks against the detector.	suggestion
2020-1855	For this reason I do not recommend acceptance for the paper at this time.	decision
2020-1855	[1] https://arxiv.org/abs/1804.08598 [2] https://arxiv.org/abs/1807.04457 [3] https://arxiv.org/abs/1712.04248 The paper proposes a method to check whether a model is under attack by using state of the art explainability model, SHAP.	abstract
2020-1855	They evaluated their technique using CIFAR-10 and SVHN w.r.t. 5 baseline techniques.	abstract
2020-1855	They showed their method outperforms all the other baselines with a significant margin.	abstract
2020-1855	+ Overall I think the paper made a valuable contribution to the adversarial ML literature.	strength
2020-1855	Using explainability to detect the presence of adversarial attacks seems like a nice intuitive idea and the results show that it indeed works.	strength
2020-1855	- However, the contribution of the paper is rather incremental.	weakness
2020-1855	They just used SHAPE to adversarial and negative examples.	weakness
2020-1855	I do not see any insight while explaining the results.	weakness
2020-1855	- Why under PGD and FGSM attack under higher noise, the proposed technique is similar or slightly worse than Lid and Mohalonabis baselines?	weakness
2020-1855	- I would also like to see how these results hold good for a complicated dataset like ImageNet A Simple method to detect adversarial examples, but needs more work.	weakness
2020-1855	#Summary: The paper proposed a method that utilizes the model's explainability to detect adversarial images whose explanations that are not consistent with the predicted class.	abstract
2020-1855	The explainability is generated by SHAP, which uses Shapley values to identify relative contributions of each input to a class decision.	abstract
2020-1855	It designs two detection methods: EXAID familiar, which is aimed to detect the known attacks and EXAID unknown, which is against unknown attacks.	abstract
2020-1855	Both of the two methods are evaluated on perturbed test data which are generated by FGSM, PGD and CW attack with perturbations of different magnitudes.	abstract
2020-1855	Qualitative results also show that the proposed method can effectively detect adversaries, especially when the perturbation is relatively small.	abstract
2020-1855	#Strength The method is easy to implement and using the idea of interpretation for detecting adversarial examples seems interesting.	strength
2020-1855	Good results are demonstrated compared with other comparators.	strength
2020-1855	#Weakness The idea of this paper is based on the interpretation method of DNN.	strength
2020-1855	However, it has been shown that these interpretation methods are not reliable and easy to be manipulated [1][2].	weakness
2020-1855	Therefore, although the method is simple to design, it also brings other security concerns.	weakness
2020-1855	Unfortunately, the paper does not address these issues.	weakness
2020-1855	In addition, the comparators listed in the experiments are not state-of-art or common baselines.	weakness
2020-1855	It is either not clear why authors modified the existing method and develop their own "unsupervised" version.	weakness
2020-1855	In the experiments, many details are omitted.	weakness
2020-1855	For example, how is the "noise level" defined?	weakness
2020-1855	Are they based on L1, L2 or L-inf perturbation?	weakness
2020-1855	For PGD attack, how many iterations does the generation run and what is the step size?	weakness
2020-1855	How many effective adversarial examples are generated for training and testing?	weakness
2020-1855	And all the experiments are conducted in a relatively small dataset, it is also suggested to do experiments on large datasets, e.g. Imagenet.	weakness
2020-1855	In the evaluation part, it looks strange to me why the EXAID familiar performs worse than EXAID unknown in evaluating FGSM attack on SVHN since the EXAID familiar is trained using FGSM attack.	weakness
2020-1855	#Presentation I think the authors used a wrong template to generate the article.	weakness
2020-1855	The font looks strange and the headnote indicates it is prepared for *CONF*2020.	weakness
2020-1855	The paper contains many typos and even the title contains a misspelling.	weakness
2020-1855	Poor coverage of citations. There are more works for detecting adversarial examples that are published, e.g. [3][4][5].	weakness
2020-1855	On the other hand, the paper does not have the literature review for work related to the model interpretation.	weakness
2020-1855	Overall, I think the paper is not good enough for publication at *CONF*.	decision
2020-1855	[1] Dombrowski, Ann-Kathrin, et al. "Explanations can be manipulated and geometry is to blame." arXiv preprint arXiv:1906.07983 (2019).	weakness
2020-1855	[2] Ghorbani, Amirata, Abubakar Abid, and James Zou.	misc
2020-1855	"Interpretation of neural networks is fragile." Proceedings of the AAAI Conference on Artificial Intelligence.	misc
2020-1855	Vol. 33. 2019. [3] Meng, Dongyu, and Hao Chen.	misc
2020-1855	"Magnet: a two-pronged defense against adversarial examples." In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp.	misc
2020-1855	135-147. ACM, 2017. [4] Liao, Fangzhou, Ming Liang, Yinpeng Dong, Tianyu Pang, Xiaolin Hu, and Jun Zhu.	misc
2020-1855	"Defense against adversarial attacks using high-level representation guided denoiser." In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.	misc
2020-1855	1778-1787. 2018. [5] Ma, Shiqing, Yingqi Liu, Guanhong Tao, Wen-Chuan Lee, and Xiangyu Zhang.	misc
2020-1855	"NIC: Detecting Adversarial Samples with Neural Network Invariant Checking." In NDSS.	misc
2020-1855	2019. Summary: The authors propose an explanation-based adversarial example detection algorithm.	abstract
2020-1855	The main idea is to train a discriminator to detect whether the explanatory saliency map is consistent with the input.	abstract
2020-1855	Experiments have been conducted on CIFAR10 and SVHN to validate the method.	abstract
2020-1855	Comments: + The idea is straightforward and easy to follow.	strength
2020-1855	- The use of SHAP as the only explanation method is not well explained.	weakness
2020-1855	There are a plenty of works on visual explanation methods, such as guided-backprop[1], excitation-backprop[2], integrated gradient[3], Grad-CAM[4], real-time saliency[5] and so on.	weakness
2020-1855	And based on my expertise, SHAP cannot generate the most accurate saliency among these methods.	weakness
2020-1855	If the proposed framework is general, why not to conduct ablation study on the different choice of explainer?	weakness
2020-1855	- Doubts on the effectiveness of the proposed method.	weakness
2020-1855	According to former works[6, 7], explanatory saliency methods  are vulnerable and unreliable with respect to input perturbations.	weakness
2020-1855	But in this paper, the authors assume that the explanation saliency map for normal examples are perfectly correct and used as positive instances for training the discriminator.	weakness
2020-1855	I think they only focus on target attack, in which the attacking target label is semantically distinct from the original label, and the resulting saliency map distribution is very different from the correct one.	weakness
2020-1855	However, considering a tabby cat image is perturbed to become tiger cat, since two classes are very close, the resulting saliency maps should be similar and the detector may fail to detect the adversarial example.	weakness
2020-1855	Therefore, I encourage the authors to provide more results on this challenging scenario (for example, conduct un-target attack on imagenet dataset).	suggestion
2020-1855	- The reported results in Figure 2(e) is abnormal.	weakness
2020-1855	First, the blue line (authors' method) is very close to AUC=1.0 across different noise levels, which means that the detector can perfectly classify all the adversarial examples in all the situation.	weakness
2020-1855	Second, the reported values of other methods are not correct.	weakness
2020-1855	For example, the black line (original Mahalanobis) is below AUC=0.5 across all the noise level.	weakness
2020-1855	However, in the Table3 ResNet-CIFAR10 row of its original paper[8], the reported AUC under C&W attack is 95.84, which is much larger than those shown in the figure.	weakness
2020-1855	Therefore, I think the comparison is invalid.	weakness
2020-1855	Similar problems also appear in Figure 2(f).	weakness
2020-1855	[1] J. Springenberg, A. Dosovitskiy, T. Brox, and M. Riedmiller. (2015).	misc
2020-1855	Striving for simplicity: The all convolutional net.	strength
2020-1855	In *CONF* (workshop track). [2] J. Zhang, Z. Lin, J. Brandt, X. Shen, and S. Sclaroff. (2016).	misc
2020-1855	Top-down neural attention by excitation backprop.	misc
2020-1855	In ECCV. [3] Sundararajan, M., Taly, A., & Yan, Q.	misc
2020-1855	(2017). Axiomatic attribution for deep networks.	misc
2020-1855	In ICML. [4] Selvaraju, R. R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., & Batra, D.	misc
2020-1855	(2017). Grad-cam: Visual explanations from deep networks via gradient-based localization.	misc
2020-1855	In ICCV. [5] Dabkowski, P., & Gal, Y.	misc
2020-1855	(2017). Real time image saliency for black box classifiers.	misc
2020-1855	In NeurIPS. [6] Kindermans, P. J., Hooker, S., Adebayo, J., Alber, M., Schütt, K.	misc
2020-1855	T., Dähne, S., ... & Kim, B. (2019).	misc
2020-1855	The (un) reliability of saliency methods.	misc
2020-1855	In Explainable AI: Interpreting, Explaining and Visualizing Deep Learning (pp.	misc
2020-1855	267-280). Springer, Cham. [7] Adebayo, J., Gilmer, J., Muelly, M., Goodfellow, I., Hardt, M., & Kim, B.	misc
2020-1855	(2018). Sanity checks for saliency maps.	misc
2020-1855	In NeurIPS [8] Lee, K., Lee, K., Lee, H., & Shin, J.	misc
2020-1855	(2018). A simple unified framework for detecting out-of-distribution samples and adversarial attacks.	abstract
2020-1855	In NeurIPS	misc

2020-1872	The paper aims to study the topology of loss surfaces of neural networks using tools from algebraic topology.	abstract
2020-1872	From what I understood, the idea is to effectively	strength
2020-1872	(1) take a grid over the parameters of a function (say a parameters of a neural net),	abstract
2020-1872	(2) evaluate the function at those points,	abstract
2020-1872	(3) compute sub-levelset persistent homology and	abstract
2020-1872	(4) study the resulting barcode (for 0/1-dim features) (i.e., the mentioned "canonical form" invariants).	abstract
2020-1872	Some experiments are presented on extremely simple toy data.	abstract
2020-1872	Overall, the paper is very hard to read, as different concepts and terminology appear all over the place without a precise definition (see comments below).	weakness
2020-1872	Given the problems in the writing of the paper, my assessment is that this idea boils down to computing persistent homology of the sub-levelset filtration of the loss surface sampled at fixed parameter realizations.	weakness
2020-1872	I do not think that this will be feasible to do, even for small-scale real-world neural networks, simply due to the difficulty of finding a suitable grid, let alone the vast number of function evaluations involved.	weakness
2020-1872	The paper is also unclear in many parts.	weakness
2020-1872	A selection is listed below: (1) What do you mean by gradient flow?	weakness
2020-1872	One can define a gradient flow in a linear space X and for a function F: X->R, e.g., as  a smooth curve R->X, such that x'(t) = -\\nabla F(x(t)); is that what is meant?	weakness
2020-1872	(2) What do you mean by "TDA package"?	weakness
2020-1872	There are many TDA packages these days (maybe the CRAN TDA package?)	weakness
2020-1872	(3) "It was tested in dimensions up to 16 ..." What is meant by dimension here?	weakness
2020-1872	The dimensionality of the parameter space?	weakness
2020-1872	(4) The author's talk about the "minima's barcode" - I have no idea what is meant by that either; the barcode is the result of sub-levelset persistent homology of a function -> it's not associated to a minima.	weakness
2020-1872	(5) Is Theorem 2.3. not just a restatement of a theorem from Barannikov '94?	weakness
2020-1872	At least the proof in the appendix seems to be .	weakness
2020-1872	(6) Right before Theorem 2.3., what does the notation F_sC_* mean?	weakness
2020-1872	This needs to be introduced somewhere.	weakness
2020-1872	From my perspective, the whole story revolves around how to compute persistence barcodes from the sub-levelset filtration of the loss surface, obtained from function values taken on a grid over the parameters.	weakness
2020-1872	The paper devotes quite some time to the introduction of these concepts, but not in a very clear or understandable manner.	weakness
2020-1872	The experiments are effectively done on toy data, which is fine, but the paper stops at that point.	weakness
2020-1872	I do not buy the argument that "it is possible to apply it [the method] to large-scale modern neural networks".	weakness
2020-1872	Without a clear strategy to extend this, or at least some preliminary "larger"-scale results, the paper does not meet the *CONF* threshold.	decision
2020-1872	The more theoretical part is too convoluted and, from my perspective, just a restatement of earlier results.	weakness
2020-1872	This work is focused on topological characterization of target surfaces of optimization objectives (i.e. loss functions) by computing so called barcodes, which are lists of pairs of local minima and their connected saddle points.	abstract
2020-1872	The authors claim that the barcodes constitute a representation of target objectives that is invariant under homeomorphisms of input to the objectives.	abstract
2020-1872	The authors present an algorithm for computing the barcodes from graph-based representation of a surface, and present barcodes computed on toy examples in numerical analysis.	abstract
2020-1872	In my opinion, the main contribution of the work i.e. creation of barcodes is based on a rather trivial idea.	strength
2020-1872	The concept of characterizing optimization objectives through pairs of local minima and one-index saddle points is straightforward given that one can (thoroughly if not exhaustively) compute them in a computationally feasible manner; this is however hardy the case in any realistic scenario.	strength
2020-1872	I therefore struggle to see how the idea can be practically significant.	weakness
2020-1872	Maybe the authors can put more emphasis on the theoretical aspect of their work, which is about the invariance nature of barcodes.	suggestion
2020-1872	They can for instance demonstrate how one can exploit the invariance property of barcodes for parameter optimization.	suggestion
2020-1872	The authors can consider application of their work to hyper-parameter optimization, which is usually low-dimensional and one can also compare with other approaches such as Gaussian processes or other Bayesian methodologies.	suggestion
2020-1872	In numerical experiments, for the toy task solved using neural network I don't find it very surprising that the barcodes descend lower as the capacity of the network is increased.	strength
2020-1872	Can the authors further clarify why it is a significant finding for them?	suggestion
2020-1872	This paper introduces the notion of barcodes as a topological invariant of loss surfaces that encodes the "depth" of local minima by associating to each minimum the lowest index-one saddle.	abstract
2020-1872	An algorithm is presented for the computation of barcodes, and some small-scale experiments are conducted.	abstract
2020-1872	For very small neural networks, the barcodes are found to live at small loss values, and the authors argue that this suggests it may be hard to get stuck in a suboptimal local minimum.	abstract
2020-1872	I believe the concept of barcodes will be new to most members of the *CONF* community (at least it was to me), and I appreciate the authors' effort to convey the ideas through multiple definitions in Section 2.	strength
2020-1872	I wasn't able to fully appreciate the importance of Definition 3, and Definitions 1 and 2 were tough to digest owing to imprecise language, but I think I got the main point.	weakness
2020-1872	I was also unable to fully comprehend the definitions of "birth" and "death" in this context.	weakness
2020-1872	I'd strongly encourage the authors to improve the readability of this section so that non-experts can follow the story.	suggestion
2020-1872	It seems like the main contribution is a new algorithm for computing barcodes of minima.	weakness
2020-1872	I am unfamiliar with prior work in this direction, and I was also unable from the paper to infer what the main improvements were relative to the existing algorithms.	weakness
2020-1872	I'd encourage the authors to state their explicit algorithmic improvements, and to demonstrate empirically that the new algorithm outperforms the prior ones in the expected ways.	suggestion
2020-1872	The main experiments are on extremely tiny neural networks, presumably owing to computational restrictions.	weakness
2020-1872	The authors state that "it is possible to apply it to large-scale modern neural networks", but it's not clear to me how that would work or what additional algorithmic improvements (if any) would need to be made in order to do so.	weakness
2020-1872	I don't think that the results on tiny neural networks have much relevance to practice, so I think the empirical data presented in this paper will have very limited impact.	weakness
2020-1872	If there were results for practical models, it would be a different story.	weakness
2020-1872	So I'd encourage the authors to devote additional effort to scaling up the method for use on practical neural network architectures.	suggestion
2020-1872	Overall, I think there may be some really nice ideas in this paper that could help shape our understanding of neural network loss surfaces, but the current paper does not explore those ideas fully and does not convey them in a sufficiently clear manner.	weakness
2020-1872	I hope to see an improved version of this paper at a future conference, but I cannot recommend acceptance of this version to *CONF*.	decision

2020-1880	This work proposes an algorithm for handling the weight-sharing neural architecture search problem.	abstract
2020-1880	It also derives generalization bound for this problem.	abstract
2020-1880	The reviewer has several concerns: 1) the SBMD and ASCA algorithms are existing generic algorithms.	weakness
2020-1880	The analysis in this work also looks very generic.	weakness
2020-1880	There is a sense of disconnection with the considered training problems.	weakness
2020-1880	The reviewer would like to see more discussions on how to connect the algorithms with specific NAS problems.	suggestion
2020-1880	For example, what is the beta parameter when training a NAS problem?	weakness
2020-1880	2) The convergence rate improvement brought by using mirror descent has been long known.	weakness
2020-1880	It is not easy to see what is the contribution of this work.	weakness
2020-1880	3) The generalization part seems to be meaningful.	weakness
2020-1880	But it may be much stronger if the NAS problem can also have a theoretical bound.	weakness
2020-1880	It is less appealing to only discuss cases with strongly convex objectives.	weakness
2020-1880	I have not worked in the optimization filed and I am only gently followed the NAS field.	weakness
2020-1880	I might under-valued the theoretical contribution.	weakness
2020-1880	This work provides  theoretical analysis for the NAS using weight sharing in two aspects: 1) The authors give non-asymptotic stationary-point convergence guarantees (based on stochastic block mirror descent (SBMD) from Dang and Lan (2015)) for the empirical risk minimization (ERM) objective associated with weight-sharing.	abstract
2020-1880	Based on this analysis, the authors proposed to use  exponentiated gradient to update architecture parameter, which enjoys faster convergence rate than the original results in Dang and Lan (2015).	abstract
2020-1880	The author also provided an alternative to SBMD that uses alternating successive convex approximation (ASCA) which has similar convergence rate.	abstract
2020-1880	2) The author provide generalization guarantees for this objective over structured hypothesis spaces associated with a finite set of architectures.	abstract
2020-1880	My biggest concern is the validity of the proposed exponentiated gradient update, at least empirically.	weakness
2020-1880	We indeed observed slightly improvement in test error over DARTS on the CIFAR10 benchmark but how reproducible the results are?	weakness
2020-1880	Can you compare at least on the other benchmark (PENN TREEBANK) used in Liu et al 2019?	suggestion
2020-1880	Also, comparing to first order DARTS, search cost is the same and this is hard to justify the better convergence rate for EDARTS.	weakness
2020-1880	In addition, the results on feature map selection is not very encouraging as the gap to the successive halving is significant.	weakness
2020-1880	The author proposed ASCA, as an alternative method to SBMD.	weakness
2020-1880	Why we need such alternative?	weakness
2020-1880	What is the advantage of ASCA comparing to SBMD?	weakness
2020-1880	When should I use ASCA and when SBMD?	weakness
2020-1880	How do they empirically different?	weakness
2020-1880	Then I feel some wording can be improved.	weakness
2020-1880	For example, "while requiring computation training …",  "…which may be of independent interest".	weakness

2020-1899	In this paper, the authors propose a reinforcement learning method for multi-robot scheduling problems.	abstract
2020-1899	They state the method's scalable performance and transferability.	abstract
2020-1899	My major concerns are as follows.	misc
2020-1899	1. The paper is not easy to read.	weakness
2020-1899	In my understanding, multi-robot scheduling is a very important problem and is very similar to many scheduling problems in complex platforms such as the dispatch system for ride sharing and package delivery.	strength
2020-1899	However, I did see any real application in this paper.	strength
2020-1899	It is very difficult to understand how this proposed method works and what is the benefit under non trivial environment.	weakness
2020-1899	2. The experiments (2~8 robots, 20~50 tasks) cannot support the scalable performance or large problems very well.	weakness
2020-1899	How about thousands and millions of robots/tasks, e.g. routing planning or dispatching for vehicles in a ride sharing platform?	weakness
2020-1899	3. It is not convincing without comparison with necessary baseline methods.	weakness
2020-1899	4. There is no in-depth analyses for the transferability.	weakness
2020-1899	5. There are many typos, such as the missing figure citation with Figure ??.	weakness
2020-1899	Paper addresses the problem of centralized multi-machine task assignment in an RL setting ("multi-robot reward collection").	abstract
2020-1899	Claim is that this has not been successfully done in a RL setting before, so a new problem is proposed (multi-agent pac-man) and results are presented on this problem.	abstract
2020-1899	Approach proposed extends prior work from Dai 2017 and 2016 (which I am a priori unfamiliar with), and it seems to me that the exposition of this method leans a bit too heavily on presumed familiarity with those works.	weakness
2020-1899	An auction-consensus approach is proposed whereby each machine makes a bid for each unclaimed task, then the coordinator picks the highest bid and assigns that task-machine pairing, after which the remaining machines make bids for the remaining tasks, and so forth.	weakness
2020-1899	As it stands, part of me leans toward rejecting for a couple reasons.	decision
2020-1899	1. The exposition of the method needs to be improved to assume less background knowledge of the heuristic PGM and  structure2vec methods, investing some text introducing them.	weakness
2020-1899	Appendix C seems to do part of this, and probably should be integrated into the body of the paper.	weakness
2020-1899	2. Another view of "random graphical models" is the sampling trace of a universal PPL.	weakness
2020-1899	This is studied in, e.g. https://cocolab.stanford.edu/papers/daipptr.pdf so it seems like this deserves at least a brief additional literature review as opposed to simply diving into MFI.	weakness
2020-1899	Appendix D looks OK: since the action space is discrete, then a fixed point approach becomes feasible.	weakness
2020-1899	On the other hand, the experiments are good, the auction approach is a nice idea/novel.	strength
2020-1899	The ablation experiment is good, and the comparison against OR tools is also good to have.	strength
2020-1899	Insofar as the structure2vec is representation-oriented, it seems like a decent fit to the venue.	decision
2020-1899	On balance, I think the paper needs too much polish and revision to accept at this time.	decision
2020-1899	Minor nits: The word "seminar" is used a couple times, where from context I think "seminal" is intended.	weakness
2020-1899	Some figure refs are broken.	weakness
2020-1899	The authors study a combinatorial multi-robot scheduling problem (in fact the robot part is a bit inflated, since the experiments only involve agents in a simulated discrete state-space maze) using a method that builds upon recent advances from [Dai et al. (2017)]. The main contribution is to consider each of the steps taken by Dai et al. to solve combinatorial problems on graphs, and adapt them to the considered scheduling problem.	abstract
2020-1899	Not being an expert in RL, my assessment should be discounted.	misc
2020-1899	However, I am not sure I follow properly the main idea of the paper.	weakness
2020-1899	The point of Dai et al. was to use RL to solve a wide family of combinatorial problems.	weakness
2020-1899	Now, the authors claim to build upon these ideas to solve...	weakness
2020-1899	what looks essentially like a far more standard RL problem, and not necessarily a combinatorial optimization problem.	weakness
2020-1899	The main insight by Dai et al. was to highlight the fact that combinatorial problems are usually solved (or approximated) without "warm starts", i.e. they do not consider distributions on problem instances to learn from.	weakness
2020-1899	The problem considered by the authors is, quite on the contrary, a typical RL problem where information is extracted from the problem's structure (here a maze).	weakness
2020-1899	Therefore, I feel there is something of a fundamental contradiction going on at a fairly high-level, in the sense that the paper "uses RL to solve a subset of combinatorial problems that were studied by RL before".	weakness
2020-1899	The absence of other baselines in experiments make this even more suspicious.	weakness
2020-1899	Therefore I believe the paper's presentation could be greatly improved if it were better "located" within the RL literature (which is almost non-existent in the very brief bibliographic section) and that the authors were able to show that  their proposals are original, within an RL context.	suggestion
2020-1899	minor points: * the comment "While learning-based methods are generally believed to suffer exponentially increasing training requirements as problem size (number of robots and tasks) increases, our method's training requirement is empirically shown not to scale while maintaining near-optimal performance" --> this is too loose a statement.	weakness
2020-1899	Provide more evidence or references.	suggestion

2020-1920	Summary: The paper uses a Gaussian Processes framework previously introduced in [1] to identify the most important samples from the past for functional regularization.	abstract
2020-1920	For evaluation authors report their average accuracy on Permuted MNIST, Split-MNIST, and CIFAR10-100 and achieve superior performance over EWC, DLP, SI, VCL-Coreset, and FRCL.	abstract
2020-1920	Pros: (+): The paper is well-written, addressed the prior work quite well despite missing a few important work from the past (more on this later)	strength
2020-1920	(+): The paper is well motivated	strength
2020-1920	Cons that significantly affected my score and resulted in rejecting the paper are as follows: 1- lack of support for "scalability": Authors claim their method is scalable in several parts of the paper (abstract in line 7, Section 3 in the 1st paragraph, and Section 5 in Discussion).	weakness
2020-1920	However, this claim is not supported in the experimental setting as the benchmark used are only toy datasets (Permuted MNIST, Split MNIST, and CIFAR10 followed by CIFAR100) where the maximum # of task considered is 10 and the maximum size of the datasets is 60K which is not convincing for ability to scale.	weakness
2020-1920	There is also no time complexity provided.	weakness
2020-1920	2- Incremental novelty over the prior work (FRCL by Titsias et al 2019): This baseline is the closest prior work to this work which according to the experiments shown in Table 2 are slightly outperformed by the proposed method.	weakness
2020-1920	(for example for P-MNIST the gain is 0.6%+-0.1) where there is a lack of complete discussion on how the two methods are different.	weakness
2020-1920	Particularly I suggest that the authors elaborate more on their claimed differences stated on page 4, paragraph 5 such as "tractability of the objective function only when we assume independence across tasks".	suggestion
2020-1920	Do authors mean assuming clear task boundary between tasks?	suggestion
2020-1920	If so, have they considered a "no-task" or an "overlapping" task boundary in their experiment?	suggestion
2020-1920	Isn't it necessary to back up this if it is stated as a shortcoming of FRCL?	suggestion
2020-1920	Also, how are these methods differ in their computational expenses?	suggestion
2020-1920	3- Lack of measuring forgetting: This is the most important drawback in the experimental setting.	weakness
2020-1920	Authors indicate on page 3 "Our goal in this paper is to design methods that can avoid such catastrophic forgetting." and reiterate on this on other parts of the paper yet there is no forgetting evaluation to support this claim.	rebuttal_process
2020-1920	Authors can simply report the initial performance of the model on each task so that readers can compare it with the reported accuracy after being done with all tasks.	rebuttal_process
2020-1920	Having a method with high average accuracy does not necessarily mean it has minimum forgetting.	rebuttal_process
2020-1920	You can use forgetting measurements such as Backward Transfer (BWT) introduced in [1] or forgetting ratio defined in [4] for this assessment.	rebuttal_process
2020-1920	4- Ambiguous claims about prior work: (a) On page 1, paragraph 3, when authors mention that methods such as GEM or iCaRL use random selection to pick previous samples, I think the line of follow-up work on these methods should be mentioned as well that have explored different techniques for sample selection and have provided benchmark comparisons (ex.	weakness
2020-1920	[2,3]). In fact it would be beneficial if authors could compare the samples selected by their method versus other sampling techniques.	weakness
2020-1920	(b) On page 1, paragraph 3, they mention some prior work such as GEM and iCaRL "do not take uncertainty of the output into account".	weakness
2020-1920	While it is true, there have been methods proposed that use uncertainty of the output for parameter regularization [5].	weakness
2020-1920	It appears to be a parallel work to this but it's worth mentioning to prevent false claims.	weakness
2020-1920	5- Claim on the state of the art should be double-checked: Although the results shown for the experiments are superior to the provided baselines, there is an important baseline missing which has achieved higher performance than the reported ones.	weakness
2020-1920	Also missed to be cited in the prior work list.	weakness
2020-1920	Serra et al [4] proposed a method at ICML 2018 called HAT, which is a regularization technique with no memory usage that learns an attention mask over parameters and was shown to be very effective on small and long sequence of significantly different tasks.	abstract
2020-1920	They do not use samples from previous task but yet achieved good average ACC as well as minimum forgetting ratio.	abstract
2020-1920	Note that 5-Split MNIST is not reported in [4], but a recent work has reported HAT's performance on this dataset (https://openreview.net/forum?id=HklUCCVKDB) that achieves 99.59%.	weakness
2020-1920	I recommend authors provide comparison of their own on the given benchmarks with the original HAT's implementation (https://github.com/joansj/hat) before claiming to be SoTA.	suggestion
2020-1920	In my opinion, it is not an issue if a novel method achieves a slightly lower performance to the sota because I think it still adds value and proposes a new direction.	ac_disagreement
2020-1920	However, a false claim should not be stated.	weakness
2020-1920	Less major (only to help, and not necessarily part of my decision assessment): 1- Providing upper bound?	weakness
2020-1920	It is common to show an upper bound for any continual learning algorithm by showing joint training performance which is considered to be the maximum achievable performance.	weakness
2020-1920	I also recommend showing the naive baseline of fine-tuning for the proposed method  which often can give insight to maximum forgetting ratio.	suggestion
2020-1920	2- Forward transfer? Regularization techniques combined with memory might have an ability to perform zero-shot transfer or so called FWT.	suggestion
2020-1920	I recommend authors provide such metric to further support their method.	suggestion
2020-1920	3- Hyper parameter tuning? It is also worth mentioning how the tuning process was performed.	suggestion
2020-1920	In continual learning we cannot assume that we have access to all tasks' data, hence authors might want to shed some light on this.	suggestion
2020-1920	References: [1] Khan, Mohammad Emtiyaz, et al. "Approximate Inference Turns Deep Networks into Gaussian Processes." arXiv preprint arXiv:1906.01930 (2019).	misc
2020-1920	[2] Chaudhry, Arslan, et al. "Continual Learning with Tiny Episodic Memories." arXiv preprint arXiv:1902.10486 (2019).	misc
2020-1920	(https://arxiv.org/abs/1902.10486) [3] Aljundi, Rahaf, et al. "Gradient based sample selection for online continual learning." arXiv preprint arXiv:1903.08671 (2019).	misc
2020-1920	(https://arxiv.org/abs/1903.08671) [4] Serrà, J., Surís, D., Miron, M.	misc
2020-1920	& Karatzoglou, A.. (2018). Overcoming Catastrophic Forgetting with Hard Attention to the Task.	misc
2020-1920	Proceedings of the 35th International Conference on Machine Learning, in PMLR 80:4548-4557	misc
2020-1920	[5] Ebrahimi, Sayna, et al. "Uncertainty-guided Continual Learning with Bayesian Neural Networks." arXiv preprint arXiv:1906.02425 (2019).	misc
2020-1920	---------------------------------------------------------------------------------------------------------------------------------------------------------------------- ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- POST-REBUTTAL Response from R1: Thank you for taking the time and replying to comments.	misc
2020-1920	Here are my responses to authors' replies: [Authors' response:] 1.	rebuttal_process
2020-1920	Scalability: Our algorithm only adds a small computational overhead on top of Adam on a standard neural network.	rebuttal_process
2020-1920	This is what we mean by scalable.	rebuttal_process
2020-1920	The additional complexity scales cubically in M, the coreset size.	rebuttal_process
2020-1920	This is due to the inversion of the kernel in fr_grad.	rebuttal_process
2020-1920	Another overhead is the computation of Jacobian which is order PKM, where K is the dimensionality of the output and P is the number of network parameters.	rebuttal_process
2020-1920	Both of these additional costs are small for small coreset sizes M.	rebuttal_process
2020-1920	We will add these details to make these points clear in the paper.	rebuttal_process
2020-1920	[Reviewer's response:] I still insist on the fact that simply explaining the overhead of a method is not a support for scalability claim versus showing the performance on a large scale dataset and comparing it with other CL methods that also have high scalability given the fact that authors only use MNIST and CIFAR datasets.	rebuttal_process
2020-1920	[Authors' response:] 4. Prior work: We discuss other works in Section 1 ("two separate methods are usually used for regularisation and memory-building"), and we will expand upon this sentence, going into more detail, and also referencing iCaRL and other works (including [3]).	rebuttal_process
2020-1920	Note that our method of choosing a memorable past follows directly from the theory in Section 3.1, and is achieved with a single forward-pass through the trained network (as mentioned in the paper).	rebuttal_process
2020-1920	Other techniques for sample selection do not integrate so naturally with the framework, and are not as straightforward to understand or implement either.	rebuttal_process
2020-1920	[Reviewer's response:] I disagree with authors on this because GEM, its faster version (A-GEM (Chaudhry et al. 2018)), and all other methods explored in the recent study which I mentioned in my review (Ref#2) use the single epoch protocol and are perfect match to be compared with this method but there is no memory-based baseline except for VCL with coreset and FRCL (only for MNIST variations) which makes it difficult to measure this method's capabilities (performance, memory size, and computational time) against methods which only require one epoch to be trained.	rebuttal_process
2020-1920	Authors have provided FWT for their method as 6% which is unbelievably large for this metric (see GEM paper) and hence does not make sense to me.	rebuttal_process
2020-1920	Please double check whether you computed this value right.	suggestion
2020-1920	While I accept the response for the remaining questions from authors but I am still concerned about the weak experiments and an issue brought up by R3 regarding lack of enough comparisons with FRCL on any other datasets besides split MNIST and P-MNIST.	rebuttal_process
2020-1920	Also in  CIFAR experiment, what is the architecture used across the baselines?	rebuttal_process
2020-1920	More importantly in results reported for VCL on CIFAR, it is not clear to me how authors obtained this results.	weakness
2020-1920	Did they use a conv net?	weakness
2020-1920	VCL was originally shown on MLPs only and it is one of the downside of this method that was never shown to be working in convolutional networks.	weakness
2020-1920	Therefor, it is important to mention how they are obtained.	weakness
2020-1920	This might explain the reason for the huge forgetting reported for VCL with coreset (−9.2 ± 1.8) as opposed to −2.3 ± 1.4 for EWC which is really strange as VCL even without coreset (on permuted mnist for example) is reported superior to EWC by a large margin (6%) in the original VCL paper.	weakness
2020-1920	Overall I am concerned about the experimental setup and some of the reported results and hence intend to keep my score.	weakness
2020-1920	The paper proposed a new functional regularization method with gaussian process which has similar direction with recent two works (khan et al, titsias et al).	weakness
2020-1920	To perform functional regularization, they introduce small coreset which are selected from previous dataset instances, called memorable past.	abstract
2020-1920	They select most memorable samples depends on eigenvalue.	weakness
2020-1920	The model FROMP outperforms baselines and their ablations.	weakness
2020-1920	However, the experiments are only performed on shallow networks, it is required to apply on much deeper networks, such as ResNet.	weakness
2020-1920	Also, in the experiment results, I feel the performance of the FROMP largely depends on the number of the coreset, while 'important' selection just shows marginal effects even on split CIFAR.	weakness
2020-1920	FROMP show higher performance than FRORP with only a few of examples, but it isn't meaningful results that anyway the performances are too poor that are even worse than old baseline, EWC.	weakness
2020-1920	I have several wonderings on the paper.	misc
2020-1920	- How about of training time on FROMP?	weakness
2020-1920	I wonder if utilizing or selecting memorable pasts requires much time for training.	suggestion
2020-1920	- Is there an analysis like figure 1 on real dataset, such as MNIST or CIFAR?	weakness
2020-1920	Summary The paper proposes a method for continuous learning called Functional Regularization of Memorable Past (FROMP) which maintains the output distribution of models on memory samples.	abstract
2020-1920	FROMP uses the Laplace approximation and Gaussian process with neural tangent kernel (NTK) to approximate the output distribution.	abstract
2020-1920	According to the leverage score strategy, the sample to be stored is selected.	abstract
2020-1920	The leverage score strategy tends to select the sample of highest variances.	abstract
2020-1920	Strengths To some extent, I think the proposed method is novel, although there is a similar work named as Functional Regularisation for Continual Learning (FRCL).	strength
2020-1920	FROMP first uses NTK in Gaussian process for continual learning and proposes a new strategy of selecting memory samples.	strength
2020-1920	The strategy of selecting samples to be stored is simple and effective.	strength
2020-1920	The method achieves a good performance.	strength
2020-1920	The paper is clearly written and easy to follow.	strength
2020-1920	Weaknesses It needs more experimental comparisons between FROMP and FRCL, like adding comparison results of FROMP and FRCL for Split-Cifar.	weakness
2020-1920	Currently, this paper only shows the performance on Permuted MNIST and Split MNIST but those two benchmark are quite simple and also the improvement is limited.	weakness
2020-1920	The experimental section needs more detailed analysis.	weakness
2020-1920	At least, in current version, it is not clear how many tasks in Permuted MNIST.	weakness
2020-1920	The setting of hype-parameters for dropout are not provided.	weakness
2020-1920	Other comments In this paper, for Split MNIST experiment with multi-head, it shows that the method of EWC achieves worse results than SI.	weakness
2020-1920	However, in my experiment, the precision of EWC is at least larger than 97%.	weakness
2020-1920	In theory, I think they should have the similar performance and at least the discrepancy of accuracy between them is not as big as shown in this paper.	weakness
2020-1920	I expect authors could explain this point.	weakness

2020-1970	This paper presents a system for predicting evolution of graphs.	abstract
2020-1970	It makes use of three different known components - (a) Graph Neural Networks (GNN); (b) Recurrent Neural Networks (RNN); (c) Graph Generator.	abstract
2020-1970	A significant portion of the paper is spent in explaining these known concepts.	abstract
2020-1970	The contribution of the paper seems to be a system of combining these to achieve graph evolution prediction.	abstract
2020-1970	As stated, this system is effectively a recurrent auto-encoder of sorts.	abstract
2020-1970	The main objection I have in this paper is that they have only used two real datasets (both of which are from the same domain).	weakness
2020-1970	There are several only available datasets that have temporally annotated graph evolution.	weakness
2020-1970	It is not possible to conclude the empirical superiority of a system based on such little evidence.	weakness
2020-1970	This paper proposes a framework to model the evolution of dynamic graphs for the task of predicting the topology of next graph given a sequence of graphs.	abstract
2020-1970	Specifically, the paper uses a combination of recently proposed techniques in graph representation learning (Graph Neural Network) and Graph Generation (GraphRNN [You et.	abstract
2020-1970	al. 2018]). Given a sequence of graphs as input, a GNN (to obtain low-dimensional representations of the graphs in this sequence) and LSTM (to model the sequence of these representations)  based encoder is used to compute a vector representation of the topology of next graph in the sequence.	weakness
2020-1970	The learned vector is then used as input to a GraphRNN decoder to generate a graph that would serve as a predicted next graph in the sequence.	abstract
2020-1970	The proposed approach is validated with experiments on three synthetic datasets and one real-world dataset (Bitcoin is same dataset from two different resources with little difference in characteristics) and compared against random graph models.	abstract
2020-1970	This paper should be rejected due to following reasons: (1) The authors do not justify/discuss the motivation and importance of the task and corresponding applications that would require to predict topology of complete graph in the next step.	weakness
2020-1970	(2) The proposed techniques are an adhoc combination of existing techniques with major concerns (details below) but also with little novelty (if any) for achieving this combination.	weakness
2020-1970	(3) The empirical efforts are very limited and does not provide enough evidence about the efficacy of the method, miss several details and does not serve as motivation for designing such a method in first place.	weakness
2020-1970	Please note that negative results on cycle graphs has no role to play in this assessment.	weakness
2020-1970	In fact, I appreciate the authors for reporting negative results as it provides a transparent insights into the effectiveness of model in different settings.	strength
2020-1970	Overall, the paper needs lot of work on all aspects - motivation, technique and experiments to make it fit for a conference publication.	decision
2020-1970	Major Concerns: (a) Motivation: The authors do not discuss or motivate the problem and why it is important to the community.	weakness
2020-1970	The authors mention that many existing work on dynamic graphs focus on learning representations.	weakness
2020-1970	This is the case because learned representations can then be used for various downstream applications and even future event predictions.	weakness
2020-1970	When such methods can be used to do future predictions required for most applications, why does one need to predict the topology of complete next graph?	weakness
2020-1970	The authors need to provide concrete justification for the problem they address, instances where such a task would be useful and discussion on other techniques that can do similar tasks but lack in aspects that such a method can capture.	weakness
2020-1970	For instance, as a preliminary step, can the authors explain how solving this problem would be helpful to bitcoin?	weakness
2020-1970	(b) Technical: The technical contributions of this paper lack novelty and has several flows: - Figure 1 seems to show that graph only grows in size.	weakness
2020-1970	While the authors do provide an experiment with removal process, that experiment does not seem to perform well.	weakness
2020-1970	So, does the method is only good to support growing graphs?	weakness
2020-1970	- Authors mention that the edge and node attributes are considered to be fixed.	weakness
2020-1970	However, if the number of nodes and edges change, X and L should also change in terms of dimensions and adding values for new nodes/edges.	weakness
2020-1970	so why should it not be considered time-varying?	weakness
2020-1970	- What was the motivation for using GRU for update function in Eq 3?	weakness
2020-1970	Was simple MLP tried and not useful?	weakness
2020-1970	Was GRU used to capture some long term dependencies in structure?	weakness
2020-1970	If so, the authors must explain how it is useful for this task.	weakness
2020-1970	- Why Set2Set was used for ReadOut function?	weakness
2020-1970	This seems to be a particularly adhoc and odd choice.	weakness
2020-1970	when sum did not work well, jump to Set2Set is not justified.	weakness
2020-1970	Can the authors provide an explanation for the same?	weakness
2020-1970	- The authors claim that the embedding h_G_T incorporates topological information -- I find this claim highly unsubstantiated and needs justification.	weakness
2020-1970	For instance, can you provide some rigorous analysis to demonstrate that this is the case?	weakness
2020-1970	At the least, can the authors use this vector and pass it through a graph decoder to recover the original graph?	weakness
2020-1970	- What is novel in 3.2.3 as compared to You et.	weakness
2020-1970	al.? Infact, it is hard to see any novelty in the entire combination.	weakness
2020-1970	Was it challenging to achieve this combination?	weakness
2020-1970	If so, what was the challenging part?	weakness
2020-1970	It is not clear what the authors contributed to address such a challenge.	weakness
2020-1970	Was the training challenging? If so, please explain.	weakness
2020-1970	If not, why is this a novel approach?	weakness
2020-1970	(c) Empirical: The empirical efforts are inadequate and raises more questions than answers.	weakness
2020-1970	- Synthetic datasets are simple and more datasets should be used e.g. You et.	weakness
2020-1970	al. 2018 to validate the performance.	weakness
2020-1970	Only one real-world dataset from two different sources is used.	weakness
2020-1970	It is hard to understand author's motivation in doing so.	weakness
2020-1970	Why not use various graph datasets available in papers that learn representations (e.g. cited by authors themselves) What is special about bitcoin dataset that makes it suitable for this task?	weakness
2020-1970	- Node/edge attributes are chosen in adhoc manner and it is unclear what role they perform.	weakness
2020-1970	Do they help with prediction?	weakness
2020-1970	If not, would it be useful to first show experiments without them?	weakness
2020-1970	Or does this method absolutely need attributes?	weakness
2020-1970	It is not clear why it is useful to set all attributes for edge as 1.	weakness
2020-1970	- How was window size of 10 chosen?	weakness
2020-1970	Why is the same window size good for all graphs?	weakness
2020-1970	What impact does window size has on performance?	weakness
2020-1970	- What is the motivation for using Graph kernel for similarity?	weakness
2020-1970	The authors borrow the decoder from You et.	weakness
2020-1970	al. 2018 which also provides a principled method to compare graphs using MMD based on statistics.	weakness
2020-1970	Why not employ the same?	weakness
2020-1970	- GraphRNN (You et. al.) and other generative models can learn over multiple graphs?	weakness
2020-1970	Did the authors try to feed the sequence of graphs to such models and then try to generate a new graph to see if they can produce similar results?	weakness
2020-1970	It is true that those generative models do not specifically model temporal sequence, but such an experiment would help to distinguish the efficacy of the proposed method.	weakness
2020-1970	-The technique of using MLP for generating predictions using random graph models seem to be highly unfair for the baselines.	weakness
2020-1970	Can you elaborate more as it is difficult to understand why one should handicap those models by using learned information instead of data information?	weakness
2020-1970	- A rigorous discussion on insights explaining the results is required.	weakness
2020-1970	The authors show high performance on Bitcoin dataset.	weakness
2020-1970	However,  it is not clear what part is contributing to the performance.	weakness
2020-1970	Similarly, authors should dig deep into the failure cases and provide justification of why such a method would fail in particular cases and propose alternatives.	weakness
2020-1970	- Why was Graph size used as a statistic to report?	weakness
2020-1970	Two graphs of same size can be entirely different and I do not see any merit in using such a metric.	weakness
2020-1970	Again, something like MMD based metric may be useful.	weakness
2020-1970	Improvements that would make future revision strong but has not impacted current assessment: Overall, the presentation of the paper is very unpolished.	weakness
2020-1970	The authors are missing many important details as described above while spending a lot of time in describing (repeating) known techniques verbatim as original works.	weakness
2020-1970	This can be removed and condensed into very short preliminary section.	weakness
2020-1970	- Notations: The authors must use clear notations.	weakness
2020-1970	For instance, on Page 2, L is used to  describe edge attributes but then it is replaced by E in Page 3.	weakness
2020-1970	Also, both X and L are shown to have dimension d.	weakness
2020-1970	Are edge and node attributes of same dimension?	weakness
2020-1970	w is used for window-size of sequence used as input and also as neighbor node.	weakness
2020-1970	When modeling evolution of graphs where a sequence is available over time points 0...T, it is not useful to use T to also represent time step of GNN propagation.	weakness
2020-1970	Infact, authors should avoid using time steps to signify GNN iterations.	weakness
2020-1970	- Empirical details: The details provided for datasets and experimental setup is inadequate.	weakness
2020-1970	Why are the two Bitcoin datasets different from each other?	weakness
2020-1970	What does Pos. Edges in Table 1 mean?	weakness
2020-1970	What does  Mean and 90th percentile in Table 2 signify?	weakness
2020-1970	Authors only talk about train-test split but then mention validation set for hyper-param tuning.	weakness
2020-1970	How was this validation set obtained?	weakness
2020-1970	Also, what hyper-params were tuned and what was sensitivity of those hyper-params?	weakness
2020-1970	Authors use GNN and multiple RNN's, what was the model capacity used and how it impacted the performance?	weakness
2020-1970	Figure 5 (c) what is a circle graph?	weakness
2020-1970	In this paper, the authors propose a new neural network architecture for predicting the next graph conditioned on a past graph sequence.	abstract
2020-1970	It seems that the proposed model is the first deep learning model for graph sequence prediction.	weakness
2020-1970	The model consists of three major components: a graph encoder that maps a graph to an encoding represented as a vector, an LSTM for graph sequence embedding, and a graph decoder for generating an affinity matrix.	weakness
2020-1970	There are two main concerns I have with this paper: - The model has some inherent limitations in the graph embedding step.	weakness
2020-1970	First, the graph encoder embeds a graph into a feature vector that represents the topology of the graph.	weakness
2020-1970	I assume that the feature vector has a small size, and it is hard to encode a large graph (i.e. 1000x1000).	weakness
2020-1970	This representation is quite sub-optimal to me.	weakness
2020-1970	The model will not be able to utilize the complete information of a large dense graph.	weakness
2020-1970	Second, the model only takes 10 graphs as input and ignores other graphs in the input graph sequences.	weakness
2020-1970	This sounds suboptimal to me.	weakness
2020-1970	- The performance of the proposed model is not satisfactory.	weakness
2020-1970	The model does not output a graph with the right size for very simple synthetic graphs.	weakness
2020-1970	The model completely fails for generating circles.	weakness
2020-1970	A better model should be proposed to address this challenge.	suggestion
2020-1970	Evaluation is not convincing enough.	weakness
2020-1970	Simply comparing the graph size between the output and ground truth is not sufficient.	weakness
2020-1970	We can further predict where graph structure matches the ground truth exactly.	weakness
2020-1970	I believe this can be done for simple graphs like circles, paths, and ladders.	weakness
2020-1970	Other comments: - The authors claim that all the sequences in the datasets are fixed to 1000.	weakness
2020-1970	However, in Figure 4, the graph index goes up to 1600.	weakness
2020-1970	Why?	weakness

2020-1984	Summary: The paper proposes an autoencoder-based initialization for RNNs with linear memory.	abstract
2020-1984	The proposed initialization is aimed at helping to maintain longer-term memory and instability during training such as  exploding gradients (due to linearity).	abstract
2020-1984	Pros: 1. The paper is well written, the motivation and methods are clearly described.	strength
2020-1984	Cons. 1. The authors claimed the proposed method could help with exploding gradient  in training the linear memories.	weakness
2020-1984	It would be helpful to include some experiments indicating that this was the case (for the baseline) and that this method does indeed help with this problem.	suggestion
2020-1984	2. The experiments on the copy task only showed results for length upto 500, which almost all baseline models are able to solve.	weakness
2020-1984	I am not too sure how the proposed initialization helps in this case.	weakness
2020-1984	3. TIMNIT is a relatively small speech recognition dataset.	weakness
2020-1984	The task/ dataset does not require long-term memorization.	weakness
2020-1984	It is nice to see that the initialization helps in this case.	weakness
2020-1984	However, it is still a little how this experiment corresponds to the messsage that the authors are attempting to deliver at the end of the introduction.	weakness
2020-1984	4. In general, it seems that the experiments could be more carefully designed to reflect the contributions of the proposed method.	weakness
2020-1984	Some suggestions for future edits are, more analysis on gradients, maybe more experiments on the stability of training such as gradients could help.	suggestion
2020-1984	Minor: 1. There are some confusions, on P2 "we can construct a simple linear recurrent model which uses the autoencoder to encode the input sequences within a single vector", I think the authors meant encode the input sequences into a sequence of vectors?	weakness
2020-1984	Equation 1 and 2 suggest that there is a vector m^t per timestep (as oppose to having 1 for the entire sequence).	weakness
2020-1984	2. Although the copy task was used in ((Arjovsky et al., 2015), I believe the original task was proposed in the following paper and hence this citation should properly be the correct one to cite here,	weakness
2020-1984	Hochreiter, Sepp and Schmidhuber, Jürgen.	misc
2020-1984	Long short-term memory. Neural computation, 9(8): 1735–1780, 1997. Summary: This paper proposes a new initialization method for recurrent neural networks.	abstract
2020-1984	They first obtain the weight from a linear optimal autoencoder.	abstract
2020-1984	And then they use the weight to initialize the Lieanr Memory Networks(LMN).	abstract
2020-1984	Basically, this paper is a combination of [1] and [2].	misc
2020-1984	Strength: The method of initializing LMN using a linear RNN is natural and simple.	strength
2020-1984	(section 3.2) The proposed initialization outperforms the baselines on the MNIST dataset.	strength
2020-1984	Weakness: What do you mean by the "optimal autoencoder"?	weakness
2020-1984	The performance on TIMIT is worse than the baseline methods.	weakness
2020-1984	The scale of the experiments is too small.	weakness
2020-1984	Do you have any experiment results on any large dataset?	weakness
2020-1984	e.g. Penn Treebank. Reference: [1] Pre-training of Recurrent Neural Networks via Linear Autoencoders	misc
2020-1984	[2] Linear Memory Networks This paper proposes an initialization scheme for the recently introduced linear memory network (LMN) (Bacciu et al., 2019) and the authors claim that this initialization scheme can help improving the model performance of long-term sequential learning problems.	abstract
2020-1984	My concerns lie with the novelty of the proposed model and the insufficiency of the experiments.	weakness
2020-1984	First, the LMN seems to be a simpler version of LSTM and it has no significant advantages compared with other recurrent structures introduced in the past several years.	weakness
2020-1984	Second, the autoencoder-based init scheme (Pasa&Sperduti, 2014) is not new while the only technical contribution of this paper is a minor change of this scheme so that it works for the LMN.	weakness
2020-1984	In my opinion, combining these two (LMN and init scheme) can hardly be considered as a solid novelty contribution.	weakness
2020-1984	For the experiment part, the first two tasks are a bit toyish in 2019 and I have not seen any significant improvement gained from the proposed model.	weakness
2020-1984	Even for the TIMIT dataset, the results are a bit far from state-of-the-art which makes the paper's claim less convincing.	weakness
2020-1984	Overall I think the novelty contribution is marginal and I suggest the authors to test their models on larger-scale real problems.	weakness
2020-1984	The writing is clear and easy to follow.	strength

2020-1999	The paper introduces a problem "few-shot few-shot learning" that aims to firstly transfer prior knowledge from one domain to the domain where the base training tasks reside, and then train a few-shot learning model on training tasks and apply it to novel test tasks.	abstract
2020-1999	The two "few-shot" in the name refers to base training tasks and novel test tasks.	abstract
2020-1999	In their algorithm, they use a model pre-trained on another dataset as the prior knowledge and fine-tune it on training tasks.	abstract
2020-1999	During the test, they use the weighted average of samples' representations per class as the prototype of each class, where the weight is large for samples with more discriminative prediction over pre-trained domain's classes.	abstract
2020-1999	Afterward, classification is reduced to finding the nearest neighbor among the class prototypes.	abstract
2020-1999	Some experiments show that the pre-trained model can improve few-shot classification accuracy.	abstract
2020-1999	My major concerns: 1) They try to propose a new problem, but their description shows that the problem is exactly the same as what most "few-shot learning" works aim to solve: use a pre-trained model, train a meta-learner on few-shot training tasks, and apply it to novel test tasks.	weakness
2020-1999	2) The algorithm does not have any important contributions comparing to existing ones: they define a prototype per class based on the pre-trained model and apply the nearest neighbor classification.	weakness
2020-1999	The so-called "prototypical classifier" is actually the nearest neighbor classifier since no prototypical network structure is learned in the proposed method.	weakness
2020-1999	3) I would not call the weighted average as "attention" because it is not: the weight in attention is computed by a module with learnable parameters, while the weight in this paper is computed by the entropy of a pre-defined model's output prediction.	weakness
2020-1999	4) The "spatial attention" only makes sense when the pre-trained domain's classes can describe the main concepts appearing in the images of novel classes.	weakness
2020-1999	This assumption is too strong since it requires class-level (rather than lower-level) relationships.	weakness
2020-1999	5) The base training is not necessary in the algorithm: it is used to only fine-tuning theta and W.	weakness
2020-1999	As the author said in the beginning of Section 4.1, they can directly solve novel tasks based on the pre-trained model.	weakness
2020-1999	6) The experiments show that the pre-trained model is helpful in few-shot learning, which is a known fact.	weakness
2020-1999	7) The writing of this paper is very poor: a lot of typos and grammar errors, inconsistency between narratives, abuse of notations, wrong equation reference, even missing punctuations.	weakness
2020-1999	They make the paper hard to understand.	weakness
2020-1999	------------- Update: Thanks for the authors' rebuttal!	rebuttal_process
2020-1999	After reading their rebuttal, I still have main concerns about the novelty of the problem and the writing quality.	rebuttal_process
2020-1999	The proposed method tends to be incremental.	weakness
2020-1999	This paper proposed a new realistic setting for few-shot learning that we can obtain representations from a pre-trained model trained on a large-scale dataset, but cannot access its training details.	abstract
2020-1999	Also, there may be a large domain shift between the dataset of the pre-trained model and our dataset.	weakness
2020-1999	For the pre-trained model, they will not only use its weights but also use it to generate a spatial attention map and help the model focuses on objects of images.	weakness
2020-1999	Back to the standard few-shot classification problem, they will first adapt the model with base class samples and then adapt to novel classes.	weakness
2020-1999	The proposed new setting is very meaningful since we already have many powerful pre-trained models and why not exploit its usage for few-shot learning problems.	strength
2020-1999	However, I doubt the novelty and effectiveness of the attention way used in the paper.	weakness
2020-1999	The attention module helps the model focuses on the objects not the background, which is absolutely correct.	weakness
2020-1999	But there are already some relevant studies in the missing reference Large-Scale Long-Tailed Recognition in an Open World, CVPR2019.	weakness
2020-1999	Also, from the results, the significant improvements come from the weights of the pre-trained model but not the attention used.	weakness
2020-1999	Is the attention way used in the paper a good way to exploit the pre-trained model for few-shot classification problems?	weakness
2020-1999	Also, I am curious about the dense classification used in the adaptation phase.	weakness
2020-1999	Will it achieve similar performance with finetuning using just standard loss?	weakness
2020-1999	Btw, according to the formatting instructions, the abstract should be limited in one paragraph.	weakness
2020-1999	========================================================= After Rebuttal: I thank the author for the response.	misc
2020-1999	I do see there are differences in the way of generating attention masks between the proposed work and (Liu et al.).	rebuttal_process
2020-1999	But the improvements from the attention module is not significant, especially when using all base data.	weakness
2020-1999	I keep my original scores.	misc
2020-1999	A new task is suggested, similarly to FSL the test is done in an episodic manner of k-shot 5-way, but the number of samples for base classes is also limited.	weakness
2020-1999	The model is potentially pre-trained on a large scale dataset from another domain.	weakness
2020-1999	The suggested method is applying spatial attention according to entropy criteria (or certainty) of the original classifier (from a different domain).	weakness
2020-1999	I think the suggested task is important and more realistic than the usual FSL benchmarks.	strength
2020-1999	I would modify it so instead of discarding mini-imagenet classes that are overlapping with Places I would discard the problematic Places classes.	suggestion
2020-1999	This way it will be easier to compare to standard FSL.	suggestion
2020-1999	Also, I don't understand why for CUB the benchmarks includes k={0,1,5} while for mini-imagenet it is k={0,20,50}, obviously k={0,1,5} are more interesting.	weakness
2020-1999	As for the suggested method, I find it hard to judge since there are no strong baselines to compare against.	weakness
2020-1999	Also, the ablation study of removing the attention and/or adaptation doesn't result in a definitive conclusion.	weakness
2020-1999	Update: While your comments do weaken some of my concerns, I'm afraid it is not enough for changing my previous rating.	misc
2020-1999	I think being more careful about the benchmark definition with regards to train/test overlap and comparing to stronger baselines will help improve the paper for future submissions.	suggestion

2020-2003	The method proposes a method for continual learning.	abstract
2020-2003	The method is an extension of recent work, called orthogonal weights modification (OWM) [Zheng,2019].	abstract
2020-2003	This method aims to find gradient updates which are perpendicular to the input vectors of previous tasks (resulting in less forgetting).	abstract
2020-2003	However, the authors argue, that the learning of new tasks is happening in the solution space of the previous tasks, which might severely limit the ability to adapt to new tasks.	weakness
2020-2003	The authors propose a 'principal component'-based solution to this problem.	abstract
2020-2003	The method is considering the 'task continual learning' scenario (also known as task-aware) which means that the task label is given at inference time.	abstract
2020-2003	Conclusion: 1. The paper is not well-positioned in related works.	weakness
2020-2003	I think the work is more related to works with 'parameter isolation methods' such as Piggyback, Packnet, HAT.	weakness
2020-2003	These methods reserve part of the capacity of the network for tasks.	weakness
2020-2003	I think the authors should relate their work with these methods, and provide an argument of the problem with these previous methods, which is addressed by their approach.	suggestion
2020-2003	I can see that rather than freezing weights (PackNet) or features (HAT) , the method freezes linear combinations of features.	suggestion
2020-2003	But it is for me not directly clear that that is desirable.	weakness
2020-2003	In HAT the backpropagated vector is projected on the mask vector which coincides with the neurons (activations).	weakness
2020-2003	2. The experimental verification of the paper is too weak, and only comparison to EWC and OWM (not well known) are provided.	weakness
2020-2003	At least a comparison with the more related works PackNet and HAT should be included.	suggestion
2020-2003	For more recent method for task-aware CL see also 'Continual learning: A comparative study on how to defy forgetting in classification tasks'.	suggestion
2020-2003	Also results seem bad. For example on CIFAR10, 5 tasks in TCL setting is two-class problem per task; I would expect better results.	suggestion
2020-2003	3. The authors claim that OWM is effective if tasks are similar, but not when dissimilar.	weakness
2020-2003	And the proposed PCP solves this problem.	strength
2020-2003	However, all experiments are on similar tasks, and no cross domain tasks are considered, e.g. going from MNIST (task1) to EMNIST-26 (task2) etc.	weakness
2020-2003	This would empirically support the claim.	weakness
2020-2003	Also, the authors expect the difference between PCP and OWM to be even larger then.	weakness
2020-2003	4. Some more analysis of the success of PCA in representing the distribution would be appreciated, e.g. the percentage of total energy which is captured (sum of selected eigenvalues divided by sum of all eigenvalues).	suggestion
2020-2003	Such an analysis of P_l^k as a function of the tasks (and for several layers) would be interesting to see, for example for EMNIST-47(10 tasks).	suggestion
2020-2003	5. Novelty with respect to OWM is rather small.	weakness
2020-2003	6. The authors should mention that the method is pretrained on ImageNet in section 4.3.	weakness
2020-2003	Given these datasets, I think it makes more sense to train from scratch and I would like to see those results.	suggestion
2020-2003	Minor remarks: - I wonder if you use OWM or PCP you discard the possibility of positive backward transfer.	misc
2020-2003	Maybe the authors could comment on that.	suggestion
2020-2003	- The authors write that 'TCL setting the classification results are usually better than those of the CCL' is that not per definition true ?	weakness
2020-2003	Anything correctly classified under CCL is correctly classified under TCL but not the other way around.	weakness
2020-2003	This paper introduces Principal Components Projection, a method that computes the principal components of input vectors, using them to train on a transformed input space and to project gradient updates.	abstract
2020-2003	Experiments show improved results over OWM (the method that this paper builds on) and EWC.	abstract
2020-2003	If I understand correctly (which I think may not be the case), the principal component vectors are computed after the first forward/backward pass of each task, for the inputs to each layer (C_l^k).	abstract
2020-2003	These principal components are then fixed, the orthogonal projection matrix P_l^k is then found, and then normal training is iterated until convergence using this C_l^k and P_l^k.	abstract
2020-2003	Questions: - Seeing as (especially for the first task), weights are initialised randomly, why does this method provide reasonable principal components for layers after the first layer?	weakness
2020-2003	- I also do not understand why the dxd projection matrix P, which is orthogonal to all previous basis matrices C, has the property span(P^i) \\subset span(P^j) for i < j.	weakness
2020-2003	Surely as more basis matrices are found, then the orthogonal space restricts in size.	weakness
2020-2003	- I also do not understand Equation 1.	weakness
2020-2003	What is \\grad{W}? If it is, as defined 2 pages later, 'the backpropagation with respect to X_{k+1}' [or X_k here], then is Equation 1 saying that only one gradient step is used per task?	weakness
2020-2003	The experiments seem reasonable, except that there are no standard deviations on the results.	weakness
2020-2003	However, as far as I'm aware, these experimental protocols (dataset and model size) are not used in other papers: it would be nice to see experiments which match previous papers' protocols, for example with MNIST and CIFAR-10 at least (other papers use smaller model sizes).	weakness
2020-2003	As it is currently, I am unable to understand the paper despite spending some time trying to understand it.	misc
2020-2003	I am therefore giving the paper a weak reject.	decision
2020-2003	Hopefully the authors can answer my questions.	suggestion
2020-2003	Finally, some minor specific suggestions for improving the writing: - Immediately after Equation 12, there is \\grad{P^j} instead of \\grad{W^j}{P^{k-2}}	suggestion
2020-2003	- The paragraph before Equation 13 uses 't' instead of 'k' sometimes for task index	weakness
2020-2003	- Use `   not ' for open quotation marks This paper tries to solve the catastrophic forgetting issue in the continual learning problem.	abstract
2020-2003	The authors propose a method based on principal components projection to tackle this issue.	abstract
2020-2003	The authors conduct experiments on image classification tasks to show the performance of the proposed method and compare it with two other baselines EWC and OWM.	abstract
2020-2003	Strong points: 1. This paper tries to solve an important problem.	strength
2020-2003	2. The intuition of applying principal components projection is straightforward.	weakness
2020-2003	Weak points: 1. The most concerned point about this paper is the experiment.	weakness
2020-2003	It is not convincing. The authors claim that OWM is one of the strongest baselines, but actually it perform really badly on EMNIST-26 (5 tasks),  EMNIST-47 (5 tasks) and EMNIST-47 (10 tasks).	weakness
2020-2003	What is the reason? Is it because of insufficient parameter tuning?	weakness
2020-2003	If different methods perform differently on various datasets, it is really necessary to show more baseline methods to illustrate that the proposed method has universally good performance on different datasets.	weakness
2020-2003	2. It might strengthen the paper if the authors can show the comparison results on more other datasets, e.g., other image classification tasks.	suggestion
2020-2003	It would be better if the authors can show the proposed method can generalize to other tasks.	suggestion
2020-2003	3. The authors point out that one key drawback of OWM is that, if the tasks are not quite related, OWM may perform very badly.	weakness
2020-2003	Is this the case in the experiment?	weakness
2020-2003	4. It is not clear why the proposed method can solve the issue that OWM faces with (bad accuracy when tasks are not quite related).	weakness

2020-2015	The paper describes a new method called Atomic Compression Network for constructing neural networks.	abstract
2020-2015	The idea is straightforward. Basically, firstly create some neurons in random fashion, then reuse a subset of those neurons in each layer.	abstract
2020-2015	The experiments shows ACN produces better accuracy than baseline models including a FC network, a Baysesina compression method, etc.	abstract
2020-2015	for MINIST, etc. The paper also show ACN uses much less numbers of parameters and achieves similar accuracy when comparing with a large optima FC network on a set of datasets.	abstract
2020-2015	Overall, I don't support accepting this paper.	decision
2020-2015	First, I don't think the proposed idea is very innovative.	weakness
2020-2015	Please elaborate why this method seems to work well when comparing baseline models.	weakness
2020-2015	Is it just randomly constructed network also perform well?	weakness
2020-2015	Secondly, I'm not convinced we will use this method to build network in real world applications.	weakness
2020-2015	The model size is small, but in what cases this small model size matters?	weakness
2020-2015	Is this a reliable way to create useful models?	weakness
2020-2015	On page 7, in Figure 3, why logistic regression only has a single point in some of the plots?	weakness
2020-2015	This paper explores the use of replicating neurons across and within layers to compress fully connected neural networks.	abstract
2020-2015	The idea is simple, and is evaluated on a number of datasets and compared with fully connected, single layer, and several compression schemes.	abstract
2020-2015	Strengths: a lot of nice experiments with clearly advantageous results are given.	strength
2020-2015	Weaknesses: One obvious baseline missing is sparse compression, which can be achieved using either l1 regularization, or hard thresholding + fine tuning, both of which are easy to implement and appear in several works, e.g. Scalable Neural Network Compression and Pruning Using Hard Clustering and L1 Regularization (Yang, Ruozzi, Gogate)	weakness
2020-2015	Training skinny deep neural networks with iterative hard thresholding methods (Yin, Yuan, Feng, Yan)	misc
2020-2015	... many others just via googling ...	misc
2020-2015	Also, I think this work should be compared with compression schemes that work via kronecker product, which seem very similar to this scheme (but where the kronecker matrix is binary to produce replication)	weakness
2020-2015	Compression of Fully-Connected Layer in Neural Network by Kronecker Product (Zhou, Wu)	misc
2020-2015	(more via google) One obvious advantage of replication over kronecker product is lower complexity, but nonetheless, the methods belong in a similar family.	rebuttal_process
2020-2015	Otherwise, I think the work makes sense, the idea is nice, and the results show promise!	strength
2020-2015	After rebuttal: I have read the rebuttal and the authors have basically addressed all my concerns.	rebuttal_process
2020-2015	It is a bit disappointing that simple L1 regularization can give competitive results, but the fact that the authors are willing to do the experiment and incorporate the results convinces me that there's nothing being hidden here, and the reader can make a fair and informed conclusion, so I have no more complaints.	ac_disagreement
2020-2015	This paper proposes a new way to create compact neural net, named Atomic Compression Networks (ACN).	abstract
2020-2015	An immediate related work is LayerNet, where a deep neural net is created by replicating the same layer.	suggestion
2020-2015	Here, this paper extends replication down to the neuron level.	abstract
2020-2015	I am leaning towards rejecting this paper because the experimental setup is not well justified and a few important details are missing before conclusions can be drawn.	decision
2020-2015	I would like to ask a few clarification questions.	misc
2020-2015	Depending on the authors' answers, I might be willing to adjust my rating.	misc
2020-2015	(1) Is there missing a delta in the first half of line 6 in Algorithm 1?	weakness
2020-2015	(2) Throughout the experiments, for the same hyperparameter (e.g. Table 4 in A.2) do you run Algorithm 1 more than once and select the best sample architecture?	weakness
2020-2015	If the answer is yes, summarizing all masks as one parameter will not be reasonable.	weakness
2020-2015	Given a yes answer, I would also like to ask if the same number of samples have been considered for FC (for the same hyperparameter).	weakness
2020-2015	(3) Is there any intuition behind why FC does a much worse job of fitting curves than ACN with much less parameters?	weakness
2020-2015	This refers to Fig. 2, if we compare FC with 41 parameters to ACN with 18 parameters.	weakness
2020-2015	I am confused because MSE on sampled points often goes down when we increase the number of parameters for the application of curve fitting.	weakness
2020-2015	(4) Convolution can be thought of as a special case of ACN.	weakness
2020-2015	ConvNet is the default architecture for working on image datasets.	weakness
2020-2015	Since MNIST and CIFAR are considered, why not also compare to ConvNet?	weakness
2020-2015	(5) The claims that "ACNs achieve compression rates of up to three orders of magnitudes compared to fine-tuned fully-connected neural networks with only a fractional deterioration of classification accuracy" is quite misleading.	weakness
2020-2015	Given fully-connected neural networks achieve up to 528 times with also a fractional deterioration (Sec. 4.3), by presumably having a shallower architecture.	weakness

2020-2068	The work is based on the recent paper 'Proximal Backpropagation', Frerix et al., *CONF* 2018, which views error back propagation as block coordinate gradient descent steps on a penalty functional comprised of activations and parameters.	abstract
2020-2068	Instead of taking proximal steps on the linear layers as in (Frerix et al., 2018), the authors also pull the non-linearity \\sigma into the proximal steps.	abstract
2020-2068	Another interesting deviation is the idea to consider the newly updated weights {W_i}^{k+1} when updating the activations F_i^{k+1} in the backward pass.	abstract
2020-2068	While potentially offering a faster convergence with respect to epochs, the nonlinear updates have two major drawbacks: 1) While there are preliminary theoretical results (fixed points of the method are critical points), it remains unclear whether the computed update is still a descent direction on the original energy.	weakness
2020-2068	While not crucial, such a result would be reassuring and might give further insights into the method.	weakness
2020-2068	2) Each update requires the solution of a nonconvex, nonlinear least squares problem which is prohibitively expensive to solve.	weakness
2020-2068	Note that such nonlinear least squares updates are already proposed in (Carreira-Perpinan & Wang, 2014).	weakness
2020-2068	When using ReLU activation, the non smoothness might be an issue for standard nonlinear least squares solvers such as Levenberg-Marquadt.	weakness
2020-2068	Furthermore, the numerical results are unfortunately a bit discouraging.	weakness
2020-2068	The experiments evaluate toy models on toy datasets and even there only a minor improvement with respect to epochs over SGD and Prox-BP is shown.	weakness
2020-2068	Furthermore, the plots only consider epochs and not the running time.	weakness
2020-2068	Due to the non-linear least squares problem, I assume that each epoch for the proposed method is way more costly.	weakness
2020-2068	Therefore I consider the experimental evaluation too preliminary.	weakness
2020-2068	A proper evaluation would require an implementation as an optimizer in state-of-the-art deep learning frameworks and a comparison with respect to running time to standard optimizers such as SGD with momentum or Adam on the GPU.	weakness
2020-2068	The reported performances for MNIST are surprisingly poor.	weakness
2020-2068	Note that vanilla SGD with momentum reaches ~98.6% test set performance on such an architecture, while the overall highest reported accuracy in this paper is 98.0%.	weakness
2020-2068	This might be due to momentum, and it would be interesting whether the proposed method could be combined with momentum or other optimizers such as Adam as in (Frerix et al. 2018).	weakness
2020-2068	Overall, I don't see this a practical algorithm for training deep networks and there are few theoretical results.	weakness
2020-2068	Therefore, I cannot recommend acceptance at this stage.	decision
2020-2068	To improve the paper, I would like to see an implementation of the method on the GPU in a recent deep learning framework and an evaluation on larger models / datasets.	suggestion
2020-2068	But I am doubtful this will reach competitive performance to standard optimizers.	weakness
2020-2068	Also, it would be interesting to see how the precision in the inner nonlinear conjugate gradient solver effects outer convergence.	suggestion
2020-2068	It might be that the subproblem does not have to be solved with very high accuracy.	suggestion
2020-2068	Minor comments: * Missing citation: 'Difference Target Propagation', https://arxiv.org/abs/1412.7525, studies a similar type of algorithm.	weakness
2020-2068	The paper introduces a novel algorithm for computing update directions for neural network's weights.	abstract
2020-2068	The algorithm consists of the modified backpropagation procedure where a layer's error is computed using implicitly-updated weights.	abstract
2020-2068	The proposed idea is interesting, but its presentation and evaluation could be significantly improved.	weakness
2020-2068	First, it is not very clear what motivates the exact form of Semi-implicit BP.	weakness
2020-2068	Second, I find the notation a bit cumbersome, especially intermediate ^{k+1/2} updates.	weakness
2020-2068	I also suspect that eq.	weakness
2020-2068	9 contains an error, probably the l.h.s. of the first part should be \\delta_i^{k+1}?	weakness
2020-2068	Algorithm 1 is not very helpful because only the forward pass is explained in detail and a reader must refer to the main text to understand the backward pass.	weakness
2020-2068	The experimental evaluation also raises a number of questions.	weakness
2020-2068	1) Why did authors chose only one value of the learning rate and the lambda hyperparameter?	weakness
2020-2068	A more appropriate comparison would require slightly more extensive hyperparameter search as it may well be that ProxBP would work better with different values.	weakness
2020-2068	2) It is also unclear if 5 CG iterations is enough to solve the intermediate problem.	weakness
2020-2068	Also all convergence guarantees are only provided for the exact implicit update, so at least one should ensure it is computed well enough.	weakness
2020-2068	3) Isn't it suspucious that ProxBP performed so bad compared to other methods on MNIST?	weakness
2020-2068	4) Should not the set of baselines include more advanced optimizers such as RMSProp, Adam etc?	weakness
2020-2068	They don't seem to add more computational burden than Semi-implicit BP.	weakness
2020-2068	I also think it is worth discussing/investigating if the obtained update directions can be used in other gradient-based optimizers instead of pure gradients and if it can have any advantages.	weakness
2020-2068	Overall, it does not feel to me that the paper is ready for publication.	decision
2020-2068	This paper proposes an implicit update scheme for the back propagation a anlgorithm.	abstract
2020-2068	The idea is quite simple and is based on proximal mappings that lead to implicit update.	abstract
2020-2068	Specifically, every update in the back propagation algorithm is being replaced by an implicit update except for the intermediate parameters that receive a "semi-implicit" update.	abstract
2020-2068	The idea is reasonable and seems to lead to good performance.	strength
2020-2068	This is more-or-less expected thanks to the superior performance of implicit updates in general.	strength
2020-2068	So, it's good that the authors could make this work in the context of deep nets as well.	suggestion
2020-2068	Here are some more critical thoughts about the paper: 1) There is not much theoretical justification about the idea in the paper.	weakness
2020-2068	Proposition 1 is a simple argument about the fixed point of the procedure.	weakness
2020-2068	The argument could be made more rigorous, right now it is a bit of a sketch.	weakness
2020-2068	Apart from Proposition 1, there is no more theory offered.	weakness
2020-2068	The authors could appeal in the theory of implicit SGD for that, e.g., [1,2,3,4].	suggestion
2020-2068	This theory suggests a lot of stability properties for the implicit SGD update of Equation (27).	suggestion
2020-2068	2) Somewhat related to (1), the authors could make a more clear connection to prior work.	weakness
2020-2068	For example, there is not mention of a very similar idea of "implicit back propagation" [5].	weakness
2020-2068	Also the literature in implicit SGD procedures is highly relevant.	strength
2020-2068	3) Can we explain the results in Table 1 theoretically?	weakness
2020-2068	[1] Bertsekas, "Incremental proximal methods for large scale convex optimization.	misc
2020-2068	Mathematical programming", 2011 [2] Kulis and Bartlett, "Implicit online learning", 2010	misc
2020-2068	[3] Toulis and Airoldi, "Asymptotic and finite-sample properties of estimators based on stochastic gradients", 2017	misc
2020-2068	[4] Toulis, Airoldi, Rennie, "Statistical analysis of stochastic gradient methods for generalized linear models", 2014	misc
2020-2068	[5] Fagan and Iyengar, "Robust Implicit Backpropagation", 2018	misc

2020-2130	In this paper the authors propose a method for training neural networks using evolutionary methods.	abstract
2020-2130	The aim of developing this method is to provide a biological alternative to back-propagation.	abstract
2020-2130	The authors prove that their method converges and with high probability succeeds in learning linear classification problems.	abstract
2020-2130	Another method is also proposed which is linked to dopaminergic neurons.	abstract
2020-2130	In terms of presentation, the paper is generally clear and well-written.	strength
2020-2130	I was not able to assess the importance of the theoretical contributions of the work as my research is not in this area, so my comments are limited to the other aspects.	weakness
2020-2130	With regard to the biological plausibility of the method, it is unclear to me how the evolutionary method proposed here can enable learning in typical scenarios such as conditioning experiments in animals.	weakness
2020-2130	The learning processes in animals typically occurs in short time spans (for example a few training sessions for conditioning to stimuli predicting food/no food) and therefore I don't find it plausible to suggest evolutionary methods across generations are behind such forms of learning.	weakness
2020-2130	Perhaps what the authors have in mind applies more to other forms of behaviour such as innate and involuntary responses in animals formed across generations rather than ongoing updates in synaptic plasticity as an animal adjusts its behaviour using environmental feedback.	weakness
2020-2130	But then in this case the biological plausibility of the method seems fairly limited and not really an alternative to methods such as back-propagation.	weakness
2020-2130	The other biological aspect of the proposed work is the connection to dopamine and using the sign of gradients for updating the weights.	weakness
2020-2130	I think connecting the current learning rule to the activity of dopamine neurons requires quantitative comparisons with experimental data, otherwise although I agree that the method is biologically inspired, but whether it is biologically plausible is not clear.	weakness
2020-2130	Based on the above comments, I think the work will benefit from further developments before being ready for publication.	decision
2020-2130	First of all, I must confess that my knowledge is quite limited to read this paper.	weakness
2020-2130	Perhap the authors present something that I can not catch up at the present.	weakness
2020-2130	I conjecture the paper would like to bring the evolution in genetics and perhap brain cirecuits as well to define a novel neural net model, called NNE by the authors.	suggestion
2020-2130	The paper is somewhat cumbersome in the introduction that makes the reader (here is myself) can not understand the main idea.	weakness
2020-2130	At first the authors introduce about evolution in genetics and genomics that is a bit different from what I known.	rebuttal_process
2020-2130	Then the authors claim that they can show that the brain circuits can evolved in their model.	rebuttal_process
2020-2130	There are so many mistake and/or typos in sentences and in mathematical formulation.	weakness
2020-2130	These make me can not finish reading the paper.	weakness
2020-2130	I have to stop reading at the end of Section 2.	suggestion
2020-2130	Here are my concerns and questions: 1).	misc
2020-2130	What is "STDP" in the 2nd papragraph in Introduction?	weakness
2020-2130	2). in the 3rd papragraph in Introduction: "Suppose that the brain circuitry for a particular classiﬁcation task, such as "food/not food",is encoded in the animal's genes, assuming each gene to have two alleles 0 and 1".	weakness
2020-2130	This is realistics, the allels in animal is 0 1 or 2 if encoded.	weakness
2020-2130	3). The authors use the words "gene, genotype, phenotype" in a special way that is different to what I known in genomics (in GWAS).	weakness
2020-2130	4). in the 3rd papragraph in Introduction: "At each generation, a gene is an independent binary variable with ﬁxed probability of 1".	weakness
2020-2130	What do you mean by fixed probability of 1?	weakness
2020-2130	I can not understand in anysense that I know.	weakness
2020-2130	5). In Section 2, What is n?	weakness
2020-2130	the authors start the mathematical formulation but I can not find out what is n?	weakness
2020-2130	Is it the sample size?	weakness
2020-2130	6). In Section 2, paragraph 2, you define y~ \\mathcal{D}, BUT then in all formulas later you denote y ~ D.	weakness
2020-2130	What is D??? I can not understand. 7).	weakness
2020-2130	In Section 2, paragraph 2, you define a label of y as \\ell(y), BUT then in the 1st sentence of the 3rd paragraph in Section 2 you wrote    L(NNE_x(t), l(y)).	weakness
2020-2130	What is l(.) here ???	weakness
2020-2130	8). In the equations (1) and (2), what is p^t  ???	weakness
2020-2130	You have NOT defined it.	weakness
2020-2130	9). Right after equations (1) and (2), What is \\epsilon ????	weakness
2020-2130	Can NOt understand. 10). The sentence right after the equation (3): "This is the standard update rule in population genetics under the weak selection assumption." This is NOT trivial to me, and even the machine learning comunity, we do not know this rule, it is not obvious.	weakness
2020-2130	PLEASE provide exact reference. 11). the first equation in the PROOF of LEMMA 1 wrong  \\mathcal{L} (p^t)  should be equal to E_{x~p^t}  NOT p.	weakness
2020-2130	12). in the PROOF of Theorem 1, I can NOT find out where \\gamma has been defined?	weakness
2020-2130	13). What is d  in Theorem 2?	weakness
2020-2130	is it the dimension? I make too many guesses !!!	weakness
2020-2130	This paper argues that Artificial Neural Network (ANN) lack in biological plausibility because of the back-propagation process.	abstract
2020-2130	Therefore, the authors provide an alternative approach, named neural net evolution (NNE) that follows evolutionary theory.	abstract
2020-2130	This approach uses a large number of genotypes (in the form of vector with binary logits) that will evolve overtime during training.	abstract
2020-2130	It does not require to calculate the gradient explicitly.	weakness
2020-2130	The authors have conducted some experiments on MNIST using ANN with only one hidden layer.	abstract
2020-2130	The experimental results show that the NNE can learn the classification task reasonably well considering that no explicit back propagation is used.	abstract
2020-2130	I think overall the motivation to combine ANN with evolutionary theory is very interesting.	strength
2020-2130	The reviewer is not very familiar with evolutionary theory.	weakness
2020-2130	So I judge this paper in the perspective of machine learning, from which I think the current approach is a week variant of back-propagation that still relies on gradient (see detailed comments below).	weakness
2020-2130	Based on this, I give my rating.	decision
2020-2130	The approach is formulated as NNE_x(y) = (x^T)*(W^T)*y.	weakness
2020-2130	In traditional linear regression, W is the weight to be learnt.	suggestion
2020-2130	In this paper's formulation, W is named as a weight generation matrix, which is choosing to be random and i.i.d. with certain probabilities.	suggestion
2020-2130	The parameters to be optimized is x, which is named as a genotype that is viewed as a vector x \\in {0, 1}^n.	weakness
2020-2130	So first of all, as W is fixed so the formulation is very similar to a traditional linear regression with an additional linear transform.	weakness
2020-2130	The difference is that x is a binary vector with probabilities.	weakness
2020-2130	These probabilities are optimized over time.	weakness
2020-2130	From the Equations 1), 2) and 3), the probabilities are updated in a way to minimize the loss.	weakness
2020-2130	This is kind of similar to back-propagation.	weakness
2020-2130	Then the probabilities are updated and thus x is changed as well.	weakness
2020-2130	In my understanding, this is still gradient-based optimization.	weakness
2020-2130	I do not see it fundamental different to back-propagation.	weakness
2020-2130	This is my main concern about this work.	misc
2020-2130	I did not check the details of Theorem 1.	weakness
2020-2130	Could the authors please comment what is the purpose of Theorem 1 before proving it?	suggestion
2020-2130	This part is unclear to me in this paper.	weakness
2020-2130	One more question, for the W matrix,  the authors choice beta = 0.0025 in the experiment.	weakness
2020-2130	Is there any particular reason for this choice?	weakness
2020-2130	Or does it matter what value to choice as it is fixed anyway?	weakness

2020-2148	SUMMARY OF REVIEW This paper discusses an interesting problem of BO in the cases of robustness and antifragility to aleatoric noise/uncertainty.	abstract
2020-2148	To tackle this problem, the authors replace the conventional homoscedastic GP model with a heteroscedastic GP model.	abstract
2020-2148	In the case of robustness to aleatoric noise/uncertainty, the authors have modified EI by simply either scaling down [32] or subtracting from its value more when the aleatoric noise increases.	abstract
2020-2148	In the case of antifragility to aleatoric noise/uncertainty, they do the opposite.	abstract
2020-2148	The modifications of EI to handle robustness and antifragility to aleatoric noise/uncertainty are simple and straightforward, one of which is similar to the augmented EI of [32].	abstract
2020-2148	There are some technical ambiguities, as detailed below.	weakness
2020-2148	In particular, the choice of objective function (equation 9) for this problem needs to be justified and motivated by the practical applications described in Section 1.	weakness
2020-2148	Since no convergence guarantee is given, a more extensive empirical analysis with real datasets needs to be provided to better understand the performance and behavior of the proposed BO algorithms.	suggestion
2020-2148	In particular, though the authors have motivated their problem using the compelling applications of materials and drug discovery, no experimental result for these applications has been provided to support the motivation of this work.	weakness
2020-2148	DETAILED COMMENTS The authors seem to motivate the significance of their problem of interest through the key applications of materials and drug discovery which I can appreciate.	weakness
2020-2148	Unfortunately, experimental results in such applications were not available in this paper to "close the loop" in supporting the motivation of this work, begging the question whether their proposed BO algorithm indeed works for these key applications.	weakness
2020-2148	For example, why is the FreeSolv hydration energy dataset not used for your experiments?	weakness
2020-2148	For Fig. 1, how exactly do you extract the error magnitudes from the FreeSolv hydration energy dataset?	weakness
2020-2148	How do you exactly define the notion of calculated vs.	weakness
2020-2148	experimental uncertainties? Fig. 1 shows that the noise peaks with a relatively high frequency at a single error magnitude value.	weakness
2020-2148	Would the assumption of homoscedastic noise at this peaked value be detrimental to BO?	weakness
2020-2148	A sensitivity analysis would be useful here.	weakness
2020-2148	For the soil phosphorus fraction dataset (Fig. 2), the skewed distribution of the measurements (few extremely large measurements and many small-valued measurements) may not be due to heteroscedastic aleatoric uncertainty.	weakness
2020-2148	In fact, in the literature of earth/environmental science, such a dataset is often modeled using a log-Gaussian process (or log-normal kriging), that is, the log-measurements follow a GP: Webster, R., and Oliver, M.	weakness
2020-2148	2007. Geostatistics for Environmental Scientists. John Wiley & Sons, 2nd edition.	misc
2020-2148	Can the authors provide supporting evidence (in the form of references) that such a dataset is due to heteroscedastic aleatoric uncertainty?	misc
2020-2148	On page 4, step 2 of the most likely heteroscedastic GP algorithm [28] cannot be understood: What is E[x]?	weakness
2020-2148	Isn't G_1 a GP? Why is it able to accept x_i and D as inputs?	weakness
2020-2148	How is z_i defined? The authors say that "A note on the form of this variance estimator is give in Appendix B." There is no Appendix B.	weakness
2020-2148	Can the authors give a detailed discussion why is the expression of f(x) = g(x) + s(x) in equation 9 the right one to be minimized in practice (e.g., in the context of materials and drug discovery)?	suggestion
2020-2148	For example, do material scientists use such an objective function?	suggestion
2020-2148	Provide references. Furthermore, why is the same equation 9 being minimized for both the cases of robustness and antifragility to aleatoric uncertainty?	weakness
2020-2148	Caption of Fig. 3: I can't understand the sentence: "The combined objective, which when optimised maximises the sin wave subject to the minimisation of aleatoric noise".	weakness
2020-2148	This was repeated in Section 5.5: "finds the first maximum as that which minimises aleatoric noise".	weakness
2020-2148	Isn't the minimum of the aleatoric noise at the origin (Fig. 3b)?	weakness
2020-2148	Can the authors provide information on how much initial data was provided prior to running BO?	weakness
2020-2148	How much data is used for learning the GP hyperparameters?	weakness
2020-2148	The performance advantage of heteroscedastic ANPEI over homoscedastic does not appear to be significant for Branin-Hoo function (Figs.	weakness
2020-2148	5b and 6b). Can the authors explain this?	weakness
2020-2148	Minor issues There are two different font types of x in bold.	weakness
2020-2148	Page 5: fixed aleaotric Which phrase is correct?	weakness
2020-2148	"is obtained by subtracting the noise function from the 1D sinusoid" in the caption of Fig. 3 or "The objective function in all cases is the principal objective g(x) minus one standard deviation of the ground truth noise function s(x)"?	weakness
2020-2148	Fig. 5b: Shouldn't the vertical axis be labeled as ...+ Noise?	weakness
2020-2148	Fig. 6a: Shouldn't the vertical axis be labeled as ...- Noise?	weakness
2020-2148	The main contribution of this paper are: 1. The use of a heteroscedastic GP when performing Bayesian Optimization, this is in contrast to the more common practice of assuming homoscedastic noise, even when this does not quite fit the data.	strength
2020-2148	They use the existing algorithm called most likely heteroscedastic GP, and quote previous work that performed BO using different heteroscedastic GP implementations.	strength
2020-2148	2. They introduce two new acquisition functions that incorporate the predicted observation noise, either making candidates more likely or less likely to be chosen when predicted noise is higher, depending on the requirements.	strength
2020-2148	This are fairly minor extensions/heuristics if taken on their own, as they do not provide a very strong motivation indicating why these acquisition functions are useful or better than existing ones, other than that they take heteroscedasticity into account.	weakness
2020-2148	3. They run a set of experiments on the above settings.	weakness
2020-2148	Unfortunately the experiments are very limited, and their method does not improve on the baselines in a statistically significant way.	weakness
2020-2148	Two of the experiments are on simple synthetic settings, the third approximates a real world setting, although the approximation is quite rough and they don't convincingly argue for it being realistic, neither do they give convincing motivation of their objective which uses g +- standard deviation.	weakness
2020-2148	4. They provide source code of their implementation.	weakness
2020-2148	The paper is easy to understand, and covers an interesting topic, so while I don't think it meets the bar of *CONF* (due to lack of convincing and non-trivial contributions) I think it could perhaps be made into a workshop submission with some of the following changes: * A wider set of experimental settings, and more replication such that any differences become statistically significant.	decision
2020-2148	It would also be worthwhile comparing to random search.	suggestion
2020-2148	* A better justification of the objective used in the experiments, using g +- the standard deviation appears fairly arbitrary, and there is no strong enough reason to believe this is a good approximation of what the cost is in the case of real world problems.	weakness
2020-2148	* Better theoretical justification of the acquisition function; one option is to introduce more principled acquisition function like, say, expected upper/lower bound.	weakness
2020-2148	Other notes/comments: abstract: as well as a real-world -> as well as *on* a real-world...	weakness
2020-2148	section 1 "As a case study" -> not very clear what this means incumbent best is not well defined, is it the empirical value of f used or the mean predicted f on the evaluated candidates?	weakness
2020-2148	section 6.2 "outperforms" -> this is not clear if one looks at the confidence intervals in the results The paper considers the heterogeneous noise in Bayesian optimisation.	weakness
2020-2148	The paper utilised the existing heterogeneous Gaussian process to model the surrogate function and proposes two acquisition functions from the Expected improvement to deal with such heterogeneous noise.	weakness
2020-2148	The proposed acquisition function is heuristic and straightforward from the existing ones, ie.	weakness
2020-2148	augmented EI and EI. I would not count this as much in terms of novelty.	weakness
2020-2148	The idea of dealing with heterogeneous noise in BO is interesting.	strength
2020-2148	The related background in Gaussian process is standard and could be omitted.	strength
2020-2148	The experimental section is weak.	weakness
2020-2148	The experiments are demonstrated using low dimensional functions (1-2 dim).	weakness
2020-2148	The experiment needs to compare with Random baseline.	weakness
2020-2148	Under the noise setting, the Random approach performs very competitive to BO.	weakness
2020-2148	The y-axis in the experiment, the paper has considered the objective function value + noise.	weakness
2020-2148	The reviewer suspects that the high/low performance is due to the high level of noise (?) rather than the better objective function value.	weakness
2020-2148	The released source code includes the Lidar, Scallop, Silverman datasets, but not the PHOSPHORUS soil.	weakness
2020-2148	I would encourage the authors to check the source code before releasing.	decision
2020-2148	The paper focuses on demonstrating the heteroscedasticity in the surrogate model using [1].	weakness
2020-2148	The reviewer is wondering what is the performance for other heteroscedastic GP approaches, such as [2,3,4] ?	weakness
2020-2148	Minor points: Page 4, step number 2, what is zi and how can we get it in a new dataset D'.	weakness
2020-2148	[1] Kersting, Kristian, et al. "Most likely heteroscedastic Gaussian process regression." Proceedings of the 24th international conference on Machine learning.	misc
2020-2148	ACM, 2007. [2] Le, Quoc V., Alex J.	misc
2020-2148	Smola, and Stéphane Canu. "Heteroscedastic Gaussian process regression." Proceedings of the 22nd international conference on Machine learning.	misc
2020-2148	ACM, 2005. [3] Binois, M., Gramacy, R.	misc
2020-2148	B., & Ludkovski, M. (2018). Practical heteroscedastic gaussian process modeling for large simulation experiments.	misc
2020-2148	Journal of Computational and Graphical Statistics, 27(4), 808-821.	misc
2020-2148	[4] Lázaro-Gredilla, M., & Titsias, M.	misc
2020-2148	K. (2011, June). Variational Heteroscedastic Gaussian Process Regression.	misc
2020-2148	In ICML (pp. 841-848).	misc

2020-2153	This paper studies the theoretical aspects of HRL.	abstract
2020-2153	It provides theoretical analysis for the complexity of Deep HRL.	abstract
2020-2153	The idea is to exploit a given action hierarchy, and known state decomposition, the fact that the high-level state space shares similar low-level structures.	abstract
2020-2153	The final result is an exponential improvement of HRL to flat RL.	abstract
2020-2153	Overall, the paper pursues an ambitious goal that analyses the complexity of Deep HRL.	abstract
2020-2153	The writing is not easy to follow.	weakness
2020-2153	I some questions and concerns as follows	misc
2020-2153	- I wonder why the state space must be defined in a product form?	weakness
2020-2153	If a standard RL is used, then it could be applied directly to the state space (SL) on that primitive actions operate.	weakness
2020-2153	Hence L-1 state spaces will be discarded?	weakness
2020-2153	I don't see why a flat RL must estimate policies for states at all levels.	weakness
2020-2153	It looks like many later derivations based on the assumption of factored state spaces and factored transitions on different levels.	weakness
2020-2153	In the case of factored representation, the authors should make clear assumptions and find a better way to describe the overall algorithm.	weakness
2020-2153	- Section 3.2: the authors use time index for Q and V, does that mean all analysis is for non-stationary MDPs?	weakness
2020-2153	This is not the assumption in Jaksch et al. (2010) and this paper.	weakness
2020-2153	The description in this section is very confusing and contains a lot of imprecise definitions e.g. should H = \\prod {i=1} H_i??	weakness
2020-2153	is h =(h_1,...h_L) not in [1,H]?	weakness
2020-2153	what is the definition of the immediate next lexicographical tuple?	weakness
2020-2153	etc. The definition of \\sigma is also unclear and hard to understand.	weakness
2020-2153	- The analysis in Section 4.	weakness
2020-2153	and Algorithm 1 are not for Deep HRL as said in Abstract and Introduction.	weakness
2020-2153	The analysis is based on PAC-MDP learning for models at each action level.	weakness
2020-2153	This paper's contributions might be clearer if the authors made clearer assumptions, e.g. on action hierarchy, abstract state space structures etc..	suggestion
2020-2153	This paper proposes a new kind of episodic finite MDPs called "deep hierarchical MDP" (hMDP).	abstract
2020-2153	An L-layer hMDP can be *roughly* thought of as L episodic finite MDPs stacked together.	abstract
2020-2153	A variant of UCRL2 [JOA10] is proposed to solve these hMDPs and some results from its regret analysis are provided.	abstract
2020-2153	Pros: 1. The essential result (Theorem 4.1) on the regret bound of the proposed algorithm seems correct.	strength
2020-2153	I have not checked the proofs in detail but in part because it does not seem surprising and that a precise assessment is hindered by many typos (see Min2 and Con2).	weakness
2020-2153	Cons (in descending order of their weights in my decisions): 1. The proposed hMDPs do _not_ seem to capture important features or challenges in hierarchical RL.	weakness
2020-2153	My understanding is that the transitions in hMDPs work _like_ a clockwork (more on this in Mis6), the algorithm interacts with the sub-MDPs at each layer in turns according to their fixed horizons H_l's.	weakness
2020-2153	This structure is very rigid temporally and seems to exclude the mentioned example of autonomous driving: the number of decision steps between intersections would be fixed.	weakness
2020-2153	2. There are many (typographical) errors in both the text and mathematical expressions.	weakness
2020-2153	Some of them are more severe than others hindering understanding.	weakness
2020-2153	3. Possible as a consequence of Con2, some quantities defined seem unclear or incorrect at worst.	weakness
2020-2153	For example, the "standard regret" defined in (2) is an expectation, not a random variable as in convention.	weakness
2020-2153	4. There are some notable deviations from similar settings in prior works.	weakness
2020-2153	They might be worthwhile innovations but their significance or motivations is omitted.	weakness
2020-2153	For example, the rewards in hMDPs are defined as a function of the full state, i.e. in general not decomposable to rewards on the states of each layer, yet the analogy for hMDP is "L levels of episodic MDPs."	weakness
2020-2153	A non-exhaustive list of obvious mistakes/typos: 1. In the title, "Provably" -> Provable.	weakness
2020-2153	2. In the abstract, "often both" -> often requires both.	weakness
2020-2153	3. In Organization, "theoremm" -> theorems.	weakness
2020-2153	4. In Section 2, "between exploration" -> between exploration and exploitation.	weakness
2020-2153	5. Above Section 3, "carried" -> carried out.	weakness
2020-2153	6. Below (1), "amount reward" -> amount of reward.	weakness
2020-2153	7. The definition of horizon H is incorrect.	weakness
2020-2153	Consider H_1 = 2 and H_2 = 3, the algorithm will interact with the sub-MDPs in the following order within one episode: 1, 1, 2, 1, 1, 2, 1, 1, 2.	weakness
2020-2153	There are 9 steps not 6 = 2 * 3 as defined.	weakness
2020-2153	8. Section 3.3, "able accumulate" -> able to accumulate.	weakness
2020-2153	9. Section 3.3, the definition of V_h^\\pi, there should be not \\max.	weakness
2020-2153	10. (5), "H" -> H - h.	misc
2020-2153	11. Section 6, "tabular R" -> tabular RL.	weakness
2020-2153	12. In References, "Posterior sampling for reinforcement learning: worst-case regret bounds" -> Optimistic posterior sampling for reinforcement learning: worst-case regret bounds.	misc
2020-2153	13. In References, "Temporal abstraction in reinforcement learning" should be cited as a PhD thesis.	weakness
2020-2153	Some other possible errors/inconsistencies: 1. Related work listed regret bounds from prior works (the presentation closely mirrors that of [JABJ18]) assume an episodic MDP with non-stationary transitions, i.e. P_t ≠ P_{t'} in general.	weakness
2020-2153	However, in 3.1 the transitions are stationary.	weakness
2020-2153	Relatedly, regardless of the stationarity of the transitions, there may not be an optimal _stationary_ policy in an episodic MDP contrary to the claim in the paper.	weakness
2020-2153	2. Indexing seems inconsistent near the top of page 3.	weakness
2020-2153	The initial state is s_0 but the trajectory starts with s_1.	weakness
2020-2153	3. Near the top of page 3, V_h^\\pi and Q_h^\\pi should sum from h'=h, not h'=1.	weakness
2020-2153	I assume that the authors intend to define h-step values (to appear in the Bellman equations).	weakness
2020-2153	4. Section 3.3, what are the k's in the equations?	weakness
2020-2153	5. (6), what is n(k-1, e)?	weakness
2020-2153	Minor (factored little to none in my decision): 1. The claim in Introduction that some games "do not require high-level planning" while others do is highly speculative and vague.	weakness
2020-2153	Note that any policy can be written a function with codomain in the primitive actions.	weakness
2020-2153	In fact, many people thought to solve a game like chess or Go requires some temporal hierarchy (opening, mid-game, and end-game).	weakness
2020-2153	2. The comparison to running UCRL2 on hMDP ignoring the given structure seems weak.	weakness
2020-2153	Given the knowledge of the particular clockwork-like structure of hMDP at each layer (horizons, states, actions), the natural attempt would be run O(L) copies of UCRL2, one for each sub-MDP (under different terminating states of the immediately lower sub-MDP).	weakness
2020-2153	Frankly, in my understanding, that seems to be roughly what the authors propose as the solution (thus the results unsurprising).	weakness
2020-2153	Moreover, it is not immediately clear that UCRL2 can apply to the proposed setting of hMDP without checking regular conditions like communicating (diameter being finite).	weakness
2020-2153	3. The claim that RL with options "can be viewed as a two-layer HRL" needs much elaboration if not correction.	weakness
2020-2153	Note that in the former, primitive actions are always taken in the original MDP at consecutive steps.	weakness
2020-2153	4. There is a limited relevance to deep learning or deep RL central to the themes at *CONF*, i.e. the general issue of representation.	weakness
2020-2153	This work may be more suitable for other general ML venues.	decision
2020-2153	Some suggestions I agree with the authors' sentiment that our theoretical understanding of hierarchical RL is relatively limited.	weakness
2020-2153	I applaud the authors' effort to address this limitation.	rebuttal_process
2020-2153	But judging from this aim of advancing our theoretical understanding, I think the paper may be improved by	suggestion
2020-2153	1. better articulating the motivations for hMDPs (concrete examples would help)	weakness
2020-2153	2. contextualizing hMDPs with respect to other well-known models such as semi-MDPs (technical and precise comparison would help).	weakness
2020-2153	To put it in a different way, it is unclear to the readers why we want to solve this special class of hMDPs and what does hMDPs have to do with the general issues in hierarchical RL.	weakness
2020-2153	Technically, I feel that assuming episodicity seems against the spirit of hierarchical RL where subtasks are often delimited by their subgoals instead of durations.	weakness
2020-2153	In conclusion, I cannot recommend accepting the current article.	decision
2020-2153	(To authors and other reviewers) Please do not hesitate to directly point out my misunderstandings if there is any.	suggestion
2020-2153	I am open to acknowledging mistakes and revising my assessment accordingly.	misc
2020-2153	Post-rebuttal update: Thank you for replying to my review and incorporating some of my suggestions into your revision.	misc
2020-2153	However, I found many concerns (and mistakes) unaddressed, such as Mis7.	weakness
2020-2153	The use of driving in Manhattan as an example troubles me because even stopping for a traffic light seems to disrupt the fixed temporal hierarchy of decisions.	weakness
2020-2153	In conclusion, I will maintain my recommendation.	decision
2020-2153	This paper performs a regret analysis for a new hierarchical reinforcement learning (HRL) algorithm that claims an exponential improvement over applying a naive RL approach to the same problem.	abstract
2020-2153	The proposed algorithm and the regret analysis performed seem rigorous and well-thought out.	strength
2020-2153	However, I think that this paper should be rejected because	decision
2020-2153	(1) the algorithm does not appear to be a substantial improvement over existing algorithms,	weakness
2020-2153	(2) the paper makes strong claims about an exponential improvement over standard RL, but doesn't provide a strong benchmark to compare to, and	weakness
2020-2153	(3) the paper is imprecise and unpolished, with many grammatical errors.	weakness
2020-2153	I would be open to reconsidering my score if a) the authors submit a revised version with significantly cleaned up text, and b) if the authors could provide more information about how their contribution compares to the existing literature.	suggestion
2020-2153	Main argument The paper would benefit from establishing stronger context for the central contributions of their paper.	weakness
2020-2153	For instance, the paper begins by contrasting HRL approaches with a number of standard RL algorithms, saying that approaches such as AlphaGo do not require high-level planning.	weakness
2020-2153	This seems surprising; many RL researchers would describe MCTS (the base of the AlphaGo algorithm) as performing planning.	weakness
2020-2153	It would be great if the authors could go into more detail as to what they view as planning, and why AlphaGo does not do so.	suggestion
2020-2153	Additionally, the main comparison the authors seem to make is between HRL and naive RL, which does not provide sufficient context to properly analyse their algorithm.	weakness
2020-2153	Many algorithms are better than applying a classical RL algorithm naively.	weakness
2020-2153	As such, it is not sufficient to show that the algorithm proposed by the authors is stronger than a naive approach; it would be better to compare the algorithm to either a) the state of the art (SOTA) approach, or b) a more credible approach than the naive one.	weakness
2020-2153	Experimental evidence would help. One point of comparison is Fruit et al. (2017), which is mentioned as another paper which carries out a regret analysis in a HRL setting.	weakness
2020-2153	Fruit et al. (2017) contains a number of simple numerical simulations; a similar effort here would help.	weakness
2020-2153	Another issue is that the paper is confusing, with systematic grammar errors and typos.	weakness
2020-2153	The paper would benefit significantly with some copy-editing/proofreading by a native English speaker.	suggestion
2020-2153	For instance, the title should (presumably) read "Provable Benefits of Deep Hierarchical RL." Such errors appear throughout the paper.	suggestion
2020-2153	Fixing them would make the paper much easier to understand.	suggestion
2020-2153	Finally, although this did not factor into the score I awarded the paper, the terminology used by the authors is confusing, referring to their setting as "Deep Hierarchical Reinforcement Learning."	weakness
2020-2153	"Deep Reinforcement Learning" is a widely used term in industry, referring to algorithms that apply Deep Learning to RL problems, such as AlphaGo or DeepStack.	weakness
2020-2153	I would encourage the authors to use a different term to describe the setting.	suggestion
2020-2153	Questions to the authors: 1) In what way is AlphaGo not doing planning?	weakness
2020-2153	What is an example of an algorithm that does planning in a standard RL setting?	weakness
2020-2153	e.g. what would planning look like in Go?	weakness
2020-2153	2) Did you run any experiments/simulations of your work?	weakness
2020-2153	If not, why not? 3) Can you elaborate on what a classical RL algorithm would look like that would serve as a proper benchmark to this algorithm?	suggestion
2020-2153	4) In your mind, what is the SOTA algorithm for your setting?	suggestion
2020-2153	5) What are some simple domains that your algorithm would apply to?	suggestion
2020-2153	[0]: Moravčík, Matej & Schmid, Martin & Burch, Neil & Lisý, Viliam & Morrill, Dustin & Bard, Nolan & Davis, Trevor & Waugh, Kevin & Johanson, Michael & Bowling, Michael.	misc
2020-2153	(2017). DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker.	misc
2020-2153	Science. 356. 10.1126/science.aam6960.	misc

2020-2174	This paper purposes to cluster data in an unsupervised manner that estimates the distribution with GMM in latent space instead of original data space.	abstract
2020-2174	Also, to better describe the distribution of latent code, the authors involve VIB to constraint the latent code.	abstract
2020-2174	The whole pipeline is clear and makes sense.	strength
2020-2174	And the experiment proves it's effective.	strength
2020-2174	However, in my eyes, it's almost like an extension of VaDE which combines VIB and GMM too.	weakness
2020-2174	The main difference is the authors use some hyperparameters to control the optimization of the whole model and make some more proper hypothesis.	weakness
2020-2174	All of those make sense but may not contribute much to the research field.	weakness
2020-2174	This paper considers the autoencoder model combining the usual information bottleneck and the Gaussian mixture model (GMM).	abstract
2020-2174	Using an approximation to deal with GMMs, the authors derive a bound on the cost function generalizing the ELBO.	abstract
2020-2174	The performance of the proposed method is tested on three benchmark datasets and compared with existing methods combining VAE with GMM.	abstract
2020-2174	While the framework and the performance of the proposed method are interesting and promising, some of its main parts are unclearly explained.	weakness
2020-2174	- Although Remark 1 well explains the difference between VaDE and the proposed objective functions, little is discussed how this difference affects the learnt model.	weakness
2020-2174	- I wonder why Q_\\phi(x|u) in Eq.	weakness
2020-2174	(11) doesn't have to be a distribution.	weakness
2020-2174	What does the expression [\\hat{x}] mean?	weakness
2020-2174	- Eq. (17) is not explained clearly.	weakness
2020-2174	Since the equality symbol is used, it is unclear where is approximation.	weakness
2020-2174	Although this approximation is one of the main parts of the proposed method, little is discussed on the influence of this approximation.	weakness
2020-2174	- Are the information plane and latent representations in Figs 5 and 6 also available for DEC and VaDE and not limited to the proposed method?	weakness
2020-2174	Minor comments: p.5, the math expression between Eqs.	suggestion
2020-2174	(16) and (17): The distribution q(x_i|u_i,m) is undefined.	weakness
2020-2174	p.6, l.4 from the bottom: ACC is defined later.	weakness
2020-2174	p.7, l.14: Should J be n_u?	weakness
2020-2174	The author(s) posit a Mixture of Gaussian's prior for a compressed latent space representation of high-dimensional data (e.g. images and documents).	abstract
2020-2174	They propose fitting this model using the Variational Information Bottleneck paradigm and explicate its derivation and tie it to the variational objective used by similar models.	abstract
2020-2174	They empirically showcase their model and optimization methodology on the MNIST, STL-10, and Reuters10k benchmarks.	abstract
2020-2174	The idea of using a latent mixture of Gaussian's to variationally encode high-dimensional data is not new.	weakness
2020-2174	The author(s) appropriately cite VaDE (Jiang, 2017) and DEC (Xie, 2016), "Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders" (Dilokthanakul, 2017).	weakness
2020-2174	However, the author(s) unfortunately did not mention "Approximate Inference for Deep Latent Gaussian Mixtures" (Nalisnick, 2016).	weakness
2020-2174	Nalisnick et al. consider the exact generative process as the proposed by the author(s), but with the addition of a Dirichlet prior on the Categorical distribution.	weakness
2020-2174	Nalisnick et al. fit their model with a VAE and circumvent Dirichlet intractability by positing a Kumarswamy stick-breaking variational posterior (the resulting distribution is on the simplex).	weakness
2020-2174	They achieve 91.58% accuracy, but do so after fitting a KNN to the latent space.	weakness
2020-2174	New techniques such as "Implicit Reparameterization Gradients" (Figurnov, 2018) and "Pathwise Derivatives Beyond the Reparameterization Trick" (Jankowiak, 2018) allow direct use of a Dirichlet posterior in VAEs.	weakness
2020-2174	These methods are respectively implemented in the TensorFlow and PyTorch APIs.	weakness
2020-2174	My point here is that there are many ways to fit this pre-existing model.	weakness
2020-2174	From my review of these other works we have, for "best run" on MNIST, that author(s) > VaDE > Nalisnick > Dilokthanakul > DEC.	weakness
2020-2174	Thus, the author(s) are SoTA for this particular generative process for their best run.	weakness
2020-2174	It would be nice to see their standard deviation to gauge how statistically significant their results are.	suggestion
2020-2174	However, I am dubious of the SoTA claim as I detail later.	weakness
2020-2174	The author(s) derivation was sound, but a bit confusing for me.	weakness
2020-2174	In particular, I found keeping track of P's and Q's very burdensome after reading sections 2.1 and 2.2.	weakness
2020-2174	In my experience, Q is typically reserved for a variational distribution that approximates some intractable P distribution, while P is used to describe the generative process (i.e. likelihood) and other exact distributions.	weakness
2020-2174	Furthermore, one typically introduces the generative process first using P distributions.	weakness
2020-2174	Once, I got past this confusion everything else made sense.	weakness
2020-2174	I might suggest introducing the generative process first and with P distributions instead of Q's.	suggestion
2020-2174	The variational model can follow with the Q distributions as the author(s) have it.	suggestion
2020-2174	Equations 4, 5, and 6 all exactly match the unsupervised information bottleneck objective (Alemi, 2017)--see appendix B.	suggestion
2020-2174	I am therefore confident in those equations.	strength
2020-2174	I carefully checked their derivation of the VADe comparison (equation 10 and appendix B).	suggestion
2020-2174	Their derivation is straightforward. The principle trick is using the MC assumption C->X->U for P distributions to claim p(u|x,c) = p(u|x).	suggestion
2020-2174	Equations 12-16 all follow naturally from equation 11.	suggestion
2020-2174	If equation 17 is indeed an approximation or bound approximation, I would suggest not using the equals sign.	suggestion
2020-2174	Instead, consider another appropriate operator or rename Dkl to indicate it is the approximated version (just as in equation 24).	suggestion
2020-2174	If the author(s) like my suggestion regarding generative vs variational nomenclature, I would also change the second sentence of page 6 to something like "We use our variational Qc|u distribution to compute assignments." Thereafter, I would drop the star indicator for optimal parameters.	suggestion
2020-2174	These parameters are not necessarily optimal given the non-convexity of the DNN.	suggestion
2020-2174	Replace with, "after convergence, we ..." Similarly, drop optimal from line 2 of algorithm 1.	suggestion
2020-2174	Circling back to the experiments, the author(s) use reported values from DEC and VaDE.	abstract
2020-2174	Those works compute cluster assignments using a KNN classifier on the latent space.	abstract
2020-2174	This paper however uses the arg max of equation 19.	weakness
2020-2174	I much prefer this article's method, but for comparison purposes, the author(s) should similarly use a KNN classifier on their latent space to compute accuracy in the same manner.	weakness
2020-2174	The use of KNN in these other works allows them to consider a number of latent clusters larger than the number of true classes (e.g. 20 clusters for MNIST).	weakness
2020-2174	I like that the author(s) stick to 10 clusters for MNIST, but for comparison I would have liked to see a KNN generated accuracy alongside their equation 19 based accuracy.	suggestion
2020-2174	It looks like the author(s) implemented VADe for STL-10 based on table 1.	weakness
2020-2174	If so, it seems they could easily implement equation 19 for their STL-10 value for VADe. If not, please correct this.	suggestion
2020-2174	Not to belabor further, but I would really like to see a table 2 that reports both equation 19 and KNN accuracies when available.	suggestion
2020-2174	Namely, the author(s) should report both values for their model and can leave equation 19 accuracies blank for reported values.	suggestion
2020-2174	Lastly, I always raise an eyebrow when I see tSNE latent space representations.	suggestion
2020-2174	STL-10 was used to generate figure 6, where one needs dim(u) >> 2.	strength
2020-2174	However, MNIST can be well reconstructed using just 2 latent dimensions.	weakness
2020-2174	In this case, tSNE is unnecessary.	weakness
2020-2174	The author(s) state "Colors are used to distinguish between clusters." This statement is unclear as to whether the author(s) are using the class label or learned latent cluster.	weakness
2020-2174	If it is the former, figure 6 makes sense in that it shows misclassifications (i.e. red dots in the green cluster).	weakness
2020-2174	However, if it is the latter then I am concerned tSNE is doing something weird.	weakness
2020-2174	To summarize, I enjoyed the paper.	misc
2020-2174	My only concern is novelty.	weakness
2020-2174	Being the first to pair an existing model with an existing method, in my eyes, does not necessarily meet the *CONF* bar.	decision
2020-2174	The author(s) seemingly achieve SoTA, but without KNN-based accuracies for their model it is hard to compare to cited works.	weakness
2020-2174	Having these KNN results and error bars would strengthen their case substantially to: achieving SoTA for an existing model by being the first to pair it with an existing method.	suggestion

2020-2188	*Synopsis*: This paper proposes using the features learned through Contrastive Predictive Coding as a means for reward shaping.	abstract
2020-2188	Specifically, they propose to cluster the embedding using the clusters to provide feedback to the agent by applying a positive reward when the agent enters the goal cluster.	abstract
2020-2188	In more complex domains they add another negative distance term of the embedding of the current state and goal state.	abstract
2020-2188	Finally, they provide empirical evidence of their algorithm working in toy domains (such as four rooms and U-maze) as well as a set of control environments including AntMaze and Pendulum.	abstract
2020-2188	Main Contributions: - Using the embedding learned through Contrastive Predictive Coding for reward shaping.	strength
2020-2188	- A reward shaping scheme that seems generally applicable to any embedding.	strength
2020-2188	*Review*: I think the paper provides a compelling motivation, and is well written.	strength
2020-2188	I think using the embedding learned through CPC could provide meaningful semantics for representation learning and for reward shaping (as done in the current paper), and encourage the authors to continue down this line of inquiry.	strength
2020-2188	Unfortunately, I have several concerns over the method as currently implemented and the empirical comparisons (specifically with the chosen competitors) which I detail below.	weakness
2020-2188	Given these concerns I am unwilling to recommend accepting this paper, unless several of these concerns are addressed.	decision
2020-2188	1. This algorithm, by nature, is purely offline as the CPC and clustering all are currently done offline.	weakness
2020-2188	Furthermore, the clustering portion of this approach requires states to be randomly sampled from the environment to create a nice set of clusters which are representative of the environment's full state space.	weakness
2020-2188	These two requirements significantly limit this approach, especially when looking at domains where simulation is not possible, or the underlying state distribution is unknown.	weakness
2020-2188	By and all, I don't think this means we should completely discount this method entirely and the authors do mention this as a detriment to their algorithm in section 6.3.	ac_disagreement
2020-2188	I'm wondering if this paper should look at implementing an online version before publication, but think this is less prescient to the other concerns.	suggestion
2020-2188	2. I am concerned about the current policy learning scheme (i.e. tiered policy (1) go to the correct cluster (2) go to the goal) which seems to only be used by your approach.	weakness
2020-2188	This invalidates the comparisons made with the other reward shaping schemes as this goes beyond reward shaping (you are learning two separate policies).	weakness
2020-2188	3. The current competitors are unsatisfactory as they don't include other reward shaping techniques from the literature.	weakness
2020-2188	Also the related works section seems to completely disregard this part of the literature.	weakness
2020-2188	I would recommend comparing your approach to (methods you even cite!): - "Reward Shaping via Meta Learning" by Zou et.	suggestion
2020-2188	al https://arxiv.org/pdf/1901.09330.pdf - "Potential based reward shaping" by Gao et.	misc
2020-2188	al. https://www.aaai.org/ocs/index.php/IJCAI/IJCAI15/paper/viewPaper/10930 (I'm sure there are others beyond these)	misc
2020-2188	4. I'm also concerned with the current significance of the results, particularly AntMaze, Half Cheetah, and Reacher.	weakness
2020-2188	I'm especially concerned because I don't feel your competitors are not relevant/representative of the current state of reward shaping.	weakness
2020-2188	5. It would be worthwhile to try this method on several RL algorithms (i.e. Q-learning, TRPO, SAC, DDPG, etc...).	suggestion
2020-2188	This will help readers understand if this approach is a general method, or only applicable to PPO.	suggestion
2020-2188	6. I quite like the idea of predictive coding (albeit the original scheme presented by Rao and Ballard 1999) as an unsupervised representation learning scheme, but am unsure this is critical for your method and the current approach is not really predictive coding in a sense (or at least the ideas I'm familiar with from cognitive computational neuroscience).	weakness
2020-2188	I am concerned with the predictive coding idea being highlighted here as a key ingredient, but none of the papers containing the originating idea of predictive coding are mentioned.	weakness
2020-2188	Rao and Ballard is one, but there is a rich literature following from this work into the free energy formulation (Friston) and active learning.	strength
2020-2188	These ideas should appear in your introduction, as you heavily rely on them.	suggestion
2020-2188	Also there are other predictive coding schemes for unsupervised representation learning (such as PredNets from David Cox https://coxlab.github.io/prednet/), which I believe should be mentioned.	suggestion
2020-2188	In light of these other methods, I'm not sure your discussion on only using predictive features for reward shaping is accurate, and instead these claims should be softened for only features learned through CPC.	suggestion
2020-2188	Missing experimental settings: - Number of runs tested	suggestion
2020-2188	- What are the error bars in your plots?	suggestion
2020-2188	I would also like to recommend "Deep Reinforcement Learning that Matters" by Henderson for a reference on how to conduct meaningful Deep RL experiments using policy gradient methods (https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/16669).	suggestion
2020-2188	I think this paper could benefit from the recommendations made there.	misc
2020-2188	More questions/clarifications: Q1: What constitutes success in the grid world domains for table 1?	weakness
2020-2188	Q2: If you were to train a single policy using your reward shaping scheme (i.e. not the tiered approach currently employed) how would the new policy perform?	suggestion
2020-2188	Are there problems with the current scheme where you have to have the tiered policy?	weakness
2020-2188	Q3: Why CPC and not say an autoencoder or VAE?	weakness
2020-2188	A comparison over many types of unsupervised embedding learning algorithms could be interesting and make your method more general than currently presented.	suggestion
2020-2188	It could also strengthen your argument for using CPC.	suggestion
2020-2188	Q4: How long were the trajectories for training CPC?	suggestion
2020-2188	*Other minor comments not taken into account in the review*	rebuttal_process
2020-2188	- I think your labels are backwards in table 1.	weakness
2020-2188	The paper presents a method to derive shaping rewards from a representation learnt with CPC.	abstract
2020-2188	They propose learning a CPC representation from some random data and fix it.	abstract
2020-2188	They assume exploration is not too difficult so that rewards are achievable without additional mechanisms.	abstract
2020-2188	Once a reward is achieved they can compute the embedding of the corresponding state as a goal under the CPC learnt representation either directly ie.	abstract
2020-2188	distance or via a clustering step.	abstract
2020-2188	The paper is clearly written and presents a nice idea.	strength
2020-2188	The paper is correct and part of the approach seems novel.	strength
2020-2188	I find the analysis of the results well executed though I think that they should be improved for publication.	decision
2020-2188	Major points: * I think this is a valid contribution and it seems like something the RL audience might be interested in.	strength
2020-2188	* I am very surprised that CPC does such a good job given that the main object for learning in CPC is the distribution of trajectories which should be quite different in random exploration and the optimal policy.	strength
2020-2188	I presume this is because the environments are quite simple.	suggestion
2020-2188	This issue is of interest to the readers so an example of a simple failure case should make that point.	strength
2020-2188	* Secondly, as nice as those embeddings in figure 5 look I wonder what happens in larger mazes with more structure i.e. somewhere where random walk will not be a uniform distribution and thus CPC will (most likely) not work as intended.	suggestion
2020-2188	* The clustering bonus how do you prevent it from staying at the edge of the goal region and deriving infinite rewards from that ?	suggestion
2020-2188	* Since these are not potential functions how do you prevent the rewards from biasing learning ?	suggestion
2020-2188	Ng et al. -- Policy invariance under reward transformations.	misc
2020-2188	This should be discussed in the paper because it is of practical importance.	weakness
2020-2188	* Contrastive learning has been used to find goal embeddings before Warde-Farley et al. Unsupervised control through non-parametric discriminative rewards.	weakness
2020-2188	In that paper they don't need the CPC future state predictors but instead contrast the goal and the final state of the trajectory.	weakness
2020-2188	They use the resulting embedding to learn a reward function and ignore the extrinsic reward.	weakness
2020-2188	Interestingly, they show that the rewards can be learnt online (maybe ideas from that paper can be applied here).	weakness
2020-2188	Minor points: * please make legends on plots readable size.	suggestion
2020-2188	The paper proposes a reward shaping method which aim to tackle sparse reward tasks.	abstract
2020-2188	The paper first trains a representation using contrastive predictive coding and then uses the learned representation to provide feedback to the control agent.	abstract
2020-2188	The main difference from the previous work (i.e. CPC) is that the paper uses the learned representation for reward shaping, not for learning on top of these representation.	abstract
2020-2188	This is an interesting research topic.	strength
2020-2188	Overall, I am leaning to reject this paper because (1) the main contribution of the paper is not clear (2) the experiments are missing some details and does not seem to support the claim that the proposed methods can tackle the sparse reward problem.	decision
2020-2188	First of all, it would've been better to have a conclusion section, so the readers can see the contributions of the paper.	suggestion
2020-2188	After reading the paper, I still do not understand what are the contributions of the paper and what're from the previous works.	weakness
2020-2188	The paper does not provide well justification why CPC feature can provide useful information for reward shaping.	weakness
2020-2188	The paper does not provide a new method to learn predictive coding.	weakness
2020-2188	It does not provide a novel reward shaping method (the "Optimizing on Negative Distance" method is very similar to [1]).	weakness
2020-2188	So, I am not sure what're the contributions of this paper.	weakness
2020-2188	Moreover, I am not convinced that the proposed method can tackle long horizon and sparse reward problems.	weakness
2020-2188	As the paper discuss in introduction, learning in sparse reward environment is hard because it relies on the agent to enter the goal during exploration.	weakness
2020-2188	However, the proposed approach seems only able to work in environments where exploration with random policy can generate trajectories that contain sufficient environment dynamics (e.g. dynamics near the goal states).	weakness
2020-2188	How can the method learn that information without entering the goal?	weakness
2020-2188	Furthermore, it seems that the proposed approach only works for goal-oriented tasks (since we need to know the goal state for reward-shaping).	weakness
2020-2188	I think this should be clearly stated in the paper.	weakness
2020-2188	There are some missing details which makes it difficult to draw conclusions: 1. How is the 'success rate' computed (e.g. in figure 7 and table 1).	weakness
2020-2188	2. How were the parameters selected (e.g. table 5 in the appendix).	weakness
2020-2188	Why did you use the default the parameters?	weakness
2020-2188	3. How many runs are the curve averaged over and what's the shaded region (e.g. one standard error)?	weakness
2020-2188	Most of the results in the paper seem not statistically significant.	weakness
2020-2188	4. In figure 4, five domains are mentioned but only three of them are tested in the section 5.	weakness
2020-2188	5. Section 6.2 seems irrelevant to the paper.	weakness
2020-2188	What's the purpose of this section?	weakness
2020-2188	6. Figure 10 shows the result of using CPC feature directly vs.	weakness
2020-2188	reward shaping. Are both feature using the same NN architecture, same PPO parameters, and same control setting?	weakness
2020-2188	Moreover, the reward shaping method assumes we know the goal state but using CPC feature does not.	weakness
2020-2188	Is it a fair comparison?	weakness
2020-2188	The paper has some imprecise parts: 1. The definition of MDPs (in section 2) is imprecise.	weakness
2020-2188	For example, how is the expectation defined?	weakness
2020-2188	how is the initial state sampled?	weakness
2020-2188	What does p∈P (last line in the first paragraph) mean where P is the state transition function?	weakness
2020-2188	Minor comments which do not impact the score: 1. Figure 1 should come before figure 2.	weakness
2020-2188	2. It would have been better if there is a short description of how the hand-shaped rewards is designed for each domain in the main text.	weakness
2020-2188	[1] The Laplacian in RL: Learning Representations with Efficient Approximations	misc

2020-2197	I have read the author response.	misc
2020-2197	Thank you for responding to my questions.	misc
2020-2197	This paper aims to predict typical "common sense" values of quantities using word embeddings.	abstract
2020-2197	It includes the construction of a data set and some experiments with regression models.	abstract
2020-2197	The general direction of this work is worthy of study, but the paper needs additional justification for its task, better discussion of recent related work, and more development of its regression models.	weakness
2020-2197	The work starts by describing the construction of interesting crowdsourced data sets that include people's estimates of typical quantities, what they would consider to be low or high values for a given object in given units e.g. the temperature of a hot spring or the height of a giraffe.	abstract
2020-2197	Overall, the data sets are interesting but are not especially large (2300 total [low, high] pairs of 230 different quantities).	weakness
2020-2197	Further, the particular task formulation here needs more justification.	weakness
2020-2197	I think most of us would agree that common sense is a critical AI challenge, and that the question of whether embeddings reflect typical quantities is important.	weakness
2020-2197	But, in a paper where the data set is considered a primary contribution, I would expect more justification for exactly how this task is formulated, and which objects and units were selected.	weakness
2020-2197	As one example, why ask about "large" and "small" values rather than something with more precise semantics (like the 10th and 90th percentile, for example)?	weakness
2020-2197	I also felt that the introduction could be improved to provide more convincing motivation.	weakness
2020-2197	E.g., the first paragraph only says that humans apply different adjectives (like "hefty" and "cheap") to different things depending on their numerical attributes (weight, cost), but does not argue why teaching AI systems to use those adjectives is a priority.	weakness
2020-2197	Regarding related work, the paper is missing a discussion of several relevant papers that use embeddings to obtain relative comparisons or estimates of commonsense properties of objects, including: Forbes, Maxwell, and Yejin Choi.	weakness
2020-2197	"Verb physics: Relative physical knowledge of actions and objects." ACL 2017	misc
2020-2197	Yang, Yiben, et al. "Extracting commonsense properties from embeddings with limited human guidance." ACL 2018	misc
2020-2197	Elazar, Yanai, et al. "How Large Are Lions?	misc
2020-2197	Inducing Distributions over Quantitative Attributes." ACL 2019	misc
2020-2197	The paper then presents the performance of some regression models.	abstract
2020-2197	These models are standard existing techniques, and given the relatively low performance I would have liked more development of the models and more analysis of the performance.	weakness
2020-2197	For a conference like *CONF* I would expect to see a more thorough exploration and analysis of possible models for the task.	weakness
2020-2197	Looking at more powerful neural regressors (perhaps using contextual embeddings rather than just fixed word embeddings) might be one option.	suggestion
2020-2197	Offering an explanation for why ARD seems to work better than the other approaches would be helpful.	suggestion
2020-2197	Minor: In Table 3, the way that small and large are interleaved makes it hard to compare systems, I think presenting all the small results together, and large results together may help.	weakness
2020-2197	In Figure 2, it would be helpful to see the histogram for size-large within the same plots here, so we could see how far apart they are.	suggestion
2020-2197	"Because Skip-gram has to handle more words to predict words, we assume Skip-gram will obtain more information about numerical values."	rebuttal_process
2020-2197	-- I didn't understand what you meant about skip-gram having to "handle more words to predict words."  Also, I did not understand how this entails that skip-gram would obtain more info about numerical values.	weakness
2020-2197	This paper attempts to study if learned word embeddings for common objects contain information about "numerical common sense".	abstract
2020-2197	The hypothesis is that certain numerical information may co-occur with the words for certain objects/measurement units within their context windows.	abstract
2020-2197	To verify this hypotheses, the authors have created a dataset through a crowd-sourcing service which represents "numerical common sense".	abstract
2020-2197	Using this dataset, the authors examine the predict abilities of regressors trained on learned word embeddings and the aforementioned crowd-sourced dataset.	abstract
2020-2197	The hypothesis is that if the regressors demonstrate good accuracy, then the word embeddings contained information relevant to "numerical common sense".	abstract
2020-2197	To the best of my knowledge, this is the first paper that attempts to analyze learned word embeddings in the context of numerical common sense.	abstract
2020-2197	This paper should be rejected because (1) the NCS datasets are too small to represent "numerical common sense" (2) the NCS datasets contain faulty data points and (3) the results from the experiments conducted are not sufficient to accept or refute the hypotheses.	decision
2020-2197	Main argument The first question that we must ask is - are the NCS-50x1 and NCS-60x3 datasets reliable for experiments on "numerical common sense".	weakness
2020-2197	No, because of two flaws: (1) The number of samples in the dataset is too small to represent "numerical common sense".	weakness
2020-2197	Consider the histogram for object "dog" in Figure 2.	weakness
2020-2197	If the largest data point in this plot was absent, the average of the distribution would be smaller by several orders of magnitude.	weakness
2020-2197	Perhaps there are other objects in the dataset which are missing samples from the tail end of the distribution that could have large effects on the mean of the collected dataset.	weakness
2020-2197	(2) Some data points in the dataset don't make sense to me.	weakness
2020-2197	For example, Fig 2 represents the "small" dataset, yet I see samples like 400m long dogs, 40m long cats, 150m long monitors and 20m long mice?	weakness
2020-2197	Also, it is not clear how the confidence scores of the participants were taken into account when training the regressors or if they were used at all.	weakness
2020-2197	If the NCS dataset does not represent "numerical common sense", it invalidates all experimental results from the paper.	weakness
2020-2197	My second issue with the paper is that it is not possible to conclude if the experimental results support or refute the hypothesis (ignoring the issue with the dataset): 1. In tables 2 and 3, the correlation coefficients were quite low and and the MAEs were pretty large.	weakness
2020-2197	In Table 3, rows 1 and 2, even though the correlation is 0.57 and 0.48, the MAE is 100 million yen and 7.5 million yen respectively which is quite large.	weakness
2020-2197	To me this suggests that just because the correlation is larger we cannot conclude mean that the model is performing well.	weakness
2020-2197	2. It is unclear why the correlation coefficient was chosen to decide that ARD is the superior model in experiment 1.	weakness
2020-2197	The MAE for random forests with concatenated feature vectors was an order of magnitude smaller than that of the ARD model.	weakness
2020-2197	3. Why are the correlation coefficients missing for the unit-only experiment in Table 2?	weakness
2020-2197	The LS model shows very good MAE relative to the other models and perhaps the correlation should have been measured for that as well?	weakness
2020-2197	In fact, if the correlation coefficients for this case is comparable to the case with concatenated features, it would mean that the word embedding for the object is not helping at all!	weakness
2020-2197	Moreover, I find it surprising that the LS model with concatenated features performs worse than the unit-only features.	weakness
2020-2197	We cannot conclude if paper's interpretation about the results is correct unless this missing information is provided.	weakness
2020-2197	4. It is hard to judge what a correlation coefficient of 0.57 means.	weakness
2020-2197	Why didn't you provide a scatter plot of the predictions vs targets as well?	weakness
2020-2197	It often happens that even noisy plots demonstrate good correlations.	weakness
2020-2197	5. The paper should have additional ablation studies - for example, what would happen in the concatenated feature vector experiment if you trained the regressors using randomly initialized word embeddings instead of the trained word embeddings?	weakness
2020-2197	Do you get the same performance as learned word embeddings?	weakness
2020-2197	This paper describes the collection and analysis of a numerical common-sense dataset.	abstract
2020-2197	The paper also states that a novel regression method is presented for quantifying numerical common sense.	abstract
2020-2197	Strengths: - the numerical common sense task and its related challenges are presented and motivated clearly	strength
2020-2197	- the data/annotations and their analysis are presented clearly.	strength
2020-2197	The experiment can be replicated reasonably (provided that the data is released, as the authors state)	strength
2020-2197	Weaknesses: - the dataset is too small (230 pairs of units and values).	weakness
2020-2197	Two observations follow from this: (1) such small-scale data is of limited use to state of the art (deep learning) data-hungry approaches; (2) the relatively low cost of crowdsourcing typically results in much bigger datasets.	weakness
2020-2197	- some decisions or definitions seem a bit ad hoc and are not convincing.	weakness
2020-2197	For instance: in Table 1, why is the apple measured in centimetres but the coffee cup measured in meters?	weakness
2020-2197	Another example from section 1: why are temperature and weight described as nonphysical scales, but money described as a subjective scale?	weakness
2020-2197	Another example of a definition: "similar words share similar units and thus concrete words contains numerical information".	weakness
2020-2197	Statements like these are problematic because one could easily think of counter examples where this is not the case.	weakness
2020-2197	- the experimental findings are not based on state on the art methods applied in a setup where the robustness and transferability of the methods on other data and domains has been analysed and discussed.	weakness
2020-2197	Overall this work is interesting as a starting point.	strength
2020-2197	My advice is to consider scaling up both the data and the methods, and to accompany this by a more comprehensive analysis of limitations.	suggestion

2020-2203	Summary - The paper first makes the observation that training algorithms and architectures for meta-learning have become increasingly specific to the few-shot set of tasks.	abstract
2020-2203	Following this, the authors first investigate if it's possible to learn good initializations for dense structured prediction tasks such as segmentation (across arbitrary amounts of available input data).	abstract
2020-2203	Concretely, the claimed contributions of the paper include	strength
2020-2203	-- (1) extension and analysis of first order MAML like approaches to image segmentation;	strength
2020-2203	(2) using a formalized notion of the generalization error of episodic meta-learning approaches to decrease error on unseen tasks;	strength
2020-2203	(3) doing this via a novel neural network parametrically efficient segmentation architecture and	strength
2020-2203	(4) empirically comparing meta-learned initializations with ImageNet pre-trained initializations with increasing training set sizes.	strength
2020-2203	Strengths - Apart from the flaws mentioned under weaknesses, the paper is generally easy to follow.	strength
2020-2203	While it's somewhat hard to understand the motivations and the concrete contributions made by the paper, sections are more-or-less well-written.	strength
2020-2203	Using the proposed hyper-parameter search scheme over first-order MAML approaches demonstrates improvements over not baselines which do not use the same and baselines which do not involve meta-learning.	strength
2020-2203	Weaknesses The paper has some major weaknesses that affect the clarity of the points being conveyed in several sections.	weakness
2020-2203	These weaknesses form the basis of my rating and addressing these would not only help in adjusting the same but would also help in improving the current version of the paper significantly.	weakness
2020-2203	Highlighting these below: - The paper claims to make several contributions but it's hard to concretely understand them in several sections.	weakness
2020-2203	For instance, the abstract mentions -- ''A natural question that …..	weakness
2020-2203	human level performance in both." The statement is slightly unclear to me -- is the intended sentiment the fact that the goal should be to develop a single algorithm that works well for both few-shot and many-shot settings?	weakness
2020-2203	If so, why should that be the case?	weakness
2020-2203	Essentially, what is the limiting factor being identified that restricts few-shot approaches from performing well in many-shot settings?	weakness
2020-2203	Maybe the statement could be framed better but in it's current form it's unclear what is being conveyed.	weakness
2020-2203	When this is mentioned again in the introductory section, it is followed by a statement indicating that meta-learning an initialization is one solution.	weakness
2020-2203	Why is this surprising? Maybe I'm mis-understanding the motivation behind the claim.	weakness
2020-2203	Could the authors clarify this?	weakness
2020-2203	- Similarly, it's unclear what question (3) in the introduction is trying to address.	weakness
2020-2203	Which "data" (training / testing set of tasks) is the fixed update policy not conditioned on?	weakness
2020-2203	Could the authors clarify this?	weakness
2020-2203	- The description of the single update hyper-parameter optimization (UHO) is hard to understand in Sec. 4.	weakness
2020-2203	-- specifically the text surrounding eqns (5) and (6).	weakness
2020-2203	The transition from Eqn (5) -> Eqn (6) is unclear.	weakness
2020-2203	Could the authors clarify this clearly?	weakness
2020-2203	This section is further referred to in subsequent sections as a supporting basis for some of the obtained results (specifically, the last para on page 6)	weakness
2020-2203	Reasons for rating I found certain sections of the paper particularly hard to understand and interpret.	weakness
2020-2203	I would encourage the authors to address these more clearly in the responses.	suggestion
2020-2203	The highlighted strengths and weaknesses of my rating and addressing those clearly would help in improving my current rating of the paper.	suggestion
2020-2203	This paper proposes to apply MAML-style meta-learning to few-shot semantic segmentation in images.	abstract
2020-2203	It argues that this type of algorithm may be more computationally-efficient than existing methods and may offer better performance with a higher number of examples.	abstract
2020-2203	They further propose to perform hyper-parameter search to choose a new learning rate for the inner learning process after optimizing for the network parameters.	abstract
2020-2203	As far as I know, this is the first paper to apply gradient-based (i.e. MAML-style) meta-learning to this specific problem.	abstract
2020-2203	Existing approaches to few-shot semantic segmentation have mostly used multi-branch conv-networks to condition the output on the training examples.	abstract
2020-2203	This paper shows that (FO)MAML achieves similar accuracy to the FSS-1000 baseline.	abstract
2020-2203	This is an empirical contribution in itself.	strength
2020-2203	The paper also demonstrates that the EfficientNet architecture can be applied to segmentation.	abstract
2020-2203	Major concerns: (1.1) The improvement obtained by the hyper-parameter optimization seems quite marginal (79.0 - 81.4 and 73.3 - 73.9) and there is no study of the variance of the results.	weakness
2020-2203	The fact that better performance is obtained by tuning the learning rate on the *training* set suggests to me that the improvement might not be significant.	weakness
2020-2203	You could repeat the experiment by sampling multiple different training and testing sets (with different classes) to estimate (some of) the variance.	weakness
2020-2203	(1.2) The formalization in Section 4 is mathematically appealing but seems unnecessary.	weakness
2020-2203	In the end, the paper is essentially arguing that it's better to use different learning rates (for the inner loop) during meta-training and meta-testing.	weakness
2020-2203	This seems obvious, since this includes equal learning rates as a special case.	weakness
2020-2203	The paper proposes to optimize the latter learning rate using a gradient-free method.	weakness
2020-2203	This argument can be made without considering generalization bounds.	weakness
2020-2203	(1.3) One of the central claims of the paper is that "meta-learned representations smoothly transition as more data becomes available." It's not entirely clear what this means.	weakness
2020-2203	I suppose it means that, with few shots, it should perform as well as existing few-shot methods, but with many shots, it should perform as well as a standard learning algorithm.	weakness
2020-2203	The paper failed to present any evidence that existing algorithms for few-shot segmentation do not satisfy this property.	weakness
2020-2203	It would strengthen the argument to include an existing few-shot segmentation algorithm in Figure 2.	suggestion
2020-2203	(1.4) The details of the experiment in Figure 2 are not clear.	weakness
2020-2203	Was a different number of iterations used when there are hundreds of examples?	weakness
2020-2203	Were different hyper-parameters used when optimizing from a pre-trained checkpoint?	weakness
2020-2203	It would be unfair to use the same hyper-parameters which had been optimized specifically for the meta-learned initialization.	weakness
2020-2203	Other issues: (2.1) It's not clear what it means to achieve human-level performance in the few-shot task and the many-shot task.	weakness
2020-2203	What is human-level performance at few-shot segmentation?	weakness
2020-2203	It seems to me that humans are capable of segmenting novel objects (i.e. zero-shot) with almost perfect accuracy.	weakness
2020-2203	Does this mean that your method should achieve the same accuracy with few- and many-shots?	weakness
2020-2203	(2.2) The use of early stopping was unclear.	weakness
2020-2203	Do you use a fixed number of SGD iterations during training and a variable number of iterations (determined by a stopping criterion) during testing?	weakness
2020-2203	However, this seems to be contradicted by the statement that the UHO algorithm determined an optimal number of iterations (8) for testing?	weakness
2020-2203	On the other hand, this seems like too few iterations with hundreds of shots.	weakness
2020-2203	Maybe the automatic stopping criterion was only used with many shots?	weakness
2020-2203	Or maybe training proceeds until either the stopping criterion is satisfied or the maximum number of iterations is reached?	weakness
2020-2203	Furthermore, the early stopping criterion was not specified.	weakness
2020-2203	(2.3) Missing reference: Meta-SGD (arxiv 2017) considers a different learning rate for every parameter and updates the learning rates during meta-training .	weakness
2020-2203	(2.4) There was no discussion of the running time of different methods.	weakness
2020-2203	This would be particularly interesting in the many-shot regime.	weakness
2020-2203	How slow are the RelationNet approaches?	weakness
2020-2203	(2.5) It is claimed that Figure 1 demonstrates that  "the estimated optimal hyperparameters for the update routine ...	weakness
2020-2203	are not the same as those specified a priori during meta-training".	weakness
2020-2203	However, it seems that the optimal learning rate is awfully close to the dotted blue line (within the variance of the results).	weakness
2020-2203	(2.6) For the IOU loss (equation 10), what are the predicted y values?	weakness
2020-2203	Are they arbitrary real numbers?	weakness
2020-2203	Do you use a sigmoid to constrain them to real numbers in [0, 1]?	weakness
2020-2203	Minor: (3.1) It is not worth stating the optimal learning rate to more than 3 or 4 significant figures.	weakness
2020-2203	(3.2) Use 1 \\times 1 instead of 1 x 1.	weakness
2020-2203	(3.3) Is there a reference for the Dice score?	weakness
2020-2203	Where does the name come from?	weakness
2020-2203	The paper examines the performance of MAML, FOMAML, and Reptile gradient based meta-learning algorithms on the task of semantic image segmentation.	abstract
2020-2203	The paper proposes to do black box optimization (successive halving) on the hyperparameters of the inner loop of the gradient meta-learners for improved performance.	abstract
2020-2203	The paper proposes some modification on the segmentation model architecture (no ablation study presented).	abstract
2020-2203	Finally, it is shown that pre-training using meta-learning on similar segmentation tasks works better then just using ImageNet based model pre-training.	abstract
2020-2203	In its current form I suggest to reject the paper and urge the authors to improve it according to the following points: 1.	decision
2020-2203	In parts (specifically the intro and some other earlier parts) the paper is very well written, but the later parts, the description of the model modifications (did you consider to add an architecture diagram?	weakness
2020-2203	), the details of the experiments, the punch-line of the theory development that has been attempted, etc are not very clear and hard to follow.	weakness
2020-2203	I suggest the authors to improve the readability of these parts, add some helpful / motivating diagrams and examples (perhaps some qualitative results too?), state more clearly what is used for meta-training?	suggestion
2020-2203	how it is made sure that meta-testing is done on a separate set of categories?	weakness
2020-2203	(I did not see this split in the Appendix) and etc	weakness
2020-2203	2. My main concern is novelty.	weakness
2020-2203	As it stands, the current novelty proposition is: black-box optimization of LR and number of iterations in MAML style meta learning (hardly novel), architecture modifications (no ablation study if these help or not), small improvement on FSS-1000 5-shot test (what about other shots?	weakness
2020-2203	still not sure about the splits), and showing meta-training on similar tasks is better then not doing it (that is using ImageNet pre-trained backbone for init) - again hardly a novel insight.	weakness
2020-2203	For the last point, saying that meta-learned model was initialized from scratch does not cut it, as it was meta-trained on massive data that is more related to the test tasks then the ImageNet.	weakness
2020-2203	I suggest the authors to mainly focus on 2, although making the writing clearer and better is also very important for a high quality paper.	suggestion

2021-874	Summary The paper describes a method for inverse reinforcement learning---called stochastic IRL---that learns a distribution over reward functions.	abstract
2021-874	In that sense, the method is similar to Bayesian approaches, however, the learned distribution doesn't seem to approximate the posterior for any given prior.	weakness
2021-874	It is hard to summarize the algorithm because it is highly unclear what the method actually does, but I will try my best by stating my most likely hypothesis.	weakness
2021-874	The algorithm starts with an initial set of N0 parameter vectors, each corresponding to the weights for a linear reward function.	weakness
2021-874	Each of these weights are improved by using a fixed number of gradient steps using MaxEnt-IRL (Ziebart et al. 2010), where different (overlapping) subsets of the demonstrations are used for the different weights.	weakness
2021-874	Subsequently, a GMM over weights is fitted to the N0 improved weights using maximum likelihood (EM).	abstract
2021-874	This procedure is iterated, where the weights at each iteration are drawn from the current GMM.	abstract
2021-874	The number of weight vectors is doubled at every iteration t, i.e., Nt=2Nt−1.	abstract
2021-874	I'm not at all confident that I got this right.	weakness
2021-874	For example, I solely inferred the use of MaxEnt-IRL from a sentence in the introduction ("In this paper, under the framework of the MaxEnt approach, [...]").	weakness
2021-874	The algorithm is evaluated on a 10x10 gridworld and compared with MaxEnt-IRL and DeepMaxEnt-IRL.	weakness
2021-874	The experiments compare two versions of the algorithm called SIRL and DSIRL.	weakness
2021-874	The paper doesn't explain how they differ, but a neural network parameterization is mentioned for DSIRL, so I guess D stands for deep and uses DeepMaxEnt-IRL instead of MaxEnt-IRL.	weakness
2021-874	Strong points Learning a distribution over reward functions is a laudable goal for inverse reinforcement learning as it can be a principled way to deal with the uncertainty in modeling the expert.	weakness
2021-874	Concerns Clarity The paper is really hard to follow, even though I'm very familiar with related work, and the algorithm and the equations seem to be quite simple.	weakness
2021-874	There are several reasons for this lack of clarity.	weakness
2021-874	Lack of details. Actually not only details, some of the most fundamental aspects of the algorithm are not mentioned anywhere.	weakness
2021-874	For example, the likelihood of the demonstrations given the weights, g(O|W,Ω) is nowhere defined.	weakness
2021-874	θ is also not defined.	weakness
2021-874	Some of the equations are very confusing.	weakness
2021-874	For example, the second to last equations at page 4 seems to overload the subscript "i" which seems to index both the sampled weight as well as the gradient step, depending on the variable.	weakness
2021-874	Even when disentangling these different meanings the equation looks weird to me.	weakness
2021-874	Based on the surrounding text, I guess it should mean m gradient steps on the likelihood are performed, but the equation says different.	weakness
2021-874	It is also strange that the weights W are updated based on the gradient w.r.t. Ω1 and that Ω1 is set to the updated weights in the last equation at page 4.	weakness
2021-874	It seems like Omega_1 is superfluous.	weakness
2021-874	Also, the mixture model D(W|ζ,Ω2) seems to be conditional independent of ζ given Ω2.	weakness
2021-874	What's the difference between D(W|ζ,Ω2) and h(W|Ω2)?	weakness
2021-874	Some algorithmic choices are not motivated at all (for example, doubling the samples at every iteration), others are only (insufficiently) motivated in hindsight.	weakness
2021-874	For example, the use of "representative trajectory classes" is motivated after introducing them and based on the example of different drivers with different driving styles.	weakness
2021-874	However, the paper never mentioned a multi-expert scenario and also doesn't try to cluster the demonstrations but only randomly removes few demonstrations; thus, it is not even clear how the trajectory classes would tackle such problem.	weakness
2021-874	Bad structure. While it is in general a legitimate approach to introduce the algorithm step by step, I think you should always also provide a rough sketch of the overall algorithm already early on, so that the reader has some context when you introduce the details.	weakness
2021-874	The way of introducing the trajectory classes is also a good example for the bad structure of the paper.	weakness
2021-874	Before introducing them, there is no mentioning of them, there is no motivation for them, and for all I can tell the paper doesn't even discuss the problem that they are supposed to tackle.	weakness
2021-874	And then in Section 2, they are introduced by stating "Suppose that we have trajectory classes [paraphrased]" and moving on as if nothing happened.	weakness
2021-874	I must say that the writing is also quite bad.	weakness
2021-874	Some sentence are hard to follow due to grammar mistakes, especially if the reader doesn't have enough background to infer their meaning.	weakness
2021-874	For example "[...] suffer from the problem that the true reward shaped the changing environment." should probably mean something like "suffer from the problem that the learned reward function is shaped---that is, it is entangled with the dynamics---and, thus, does not transfer to different environments".	weakness
2021-874	As another example "However, GAIL is in a lack of an explanation of expert's behavior and a portable representation for the knowledge transfer which are the merits of the class of the MaxEnt approach, because the MaxEnt approach is equipped with the "transferable" regular structures over reward functions."	weakness
2021-874	Soundness It doesn't make sense to talk a lot about the soundness of the approach before clarifying what it actually does.	weakness
2021-874	However, it seems to me that the learned distribution is only heuristic and does not approximate the posterior for any given prior.	weakness
2021-874	Also, for the linear reward function, the maximum likelihood objective is convex, so I think that the different weights should even converge to the same solution.	weakness
2021-874	Evaluation I don't demand MuJoCo experiments and the like, and in some cases evaluations on gridworlds can be sufficient.	weakness
2021-874	But I must say, that the excuse for not performing continuous control problems because the reward functions can not be visualized by 2d-heatmaps lured out a smile when reading the article.	weakness
2021-874	If I understand the algorithm correctly, it is significantly more expensive than standard MaxEnt-IRL which already doesn't scale to such problem settings as it requires iteratively solving the reinforcement learning problem.	weakness
2021-874	The results on the objectworld are also not convincing.	weakness
2021-874	The expected value difference is for 80 demonstrations larger than for 40, and for 160 demonstrations larger than for 80.	weakness
2021-874	Similary, the performance initially degrades when increasing trajectory lengths and only improves again when taking trajectories of length 32 or more.	weakness
2021-874	The sentence "A notable point in Figure 3 is that very few expert demonstrations (less than 200) for our approach also yields a small EVDs, which manifests the merit of Monte Carlo mechanism in our approach." is highly misleading.	weakness
2021-874	200 trajectiories are not "few" for a 10x10 gridworld and an EVD over 20 is not small.	weakness
2021-874	When introducing this environment, Levine et al. (2011) achieved an EVD of around 1 based on 8 demonstrations (using 8 steps instead of 5).	weakness
2021-874	The robustness experiment seems to subsample the weights based on the EVD (which requires knowledge of the true reward) before evaluation.	weakness
2021-874	Questions To better understand the proposed algorithm, I have the following questions.	weakness
2021-874	How does the algorithm relate to MCEM?	weakness
2021-874	Is it some sort of EM within MCEM, where the first stage corresponds to the Monte-Carlo E-Step and the EM in the second stage corresponds to M-step of MCEM?	weakness
2021-874	How are the densities g and h defined?	weakness
2021-874	How does Ω1 affect the optimziation.	weakness
2021-874	How does it differ from W?	weakness
2021-874	How exactly are the m-step update steps performed?	weakness
2021-874	Do they indeed correspond to m gradient steps on the MaxEnt objective?	weakness
2021-874	Section 3.3.: Should the inequality hold for limt→∞?	weakness
2021-874	What's the difference between DSIRL and SIRL?	weakness
2021-874	How do the algorithm compare in terms of computational cost?	weakness
2021-874	Assessment Unfortunately, I don't see a chance for acceptance here.	decision
2021-874	Even if the algorithm was sound and sufficiently novel, the paper would need to be almost completely rewritten in order to address severe problems of the current presentation.	weakness
2021-874	The authors propose an approach to model-based inverse reinforcement learning which estimates a Gaussian mixture model over reward-function parameters.	abstract
2021-874	The method uses MCEM and samples reward functions from a current estimate of the GMM, updates them via a gradient-descent based maximum likelihood approach and then updates the GMM to fit the updated parameters.	abstract
2021-874	The authors evaluate the approach on objectworld.	abstract
2021-874	The paper is at times hard to follow and should be rewritten to be more clear.	weakness
2021-874	The contributions and assumptions could be stated more clearly and the paper would strongly benefit from proof-reading.	weakness
2021-874	It would also be helpful to disentangle the machinery of MCEM from the novel algorithmic contributions of this paper.	weakness
2021-874	The choice of a GMM to represent the distribution of parameters is not motivated at all in the paper.	weakness
2021-874	Intuitively, the main benefit is to allow for k reward-function archetypes that represent the set of expert trajectories well; however, there are no examples nor any evaluation to show in which case this is beneficial.	weakness
2021-874	DSIRL is used as an acronym for a variant of the method but is not defined in the paper as far as I can tell.	weakness
2021-874	While the method can seemingly be applied to deep as well as linear representations, it is unclear what the chosen features and representation is in the experiments.	weakness
2021-874	The method appears to draw a set of weights W_i as well as a corresponding set of expert trajectories O_i at random in each iteration.	weakness
2021-874	The motivation for the use of O_i is that it may correspond to different modes in the expert set, e.g. demonstrations by different experts;	weakness
2021-874	however, the assignment of weights to object sets is not consistent between iterations so it is unclear to me how this would be able to handle different experts.	weakness
2021-874	In the beginning it is mentioned that IRL methods require knowledge of the transition model.	weakness
2021-874	While many methods do, modern IRL methods are model-free more often than not, so this claim is misleading.	weakness
2021-874	Summary The authors proposed inverse reinforcement learning (IRL) algorithm based on Monte Carlo expectation-maximization (MCEM) that maximizes the predictive distribution of trajectories given the reward distribution parameter (eq (1)).	abstract
2021-874	In my understanding, the knowledge of the environment dynamics is assumed.	weakness
2021-874	The authors tried to validate the proposed idea on objectworld (Levine et al., 2011)	weakness
2021-874	Quality The quality needs to be improved in the sense that a clear theoretical link between the target problem and MC-EM cannot be found in the submission.	weakness
2021-874	For example, the main objective (3) is optimized through (4) and (5), but the relation is unclear.	weakness
2021-874	There are lots of such things in the submission.	misc
2021-874	Clarity The readability of the submission is poor and needs to be improved.	weakness
2021-874	Lots of terms are unclear to me (e.g., succinctness, robustness, transferability of rewards).	weakness
2021-874	At some part of derivation, I couldn't understand the motivation.	weakness
2021-874	Experiment settings are unclear, and the results are not confident and seem irreproducible with given information.	weakness
2021-874	Originality Exploiting the distribution of reward is considered in Bayesian IRL.	abstract
2021-874	I think the probabilistic view was originated from Bayesian IRL (e.g., uniform prior on rewards may cover the idea of this work).	weakness
2021-874	The submission only sets MaxEntIRL as its baseline, but I think Bayes IRL should have been considered.	weakness
2021-874	Significance There seems to be a minor contribution	weakness
2021-874	Detailed comments (p.1, Abstract) expert demonstrations may be optimal for many policies	weakness
2021-874	I feel this statement is weird since we haven't defined the optimality of expert demonstrations.	weakness
2021-874	(p.1, Abstract) we generalize the IRL problem to a well-posed expectation optimization problem stochastic inverse reinforcement learning (SIRL) to recover the probability distribution over reward functions.	abstract
2021-874	SIRL tries to solve the inherent issue of IRL problem, not generalize IRL.	weakness
2021-874	Also, since Bayesian IRL also recovers the reward distribution, I couldn't get the major advantage of the SIRL from this statement.	weakness
2021-874	(p.1, Abstract) The solution is succinct, robust, and transferable	strength
2021-874	Definitions of these expressions seem ambiguous to me.	weakness
2021-874	(p.1, Abstract) a global viewpoint	weakness
2021-874	Again, ambiguous. (p.1, Introduction) It would be better to write it in a more abstract way and separately write down the Related Work section.	weakness
2021-874	References should be much clearer: LaTeX commands like \\citet{} and \\citep{} should both be used.	weakness
2021-874	(p.1, Introduction) if the model dynamics are known	weakness
2021-874	Recent works on IRL such as adversarial IRL (Fu et al, 2017) didn't require the knowledge of model dynamics.	weakness
2021-874	(p.1, Introduction) The recovered reward function provides a succinct, robust, and transferable definition of the learning task succinct, robust, and transferable: Ambiguous	weakness
2021-874	(p.1, Introduction) First paragraph Lots of words from Abstract seem to be repeated.	weakness
2021-874	(p.1, Introduction) In a real-world scenario, experts always act sub-optimally or inconsistently, which is another challenge.	weakness
2021-874	The sentence seems abrupt. The terms like sub-optimal and inconsistent here are awkward.	weakness
2021-874	(p.1, Introduction) imposes regular structures of reward functions in a combination of hand-selected features	weakness
2021-874	GAIL (Ho et al, 2016) doesn't require a hand-crafted feature.	weakness
2021-874	(p.1, Introduction) hand-selected by experts	misc
2021-874	A word experts here seems to imply a reward designer, not an expert on target tasks.	weakness
2021-874	I'd rather use a different word here.	weakness
2021-874	(p.1, Introduction) based on demonstrations respectively respectively seems inappropriate.	weakness
2021-874	(p.1, Introduction) Influenced by the work of Finn et al. (2016a;b)	weakness
2021-874	How these references affected AIRL needs to be mentioned.	weakness
2021-874	(p.2, Introduction) because the MaxEnt approach is equipped with the "transferable" regular structures over reward functions.	weakness
2021-874	In Ziebart et al., 2008, transferability wasn't mentioned.	weakness
2021-874	I believe the statement -- MaxEnt itself gives transferable reward feature -- is wrong but you should share the correct reference if this is true.	weakness
2021-874	(p.2, Introduction) The solution of SIRL is succinct and robust for the learning task in the meaning that it can generate more than one weight over feature basis functions which compose alternative solutions to the IRL problem	weakness
2021-874	This explanation seems insufficient to understand the meanings of "succinctness" and "robustness".	weakness
2021-874	(p.2, Introduction) Benefits of the class of the MaxEnt method,	strength
2021-874	Thanks to the benefits of the class of the MaxEnt method?	weakness
2021-874	(p.2, Introduction) Since of the intractable integration in our formulation,	weakness
2021-874	Due to the intractable integral in our formulation?	weakness
2021-874	I think the intractability of the mathematical derivation didn't need to be mentioned in Introduction.	weakness
2021-874	(p.2, Introduction) in a model-based environment when model dynamics is known?	weakness
2021-874	(p.2, Introduction) In general, the solutions to the IRL problem are not always best-fitting in the previous approaches because a highly nonlinear inverse problem with the limited information is very likely to get trapped in a secondary maximum in the recovery.	weakness
2021-874	I couldn't understand what the authors wanted to emphasize.	weakness
2021-874	It seems like they intended to emphasize the problem of local optima, but I don't know if such a problem is exactly what's happening in IRL.	weakness
2021-874	(p.2, Introduction) global exhaustive search	weakness
2021-874	What does global imply? Knowledge of dynamics?	weakness
2021-874	(p.2, Introduction) theoretically convergent demonstrated by pieces of literature is theoretically convergent?	weakness
2021-874	How the theorem in the references (Caffo et al., 2005, Chan and Ledolter, 1995)  is applicable to the proposed idea should be much clearer since this is one main advantage that the authors argue.	weakness
2021-874	For example, what kind of assumptions are required to acquire global optimality?	weakness
2021-874	What is the algorithmic assumption of MC-EM for optimality?	weakness
2021-874	How are those assumptions linked with IRL setting?	weakness
2021-874	(p.2, Introduction) is also quickly convergent converges quickly?	weakness
2021-874	How can we guarantee the convergence speed?	weakness
2021-874	Empirically or theoretically? (p.2, Introduction) the preset simple geometric configuration over weight space in which we approximate it with a Gaussian Mixture Model (GMM)	weakness
2021-874	preset -> predefined? approximate it -> approximate	weakness
2021-874	(p.2, Introduction) We generalize the IRL problem	weakness
2021-874	It seems the objective is not a generalization.	weakness
2021-874	(p.2, Preliminary) T:=P(st+1=s′|st=s,at=a) T(s′|s,a):=P(st+1=s′|st=s,at=a) (p.2, Preliminary)  a sequential of state-action pairs a sequence of state-action pairs?	weakness
2021-874	(p.2, Preliminary) The estimated complete MDP yields an optimal policy that acts as closely as the expert demonstrations.	weakness
2021-874	The discount factor should be considered as well.	weakness
2021-874	(p.3, Regular Structure of Reward Functions) N	weakness
2021-874	I'd rather use a different letter since N is used to indicate Gaussian distribution in Section Second Stage.	suggestion
2021-874	(p.3, Regular Structure of Reward Functions) ϕi(s,a)i=1	misc
2021-874	ϕi(s,a)i=1M? (p.3, Problem Statement) MDP∖R:=(S,A,T,γ) The definition doesn't match with one without the discount factor γ in Preliminary.	weakness
2021-874	(p.3, Problem Statement) ϕi(s)i=1M ϕi(s,a)i=1M? (p.3, Problem Statement) weights W	weakness
2021-874	The definition should be provided.	weakness
2021-874	Either W=(α1,…,αM) (for linear model) or the weights of neural network (for non-linear model)?	weakness
2021-874	(p.3, Problem Statement) more likely generates weights to compose reward functions as the ones derived from expert demonstrations	weakness
2021-874	Is this only a special case of Bayesian IRL?	weakness
2021-874	(p.3, Problem Statement) Suppose a representative trajectory class ~	weakness
2021-874	The explanation should be clarified.	weakness
2021-874	In my understanding, CϵE is a class of sets of trajectories.	weakness
2021-874	Why do we need to care such a class with \\epslion threshold?	weakness
2021-874	(p.3, Problem Statement) Integrate out unobserved weights W	weakness
2021-874	What does unobserved weights mean?	weakness
2021-874	Integrate out -> Marginalizing out?	weakness
2021-874	(p.3, Problem Statement) trajectory element set O assumes to be uniformly distributed for the sake of simplicity in this study	weakness
2021-874	I don't fully understand what's the advantage of considering a representative trajectory class and why it is required.	weakness
2021-874	The section Note: tries to explain it, but more explanation or theorems seems to be needed.	weakness
2021-874	How can we theoretically guarantee that using a representative trajectory class doesn't affect our estimation?	weakness
2021-874	It seems to me that we cannot guarantee the optimality with this class is the same as the original optimality.	weakness
2021-874	(p.3, Problem Statement) fM How this quantity is related to reward weights is unclear to me.	weakness
2021-874	The relationship between weights and fM for both linear and non-linear models should be specified.	weakness
2021-874	(p.3, `Note:) Instead of using a separate section, I'd rather put these statements in the middle of Problem Statement for a clearer explanation.	weakness
2021-874	(p.4, Two-stage Hierarchical Method) Why do we need to use two-stage method instead of single-stage method (joint optimization over Θ1 and Θ2)?	weakness
2021-874	The advantage of two-stage methods should be briefly mentioned when it first appears for readability.	weakness
2021-874	How does the iterative update rule (4), (5) guarantee the optimization of (3)?	weakness
2021-874	It's unclear to me due to the expectation in (4) and (5).	weakness
2021-874	My guess is that direct optimization of RHS of (3) is not possible and (4) and (5) might be either lower or upper bound of (3) due to Jensen's inequality.	weakness
2021-874	(p.4, Initialization) ~in each learning task	weakness
2021-874	Do we care about multi-task learning or multiple reward weights only?	weakness
2021-874	I believe the latter case.	misc
2021-874	(p.6, Experiments) since almost only objectworld provides a tool that allows analysis and display the evolution procedure of the SIRL problem in a 2D heat map, we skip the typical invisible physics-based control tasks for the evaluation of our approach, i.e. cartpole Barto et al. (1983), mountain car Moore (1990), MuJoCo Todorov et al. (2012), and etc.	weakness
2021-874	I think this makes the contribution weaker.	weakness
2021-874	At least a few classic control tasks should have been considered.	weakness
2021-874	One way of evaluating the quality of rewards is retraining the agent with acquired reward, which is already widely used in the literature.	weakness
2021-874	(p.6, Objectworld) One figure for illustration will enhance readability.	weakness
2021-874	(p.7, Evaluation Procedure and Analysis) DSIRL	misc
2021-874	DSIRL abbreviates Deep SIRL but wasn't mentioned.	weakness
2021-874	(p.7, Recovery Experiments) How many runs were used?	weakness
2021-874	How's the mean and confidence interval of the empirical result?	weakness
2021-874	(p.8, Robustness Experiments) I couldn't understand how the robustness of reward is related to the proposed experiments.	weakness
2021-874	How the robustness is defined and its relation to the experiment should be clarified.	weakness
2021-874	(p.8, Hyperparameter Experiments) How is the range of hyperparameter search for all methods?	weakness
2021-874	Currently, only the results for SIRL and DSIRL are given.	weakness
2021-874	(p.8, Conclusion) It seems like both succinctness and transferability were not discussed in the main part of the submission.	weakness
2021-874	References Levine et al., 2011, "Nonlinear inverse reinforcement learning with gaussian processes"	misc
2021-874	Fu et al., 2017, "Learning robust rewards with adversarial inverse reinforcement learning"	misc
2021-874	Ho et al., 2016, "Generative adversarial imitation learning"	misc
2021-874	Ziebart et al., 2008, "Maximum Entropy Inverse Reinforcement Learning"	misc
2021-874	Caffo et al., 2005, "Ascent-based Monte Carlo expectation-maximization"	misc
2021-874	Chan and Ledolter, 1995, "Monte Carlo em estimation for time series models involving counts" The authors propose to solve underspecified IRL problem  using an MCEM approach.	abstract
2021-874	They claim it is the first succint, robust and transferrable solution and have some results on a Gridworld-like environment.	abstract
2021-874	Assessment: The MCEM framework actually is a good fit to the IRL problem and I dont recall if this has been explicitly called out in the literature before.	strength
2021-874	But to me, the connection and resulting algorithm don't seem enough it terms of innovation and usefulness.	weakness
2021-874	Arguably, both BIRL and MaxentIRL do essentially (sampled) EM with different parametric forms.	weakness
2021-874	The experiments are unacceptably small scale and inconclusive.	weakness
2021-874	There were confusing parts in the exposition that I will outline below.	weakness
2021-874	Going by section: Intro: A good overview of the IRL literature.	strength
2021-874	sec 2: In the problem statement itself you need to say something about how the expert demonstrations are connected to R.	weakness
2021-874	Otherwise they seem like there is no relation at all.	weakness
2021-874	2.2: I'm trying to understand the motivation behind the definition of C^E_\\epsilon.	weakness
2021-874	In the objective formulation you are setting \\Theta to maximize the likelihood of a randomly choose subset of expert trajectories.	weakness
2021-874	I have never seen such a thing done before and it is interesting and possibly a route to robustness, but I would have liked more explanation and discussion.	weakness
2021-874	In particular, the choice of a uniform measure across subsets of different cardinalities seems bad.	weakness
2021-874	Would it be simpler to just introduce a hidden variable for each trajectory, stating whether it is valid or not (i.e. drawn from the true reward function and should therefore be used in likelihood computation).	weakness
2021-874	I agree then with the 3rd point in 2.2.1, this could be a different way to model expert sub-optimality than BIRL.	weakness
2021-874	3.1.2: It took me a while to read this and I dont think I understand.	weakness
2021-874	You seem to set \\Theta_2 = W by the end.	weakness
2021-874	Then this seems to be very complicated and redundant.	weakness
2021-874	In particular, it is very confusing how the dimensionality of the parameter space can depend on the number of monte carlo samples and changes at each iteration !	weakness
2021-874	Maybe I misunderstood something. 3.1.3: This seems like a straightforward EM derivation.	weakness
2021-874	3.2: What is the difference between the 2 stopping criteria?	weakness
2021-874	Just the fact that the 2nd has a patience of 3?	weakness
2021-874	if so, seems trivial. 3.3: what is being formally claimed here?	weakness
2021-874	That given the condition on N_t, convergence will hold and proof is in one of the references?	weakness
2021-874	4 (Experiments): Experiments are done on exactly 2 small instances of a variant of Gridworld.	weakness
2021-874	This is much smaller scale than the experiments you would expect to see in an *CONF* paper (even granted that *CONF* is very theory-focused).	weakness
2021-874	Previous papers have used IRL for real world problems like robotics, vehicle routing etc.	weakness
2021-874	Summation: A couple interesting starting point ideas in the theory part, but not completely fleshed out and ultimately the development of the EM approach is partly straightforward and part of it is very confusing to me (sec 3.1.2).	weakness
2021-874	Experiments are very unconvincing in terms of scope.	weakness
2021-874	The paper proposes a novel method for inverse reinforcement learning: inferring a (distribution over) reward functions from a set of expert demonstrations.	abstract
2021-874	Prior work has either learned a point-estimate, notably maximum entropy IRL, or used Bayesian methods to learn a probability distribution over reward functions.	suggestion
2021-874	Maximum entropy IRL has scaled to complex environments with unknown dynamics and non-linear rewards (with methods such as AIRL), but do not learn a probability distribution.	abstract
2021-874	By contrast, Bayesian IRL is more theoretically principled, but has not scaled to complex environments or non-linear rewards.	weakness
2021-874	This paper performs maximum likelihood estimation of a parameter for a generative model over probability distributions, using a Monte-Carlo expectation-maximization (MCEM) method.	abstract
2021-874	It therefore still outputs a probability distribution like Bayesian IRL, but is able to learn non-linear rewards unlike prior Bayesian methods.	abstract
2021-874	Strengths: The method is novel. The motivation of the work is good: you identify important problems on IRL in the first introductory paragraph.	strength
2021-874	(It would benefit from more follow-through -- which of these problems have you solved?)	weakness
2021-874	Reporting examples of learned reward functions (or mean of the distribution learned) as well as summary statistics like EVD gives a more thorough understanding of the method.	strength
2021-874	Weaknesses: The paper was difficult to understand.	weakness
2021-874	The contribution seems limited. The method still seems challenging to scale (and no attempt is made to evaluate this), which seems to be it's main advantage relative to Bayesian IRL.	weakness
2021-874	Moreover, it is unclear if the probability distribution learned is well-calibrated, unlike Bayesian IRL.	weakness
2021-874	Weak baselines. DeepMaxEnt is a fairly old approach -- why not try e.g. AIRL?	weakness
2021-874	There's also no information as to how you trained the baselines, so it's difficult to know whether e.g. hyperparameter tuning was performed appropriately (noting that this environment is fairly different to what DeepMaxEnt was originally trained in).	weakness
2021-874	You should report the results of GPIRL given that this algorithm was developed for exactly this environment.	weakness
2021-874	I find the approach intriguing and would encourage you to continue developing it, but the submission is too preliminary to accept at this stage.	decision
2021-874	In particular, I would suggest the following modifications: Significant edits to improve clarity.	weakness
2021-874	For example, the abstract is quite terse, especially the second sentence.	weakness
2021-874	I understood it since I am very familiar with this area, but most readers would be lost.	weakness
2021-874	I had to read section 2.2 several times to understand what you were proposing -- here (and elsewhere) you would benefit from giving the reader some intuition before diving into the math.	weakness
2021-874	The basic idea is relatively simple: you are performing maximum likelihood estimation on parameters Θ that define a probability distribution over weights.	weakness
2021-874	Then there are some details: how you sample the data when you perform MLE (effectively from a power set of the demonstrations, thresholded by some minimum size),	weakness
2021-874	Clarify what the benefits of your method relative to prior work are, and then rigorously justify this (whether theoretically or empirically).	suggestion
2021-874	For example, is having a probability distribution over rewards actually a desiderata (in which case you should evaluate if they're well-calibrated), or is it an artifact of the method?	suggestion
2021-874	Likewise, being candid about it's limitations would help the reader evaluate whether it is appropriate for their application or what novel research directions exist to improve it.	suggestion
2021-874	Improved evaluation. Stronger baselines as discussed in "Weakness" above.	suggestion
2021-874	More environments. Perhaps report runtimes -- this would help assess scalability.	suggestion
2021-874	I found this line uncompelling: "Note that since almost only objectworld provides a tool that allows analysis and display the evolution procedure of the SIRL problem in a 2D heat map, we skip the typical invisible physics-based control tasks for the evaluation of our approach".	weakness
2021-874	First, this is wrong: objectworld is not that unique, you could visualize reward over e.g. a gridworld or tabular MDP, and many IRL papers have done so.	weakness
2021-874	Second, providing this visualization does not preclude also evaluating in more complex environments -- as the AIRL paper did, for example.	weakness
2021-874	I strongly suspect your algorithm simply won't scale to such environments (at least without considerable hand-designed feature engineering) -- if this is true then admit it and discuss how you can address it in future work, and if it's false then show that I'm wrong with results.	weakness
2021-874	You should discuss limitations of your work somewhere, e.g. conclusion.	suggestion
2021-874	For example the convergence guarantee only holds in the limit of infinite data if I understand -- there is no finite-time bound?	suggestion
2021-874	This is common for MCMC methods which your approach is related to, so not too surprising, but it's important to make the reader aware of.	suggestion
2021-874	Some questions I would appreciate clarification on: How is fM actually defined?	weakness
2021-874	In particular, what do the weights W really do?	weakness
2021-874	A naive reading would suggest that you take a linear combination of the "feature basis functions" -- but I think you must do something more complex since you evaluate in an environment with a highly non-linear reward?	weakness
2021-874	What is Algorithm 1: Generative Algorithm actually meant to be doing?	weakness
2021-874	It seems one could not use this in practice, since it requires computing the EVD, which is only computable if one knows the ground-truth reward -- in which case no need for IRL.	weakness
2021-874	So I assume it is meant solely for evaluation -- but I am unsure what this is evaluation.	weakness
2021-874	If this is meant to be focusing on the most robust samples, then you should report what probability mass these samples have.	weakness
2021-874	Also, is "any W'" meant to be a universal or existential quantifier?	weakness
2021-874	Some points to improve clarity.	weakness
2021-874	At a high-level: Paper might benefit from separate related work section.	weakness
2021-874	Intro is currently serving as this.	weakness
2021-874	But it detracts from the story.	weakness
2021-874	You could just summarize the IRL problem, what the key deficiency in existing work is that you're trying to solve, and then dive into describing your method and contributions.	weakness
2021-874	Many parentheses should be parenthetical, e.g. "are known Russel (1998)" -> "are known (Russel, 1998)" – change \\cite to \\citep in the source.	weakness
2021-874	As mentioned before, would benefit from proofreading for grammar.	weakness
2021-874	Examples: "problem is ill-posed that the" -> "problem is ill posed: the", "an inverse problem that a" -> "an inverse problem where a"; "is in a lack of an explanation" -> "does not explain"; "variability set" -> "variable set".	weakness
2021-874	Some specific points: Abstract, "considerable performance" – weaselword, how good is it relative to expert, to a baseline, ...?	weakness
2021-874	Preliminary, description of transition dynamics: "being current state s, taking action a and yielding next state s'" – does not make the conditionality clear.	weakness
2021-874	Perhaps "transitioning to next state s' when taking action a in state s".	weakness
2021-874	Preliminary, MDP\\R: I have normally seen this include the discount factor, which is important to understand expert behavior.	weakness
2021-874	I think you assume this too in your algorithm?	weakness
2021-874	If not, flag this, and describe how you recover rewards without knowing the discount.	suggestion
2021-874	Typo: "experimental trail"->"experimental trial".	weakness

2021-1156	########################################################################## Summary: The authors proposed CNV-Net, a deep learning-based approach for copy number variation identification.	abstract
2021-1156	They encoded mapped DNA sequences into a pileup image that captures reference sequence, sequencing coverage, and mapped reads.	abstract
2021-1156	Then, they used CNNs to classify it into deletions, duplications, or non-breakpoints.	abstract
2021-1156	They benchmarked CNV-Net with two whole-genome sequencing datasets and claimed to obtain more accurate and efficient results than current tools.	abstract
2021-1156	########################################################################## Major comments: While the paper has its own merits, unfortunately, it has several issues that need to be addressed.	misc
2021-1156	Although the authors claimed that CNV-Net is the first tool to use a CNN to detect CNVs, this is not true.	rebuttal_process
2021-1156	Several previous works used CNNs for CNV detection.	rebuttal_process
2021-1156	Furthermore, I think other machine learning and deep learning-based works should also be acknowledged.	rebuttal_process
2021-1156	I'd recommend authors properly cite and compare previous works with the proposed method.	suggestion
2021-1156	Some of the previous works include the followings: (1) Zhang, Yun Xiang, et al. "DL-CNV: A deep learning method for identifying copy number variations based on next generation target sequencing." Mathematical biosciences and engineering: MBE 17.1 (2019): 202-215.	misc
2021-1156	(2) Cai, Lei, Yufeng Wu, and Jingyang Gao.	misc
2021-1156	"DeepSV: accurate calling of genomic deletions from high-throughput sequencing data using deep convolutional neural network." BMC bioinformatics 20.1 (2019): 665.	misc
2021-1156	(3) Hill, Tom, and Robert L.	misc
2021-1156	Unckless. "A deep learning approach for detecting copy number variation in next-generation sequencing data." G3: Genes, Genomes, Genetics 9.11 (2019): 3575-3582.	misc
2021-1156	(4) Pounraja, Vijay Kumar, et al. "A machine-learning approach for accurate detection of copy number variants from exome sequencing." Genome research 29.7 (2019): 1134-1143.	misc
2021-1156	The main contribution of the paper would be using a pileup image of mapped reads and a CNN to detect CNVs. However, in my view, the novelty of the paper is quite limited.	weakness
2021-1156	As stated in the introduction, the pileup image encoding and CNNs have already been used in a couple of previous works for SNV detection.	weakness
2021-1156	I could find any significant methodological differences in CNV and SNV detections; it seems like rather a straightforward application of previous methods on another similar problem.	weakness
2021-1156	Otherwise, please clarify the differences between the two problems and what authors have done to overcome the new obstacles.	suggestion
2021-1156	The core issue I have with this paper is that I do not think the experiment settings are realistic.	weakness
2021-1156	As stated by the authors, CNV-Net must know the candidate CNV positions.	weakness
2021-1156	I think this is a serious issue that must be handled rather than leaving it as a limitation of the work.	ac_disagreement
2021-1156	Currently, the CNV-Net is evaluated with mapped and pre-preprocessed reads with CNV centered breakpoints.	ac_disagreement
2021-1156	Compared to the experiments conducted in the previous works, the experiments of the proposed work seem limited, unrealistic, and biased in favor of the proposed method.	weakness
2021-1156	In my view, the authors left out too much information.	weakness
2021-1156	For examples, it is quite difficult to understand how they used other tools for the experiments; Do they only use the CNV breakpoints that passed the quality control filter as CNV-Net?	weakness
2021-1156	Or do they use all the mapped reads?	weakness
2021-1156	What tool-specific arguments did the authors use for each tool?	weakness
2021-1156	Currently, it is extremely difficult to reproduce the results presented in the paper.	weakness
2021-1156	########################################################################## Minor comments: How did the authors choose the specific numbers to encode individual base into R channel (e.g. A with 250, G with 180)	weakness
2021-1156	In the results section, the authors stated that they only used CNVs passing the quality control filter.	weakness
2021-1156	Please provide more details for the filter explaining the filtering criteria and how they chose them.	suggestion
2021-1156	In Table 2, how did the authors obtain the metrics for the multi-class problem?	weakness
2021-1156	Please state whether they are macro or micro averages of scores.	suggestion
2021-1156	########################################################################## The authors present an innovative approach to CNV detection using CNNs. However, I believe that additional experiments need to performed before this paper is ready for publication.	decision
2021-1156	Below is a breakdown of strengths and weaknesses of this submission.	misc
2021-1156	Strengths: The empirical results seem encouraging compared to baselines.	strength
2021-1156	The method seems easy to implement and runs very fast.	strength
2021-1156	Cons: There is only one comparison performed.	weakness
2021-1156	I was wondering what the results are like in the opposite direction (training in HG002 and testing on NA12878)?	weakness
2021-1156	Furthermore, the authors should consider other datasets, in particular the TCGA data where bam files, and copy number variations are available.	suggestion
2021-1156	The authors can train the method on one patient and test on another.	suggestion
2021-1156	There is lack of analysis on whether the method can recover known canonical copy number variations.	weakness
2021-1156	In the TCGA dataset, and for certain cancer types, there are small and large copy-number variations that are known and have been validated in the lab.	weakness
2021-1156	The authors should ensure that their method can recover these events using their method.	suggestion
2021-1156	The authors have considered baselines that do not take as input already known break points, which makes the comparison somewhat unfair.	weakness
2021-1156	I was wondering if there is a way in which the authors can use the discovered breakpoints for each respective baseline and then determine whether their algorithm can improve the predictions?	weakness
2021-1156	Summary They authors describe a method to detect structural variation from aligned sequencing reads in a genome browser view.	abstract
2021-1156	Their model encodes this genome browser view into an RGB image and applies a deep convolutional neural network to classify variant type (or no variant).	abstract
2021-1156	They make use of curated variant annotations to train and test their model.	abstract
2021-1156	Major comments The RGB encoding is entirely arbitrary, unnecessary, and confusing.	weakness
2021-1156	The authors should consider the actual range of the various input data and encode with a simple and interpretable strategy.	suggestion
2021-1156	For example, nucleotides are typically one hot encoded.	suggestion
2021-1156	The improved accuracy on this task is abstract when only summarized in tables.	weakness
2021-1156	Depicting an example of a structural variant whose prediction is improved by the authors' method would be very valuable.	suggestion
2021-1156	Ideally, both a false positive turned true negative and a false negative turned true positive could be shown.	suggestion
2021-1156	The requirement that this method be provided candidate structural variation start and end points means that it's actually a module that would need to be plugged into a pipeline that also specified how those candidates are obtained.	suggestion
2021-1156	I would encourage the authors to develop that strategy before publishing their method.	suggestion
2021-1156	The authors have not clearly described how the predictions of the other methods were used to annotate these curated variants.	weakness
2021-1156	Doing so involves critical parameters, such as the allowed distance between the method prediction and true specified variant break points.	suggestion
2021-1156	Setting these parameters to strict values would be very unfair given that the authors method is not required to produce such breakpoints de novo.	suggestion
2021-1156	The Zook et al. paper describes this process in detail and discusses several software packages to do it.	suggestion
2021-1156	Minor comments Does the authors' method make use of paired end read information?	suggestion
2021-1156	How does Table 2 combine the accuracies for duplications and indels?	suggestion
2021-1156	The authors in the paper describe a deep learning approach to detect copy number variants (CNVs) from DNA sequencing data, CNV-Net.	abstract
2021-1156	It described the approach by transforming the pileups into images and pass them through a CNN.	abstract
2021-1156	This strategy has been proposed four or five years back to do SNPs and indels calling (DeepVariant).	abstract
2021-1156	It is challenging for SVs and CNVs as they can be arbitrarily large.	abstract
2021-1156	However, there are also several existing models for this task (e.g. DeepSV, RDBKE).	weakness
2021-1156	In this work, the authors only consider "candidate CNV regions" which are 201-bp small genomic regions that centered at the breakpoints.	weakness
2021-1156	The paper is only 4.5 pages.	weakness
2021-1156	First, the authors did not explain or investigate many decisions in their model design.	weakness
2021-1156	Then the experiments are flawed.	weakness
2021-1156	I have many questions and concerns.	misc
2021-1156	First of all, this should not be called a CNV detector because it is in fact a breakpoint detector	weakness
2021-1156	How did the authors do negative sampling?	suggestion
2021-1156	Were the negative samples randomly drawn from the genome?	weakness
2021-1156	This creates bias as the sequence features might shift dramatically.	weakness
2021-1156	Why are the negative samples not balanced with the positive samples?	weakness
2021-1156	Are there differences in performance between deletion and duplications breakpoints?	weakness
2021-1156	Does the model distinguish these two types?	suggestion
2021-1156	When splitting the training/validation/testing dataset, there will be significant data leakage if this is done randomly.	suggestion
2021-1156	Many SV/CNV regions have characteristic repeats patterns.	weakness
2021-1156	The comparison between CNV-Net and other methods is not fair as the other methods are finding CNVs in the whole genome while CNV-Net is given a pre-defined set of "candidate breakpoint regions" in which positive samples have breakpoints perfectly centered in the middle.	weakness
2021-1156	Moreover, such candidate regions might suffer from data leakage.	weakness
2021-1156	Does HG002 really only has 174 duplications while NA12878 has 22,936?	weakness
2021-1156	GIAB has more than two genomes available.	weakness
2021-1156	Can we test on more genomes?	weakness
2021-1156	Minor: RELU -> ReLU	misc

2021-2058	In this paper, the authors proposed two graph pooling methods, i.e., Neural Pooling Method 1 and 2.	abstract
2021-2058	Both of them are flat pooling strategies, which try to obtain a graph representation directly from its node representations without coarsening graphs step by step.	abstract
2021-2058	Specifically, the major idea of Neural Pooling Method 1 is to use GCN layer to learn a score for each node.	abstract
2021-2058	Then, the graph representation is obtained by weighted summing the node representations with the learned scores as weights.	abstract
2021-2058	Neural Pooling Method 2 follows a similar design.	abstract
2021-2058	The difference is that, instead of a single score, it has multiple scores for each node, which leads to a matrix for graph representation.	abstract
2021-2058	This matrix is then flattened into a vector to serve as the graph representation.	abstract
2021-2058	In general, the novelty of this paper is limited.	weakness
2021-2058	Some other concerns are listed as follows: It is not clearly motivated why the topology information can be preserved by the two proposed pooling method.	weakness
2021-2058	It would be better if the authors could provide more explanation.	weakness
2021-2058	The process in Equation (6) can be viewed as a weighted summation.	weakness
2021-2058	However, the values in Q seem to be unbounded, which makes the magnitude of the graph representation h_G highly dependent on the size of graphs (i.e., number of nodes).	weakness
2021-2058	Is it designed in this way on purpose to capture the node size information?	weakness
2021-2058	The same issue exists in the Neural Pooling Method 2.	weakness
2021-2058	It would be better if the users could adopt more datasets should for experiments.	weakness
2021-2058	Minor comments: When analyzing the complexity of algorithms, it might be better to use general notations instead of concrete numbers.	weakness
2021-2058	1). The claim of "the variable number of node representations as inputs and producing fixed-sized graph representations" is weak.	weakness
2021-2058	This can be easily addressed by simply using average pooling or sum pooling.	weakness
2021-2058	2).. The writing needs to be improved.	weakness
2021-2058	The quality is very low.	weakness
2021-2058	For example, even in the introduction, where is the ending of the second paragraph?	weakness
2021-2058	some  full stop mark is needed.	weakness
2021-2058	"Neural Pooling Method 1 and 2", it is better to give them specific names for better reference.	weakness
2021-2058	"After this H0 is again passed through", simply not readable..	weakness
2021-2058	3). "Neural Pooling Method 2" lacks of intuition.	weakness
2021-2058	Could you please provide more intuitions on the solution during the rebuttal?	suggestion
2021-2058	4). The results reported seems much worse than results reported in other paper.	weakness
2021-2058	For example, in the paper below.	suggestion
2021-2058	We can easily see the best result in PTC, best result is 80.41±6.92 while the submission gives only 76.2 ± 4.2  From that perspective, I did not see any advantage in the submission.	weakness
2021-2058	Structural Landmarking and Interaction Modelling: on Resolution Dilemmas in Graph Classification,	misc
2021-2058	https://arxiv.org/pdf/2006.15763.pdf 5). The paper is lack of parameter sensertivity analysis, without which the robustness of the proposed algorithms is unknown to me.	weakness
2021-2058	I would suggest the authors add additional section to discuss that.	suggestion
2021-2058	6). The draft includes an github link to share the code, however that link indicates the author affiliation information.	suggestion
2021-2058	Clearly I could not access the code on the github as I would have risked infringing anonymity.	weakness
2021-2058	In this manuscript, the authors propose two novel methods using fully connected neural network layers for graph pooling, namely Neural Pooling Method 1 and 2.	abstract
2021-2058	compared to existing graph pooling methods, the authors think their methods are able to capture information from all nodes, collect second-order statistics, and leverage the ability of neural networks to learn relationships among node representations, making them more powerful.	abstract
2021-2058	Pros : This work studies an important topic but less explored topic, graph pooling.	strength
2021-2058	Propose to perform graph representation learning with Neural Pooling.	misc
2021-2058	Experimental results are interesting. Cons: The main concern is the lack of novelty, and the technical contribution is very limited.	weakness
2021-2058	The essential difference between the author's manuscript and this article is unclear -- 'Z.	weakness
2021-2058	Wang and S. Ji. Second-order pooling for graph neural networks.	misc
2021-2058	IEEE Transactions on Pattern Analysis and Machine Intelligence, 2020.'?	misc
2021-2058	Just one more layer? And there is a lot of overlap in content with this article.	weakness
2021-2058	It is actually a stealth exchange of concepts that the authors attribute the success of the methods to the neural networks.	weakness
2021-2058	On the one hand, the reason H′TQ or  H′TH′ can capture topology information is not that the neural networks can learn H′ that contains topology information, but that H itself contains local topology information and HTH is capable of capturing second-order statistics.	weakness
2021-2058	In fact, the neural networks don't use topological structure.	weakness
2021-2058	They play a vital role in reducing dimension and parameters, which is proven in Section 6.	weakness
2021-2058	On the other hand, Q can be thought of as the weight of the node, not as the correlation among the node representations.	weakness
2021-2058	Therefore, the statement 'Neural networks can learn the correlation among the node representation' lack of further explanation.	weakness
2021-2058	About the experiment of this manuscript: a.    Several advanced pooling methods are ignored, especially EigenPooling.	weakness
2021-2058	Why does it appear in the method comparison in Section 4.3, but disappear in Table 2.	weakness
2021-2058	b.    Datasets are not enough.	weakness
2021-2058	Just 4 of the 9 data sets in this article are used -- 'Z.	weakness
2021-2058	Wang and S. Ji. Second-order pooling for graph neural networks.	misc
2021-2058	IEEE Transactions on Pattern Analysis and Machine Intelligence, 2020.'	misc
2021-2058	About the clarity of this manuscript: a.    Figures 1 and 2 are not beautiful and have minor issues.	weakness
2021-2058	H′TQ and QH′T are not equal, which can be corrected by slightly changing the diagrams.	weakness
2021-2058	b.    Repeat a paragraph and an equation many times.	weakness
2021-2058	For example, in Sections 3.1, 3.2, 3.3 and Section 6, there are redundant.	weakness
2021-2058	c.    The lack of punctuation, such as the end of the second paragraph of Section 1 on the first page, and the end of the second last paragraph of Section 3.3 on page 5, etc.	weakness
2021-2058	d.    Many long sentences make understanding difficult.	weakness
2021-2058	For example, in section 3.2, there is only one long sentence in a paragraph.	weakness
2021-2058	This paper proposes two fully-connected layers based neural graph pooling methods for graph neural networks, named Neural Pooling Method 1 and Neural Pooling Method 2.	abstract
2021-2058	The first method uses a first FC to reduce the feature dimension and then FC2 to compute the weights to do weighted-average over features for different nodes.	abstract
2021-2058	The second method uses two FC to reduce the dimension and then compute second-order statistics by Flatten(H^{\\top}H).	weakness
2021-2058	Experimental results on four datasets (PTC, PROTEINS, IMDB-BINARY, IMDB-MULTI) of two tasks (bioinformatics, social networks) show that the proposed graph pooling method can improve the performance by 0.5%-1.2% accuracy while decreasing the std.	abstract
2021-2058	Strengths: The proposed method is simple and motivated by several limitations of current graph pooling methods such as average and summation, DIFFPOOL, SORTPOOL, TOPKPOOL, SAGPOOL, and EIGENPOOL.	strength
2021-2058	The proposed approach is simple and the experimental results can deliver improvements on several tasks and datasets.	strength
2021-2058	Weaknesses: My biggest concern is that the proposed approach lacks originality and novelty because it is a simplification and variant of SOPOOL from Second-Order Pooling for Graph Neural Networks (Ji and Wang, 2020)	weakness
2021-2058	Based on the author's writing, it is unclear what is the second-order statistics for graph pooling, why it is important to have second-order pooling, and how the proposed method can capture the second-order statistics.	weakness
2021-2058	The proposed graph pooling method is only experimented with 1 underlying particular choice of GNN (Xu et al., 2019), so it is unclear how well the method can perform on other GNN architectures.	weakness
2021-2058	The four datasets only have 2 or 3 classes and upto 620 nodes.	weakness
2021-2058	So it is clear how well the method can generalize to large-scale graph classification problems.	weakness
2021-2058	The improvement of the proposed methods compared with SOPpool is marginal.	weakness
2021-2058	For example, On PROTEINS, the accuracy is improved by 0.5% with the same std.	weakness
2021-2058	On other datasets, the improvements are only at most 1.2%.	weakness
2021-2058	To show the proposed approach is better, more datasets or tasks should be used.	weakness
2021-2058	For example, there are five bioinformatics datasets (MUTAG, PTC, PROTEINS, NCI1, DD) and five social network datasets (COLLAB, IMDB-BINARY, IMDB-MULTI, REDDIT-BINARY, REDDIT-MULTI5K).	weakness
2021-2058	There is not enough discussion and analysis of the results.	weakness
2021-2058	Especially, there should be some analysis to compare the method 1 and method 2: For different datasets, when one method is better than the other?	weakness
2021-2058	Some examples would be helpful, too.	weakness
2021-2058	While the author explains the proposed method has lower complexity, there is still no formal analysis or quantitative measures of running time from experiments.	weakness
2021-2058	The writing can be improved, In the abstract and introduction, the author should describe the approach briefly and explain its characteristics including why it can handle variable number of nodes, invariant to isomorphic graph structures, capture information of all nodes, and especially why it can collect second-order statistics.	weakness
2021-2058	Furthermore, there is a lot of repetition of problem statements.	weakness
2021-2058	The problem and notation is introduced formally in section 3.1, but is repeated again and again at the beginning of section 3.2 and section 3.3	weakness
2021-2058	Questions: Do both of your method 1 and method 2 capture second-order statistics?	weakness
2021-2058	My understanding is that only method 2 captures second-order statistics by computing Flatten(H^{\\top}H).	weakness
2021-2058	Is this correct? How do you compare your method with SOPpool (Ji and Wang, 2020)?	weakness
2021-2058	Have you tried other datasets or other tasks?	weakness
2021-2058	Have you tried your graph pooling approaches on other underlying GNN models?	suggestion
2021-2058	Is your standard deviation in Table 2 based on 1 run of 10 folds or multiple runs of 10-fold cross-validation?	suggestion
2021-2058	Minor: Please give better names for your approaches and give a better title.	suggestion
2021-2058	"Neural Pooling Method" is too general and thus not particular enough to summarize your method.	weakness

