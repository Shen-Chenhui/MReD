2018-490	Unfortunately, it falls short of *CONF* standards -- from evaluation, novelty and clarity perspectives.	decision
2018-490	The method is also not discussed in all details.	weakness

2018-521	Thank you for submitting you paper to *CONF*.	misc
2018-521	*CONF*.	misc
2018-521	The consensus from the reviewers is that this is not quite ready for publication.	rating_summary

2018-541	meta score: 4 <sep>	decision
2018-541	The paper has been extensively edited during the review process - the edits are so extensive that I think the paper requires a re-review, which is not possible for *CONF* 2018 <sep>	rebuttal_process
2018-541	Pros: <sep> - potentially interesting and novel approach to prefix encoding for character level CNN text classification <sep>	strength
2018-541	- some experimental comparisons <sep>	strength
2018-541	Cons: <sep> - lacks good comparison with the state-of-the-art, which makes it difficult to determine conclusions <sep>	weakness
2018-541	- writing style lacks clarity. <sep>	weakness
2018-541	I would recommend that the authors continue to improve the paper and submit it to a later conference.	decision

2018-550	This work is interested in using sentence vector representations as a method for both doing extractive summarization and as a way to better understand the structure of vector representations.	abstract
2018-550	While the methodological aspects utilize representation learning, the reviewers felt that the main thrust of the work would be better suited for a summarization workshop or even NLP venue, as it did not target DL based contributions.	suggestion
2018-550	Additionally they felt that the work did not significantly engage with the long literature on the problem of summarization.	weakness

2018-656	This paper is lacking in terms of clarity and experimentation, and would require a lot of additional work to bring it to the standards of any high quality venue.	weakness

2018-673	The reviewers rightly point out that presented analysis is limiting and that the experimental results are not extensive enough.	weakness
2018-673	Moreover, several existing work that use raw waveforms have interesting analysis of what the network is trying to learn.	weakness
2018-673	Given these comments, the AC recommends that the paper be rejected.	decision

2018-695	Two of the reviewers liked the intent of the paper -- to analyze gradient flow in residual networks and understand the tradeoffs between width and depth in such networks.	strength
2018-695	However, all reviewers flagged a number of problems in the paper, and the authors did not participate in the discussion period. <sep>	rebuttal_process
2018-695	Pros: <sep> + Interesting analysis suggests wider, shallower ResNets should outperform narrower, deeper ResNets, and empirical results support the analysis. <sep>	strength
2018-695	Cons: <sep> - Independence assumption on weights is not valid after any weight updates. <sep>	weakness
2018-695	- The notation is not as clear as it should be. <sep>	weakness
2018-695	- Empirical results would be more convincing if obtained on several tasks. <sep>	weakness
2018-695	- The architecture analyzed in the paper is not standard, so it isn't clear how relevant it is for other practitioners. <sep>	weakness
2018-695	- Analysis and paper should take into account other work in this area, eg Veit et al, 2016 and Schoenholz et al, 2017.	weakness

2018-742	Pros: <sep> - Addresses an important medical imaging application <sep>	strength
2018-742	- Uses an open dataset <sep>	strength
2018-742	Con: <sep> - Authors do not cite original article describing challenge from which they use their data: https://arxiv.org/pdf/1612.08012. pdf , or the website for the corresponding challenge: https://luna16. grand-challenge.org/results/ <sep>	weakness
2018-742	- Authors either 1) do not follow the evaluation protocol set forth by the challenge, making it impossible to compare to other methods published on this dataset, or 2) incorrectly describe their use of that public dataset. <sep>	weakness
2018-742	- Compares only to AlexNet architecture, and not to any of the other multiple methods published on this dataset (see: https://arxiv.org/pdf/1612.08012. pdf). <sep>	weakness
2018-742	- Too much space is spent explaining well-understood evaluation functions. <sep>	weakness
2018-742	- As reviewers point out, no motivation for new architecture is given.	weakness

2018-743	The presented method essentially builds a model that remaps features into a new space that optimizes nearest-neighbor classification.	abstract
2018-743	The model is a neural network, and the optimization is carried out through a genetic algorithm. <sep>	abstract
2018-743	Pros: <sep> - One major issue with neural network classification is that of a lack of explainability.	strength
2018-743	Many networks are currently "black box" approaches.	strength
2018-743	By moving to the optimization problem to that of building a feature space for nearest neighbor classification, one can, to a degree, alleviate the "black box" issue by providing the discovered nearest neighbor instances as "evidence" of the decision. <sep>	strength
2018-743	- Authors use established datasets. <sep>	strength
2018-743	Cons: <sep> - Authors do not properly cite previous work, as brought up by reviewers.	weakness
2018-743	There is much literature on optimization of feature spaces (such as the entire field of metric learning), as well as prior approaches using genetic optimization.	weakness
2018-743	The originality and significance here is therefore not clear.	weakness

2018-764	The reviewers were quite unanimous in their assessment of this paper. <sep>	misc
2018-764	PROS: <sep> 1. The paper is relatively clear and the approach makes sense <sep>	strength
2018-764	2. The paper presents and evaluates a collection of approaches to speed learning of policies for manipulation tasks. <sep>	strength
2018-764	3. Improving the data efficiency of learning algorithms and enabling learning across multiple robots is important for practical use in robot manipulation. <sep>	strength
2018-764	4. The multi-stage structure of manipulation is nicely exploited in reward shaping and distribution of starting states for training. <sep>	strength
2018-764	CONS <sep> 1. Lack of novelty eg wrt to Finn et al in "Deep Spatial Autoencoders for Visuomotor Learning" <sep>	weakness
2018-764	2. The techniques of asynchronous update and multiple replay steps may have limited novelty, building closely on previous work and applying it to this new problem. <sep>	weakness
2018-764	3. The contribution on reward shaping would benefit from a more detailed description and investigation. <sep>	weakness
2018-764	4. There is concern that results may be specific to the chosen task. <sep>	weakness
2018-764	5. Experiments using real robots are needed for practical evaluation.	weakness

2018-799	The reviewers highlight a lack of technical content and poor writing. <sep>	weakness
2018-799	They all agree on rejection. <sep>	rating_summary
2018-799	There was no author rebuttal or pointer to a new version.	rebuttal_process

2018-801	Reviewers are unanimous that this is a reject. <sep>	rating_summary
2018-801	A "class project" level presentation. <sep>	weakness
2018-801	Errors in methodology and presentation. <sep>	weakness
2018-801	No author rebuttal or revision	rebuttal_process

2018-821	The reviewers have found that while the task of visual domain adaptation is meaningful to explore and improve, the proposed method is not sufficiently well-motivated, explained or empirically tested.	weakness

2018-827	This paper proposes a method for refining distributional semantic representation at the lexical level.	abstract
2018-827	The reviews are fairly unanimous in that they found both the initial version of the paper, which was deemed quite rushed, and the substantial revision unworthy of publication in their current state.	rating_summary
2018-827	The weakness of both the motivation and the experimental results, as well as the lack of a clear hypothesis being tested, or of an explanation as to why the proposed method should work, indicates that this work needs revision and further evaluation beyond what is possible for this conference.	weakness
2018-827	I unfortunately must recommend rejection.	decision

2019-22	The authors propose two contributions a) data augmentation techniques for scene graph to image generation as well as b) a new mechanism for the scene graph to image generation that maintains context using a GCNN. <sep>	abstract
2019-22	Pros: <sep> - The augmentation strategy makes sense and is reasonably illustrated <sep>	strength
2019-22	- Improve on highly relevant problem that is not well solved or easily evaluated as the authors mentioned <sep>	strength
2019-22	-The metareviewer and R1 appreciate the perceptual studies with amazon turk. <sep>	strength
2019-22	-The first contribution is well in keeping with the theme of this workshop. <sep>	strength
2019-22	Cons: <sep> -As mentioned by R2 more details should really be included at least in the appendix.	weakness
2019-22	eg any major differences to the JJ pipeline such as size and form of the Graph CNN context rep.	weakness
2019-22	The authors also should cite the graphic copied from Johnson et al <sep>	weakness
2019-22	- No ablations to show the effect of the different contributions compared to JJ (it is not completely clear whether the gain comes from the augmentation, use of the context GCNN or from architecture/other changes to JJ pipeline). <sep>	weakness
2019-22	-It should be made more clear if the scene augmentations are also used for the evaluation scene graphs and if so whether the JJ model also sees the same augmented scenes at evaluation. <sep>	weakness
2019-22	Overall this paper handles a very difficult and challenging problem and both contributions as well as the suggested evaluations are substantial.	strength

2019-24	Reviewers appreciated the idea  but found it difficult to understand the details.	weakness
2019-24	Most notably major experimental details such as the datased are not described.	weakness

2019-68	Although the scores are below our average acceptance rate, we believe this paper has interesting contributions: <sep> 1. The set of chosen languages is diverse. <sep>	strength
2019-68	2. Synthetic and real dataset for digits in these languages <sep>	strength
2019-68	3. Interesting way of using GANs to improve the downstream task.	strength

2019-73	This paper  studies sequential MC for training deep generative models.	abstract
2019-73	The paper is well-written but the authors should connect the work to existing works as mentioned by reviewer 1	suggestion

2019-74	This work presents a method for style transfer which enables users to modify the output via adjusting different hyperparameters.	abstract
2019-74	The reviewers agreed that this is a well-written paper with interesting experimental results.	strength

2019-81	This paper proposes a VAE for images with multiple labels and a new evaluation metric called Conditional Inception Score (CIS) that measures the influence of the target class to the image.	abstract
2019-81	The experiments are reasonable.	strength

2019-86	The authors propose new model with geometric features for modeling 3d structure.	abstract
2019-86	There were some concerns with regard to clarity (eg how does decoding work?), which should be addressed for the camera-ready.	weakness

2019-87	This paper presents a fusion discriminator which conditions upon extra information through fusion at multiple layers of the discriminator.	abstract
2019-87	The paper is well-executed and the experiments are convincing.	strength

2019-92	The paper's results are interesting but the reviewers note that the loss is not well motivated theoretically.	weakness
2019-92	It would be good to explore this aspect further.	suggestion

2019-96	The paper proposes and interesting task/dataset, but the description of the model could be improved.	weakness
2019-96	It would be great to take this account for the camera-ready.	suggestion

2019-101	As the reviewers note, it is true that both SCST and Gumbel ST have been utilized in the past for reinforcement-learning style problems.	strength
2019-101	However the application to GAN-based image captioning and the thorough experiments will make a nice contribution to the workshop.	strength

2019-104	The generated images are impressive but as the reviewers note, it would be good to have quantitative comparison against existing methosd.	suggestion

2019-106	This paper has interesting contributions.	strength
2019-106	However both reviewers agree it would be valuable to add an analysis as to whether the objective is a bound on the log marginal or not.	suggestion

2019-672	The paper describes the use of tactile sensors for exploration.	abstract
2019-672	An important topic which has been addressed in various previous publications, but is unsolved to date. <sep>	abstract
2019-672	The research and the paper are unfortunately in a raw state.	weakness
2019-672	Rejected unanimously by the reviewers, without rebuttal chances used by the authors.	rating_summary

2019-697	This paper focuses on the problem of detecting visual anomalies within textures.	abstract
2019-697	For that purpose, the authors consider several parametric texture models and train anomaly detection models on the corresponding outputs. <sep>	abstract
2019-697	Reviewers were generally positive about the topic under study, but were unanimous in signaling a severe weaknesses in the experimental setup.	weakness
2019-697	In particular, in R2 words, "my main concern is that the performance evaluation is not suitable to achieve meaningful results", and "showing quantitative results from only two textures does not feel like a very comprehensive analysis".	weakness
2019-697	Moreover, the authors did not respond to reviewers feedback.	rebuttal_process
2019-697	Therefore, the AC recommends rejection at this time.	decision

2019-703	Dear authors, <sep>	misc
2019-703	All reviewers pointed to severe issues with the analysis, making the paper unsuitable for publication to *CONF*.	decision
2019-703	Please take their comments into account should you decide to resubmit this work.	suggestion

2019-784	This manuscript presents a reinterpretation of hindsight experience replay which aims to avoid recomputing the reward function, and investigates Floyd-Warshall RL in the function approximation setting. <sep>	abstract
2019-784	The paper was judged as relatively clear.	strength
2019-784	The authors report a slight improvement in computational cost, which some reviewers called into question.	weakness
2019-784	However, all of the reviewers pointed out that the experimental evidence for the method's superiority is weak.	weakness
2019-784	Two reviewers additionally raised that this wasn't significantly different than the standard formulation of Hindsight Experience Replay, which doesn't require the computation of rewards for relabeled goals. <sep>	weakness
2019-784	Ultimately, reviewers were in agreement that the novelty of the method and quality of the obtained results rendered the work insufficient for publication.	rating_summary
2019-784	The Area Chair concurs, and urges the authors to consider the reviewers' pointers to the existing literature in order to clarify their contribution for subsequent submission.	decision

2019-814	The reviewers and AC note the potential weaknesses of the paper in various aspects, and decided that the authors need more works to publish.	decision

2019-823	The paper presents Dopamine, an open-source implementation of plenty of DRL methods.	abstract
2019-823	It presents a case study of DQN and experiments on Atari.	abstract
2019-823	The paper is clear and easy to follow. <sep>	strength
2019-823	While I believe Dopamine is a very welcomed contribution to the DRL software landscape, it seems there is not enough scientific content in this paper to warrant publication at *CONF*.	decision
2019-823	Regarding specifically the ELF and RLlib papers, I think that the ELF paper had a novelty component, and presented RL baselines to a new environment (miniRTS), while the RLlib paper had a stronger "systems research" contribution.	weakness
2019-823	This says nothing about the future impact of Dopamine, ELF, and RLlib – the respective software.	weakness

2019-955	This paper proposes an "iterative" regularized dual averaging method to sparsify CNN weights during learning.	abstract
2019-955	The main contribution seems to be in an iterative procedure where the weights are pruned out greedily by observing the sparsity of the averaged gradients.	abstract
2019-955	The reviewers agree that the idea seems straightforward and novelty is limited.	weakness
2019-955	For this reason, I recommend to reject this paper.	decision

2019-958	The paper presents the combination of a model-based (probabilistic program representing the physics) and model-free (CNN trained with DQN) to play Flappy Bird. <sep>	abstract
2019-958	The approach is interesting, but the paper is hard to follow at times, and the solution seems too specific to the Flappy Bird game.	weakness
2019-958	This feels more like a tech report on what was done to get this score on Flappy Bird, than a scientific paper with good comparisons on this environment (in terms of models, algorithms, approaches), and/or other environments to evaluate the method.	weakness
2019-958	We encourage the authors to do this additional work.	suggestion

2019-1022	The authors present a system for end-to-end multi-lingual and multi-speaker speech recognition.	abstract
2019-1022	The presented method is based on multiple prior works that propose end-to-end models for multi-lingual ASR and multi-speaker ASR; the work combines these techniques and shows that a single system can do both with minimal changes. <sep>	abstract
2019-1022	The main critique from the reviewers is that the paper lacks novelty.	weakness
2019-1022	It builds heavily on existing work, and  does not make any enough contributions to be accepted at *CONF*.	weakness
2019-1022	Furthermore, training and evaluations are all on simulated test sets that are not very realistic.	weakness
2019-1022	So it is unclear how well the techniques would generalize to real use-cases.	weakness
2019-1022	For these reasons, the recommendation is to reject the paper.	decision

2019-1030	Dear authors, <sep>	misc
2019-1030	All reviewers pointed out the fact that your result is about the expressivity of the big network rather than its accuracy, a result which is already known for the literature. <sep>	weakness
2019-1030	I encourage you to carefully read all reviews should you wish to resubmit this work to a future conference.	suggestion

2019-1048	Pros: <sep> - an original idea: learn an additional inverse policy (that minimizes reward) to help find actions that should be avoided. <sep>	strength
2019-1048	Cons: <sep> - not clearly presented <sep>	weakness
2019-1048	- conclusions are not not validated <sep>	weakness
2019-1048	- empirical evidence is weak <sep>	weakness
2019-1048	- no rebuttal <sep>	weakness
2019-1048	The three reviewers reached consensus that the paper should be rejected in its current form, but make numerous suggestions for improving it for a future submission.	rating_summary

2019-1106	This paper combines two recently proposed ideas for GAN training: Fisher integral probability metrics, and the Deli-GAN.	abstract
2019-1106	As the reviewers have pointed out, the writing is somewhat haphazard, and it's hard to identify the key contributions, why the proposed method is expected to help, and so on.	weakness
2019-1106	The experiments are rather minimal: a single experiment comparing Inception scores to previous models on CIFAR; Inception scores are not a great measure, and the experiments don't yield much insight into where the improvement comes from.	weakness
2019-1106	No author response was given.	rebuttal_process
2019-1106	I don't think this paper is ready for publication in *CONF*.	decision

2019-1151	The paper proposes a neural network architecture for video compression.	abstract
2019-1151	The reviewers point out lack of novelty with respect to recent neural compression works on static images, which the present paper extends by adding a temporal consistency loss.	weakness
2019-1151	More importantly, reviewers point our severe problems with the metrics used to measure compression quality, which the authors promise to take into account in a future manuscript.	rebuttal_process

2019-1181	This paper presents a meta-learning approach which relies on a learned prior over neural networks for different tasks. <sep>	abstract
2019-1181	The reviewers found this work to be well-motivated and timely.	strength
2019-1181	While there are some concerns regarding experiments, the results in the miniImageNet one seem to have impressed some reviewers. <sep>	strength
2019-1181	However, all reviewers found the presentation to be inaccurate in more than one points.	weakness
2019-1181	R1 points out to "issues with presentation" for the hierarchical Bayes motivation, R2 mentions that the motivation and derivation in Section 2 is "misleading" and R3 talks about "short presentation shortcomings". <sep>	weakness
2019-1181	R3 also raises important concerns about correctness of the derivation.	weakness
2019-1181	The authors have replied to the correctness critique by explaining that the paper has been proofread by strong mathematicians, however they do not specifically rebut R3's points.	rebuttal_process
2019-1181	The authors requested R3 to more specifically point to the location of the error, however it seems that R3 had already explained in a very detailed manner the source of the concern, including detailed equations.<sep>	rebuttal_process
2019-1181	There have been other raised issues, such as concerns about experimental evaluation.	weakness
2019-1181	However, the reviewers' almost complete agreement in the presentation issue is a clear signal that this paper needs to be substantially re-worked.	rating_summary

2019-1189	1. Describe the strengths of the paper.	misc
2019-1189	As pointed out by the reviewers and based on your expert opinion. <sep>	misc
2019-1189	The paper tackles an interesting and relevant problem for *CONF*: optical character recognition in document images.<sep>	strength
2019-1189	2. Describe the weaknesses of the paper.	misc
2019-1189	As pointed out by the reviewers and based on your expert opinion.	misc
2019-1189	Be sure to indicate which weaknesses are seen as salient for the decision (ie, potential critical flaws), as opposed to weaknesses that the authors can likely fix in a revision.<sep>	misc
2019-1189	- The authors propose to use small networks to localize text in document images, claiming that for document images smaller networks work better than standard SOTA networks for scene text.	weakness
2019-1189	As pointed out in the reviews, the authors didn't make any comparisons to SOTA object detection networks (trained either on scene text or on document images) so their central claim has not been experimentally verified. <sep>	weakness
2019-1189	- The reviewers were unanimous that the work lacks novelty as object detection pipelines have already been used for OCR so a contribution of considering smaller detection networks is minor. <sep>	weakness
2019-1189	- There were serious issues with formatting and clarity. <sep>	weakness
2019-1189	These three issues all informed the final decision. <sep>	misc
2019-1189	3. Discuss any major points of contention.	misc
2019-1189	As raised by the authors or reviewers in the discussion, and how these might have influenced the decision.	misc
2019-1189	If the authors provide a rebuttal to a potential reviewer concern, it's a good idea to acknowledge this and note whether it influenced the final decision or not.	misc
2019-1189	This makes sure that author responses are addressed adequately.<sep>	misc
2019-1189	There were no major points of contention and no author feedback. <sep>	rebuttal_process
2019-1189	4. If consensus was reached, say so.	misc
2019-1189	Otherwise, explain what the source of reviewer disagreement was and why the decision on the paper aligns with one set of reviewers or another. <sep>	misc
2019-1189	The reviewers reached a consensus that the paper should be rejected.	rating_summary

2019-1207	All reviewers agree to reject.	rating_summary
2019-1207	While there were many positive points to this work, reviewers believed that it was not yet ready for acceptance.	rating_summary

2019-1231	The reviewers reached a consensus that the paper is not ready for publication in *CONF*.	rating_summary
2019-1231	(see more details in the reviews below. )	misc

2019-1235	The paper is poorly written and below the bar of *CONF*.	decision
2019-1235	The paper could be improved with better exposition and stronger experiment results (or clearer exposition of the experimental results.)	weakness

2019-1260	As the reviewers point out, the paper is below the acceptance standard of *CONF* due to low novelty, unclear presentation, and lack of experimental comparison against the state-of-the-art baselines.	decision

2019-1265	The authors consider the interesting and important problem of how to train a robust driving policy without allowing unsafe exploration, an important challenge for real-world training scenarios.	abstract
2019-1265	They suggest that both good and intentionally bad human demonstrations could be used, with the intuition being that humans can readily produce unsafe exploration such as swerving which can then be learnt using both positive and negative regressions.	abstract
2019-1265	The reviewers all agree that the paper would not appeal to or have relevance for the wider community.	rating_summary
2019-1265	The reviewers also agree that the main ideas are not well presented, that some of the claims are confusing, and that the writing is not technical enough.	weakness
2019-1265	They also question the thoroughness of the empirical validation.	weakness

2019-1272	The proposed "input forgetting" problem is interesting, and the reflective likelihood can come to be seen as a natural solution, however the reviewers overall are concerned about the rigor of the paper.	weakness
2019-1272	Reviewer 2 pointed out a technical flaw and this was addressed, however the reviewers remain unconvinced about the theoretical justification for the approach.	rebuttal_process
2019-1272	One suggestion made by reviewer 1 is to focus on simpler models that can be studied more rigorously.	suggestion
2019-1272	Alternatively, it could be useful to focus on stronger empirical results.	suggestion
2019-1272	The method works in the experiments given, but for example in the imbalanced data experiments, only MLE is compared to as a baseline.	weakness
2019-1272	I think it would be more convincing to compare against stronger baselines from the literature.	suggestion
2019-1272	If they are orthogonal to the choice of estimator, then it would be even better to show that these baselines + RLL outperforms the baselines + MLE.	suggestion
2019-1272	Alternatively, you mention some challenging tasks like seq2seq, where a convincing demonstration would greatly strengthen the paper.	suggestion
2019-1272	While the paper is not yet ready in its current form, it seems like a promising approach that is worth further exploration.	decision

2019-1276	Although all the reviewers find the problem and the approach of using hierarchical models important and interesting, how it has been executed in this submission has not been found favourable by the reviewers.	weakness

2019-1301	The paper is addressing an important problem, but misses many related references (see Reviewer 2's comments for a long list of highly relevant papers). <sep>	weakness
2019-1301	More importantly, as Reviewer 3 pointed out (which the AC fully agrees): <sep> "The gradient estimator the paper proposes is the REINFORCE estimator [Williams, ML 1992] re-derived through importance sampling." <sep>	weakness
2019-1301	"The equivalence would not be exact if the authors chose the importance distribution to be different than the variational approximation q(z|x), so there still may be room for novelty in their proposal, but in the current draft only q(z|x) is considered."	weakness

2019-1354	I would like to highlight to the PCs that reviewers highlighted clear evidence of plagiarism from prior work, which I was able to easily verify (a full paragraph of text was copied, word-for-word, from a paper describing one of the baselines the current work compares against).	weakness
2019-1354	Further, all reviewers unanimously agreed that the paper was poorly written, and contains no useful advances for the *CONF* audience.	weakness
2019-1354	I recommend a rejection, and further, examination by the PCs of the conduct of the authors.	decision

2019-1383	All reviewers agree to reject.	rating_summary
2019-1383	While there were many positive points to this work, reviewers believed that it was not yet ready for acceptance.	rating_summary

2019-1393	This paper proposes an optimization algorithm based on 'weak contraction mapping'.	abstract
2019-1393	The paper is written poorly without clear definitions and mathematical rigor.	weakness
2019-1393	Reviewers doubt both the correctness and the usefulness of the proposed method.	weakness
2019-1393	I strongly suggest authors to rewrite the paper addressing all the reviews before submitting to a different venue.	decision

2019-1406	The paper compared between different CNNs for UAV trail guidance.	abstract
2019-1406	The reviewers arrived at a consensus on rejection due to lack of new ideas, and the paper is not well polished.	rating_summary

2019-1466	The paper evaluates several off-the-shelf algorithms for predicting the return on real-estate property investment.	abstract
2019-1466	The problem is interesting, but there is a consensus that the paper contains little technical novelty, and the empirical study on a fairly small dataset is also not convincing.	weakness

2019-1467	This paper attempts at modeling coherence of generated text, and proposes two kinds of discriminators that tries to measure whether a piece of text is coherent or not. <sep>	abstract
2019-1467	However, the paper misses several related critical references, and also lacks extensive evaluation (especially manual evaluation). <sep>	weakness
2019-1467	There is consensus between the reviewers that this paper needs more work before it is accepted to a conference such as *CONF*.	rating_summary

2019-1481	This paper attempts to address a problem they dub "inverse" covariate shift where an improperly trained output layer can hamper learning.	abstract
2019-1481	The idea is to use a form of curriculum learning.	abstract
2019-1481	The reviewers found that the notion of inverse covariate shift was not formally or empirically well defined.	weakness
2019-1481	Furthermore the baselines used were too weak: the authors should consider comparing against state-of-the-art curriculum learning methods.	weakness

2019-1492	All three reviewers found this to be an interesting exploration of a reasonable topic—the use of ontologies in word representations—but all three also expressed serious concerns about clarity and none could identify a concrete, sound result that the paper contributes to the field.	weakness

2019-1498	This paper studies a variational formulation of the loss minimization to study the solution that generalizes the most.	abstract
2019-1498	An expectation of the loss wrt a Gaussian distribution is minimized to find the mean and variance of the Gaussian distribution.	abstract
2019-1498	As the variance goes to zero, we recover the original loss, but for a higher value of variance, the loss may be convex.	abstract
2019-1498	This is used to study the generalizability of the landscape. <sep>	abstract
2019-1498	Both objective and solutions of the paper are unclear and not communicated well.	weakness
2019-1498	There is not enough citation to previous work (eg, Gaussian homotopy exactly considers this problem, and there are papers that study the convexity of the expectation of the loss function).	weakness
2019-1498	There are no experimental results either to confirm the theoretical finding. <sep>	weakness
2019-1498	All the reviewers struggle to understand both the problem and solutions discussed in this paper.	weakness
2019-1498	I believe that the paper could become useful if reviewers' feedback is taken seriously to improve the paper.	suggestion

2019-1552	The paper presents a CNN that is trained from human games to predict which actions to take for China Competitive Poker (Dou dizhu). <sep>	abstract
2019-1552	The paper is poorly written, not because of the English, but because it is hard to understand the details of the proposed solution: it is not straight-forward to reimplement a solution from the presentation in the paper.	weakness
2019-1552	It lacks explanations for several design decisions.	weakness
2019-1552	This is unfortunate, as the authors point out in the rebuttal that they actually did way more experiments that are presented in the paper.	rebuttal_process
2019-1552	Moreover, the experimental results lack comparisons to baselines, ablations, so that the proposed solution could be evaluated fairly. <sep>	weakness
2019-1552	In its current state, this paper can not be accepted for presentation at *CONF* 2019.	decision

2019-1574	The paper proposes an approach to define an "interpretable representation", <sep>	abstract
2019-1574	in particular for the case of patient condition monitoring.	abstract
2019-1574	Reviewers point to several concerns, including even the definition of explainability and limited significance.	weakness
2019-1574	The authors tried to address the concerns but reviewers think the paper is not ready for acceptance.	rating_summary
2019-1574	I concur with them in rejecting it.	decision

2019-1623	In this paper, neural networks are taken a step further by increasing their biological likeliness.	abstract
2019-1623	In particular, a model of the membranes of biological cells are used computationally to train a neural network.	abstract
2019-1623	The results are validated on MNIST. <sep>	abstract
2019-1623	The paper argumentation is not easy to follow, and all reviewers agree that the text needs to be improved.	weakness
2019-1623	˜The neuroscience sources that the models are based on are possibly outdated.	weakness
2019-1623	Finally, the results are too meagre and, in the end, not well compared with competing approaches. <sep>	weakness
2019-1623	All in all, the merit of this approach is not fully demonstrated, and further work seems to be needed to clarify this.	weakness

2019-1660	All three reviewers raised the issues that (a) the problem tackled in the paper was insufficiently motivated, (b) the solution strategy was also not sufficiently motivated and (c) the experiments had serious methodological issues.	weakness

2019-1672	This work proposes a method for both instance and feature based transfer learning. <sep>	abstract
2019-1672	The reviewers agree that the approach in current form lacks sufficient technical novelty for publication.	weakness
2019-1672	The paper would benefit from experiments on larger datasets and with more analysis into the different aspects of the proposed model.	suggestion

2020-425	This paper is far more borderline than the review scores indicate.	rating_summary
2020-425	The authors certainly did themselves no favours by posting a response so close to the end of the discussion period, but there was sufficient time to consider the responses after this, and it is somewhat disappointing that the reviewers did not engage. <sep>	rebuttal_process
2020-425	Reviewer 2 states that their only reason for not recommending acceptance is the lack of experiments on more than one KG.	rating_summary
2020-425	The authors point out they have experiments on more than one KG in the paper.	rebuttal_process
2020-425	From my reading, this is the case.	rebuttal_process
2020-425	I will consider R2 in favour of the paper in the absence of a response. <sep>	rebuttal_process
2020-425	Reviewer 3 gives a fairly clear initial review which states the main reasons they do not recommend acceptance.	rating_summary
2020-425	While not an expert on the topic of GNNs, I have enough of a technical understanding to deem that the detailed response from the authors to each of the points does address these concerns.	rebuttal_process
2020-425	In the absence of a response from the reviewer, it is difficult to ascertain whether they would agree, but I will lean towards assuming they are satisfied. <sep>	rebuttal_process
2020-425	Reviewer 1 gives a positive sounding review, with as main criticism "Overall, the work of this paper seems technically sound but I don't find the contributions particularly surprising or novel.	strength
2020-425	Along with plogicnet, there have been many extensions and applications of Gnns, and I didn't find that the paper expands this perspective in any surprising way."	weakness
2020-425	This statement is simply re-asserted after the author response.	rebuttal_process
2020-425	I find this style of review entirely inappropriate and unfair: it is not a the role of a good scientific publication to "surprise".	weakness
2020-425	If it is technically sound, and in an area that the reviewer admits generates interest from reviewers, vague weasel words do not a reason for rejection make. <sep>	ac_disagreement
2020-425	I recommend acceptance.	decision

2020-696	This work proposes a new regularization method for weakly supervised localization based on counting. <sep>	abstract
2020-696	Reviewers agree that this is an interesting topic but the experimental validation is weak (qualitative, lack of baselines), and the contribution too incremental. <sep>	weakness
2020-696	Therefore, we recommend rejection.	decision

2020-699	Main content: <sep> This paper presents negation handling approaches for Amharic sentiment classification. <sep>	abstract
2020-699	-- <sep>	misc
2020-699	Discussion: <sep> All reviewers agree the paper is poorly written, uses outdated approaches, and requires better organization and formatting. <sep>	weakness
2020-699	-- <sep>	misc
2020-699	Recommendation and justification: <sep> This paper after more work might be better submitted in an NLP workshop on low resource languages, rather than *CONF* which is more focused on new machine learning methods.	decision

2020-701	Main content: <sep> Blind review #2 summarizes it well: <sep> This paper extends the neural coreference resolution model in Lee et al (2018) by 1) introducing an additional mention-level feature (grammatical numbers), and 2) letting the mention/pair scoring functions attend over multiple mention-level features.	abstract
2020-701	The proposed model achieves marginal improvement (0.2 avg.	abstract
2020-701	F1 points) over Lee et al, 2018, on the CoNLL 2012 English test set. <sep>	abstract
2020-701	-- <sep>	misc
2020-701	Discussion: <sep> All reviewers rejected. <sep>	rating_summary
2020-701	-- <sep>	misc
2020-701	Recommendation and justification: <sep> The paper must be rejected due to its violation of blind submission (the authors reveal themselves in the Acknowledgments). <sep>	decision
2020-701	For information, blind review #2 also summarized well the following justifications for rejection: <sep>	rating_summary
2020-701	I recommend rejection for this paper due to the following reasons: <sep>	rating_summary
2020-701	- The technical contribution is very incremental (introducing one more features, and adding an attention layer over the feature vectors). <sep>	weakness
2020-701	- The experiment results aren't strong enough.	weakness
2020-701	And the experiments are done on only one dataset. <sep>	weakness
2020-701	- I am not convinced that adding the grammatical numbers features and the attention mechanism makes the model more context-aware.	weakness

2020-704	The authors demonstrate that starting from the 3rd epoch, freezing a large fraction of the weights (based on gradient information), but not entire layers, results in slight drops in performance. <sep>	abstract
2020-704	Given existing literature, the reviewers did not find this surprising, even though freezing only some of a layers weights has not been explicitly analyzed before.	weakness
2020-704	Although this is an interesting observation, the authors did not explain why this finding is important and it is unclear what the impact of such a finding will be.	weakness
2020-704	The authors are encouraged to expand on the implications of their finding and theoretical basis for it.	suggestion
2020-704	Furthermore, reviewers raised concerns about the extensiveness of the empirical evaluation. <sep>	weakness
2020-704	This paper falls below the bar for *CONF*, so I recommend rejection.	decision

2020-708	The paper makes its contribution by deriving an accelerated gradient flow for the Wasserstein distances.	abstract
2020-708	It is technically strong and demonstrates it applicability using examples fo Gaussian distributions and logistic regression. <sep>	abstract
2020-708	Reviewer 3 provided a deep technical assessment, pointing out the relevance to our ML community since these ideas are not yet widespread, but had concerns about the clarity of the paper.	weakness
2020-708	Reviewer 2 had similar concerns about clarity, and was also positive about its relevance to the ML community.	weakness
2020-708	The authors provided details responses to the technical questions posed by the reviewers.	rebuttal_process
2020-708	The AC believes that such work is a good fit for the conference.	misc
2020-708	The reviewers felts that this paper does not yet achieve the aim of making this work more widespread and needs more focus on communication. <sep>	weakness
2020-708	This is a strong paper and the authors are encouraged to address the accessibility questions.	suggestion
2020-708	We hope the review offers useful points of feedback for their future work.	misc

2020-710	Reviewers found the problem statement having merit, but found the solution not completely justifiable.	weakness
2020-710	Bandit algorithms often come with theoretical justification because the feedback is such that the algorithm could be performing horribly without giving any indication of performance loss.	weakness
2020-710	With neural networks this is obviously challenging given the lack of supervised learning guarantees, but reviewers remain skeptical and prefer not to speculate based on empirical results.	weakness

2020-714	The paper proposes a method for OOD detection which leverages the uncertainties associated with the features at the intermediate layers (and not just the output layer). <sep>	abstract
2020-714	All the reviewers agreed that while this is an interesting direction, the paper requires more work before it can be accepted.	rating_summary
2020-714	In particular, the reviewers raised several concerns about other relevant baselines, some of the reported empirical results, and clarity of the explanation. <sep>	weakness
2020-714	I encourage the authors to revise the draft based on the reviewers' feedback and resubmit to a different venue.	decision

2020-718	There is no author response for this paper.	rebuttal_process
2020-718	The paper addresses the affective analysis of video sequences in terms of continual emotions of valence and arousal.	abstract
2020-718	The authors propose a multi-modal approach (combining modalities such as audio, pose estimation, basic emotions and scene analysis) and a multi-scale temporal feature extractor (to capture short and long temporal context via LSTMs) to tackle the problem.	abstract
2020-718	All the reviewers and AC agreed that the paper lacks (1) novelty, as the proposed approach is a combination of the existing well-studied techniques without explanations why and when this could be advantageous beyond the considered task, (2) clarity and motivation -- see R2's and R3's concerns and suggestions on how to improve.	weakness
2020-718	We hope the reviews are useful for improving the paper.	misc

2020-721	The paper explores the setting of *just* using data augmentation without an additional regularization term included.	abstract
2020-721	The submission claims that comparatively good performance can be achieved with data augmentation alone.	abstract
2020-721	The reviewers unanimously felt that the submission was not suitable for publication at *CONF*.	rating_summary
2020-721	The reasons included skepticism that augmentation without regularization is a useful setting to explore, as well as concerns about the experiments used to support the conclusions in the paper.	weakness
2020-721	In particular, there were concerns that the experiments do not match best practice and that the error rates were too high.	weakness
2020-721	Finally, there were concerns about the clarity of definitions of "implicit" and "explicit" regularization.	weakness

2020-724	This paper proposes a new method for measuring pairwise similarity between data points.	abstract
2020-724	The method is based on the idea that similarity between two data points to be the probability (over the randomness in constructing the trees) that they are close in a Random Projection tree. <sep>	abstract
2020-724	Reviewers found important limitations in this work, pertaining to clarity of mathematical statements and novelty.	weakness
2020-724	Unfortunately, the authors did not provide a rebuttal, so these concerns remain.	rebuttal_process
2020-724	Moreover, the program committee was made aware of the striking similarities between this submission and the preprint https://arxiv.org/abs/1908.10506 from Yan et al, which by itself would be grounds for rejection due to concerns of potential plagiarism. <sep>	weakness
2020-724	As a result, the AC recommends rejection at this time.	decision

2020-726	This paper presents a large-scale automatically extracted knowledge base in Chinese which contains information about entities and their relations present in academic papers.	abstract
2020-726	The authors have collected several papers that come from around 38 different domains.	abstract
2020-726	As such this is a dataset creation paper where the authors have used existing methodologies to perform relation extraction in Chinese. <sep>	abstract
2020-726	After having read the reviews and followup replies by authors, the main criticisms of the paper still hold.	rebuttal_process
2020-726	In addition to the lack of technical contribution, I feel that the writing of the paper can be improved a lot, for example, I would like to see a table with some example entities and relations extracted.	weakness
2020-726	That said, with further improvements this paper could potentially be a good contribution to LREC which is focused on dataset creation. <sep>	strength
2020-726	In its current form, I recommend the paper to be rejected.	decision

2020-732	The authors propose Group Connected Multilayer Perceptron Networks which allow expressive feature combinations to learn meaningful deep representations.	abstract
2020-732	They experiment with different datasets and show that the proposed method gives improved performance. <sep>	abstract
2020-732	The authors have done a commendable job of replying to the queries of the reviewers and addresses many of their concerns.	rebuttal_process
2020-732	However, the main concern still remains: The improvements are not very significant on most datasets except the MNIST dataset.	rebuttal_process
2020-732	I understand the author's argument that other papers have also reported small improvements on these datasets and hence it is ok to report small improvements.	rebuttal_process
2020-732	However, the reviewers and the AC did not find this argument very convincing.	rebuttal_process
2020-732	Given that this is not a theoretical paper and that the novelty is not very high (as pointed out by R1) strong empirical results are accepted.	weakness
2020-732	Hence, at this point, I recommend that the paper cannot be accepted.	decision

2020-739	This work combines style transfer approaches either in a serial or parallel fashion, and shows that the combination of methods is more powerful than isolated methods. <sep>	abstract
2020-739	The novelty in this work is extremely limited and not offset by insightful analysis or very thorough experiments, given that most results are qualitative.	weakness
2020-739	Authors have not provided a public response. <sep>	rebuttal_process
2020-739	Therefore, we recommend rejection.	decision

2020-748	The paper makes an interesting attempt at connecting graph convolutional neural networks (GCN) with matrix factorization (MF) and then develops a MF solution that achieves similar prediction performance as GCN. <sep>	abstract
2020-748	While the work is a good attempt, the work suffers from two major issues: (1)  the connection between GCN and other related models have been examined recently.	weakness
2020-748	The paper did not provide additional insights; (2) some parts of the derivations could be problematic. <sep>	weakness
2020-748	The paper could be a good publication in the future if the motivation of the work can be repositioned.	decision

2020-749	The paper focuses on adversarial domain adaptation, and proposes an approach inspired from the DANN.	abstract
2020-749	The contribution lies in additional terms in the loss, aimed to i) align the source and target prototypes  in each class (using pseudo labels for target examples); ii) minimize the variance of the latent representations for each class in the target domain. <sep>	abstract
2020-749	Reviews point out that the expected benefits of target prototypes might be ruined if the pseudo-labels are too noisy; they note that the specific problem needs be more clearly formalized and they regret the lack of clarity of the text.	weakness
2020-749	The sensitivity wrt the hyper-parameter values needs be assessed more thoroughly. <sep>	weakness
2020-749	One also notes that SAFN is one of the baseline methods; but its best variant (with entropic regularization) is not considered, while the performance thereof is on par or greater than that of PACFA for ImageCLEF-Da; idem for AdapSeg (consider its multi-level variant) or AdvEnt with MinEnt. <sep>	weakness
2020-749	For these reasons, the paper seems premature for publication at *CONF* 2020.	decision

2020-752	The paper proposed U-net for segmentation of stagnant zones in computed tomography.	abstract
2020-752	Technical contribution of the paper is severely limited, and is not of the quality expected of publications in this venue.	weakness
2020-752	The paper is not anonymized and violates the double blind review rule.	weakness
2020-752	I'm thus recommending rejection.	decision

2020-756	This paper received two weak and one strong reject from the reviewers.	rating_summary
2020-756	The major issues cited were 1) a lack of strong enough baselines or empirical results, 2) Novelty with respect to "Certified adversarial robustness via randomized smoothing" and 3) a limitation to Gaussian noise perturbations.	weakness
2020-756	Unfortunately, as a result the reviewers agreed that this work was not ready for acceptance.	rating_summary
2020-756	Adding stronger empirical results and a careful treatment of related work would make this a much stronger paper for a future submission.	decision

2020-757	The authors propose a new technique for training networks to be robust to adversarial perturbations.	abstract
2020-757	They do this by computing bounds on the impact of the worst case adversarial attack, but that only hold under strong assumptions on the distribution of the network weights.	abstract
2020-757	While these bounds are not rigorous, the authors show that they can produce networks that improve the robustness-accuracy tradeoff on image classification tasks. <sep>	abstract
2020-757	While the idea proposed by the authors is interesting, the reviewers had several concerns about this paper: <sep> 1) The assumptions required for the bounds to hold are unrealistic and unlikely to hold in practice, especially for convolutional neural networks. <sep>	weakness
2020-757	2) The comparisons are not presented in a fair manner that allow the reader to interpret the difference between the nature of certificates computed by the authors and those computed in prior work. <sep>	weakness
2020-757	3) The empirical gains are not substantial if one normalizes for the non-rigorous nature of the certificates computed (given that they only hold under hard-to-justify assumptions). <sep>	weakness
2020-757	The rebuttal phase clarified some issues in the paper, but the fundamental flaws with the approach remain unaddressed.	rebuttal_process
2020-757	Thus, I recommend rejection and suggest that the authors revisit the assumptions and develop more convincing arguments and/or experiments justifying them for practical deep learning scenarios.	decision

2020-758	While the reviewers found the paper interesting, all the reviewers raised concerns about the fairly simple experimental settings, which makes it hard to appreciate the strengths of the proposed method.	weakness
2020-758	During rebuttal phase, the reviewers still felt this weakness was not sufficiently addressed.	rebuttal_process

2020-762	This work extends Leaky Integrate and Fire (LIF)  by proposing a recurrent version. <sep>	abstract
2020-762	All reviewers agree that the work as submitted is way too preliminary.	weakness
2020-762	Prior art is missing many results, presentation is difficult to follow and incomplete and contains errors.	weakness
2020-762	Even if these concerns were addressed, the benefit of the proposed method is unclear.	weakness
2020-762	Authors have not responded. <sep>	rebuttal_process
2020-762	We thus recommend rejection.	decision

2020-766	This paper proposes a few architectural modifications to the BERT model for language understanding, which are meant to apply during fine-tuning for target tasks. <sep>	abstract
2020-766	All three reviewers had concerns about the motivation for at least one of the proposed methods, and none of three reviewers found the primary experimental results convincing: The proposed methods yield a small improvement on average across target tasks, but one that is not consistent across tasks, and that may not be statistically significant. <sep>	weakness
2020-766	The authors clarified some points, but did not substantially rebut any of the reviewers concerns.	rebuttal_process
2020-766	Even though the reviewers express relatively low confidence, their concerns sound serious and uncontested, so I don't think we can accept this paper as is.	decision

2020-767	In this work, the authors interpret the Transformer as a numerical ODE modelling multi-particle convection.	abstract
2020-767	Guided by this connection, the authors take the Transformer that uses a feed forward net over attentions, and create a variant of transformer which instead uses an FFN-attention-FFN layer, thus the name macaron net.	abstract
2020-767	The authors present experiments in the GLUE dataset and in two MT datasets, and they overall report improved performance using their variant of Transformer.	abstract
2020-767	Thus, the main selling point of the paper is how seeing Transformer under his new light can potentially improve results through the construction of better models.	abstract
2020-767	The main criticisms from the authors is that  this story is not entirely convincing because the proposed variant departs a bit from the theory (R1 and comment about the Strang-Marchuk splitting) and the papers does not consider an evaluation of accuracy of Macaron in solving the underlying set of ODEs (comment from R3).	weakness
2020-767	As such, I cannot recommend acceptance of this paper -- I believe another set of revisions would increase the impact of this paper.	decision

2020-770	This work proposes context-aware representation of graph nodes leveraging attention over neighbors (as already done in previous work).	abstract
2020-770	Reviewers concerns about lack of novelty, lack of clarity of paper and lack of comparison to state of the art methods have not been addressed at all. <sep>	rebuttal_process
2020-770	We recommend rejection.	decision

2020-774	Three reviewers have scored this paper  as 1/1/3 and they have not increased their rating after the rebuttal and the paper revision.	rating_summary
2020-774	The main criticism revolves around the choice of datasets, missing comparisons with the existing methods, complexity and practical demonstration of speed.	weakness
2020-774	Other concerns touch upon a loose bound and a weak motivation regarding the low-rank mechanism in connection to DA.	weakness
2020-774	On balance, the authors resolved some issues in the revised manuscripts but reviewers remain unconvinced about plenty other aspects, thus this paper cannot be accepted to *CONF*2020.	decision

2020-777	This paper proposes a method to automatically generate corpora for training program synthesis systems. <sep>	abstract
2020-777	The reviewers did seem to appreciate the core idea of the paper, but pointed out a number of problems with experimental design that preclude the publication of the paper at this time.	decision
2020-777	The reviewers gave a number of good comments, so I hope that the authors can improve the paper for publication at a different venue in the future.	decision

2020-778	The paper presents a semi-supervised learning approach to handle semantic classification (pixel-level classification).	abstract
2020-778	The approach extends Hung et al 18, using a confidence map generated by an auxiliary network, aimed to improve the identification of small objects. <sep>	abstract
2020-778	The reviews state that the paper novelty is limited compared to the state of the art; the reviewers made several suggestions to improve the processing pipeline (including all images, including the confidence weights). <sep>	weakness
2020-778	The reviews also state that the paper needs be carefully polished. <sep>	weakness
2020-778	The area chair hopes that the suggestions about the contents and writing of the paper will help to prepare an improved version of the paper.	misc

2020-783	The authors propose a simple but effective method for feature crossing using interpretation inconsistency (as defined by the authors). <sep>	abstract
2020-783	I think this is a good work and the authors as well as the reviewers participated well in the discussions.	rebuttal_process
2020-783	However, there is still disagreement about the positioning of the paper.	rebuttal_process
2020-783	In particular, all the reviewers  felt that additional baselines should be tried.	rebuttal_process
2020-783	While the authors have strongly rebutted the necessity of these baselines the reviewers are not convinced about it.	rebuttal_process
2020-783	Given the strong reservations of the all the 3 reviewers at this point I cannot recommend the acceptance of this paper.	decision
2020-783	I strongly suggest that in subsequent submissions the authors should position their work better and perhaps compare with some of the related works recommended by the reviewers.	suggestion

2020-787	This paper studies the problem of optimization for neural networks, by comparing the optimization problem in parameter space with the corresponding problem in function space.	abstract
2020-787	It argues that overparametrised models leads to a convex problem formulation leading to global optimality. <sep>	abstract
2020-787	All reviewers agreed that this paper lacks mathematical rigor and novelty relative to the current works on overparametrised neural networks.	weakness
2020-787	Its arguments need to be substantially reworked before it can be considered for publication, and as a consequence the AC recommends rejection.	decision

2020-795	The paper is interested in Chinese Name Entity Recognition, building on a BERT pre-trained model.	abstract
2020-795	All reviewers agree that the contribution has limited novelty.	weakness
2020-795	Motivation leading to the chosen architecture is also missing.	weakness
2020-795	In addition, the writing of the paper should be improved.	weakness

2020-797	This paper seeks to understand the effect of learning rate decay in neural net training.	abstract
2020-797	This is an important question in the field and this paper also proposes to show why previous explanations were not correct.	abstract
2020-797	However, the reviewers found that the paper did not explain the experimental setup enough to be reproducible.	weakness
2020-797	Furthermore, there are significant problems with the novelty of the work due to its overlap with works such as (Nakiran et al, 2019), (Li et al 2019) or (Jastrzębski et al 2017).	weakness

2020-809	The paper proposes a novel mechanism to reduce the skewness of the activations.	abstract
2020-809	The paper evaluates their claims on the CIFAR-10 and Tiny Imagenet dataset.	abstract
2020-809	The reviewers found the scale of the experiments to be too limited to support the claims.	weakness
2020-809	Thus we recommend the paper be improved by considering larger datasets such as the full Imagenet.	suggestion
2020-809	The paper should also better motivate the goal of reducing skewness.	suggestion

2020-810	This paper introduces MELEE, a meta-learning procedure for contextual bandits.	abstract
2020-810	In particular, MELEE learns how to explore by training on datasets with full-information about what every reward each action would obtain (eg, using classification datasets).	abstract
2020-810	The idea is strongly related to imitation learning, and a regret bound is demonstrated for the procedure that comes from that literature.	abstract
2020-810	Experiments are performed. <sep>	abstract
2020-810	Perhaps due to the generality in which the algorithm was presented, reviewers found some parts of the work unintuitive and difficult to follow.	weakness
2020-810	The work may greatly benefit from having an explicit running example for F and pi and how it evolves during training.	suggestion
2020-810	Some reviewers were not impressed by the experimental results relative to epsilon-greedy.	weakness
2020-810	Yes, epsilon-greedy is a strong baseline, but MELEE introduces significant technical debt and data infrastructure so it seems fair to expect a sizable bump over epsilon-greedy or else why is it worth it? <sep>	weakness
2020-810	Perhaps with revisions and experiments within a domain that justify its complexity, this paper may be suitable at another venue.	decision
2020-810	But it is not deemed acceptable at this time, Reject.	decision

2020-814	This paper proposes a method for neural architecture search in embedding space.	abstract
2020-814	This is an interesting idea, but its novelty is limited due to its similarity to the NAO approach.	weakness
2020-814	Also, the empirical evaluation is too limited; comparisons should have been performed to NAO and other contemporary NAS methods, such as DARTS. <sep>	weakness
2020-814	Due the factors above, all reviewers gave rejecting scores (3,3,1).	rating_summary
2020-814	The rebuttal did not remove the main issues, resulting in the reviewers sticking to their scores.	rebuttal_process
2020-814	I therefore recommend rejection.	decision

2020-815	The reviewers all appreciated the importance of the topic: understanding the local geometry of loss surfaces of large models is viewed as critical to understand generalization and design better optimization methods. <sep>	strength
2020-815	However, reviewers also pointed out the strength of the assumptions and the limitations of the empirical study.	weakness
2020-815	Despite the claim that these assumptions are weaker than those made in prior work, this did not convince the reviewers that the conclusion could be applied to common loss landscapes. <sep>	weakness
2020-815	I encourage the authors to address the points made by the reviewers and submit an updated version to a later conference.	decision

2020-816	This paper tackles the problem of how to adapt a model from a source to a target domain when both data is not available simultaneously (even unlabeled) to a single learner.	abstract
2020-816	This is of relevance for certain privacy preserving applications where one setting would like to benefit from information learned in a related setting but due to various factors may not be willing to directly share data.	abstract
2020-816	The proposed solution is a transfer alignment network (TAN) which consists of two autoencoders (each trained independently on the source and the target) and an aligner which has the task of mapping the latent codes of one domain to the other. <sep>	abstract
2020-816	All three reviewers expressed concerns for this submission.	misc
2020-816	Of greatest concern was the experimental setting.	weakness
2020-816	The datasets chosen were non-standard and there was no prior work to compare against directly so the results presented are difficult to contextualize.	rebuttal_process
2020-816	The authors have responded to this concern by specifying the existing domain adaptation benchmarks are more challenging and require more complex architectures to handle the "more complex data manifolds".	rebuttal_process
2020-816	The fact that existing benchmark datasets may be more complex the the dataset explored in this work is a concern.	weakness
2020-816	The authors should take care to clarify whether their proposed solution may only be applicable to specific types of data.	suggestion
2020-816	In addition, the authors claim to address a new problem setting and therefore cannot compare directly to existing work.	suggestion
2020-816	One suggestion is if using new data, report performance of existing work under the standard setting to give readers some grounding for the privacy preserving setting.	suggestion
2020-816	Another option would be to provide scaffold results in the standard UDA setting but with frozen feature spaces.	suggestion
2020-816	Another option would be to ablate the choice of L2 loss for learning the transformer and instead train using an adversarial loss, L1 loss etc.	suggestion
2020-816	There are many ways the authors could both explore a new problem statement and provide convincing experimental evidence for their solution.	misc
2020-816	The AC encourages the authors to revise their manuscript, paying special attention to clarity and experimental details in order to further justify their proposed work.	suggestion

2020-817	This papers addresses the problem of creating sentiment lexicon for a resource limited language (Amharic).	abstract
2020-817	This task is time consuming and requires skilled annotators.	abstract
2020-817	Hence the authors propose a method for constructing this automatically from News corpora.	abstract
2020-817	They start with a seed list of sentiment bearing words and then add new words to this list based on their PPMO scores with existing words. <sep>	abstract
2020-817	While the reviewers agreed that this work is of practical importance, they had a few objections which I have summarised below: <sep> 1) Lack of novelty: The work has very few new ideas <sep>	weakness
2020-817	2) Lack of comparison with existing work: Several missing citations have been pointed out by the reviewers <sep>	weakness
2020-817	3) Weak experiments: The experimental section needs to be strengthened with more comparisons to existing work as well as proving the results for at least one more language. <sep>	weakness
2020-817	4) Organisation of the paper: The paper needs to be restructured for better presentation.	weakness
2020-817	In particular,  the Results and Discussions section does not really contain any discussions. <sep>	weakness
2020-817	5) Grammatical errors: Please proofread the paper thoroughly and fix all grammatical and typo errors. <sep>	weakness
2020-817	Based on the reviewer comments and lack of any response from the authors, I recommend that the paper in it current form cannot be accepted.	decision

2020-821	The authors propose an alternative to batch norm, which they call POP-norm, and provide theoretical justification for POP-norm in nonconvex optimization on the basis of variance reduction.	abstract
2020-821	They then present empirical arguments. <sep>	abstract
2020-821	One of the most cogent reviewers believed the theoretical results were known and the empirical arguments unconvincing because the method is similar to batch norm up to a change in learning rate and some minor differences. <sep>	weakness
2020-821	Unfortunately, the reviewers did not engage with the author rebuttals at all.	rebuttal_process
2020-821	The authors seem to have addressed most points.	rebuttal_process
2020-821	However, if the reviewers are unwilling to engage, despite multiple emails, there's not much I can do, short of redoing the whole process from scratch.	rebuttal_process
2020-821	And I'll take the lack of engagement as lack of interest by the reviewers.	rebuttal_process
2020-821	Not being an expert in optimization myself, I'm not going to override the scores.	misc
2020-821	I do know enough to know that there are standard bounds for both convex and nonconvex optimization that improve with decreased variance.	misc

2020-822	The paper proposes a modification to improve adversarial invariance induction for learning representations under invariance constraints.	abstract
2020-822	The authors provide both a formal analysis and experimental evaluation of the method.	abstract
2020-822	The reviewers generally agree that the experimental evaluation is rigorous and above average, but the paper lacks clarity making it difficult to judge the significance of it.	weakness
2020-822	Therefore, I recommend rejection, but encourage the authors to improve the presentation and resubmit.	decision

2020-838	The authors propose a framework for improving the robustness of neural networks to adversarial perturbations via optimal control techniques (Lyapunov Stability and the Pontryagin Maximum Principle, in particular).	abstract
2020-838	By considering a continuous-time limit of the training process, the authors use the PMP to derive udpate rules for the neural network weights that would result in a robust network.	abstract
2020-838	While the approach is interesting, the paper has some serious deficiencies that make it unacceptable for publication in its current form: <sep>	decision
2020-838	1. Quality of empirical evaluation: The authors only report final numbers on CIFAR-10 for a fixed set of adversarial attacks.	weakness
2020-838	It has been observed repeatedly in the adversarial robustness literature that adversarial evaluation of neural networks has to be done carefully to guard against possible underestimation of the worst-case attack.	weakness
2020-838	In particular, the specific details of the adversarial attacks used (number of steps, number of initializations, performance under larger perturbation radii) that are necessary to trust the results are not given (see https://arxiv.org/pdf/1902.06705. pdf for example). <sep>	weakness
2020-838	2. Unclear novelty: The authors do not sufficiently explain the novelty in their approach relative to prior work (particular prior work that has used optimal control ideas in this context). <sep>	weakness
2020-838	3. Computational cost: The authors do not give sufficient details to judge the computational overhead of their method to judge how much more expensive it is to train with their approach relative to standard or adversarial training. <sep>	weakness
2020-838	While one reviewer voted for a weak accept, the other reviewers were in consensus on rejection.	rating_summary
2020-838	The authors did not respond during the rebuttal phase and hence the reviews were unchanged. <sep>	rebuttal_process
2020-838	In summary, I vote for rejection.	decision
2020-838	However, I think this paper has potentially interesting ideas that should be carefully developed and evaluated in a future revision.	strength

2020-840	The main concern raised by reviewers is the limited experiments, which are on simple tasks and missing some baselines to state-of-the-art methods.	weakness
2020-840	While the overall approach is interesting, the reviewers found the empirical evidence to be fairly unconvincing.	weakness

2020-842	The reviewers attempted to give this paper a fair assessment, but were unanimous in recommending rejection.	rating_summary
2020-842	The technical quality of motivation was questioned, while the experimental evaluation was not found to be clear or convincing.	weakness
2020-842	Hopefully the feedback provided can help the authors improve their paper.	misc

2020-845	This paper proposes a neural architecture search method based on greedily adding layers with random initializations.	abstract
2020-845	The reviewers all recommend rejection due to various concerns about the significance of the contribution, novelty, and experimental design.	rating_summary
2020-845	They checked the author response and maintained their ratings.	rebuttal_process

2020-847	There is a consensus among reviewers that the paper should not be accepted.	rating_summary
2020-847	No rebuttal was provided, so the paper is rejected.	decision

2020-848	This paper proposes a method for finding neural architecture which, through the use of selective branching, can avoid processing portions of the network on a per-data-point basis. <sep>	abstract
2020-848	While the reviewers felt that the idea proposed was technically interesting and well-presented, they had substantial concerns about the evaluation that persisted post-rebuttal, and lead to a consensus rejection recommendation.	rating_summary

2020-853	This manuscript proposes an approach for estimating cross-correlations between model outputs, related to deep CCA.	abstract
2020-853	Authors note that the procedure improves results when applied to supervised learning problems. <sep>	abstract
2020-853	The reviewers have pointed out the close connection to previous work on deep CCA, and the author(s) have agreed.	weakness
2020-853	The reviewers agree that the paper has promise if properly expanded both theoretically and empirically.	misc

2020-859	This paper addresses the problem of few-shot classification across multiple domains.	abstract
2020-859	The main algorithmic contribution consists of a selection criteria to choose the best source domain embedding for a given task using a multi-domain modulator. <sep>	abstract
2020-859	All reviewers were in agreement that this paper is not ready for publication.	rating_summary
2020-859	Some key concerns were the lack of scalability (though the authors argue that this may not be a concern as all models are only stored during meta-training, still if you want to incorporate many training settings it may become challenging) and low algorithmic novelty.	weakness
2020-859	The issue with novelty is that there is inconclusive experimental evidence to justify the selection criteria over simple methods like averaging, especially when considering novel test time domains.	rebuttal_process
2020-859	The authors argue that since their approach chooses the single best training domain it may not be best suited to generalize to a novel test time domain. <sep>	rebuttal_process
2020-859	Based on the reviews and discussions the AC does not recommend acceptance.	decision
2020-859	The authors should consider revisions for clarity and to further polish their claims providing any additional experiments to justify where appropriate.	suggestion

2020-861	The submission is concerned with the catastrophic forgetting problem of continual learning, and proposes a gradient-based method which uses buffers of data seen previously to integrate the angles of the gradients and thereby mitigate forgetting.	abstract
2020-861	Empirical results are given on several benchmarks. <sep>	abstract
2020-861	The reviewers were impressed with the thorough validation and strong results, but noticed that the much simpler MEGA-D baseline did almost as well.	weakness
2020-861	Given this, they were not convinced that the proposed approach was necessary.	weakness
2020-861	Although the authors provided a strong rebuttal and an additional ablation, the reviewers did not feel that their concerns were met. <sep>	rebuttal_process
2020-861	My recommendation is to reject the submission at this time.	decision

2020-862	The paper investigates questions around adversarial attacks in a continual learning algorithm, ie, A-GEM.	abstract
2020-862	While reviewers agree that this is a novel topic of great importance, the contributions are quite narrow, since only a single model (A-GEM) is considered and it is not immediately clear whether this method transfers to other lifelong learning models (or even other models that belong to the same family as A-GEM).	weakness
2020-862	This is an interesting submission, but at the moment due to its very narrow scope, it seems more appropriate as a workshop submission investigating a very particular question (that of attacking A-GEM).	decision
2020-862	As such, I cannot recommend acceptance.	decision

2020-865	This paper presents a method to learn a pruned convolutional network during conventional training.	abstract
2020-865	Pruning the network has advantages (in deployment) of reducing the final model size and reducing the required FLOPS for compute.	abstract
2020-865	The method adds a pruning mask on each layer with an additional sparsity loss on the mask variables.	abstract
2020-865	The method avoids the cost of a train-prune-retrain optimization process that has been used in several earlier papers.	abstract
2020-865	The method is evaluated on CIFAR-10 and ImageNet with three standard convolutional network architectures.	abstract
2020-865	The results show comparable performance to the original networks with the learned sparse networks. <sep>	abstract
2020-865	The reviewers made many substantial comments on the paper and most of these were addressed in the author response and subsequent discussion.	rebuttal_process
2020-865	For example, Reviewer1 mentioned two other papers that promote sparsity implicitly during training (Q3), and the authors acknowledged the omission and described how those methods had less flexibility on a target metric (FLOPS) that is not parameter size.	rebuttal_process
2020-865	Many of the author responses described changes to an updated paper that would clarify the claims and results (R1: Q2-7, R2:Q3). <sep>	rebuttal_process
2020-865	However, the reviewers raised many concerns for the original paper and they did not see an updated paper that contains the proposed revisions.	rebuttal_process
2020-865	Given the numerous concerns with the original submission, the reviewers wanted to see the revised paper to assess whether their concerns had been addressed adequately.	rebuttal_process
2020-865	Additionally, the paper does not have a comparison experiment with state-of the art results, and the current results were not sufficiently convincing for the reviewers.	weakness
2020-865	Reviewer1 and author response to questions 13--15 suggest that the experimental results with ResNet-34 are inadequate to show the benefits of the approach, but results for the proposed method with the larger ResNet-50 (which could show benefits) are not yet ready. <sep>	rebuttal_process
2020-865	The current paper is not ready for publication.	decision

2020-867	This paper investigates how the properties of an environment affect the success of reinforcement learning, and in particular finds that random dynamics and non-episodic learning makes learning easier, even though these factors make learning more difficult when applied individually.	abstract
2020-867	The paper was reviewed by three experts who gave Reject, Weak Reject, and Weak Reject recommendations.	rating_summary
2020-867	The main concerns are about missing connections to related work, overstating some contributions, and experimental details.	weakness
2020-867	While the author response addressed many of these issues, reviewers felt another round of peer review is really needed before this paper can be accepted; R2's post-rebuttal comments give some specific, constructive, concrete suggestions for preparing a revision.	rating_summary

2020-868	The paper proposes a  deep learning architecture for forecasting Origin-Destination (OD) flow.	abstract
2020-868	The model integrates several existing modules including spatiotemporal graph convolution and periodically shifted attention mechanism. <sep>	abstract
2020-868	The reviewers agree that the paper is not written well, and the experiments are also not executed well.	weakness
2020-868	Overall, we recommend rejection.	decision

2020-885	This paper proposes a CNN-based text classification model that uses words, characters, and labels as its input.	abstract
2020-885	It also presents an attention block to replace the pooling operation that is typically used in a CNN.	abstract
2020-885	The proposed method is evaluated on six benchmark classification datasets, achieving reasonably good results. <sep>	abstract
2020-885	While the proposed method performs reasonably well compared to baselines in the papers, all reviewers pointed out that there is no discussion or comparison with existing SotA based on pretrained models (eg, BERT, XLNet), which would strengthen the main claim of the paper.	weakness
2020-885	All three reviewers also suggested that the writing of the paper could be improved.	weakness
2020-885	The authors did not respond to these reviews, so there was little discussion needed to arrive at a consensus. <sep>	rebuttal_process
2020-885	I agree with all reviewers and recommend to reject the paper.	decision

2020-888	This paper proposes looking at the duality gap to measure performance.	abstract
2020-888	However, the metric is just an upperbound on the true metric of interest, and therefore its value can be ambiguous. <sep>	weakness
2020-888	The reviewers found the paper to be in an unacceptable form and was clearly hastily prepared.	weakness
2020-888	They were also skeptical about the novelty of the result as well as the comprehensiveness of the experiments. <sep>	weakness
2020-888	This paper would require extensive revisions before any potential acceptance.	weakness
2020-888	Reject	decision

2020-891	The authors propose a framework for incorporating homogeneous linear inequality constraints on neural network activations into neural network architectures.	abstract
2020-891	The authors show that this enables training neural networks that are guaranteed to satisfy non-trivial constraints on the neurons in a manner that is significantly more scalable than prior work, and demonstrate this experimentally on a generative modelling task. <sep>	abstract
2020-891	The problem considered in the paper is certainly significant (training neural networks that are guaranteed to satisfy constraints arises in many applications) and the authors make some interesting contributions.	strength
2020-891	However, the reviewers found the following issues that make it difficult to accept the paper in its present form: <sep>	rating_summary
2020-891	1) The setting of homogeneous linear equality constraints is not well-motivated and the significance of being able to impose such constraints is not clearly articulated in the paper.	weakness
2020-891	The authors would do well to prepare a future revision documenting use-cases motivated by practical applications and add these to the paper. <sep>	suggestion
2020-891	2) The experimental evaluation is not sufficiently thorough: the authors evaluate their method on an artificial constraint involving a "checkerboard pattern" on MNIST.	weakness
2020-891	Even in this case, the training method proposed by the authors seems to suffer from some issues, and more thorough experiments need to be conducted to confirm that the training method can perform well across a variety of datasets and constraints. <sep>	weakness
2020-891	Given these issues, I recommend rejection.	decision
2020-891	However, I encourage the authors to revise their work on this important topic and prepare a future version including practical examples of the constraints and experiments on a variety of prediction tasks.	suggestion

2020-896	The submission proposes a method to improve over a standard binary network pruning strategy by the inclusion of a structured matrix product to encourage network weight sparsification that can have better memory and computational properties.	abstract
2020-896	The idea is well motivated, but there were reviewer concerns about the quality of writing and in particular the quality of the experiments.	weakness
2020-896	The reviewers were unanimous that the paper is not suitable for acceptance at *CONF*, and no rebuttal was provided.	rating_summary

2020-900	This paper presents an approach combining multi-agent with hierarchical RL in a custom-made simulated humanoid robotics setting. <sep>	abstract
2020-900	Although it is an interesting premise and has a compelling motivation (multi-agent, real-world interaction, humanoid robotics), the reviewers had some trouble pinpointing what the significant contributions are.	weakness
2020-900	Partly this is due to lack of clarity in the presentation, such as with overlong sections (eg 5.2), unclear descriptions, mistakes in the text, etc.	weakness
2020-900	Reviewers also remarked that this paper might be trying to do too much, without performing the necessary experiments/comparisons and analyses needed to interpret the contributions of each component. <sep>	weakness
2020-900	This work is definitely promising and has the potential to make a nice contribution, given some additional care (experiments, analyses) and rewriting/polishing.	strength
2020-900	As it is, it's probably a bit premature for publication at *CONF*.	decision

2020-906	The authors present a Bayesian model for time series which are represented as discrete events in continuous time and describe methods for doing parameter inference, future event prediction and entropy rate estimation for such processes. <sep>	abstract
2020-906	However, the reviewers find that the novelty of the paper is not high enough, and without sufficient acknowledgement and comparison to existing literature.	weakness

2020-910	This paper presents an encoder-decoder based architecture to generate summaries.	abstract
2020-910	The real contribution of the paper is to use  a recoder matrix which takes the output from an existing encoder-decoder network and tries to generate the reference summary again.	abstract
2020-910	The output here is basically the softmax layer produced by the first encoder-decoder network which then goes through a feed-forward layer before being fed as embeddings into the recoder.	abstract
2020-910	So, since there is no discretization, the whole model can be trained jointly.	abstract
2020-910	(the original loss of the first encoder-decoder model is used as well anyway). <sep>	abstract
2020-910	I agree with the reviewers here, that this whole model can in fact be viewed as a large encoder-decoder model, its not really clear where the improvements come from.	weakness
2020-910	Can you just increase the number of parameters of the original encoder-decoder model and see if it performs as good as the encoder-decoder + recoder?	weakness
2020-910	The paper also does not achieve SOTA on the task as there are other RL based papers which have been shown to perform better, so the choice of the recorder model is also not empirically justified.	weakness
2020-910	I recommend rejection of the paper in its current form.	decision

2020-917	This paper proposes a data augmentation method based on Generative Adversarial Networks by training several GANs on subsets of the data which are then used to synthesise new training examples in proportion to their estimated quality as measured by the Inception Score.	abstract
2020-917	The reviewers have raised several critical issues with the work, including motivation (it can be harder to train a generative model than a discriminative one), novelty, complexity of the proposed method, and lack of comparison to existing methods.	weakness
2020-917	Perhaps the most important one is the inadequate empirical evaluation.	weakness
2020-917	The authors didn't address any of the raised concerns in the rebuttal.	rebuttal_process
2020-917	I will hence recommend the rejection of this paper.	decision

2020-919	There was a clear consensus amongst reviewers that the paper should not be accepted.	rating_summary
2020-919	This view was not changed by the rebuttal.	rebuttal_process
2020-919	Thus the paper is rejected.	decision

2020-926	This paper proposes a benchmark for assessing the impact of image quality degradation (eg simulated fog, snow, frost) on the performance of object detection models.	abstract
2020-926	The authors introduce corrupted versions of popular object detection datasets, namely PASCAL-C, COCO-C and Cityscapes-C, and an evaluation protocol which reveals that the current models are not robust to such corruptions (losing as much as 60% of the performance).	abstract
2020-926	The authors then show that a simple data augmentation scheme significantly improves robustness.	abstract
2020-926	The reviewers agree that the manuscript is well written and that the proposed benchmark reveals major drawbacks of current detection models.	strength
2020-926	However, two critical issues with the paper paper remain, namely lack of novelty in light of Geirhos et al, and how to actually use this benchmark in practice.	weakness
2020-926	I will hence recommend the rejection of this paper in the current state.	decision
2020-926	Nevertheless, we encourage the authors to address the raised shortcomings (the new experiments reported in the rebuttal are a good starting point).	suggestion

2020-935	The presented work has worse accuracy than existing (and not all the baselines are given correctly) and does not provide the running time comparison.	weakness
2020-935	All reviewers recommend rejection, and I am with them.	decision

2020-936	This paper proposes to introduce perturbation biases as a counter-measure against adversarial perturbations.	abstract
2020-936	The perturbation biases are additional bias terms that are trained by a variant of gradient ascent.	abstract
2020-936	Serious issues were raised in the comments.	misc
2020-936	No rebuttal was provided.	rebuttal_process

2020-937	This paper proposes an efficient implementation of piecewise linear functions. <sep>	abstract
2020-937	While this paper tackles a problem of large apparent interest, as noted by the reviewers the paper (1) is pretty far from the domain of the average *CONF* paper, and (2) not written with the high standards of clarity that would make it accessible to the average *CONF* reader.	weakness
2020-937	I am not impugning on the merits of the paper itself, but would suggest that the authors both take the reviewer's advice with regards to the clarity issues (among other) and consider submitting to the Systems for ML workshop, a systems conference, a compilers conference, or some other venue with a larger percentage of qualified readers (and reviewers).	decision

2020-938	The reviewers were unanimous that this submission is not ready for publication at *CONF* in its present form. <sep>	rating_summary
2020-938	Concerns raised included lack of relevant baselines, and lack of sufficient justification of the novelty and impact of the approach.	weakness

2020-939	Thank you very much for your feedback to the reviewers, which helped us a lot to better understand your paper. <sep>	misc
2020-939	However, the paper is still premature to be accepted to *CONF*2020.	decision
2020-939	We hope that the detailed reviewers' comments help you improve your paper for potential future submission.	misc

2020-940	The authors presents a method for adapting models to new tasks in a zero shot manner using learned meta-mappings.	abstract
2020-940	The reviewers largely agreed that this is an interesting and creative research direction.	strength
2020-940	However, there was also agreement that the writing was unclear in many sections, that the appropriate met alearning baselines were not compared to, and that the power of the method was unclear due to overly simplistic domains.	weakness
2020-940	While the baseline issue was mostly cleared up in rebuttal and discussion, the other issues remain.	rebuttal_process
2020-940	Thus, I recommend rejection at this time.	decision

2020-941	The submission proposes methodology for quantizing neural networks.	abstract
2020-941	The reviewers were unanimous in their opinion that the paper is not suitable for publication at *CONF*.	rating_summary
2020-941	Concerns included novelty over previous works, comparatively weak baseline comparisons, and overly restrictive assumptions.	weakness

2020-951	The paper proposed new version of LSTM which is claimed to abandon the redundancies in LSTM.	abstract
2020-951	It is weak both in theory and experiments.	weakness
2020-951	All reviewers gave clear rejects and the AC agree.	decision

2020-955	The reviewers have issues with the lack of enough experimental results as well as with novelty of the solution proposed.	weakness
2020-955	I recommend rejection.	decision

2020-957	The paper applies tensor analysis techniques to anomaly detection from satellite data.	abstract
2020-957	The proposed solution is simple and seems to achieve good results.	strength
2020-957	However, there is limited novelty in methodology and no sufficient experiments have been conducted to explain the performance gain.	weakness
2020-957	The paper is not ready for publication in *CONF* but could be suitable for an application oriented venue.	decision

2020-959	This paper uses Bayesian optimization with neural networks for neural architecture search. <sep>	abstract
2020-959	One of the contributions is a path-based encoding that enumerates every possible path through a cell search space.	abstract
2020-959	This encoding is shown to be surprisingly powerful, but it will not scale to large cell-based search spaces or non-cell-based search spaces.	abstract
2020-959	The availability of code, as well as the careful attention to reproducibility is much appreciated and a factor in favor of the paper. <sep>	strength
2020-959	In the discussion, it surfaced that a comparison to existing Bayesian optimization approaches using neural networks would have been possible, while the authors initially did not think that this would be the case.	rebuttal_process
2020-959	The authors promised to include these comparisons in the final version, but, as was also discussed in the private discussion between reviewers and AC, this is problematic since it is not clear what these results will show.	rebuttal_process
2020-959	Therefore, the one reviewer who was debating about increasing their score did in the end not do so (but would be inclined to accept a future version with a clean and thorough comparison to baselines). <sep>	rebuttal_process
2020-959	All reviewers stuck with their score of "weak reject", leaning to borderline.	rating_summary
2020-959	I read the paper myself and concur with this judgement.	decision
2020-959	I recommend rejection of the current version, with an encouragement to submit to another venue after including a comparison to BO methods based on neural networks.	decision

2020-963	The paper addresses the problem of learning disentangled representations in supervised and unsupervised settings. <sep>	abstract
2020-963	In general, the problem of representation learning in of course a core problem in *CONF*.	abstract
2020-963	However, in the set-up described by the authors, R2 commented on the the set-up for supervised being a bit unnatural in as detailed labels need to be given (somewhat confusingly, the labels are called control variates in the paper). <sep>	weakness
2020-963	Several reviewers commented on the novelty of the paper being on the low side, with R2 commenting the contribution being fairly small, and R3 noting similarities to stackgan. <sep>	weakness
2020-963	There were also some comments on quality, and clarity.	weakness
2020-963	On the topic of technical quality, R2 did note that the authors present extensive results, but R3 mentions that the case for the disentanglement improving is not sufficiently supported.	weakness
2020-963	In terms of clarity, there was some initial confusing about eg the inference procedure, though the authors addressed these issues in the discussion.	rebuttal_process

2020-968	The paper proposes new regularizations on contrastive disentanglement.	abstract
2020-968	After reading the author's response,  all the reviewers still think that the contribution is too limited and all agree to reject.	rating_summary

2020-973	This paper proposes a new algorithmic approach to reduced variance in off-policy, policy gradient updates. <sep>	abstract
2020-973	Multiple reviewers were concerned with both the soundness of the proposed approach, and the cost of using rollouts.	weakness
2020-973	In particular, the interaction between the target policy and the behavior policy, and how they are swapped was unclear, where the algorithms in the paper do not match the code provided. <sep>	weakness
2020-973	The results show apparent reduction in variance across runs compared with TD3: clear improvements in two domains, minor improvements , and/or an increase in variance in others.	weakness
2020-973	In some domains there was decrease in mean performance.	weakness
2020-973	The reviewers wanted comparisons with other baseline methods (even in terms of variance across runs). <sep>	suggestion
2020-973	It is difficult to evaluate the results in this paper, as the performance is averaged over only 5 runs, and runs which result in "failure" are discarded from analysis.	weakness
2020-973	The authors explain this was done in the original TD3 code, and one can sympathise in following common practices in the literature.	rebuttal_process
2020-973	However, the consensus of the reviewers and the AC was that this choice was not well defended, obscures a key difficulty of the learning problem, and makes algorithms look considerably stronger then they actually are.	rebuttal_process
2020-973	This is particularly confounding in a paper about improving the robustness of learning algorithms.	rebuttal_process
2020-973	This is not acceptable empirical practice and we strongly encourage the authors to discontinue this. <sep>	rebuttal_process
2020-973	The reviewers gave nice suggestions including changing the pitch of the paper, and including results in noisy tasks.	suggestion
2020-973	To reduce the burden of doing more scientific experiments, we suggest the authors start with small or even designed problems to carefully study robustness of learning and the potential improvements due to their algorithm.	suggestion
2020-973	After this is done in a statistically significant way, it would be natural to move to more demonstration style scaled up results.	suggestion

2020-976	Authors propose a new method of semi-supervised learning and provide empirical results.	abstract
2020-976	Reviewers found the presentation of the method confusing and poorly motivated.	weakness
2020-976	Despite the rebuttal, reviewers still did not find clarity on how or why the method works as well as it does.	rebuttal_process

2020-980	The authors consider improvements to model-based reinforcement learning to improve sample efficiency and computational speed.	abstract
2020-980	They propose a method which they claim is simple and elegant and embeds the model in the policy learning step, this allows them to compute analytic gradients through the model which can have lower variance than likelihood ratio gradients.	abstract
2020-980	They evaluate their method on Mujoco with limited data. <sep>	abstract
2020-980	All of the reviewers found the presentation confusing and below the bar for an acceptable submission.	rating_summary
2020-980	Although the authors tried to explain the algorithm better to the reviewers, they did not find the presentation sufficiently improved.	rebuttal_process
2020-980	I agree that the paper has substantial room for improvement around clarity.	weakness
2020-980	Reviewers also asked that experiments be run for more time steps.	suggestion
2020-980	I agree that this would be an important addition as many model-based reinforcement learning approaches perform worse asymptotically model free approaches and it would be interesting to see how the proposed approach does.	suggestion
2020-980	A reviewer pointed out that equation 2 is missing a term, and indeed I believe that is true.	weakness
2020-980	The authors response is not correct, they likely refer to an equation in SVG where the state is integrated out.	rebuttal_process
2020-980	Finally, the method does not compare to state-of-the-art model-based approaches, claiming that they use ensembles or uncertainty to improve performance.	weakness
2020-980	The authors would need to show that adding either of these to their approach attains similar performance to state-of-the-art approaches. <sep>	suggestion
2020-980	At this time, this paper is below the bar for acceptance.	decision

2020-981	This paper proposes adding a Dirichlet distribution as a wrapper on top of a black box classifier in order to better capture uncertainty in the predictions.	abstract
2020-981	This paper received four reviews in total with scores (1,1,1,6).	rating_summary
2020-981	The reviewer who gave the weak accept found the paper well written, easy to follow and intuitive.	strength
2020-981	The other reviewers, however, were primarily concerned about the empirical evaluation of the method.	weakness
2020-981	They found the baselines too weak and weren't convinced that the method would work well in practice.	weakness
2020-981	The reviewers also cited a lack of comparison to existing literature for their scores.	weakness
2020-981	One reviewer noted that while the method addresses aleatoric uncertainty, it doesn't provide any mechanism for epistemic uncertainty, which would be necessary for the applications motivating the work. <sep>	weakness
2020-981	The authors did not provide a response and thus there was no discussion.	rebuttal_process

2020-982	This paper provides a series of empirical evaluations on a small neural architecture search space with 64 architectures.	abstract
2020-982	The experiments are interesting, but limited in scope and limited to 64 architectures trained on CIFAR-10.	weakness
2020-982	It is unclear whether lessons learned on this search space would transfer to large search spaces.	weakness
2020-982	One upside is that code is available, making the work reproducible. <sep>	strength
2020-982	All reviewers read the rebuttal and participated in the private discussion of reviewers and AC, but none of them changed their mind.	rebuttal_process
2020-982	All gave a weak rejection score. <sep>	rating_summary
2020-982	I agree with this assessment and therefore recommend rejection.	decision

2020-990	The paper builds a transition-based dependency parser for Amharic, first predicting transitions and then dependency labels.	abstract
2020-990	The model is poorly motivated, and poorly described.	weakness
2020-990	The experiments have serious problems with their train/test splits and lack of baseline.	weakness
2020-990	The reviewers all convincingly argue for reject.	rating_summary
2020-990	The authors have not responded.	rebuttal_process

2020-997	The authors propose a graph residual flow model for molecular generation.	abstract
2020-997	Conceptual novelty is limited since it is simple extension and there isn't much improvement over state of art.	weakness

2020-998	The authors propose a hardware-agnostic metric called effective signal norm (ESN) to measure the computational cost of convolutional neural networks.	abstract
2020-998	They then demonstrate that models with fewer parameters achieve far better accuracy after quantization.	abstract
2020-998	The main novelty is on the metric ESN.	strength
2020-998	However, ESN is based on ideal hardware, and thus not suitable for existing hardware.	weakness
2020-998	Assumptions made in the paper are hard to be proved.	weakness
2020-998	Experimental results are not convincing, and related pruning methods are not compared.	weakness
2020-998	Finally, the paper is not written clearly, and the structure and some arguments are confusing.	weakness

2020-1006	Main content: <sep> Blind review #2 summarizes it well: <sep> The aim of this work is to improve interpretability in time series prediction.	abstract
2020-1006	To do so, they propose to use a relatively post-hoc procedure which learns a sparse representation informed by gradients of the prediction objective under a trained model.	abstract
2020-1006	In particular, given a trained next-step classifier, they propose to train a sparse autoencoder with a combined objective of reconstruction and classification performance (while keeping the classifier fixed), so as to expose which features are useful for time series prediction.	abstract
2020-1006	Sparsity, and sparse auto-encoders, have been widely used for the end of interpretability.	abstract
2020-1006	In this sense, the crux of the approach is very well motivated by the literature. <sep>	strength
2020-1006	-- <sep>	misc
2020-1006	Discussion: <sep> All reviews had difficulties understanding the significance and novelty, which appears to have in large part arisen from the original submission not having sufficiently contextualized the motivation and strengths of the approach (especially for readers not already specialized in this exact subarea). <sep>	weakness
2020-1006	-- <sep>	misc
2020-1006	Recommendation and justification: <sep> The reviews are uniformly low, probably due to the above factors, and while the authors' revisions during the rebuttal period have improved the objections, there are so many strong submissions that it would be difficult to justify override the very low reviewer scores.	decision

2020-1008	The submission proposes to train a model to modify objects in an image using language (the modified image is the effect of an action).	abstract
2020-1008	The model combines CNN, RNN, Relation Nets and GAN and is trained and evaluated on synthetic data, with some examples of results on real images. <sep>	abstract
2020-1008	The paper received relatively low scores (1 reject and 2 weak rejects).	rating_summary
2020-1008	The authors did not provide any responses to the reviews and did not revise their submission.	rebuttal_process
2020-1008	Thus there was no reviewer discussion and the scores remained unchanged. <sep>	rebuttal_process
2020-1008	The reviewers all agreed that the submission addressed an interesting task, but there was no special insight in how the components were put together, and the work was limited in the experimental results.	weakness
2020-1008	Comparisons against additional baselines (AE, VAE), and ablation studies or examinations of how the components can be varied is needed. <sep>	weakness
2020-1008	The paper is currently too weak to be accepted at *CONF*.	decision
2020-1008	The authors are encouraged to improve their evaluation and resubmit to an appropriate venue.	decision

2020-1015	This paper introduces a new architecture for sparse coding. <sep>	abstract
2020-1015	The reviewers gave long and constructive feedback that the authors in turn responded at length on.	rebuttal_process
2020-1015	There is consensus among the reviewers that despite contributions this paper in its current form is not ready for acceptance. <sep>	rating_summary
2020-1015	Rejection is therefore recommended with encouragement to make updated version for next conference.	decision

2020-1022	The authors propose a novel method to estimate the Lipschitz constant of a neural network, and use this estimate to derive architectures that will have improved adversarial robustness.	abstract
2020-1022	While the paper contains interesting ideas, the reviewers felt it was not ready for publication due to the following factors: <sep> 1) The novelty and significance of the bound derived by the authors is unclear.	weakness
2020-1022	In particular, the bound used is coarse and likely to be loose, and hence is not likely to be useful in general. <sep>	weakness
2020-1022	2) The bound on adversarial risk seems of limited significance, since in practice, this can be estimated accurately based on the adversarial risk measured on the test set. <sep>	weakness
2020-1022	3) The paper is poorly organized with several typos and is hard to read in its present form. <sep>	weakness
2020-1022	The reviewers were in consensus and the authors did not respond during the rebuttal phase. <sep>	rating_summary
2020-1022	Therefore, I recommend rejection.	decision
2020-1022	However, all the reviewers found interesting ideas in the paper.	strength
2020-1022	Hence, I encourage the authors to consider the reviewers' feedback and submit a revised version to a future venue.	suggestion

2020-1024	This paper analyzes a mechanism of the implicit regularization caused by nonlinearity of ReLU activation, and suggests that the learned DNNs interpolate almost linearly between data points, which leads to the low complexity solutions in the over-parameterized regime.	abstract
2020-1024	The main objections include (1) some claims in this paper are not appropriate; (2) lack of proper comparison with prior work; and many other issues in the presentation.	weakness
2020-1024	I agree with the reviewers' evaluation and encourage the authors to improve this paper and resubmit to future conference.	decision

2020-1025	All reviewers suggest rejection.	rating_summary
2020-1025	Beyond that, the more knowledgable two have consistent questions about the motivation for using the CCKL objective.	weakness
2020-1025	As such, the exposition of this paper, and justification of the work could use improvement, so that experienced reviewers understand the contributions of the paper.	weakness

2020-1026	This paper describes a method to incorporate multiple candidate templates to aid in response generation for an end-to-end dialog system.	abstract
2020-1026	Reviewers thought the basic idea is novel and interesting.	strength
2020-1026	However, they also agree that the paper is far from complete, results are missing, further experiments are needed as justification, and the presentation of the paper is not very clear.	weakness
2020-1026	Given the these feedback from the reviews, I suggest rejecting the paper.	decision

2020-1027	Thanks for the discussion with reviewers, which improved our understanding of your paper significantly. <sep>	misc
2020-1027	However, we concluded that this paper is still premature to be accepted to *CONF*2020.	decision
2020-1027	We hope that the detailed comments by the reviewers help improve your paper for potential future submission.	misc

2020-1028	This paper proposes a method to address the covariate shift and label shift problems simultaneously. <sep>	abstract
2020-1028	The paper is an interesting attempt towards an important problem.	strength
2020-1028	However, Reviewers and AC commonly believe that the current version is not acceptable due to several major misconceptions and misleading presentations.	decision
2020-1028	In particular: <sep> - The novelty of the paper is not very significant. <sep>	weakness
2020-1028	- The main concern of this work is that its shift assumption is not well justified. <sep>	weakness
2020-1028	- The proposed method may be problematic by using the minimax entropy and self-training with resampling. <sep>	weakness
2020-1028	- The presentation has many errors that require a full rewrite. <sep>	weakness
2020-1028	Hence I recommend rejection.	decision

2020-1034	The paper investigates calibration for regression problems.	abstract
2020-1034	The paper identifies a shortcoming of previous work by Kuleshov et al 2018 and proposes an alternative. <sep>	abstract
2020-1034	All the reviewers agreed that while this is an interesting direction, the paper requires more work before it can be accepted.	rating_summary
2020-1034	In particular, the reviewers raised several concerns about motivation, clarity of the presentation and lack of in-depth empirical evaluation. <sep>	weakness
2020-1034	I encourage the authors to revise the draft based on the reviewers' feedback and resubmit to a different venue.	decision

2020-1040	This paper addresses the problem of estimating treatment responses involving a continuous dosage parameter.	abstract
2020-1040	The basic idea is to learn a GAN model capable of generating synthetic dose-response curves for each training sample, which then facilitates the supervised training of an inference model that estimates these curves for new cases.	abstract
2020-1040	For this purpose, specialized architectures are also proposed for the GAN, which involves a multi-task generator network and a hierarchical discriminator network.	abstract
2020-1040	Empirical results demonstrate improvement over existing methods. <sep>	abstract
2020-1040	While there is always a chance that reviewers may underappreciate certain aspects of a submission, the fact that there was a unanimous decision to reject this work indicates that the contribution must be better marketed to the ML community.	rating_summary
2020-1040	For example, after the rebuttal one reviewer remained unconvinced regarding explanations for why the proposed method is likely to learn the full potential outcome distribution.	rebuttal_process
2020-1040	Among other things, another reviewer felt that both the proposed DRGAN model, and the GANITE framework upon which it is based, were not necessarily working as advertised in the present context.	weakness

2020-1049	The authors present a deep model for probabilistic clustering and extend it to handle time series data.	abstract
2020-1049	The proposed method beats existing deep models on two datasets and  the representations learned in the process are also interpretable. <sep>	abstract
2020-1049	Unfortunately, despite detailed responses by the authors, the reviewers felt that some of their main concerns were not addressed.	rebuttal_process
2020-1049	For example, the authors and the reviewers are still not converging on whether SOM-VAE uses a VAE or an autoencoder.	rebuttal_process
2020-1049	Further, the discussion about the advantages of VAE over AE is still not very convincing.	rebuttal_process
2020-1049	Currently the work is positioned as a variational clustering method but the reviewers feel that it is a clustering method which uses a VAE (yes, I understand that this difference is subtle but needs to be clarified). <sep>	rebuttal_process
2020-1049	The reviewers read the responses of the author and during discussions with the AC suggested that there were still not convinced about some of their initial questions.	rebuttal_process
2020-1049	Given this, at this point I would prefer going by the consensus of the reviewers and recommend that this paper cannot be accepted.	decision

2020-1054	This paper proposes constraints to tackle the problems of dead neurons and dead points.	abstract
2020-1054	The reviewers point out that the experiments are only done on small datasets and it is not clear if the experiments will scale further.	weakness
2020-1054	I encourage the authors to carry out further experiments and submit to another venue.	decision

2020-1055	What is investigated is what kind of representations are formed by embodied agents; it is argued that these are different than from non-embodied arguments.	abstract
2020-1055	This is an interesting question related to foundational AI and Alife questions, such as the symbol grounding problem.	abstract
2020-1055	Unfortunately, the empirical investigations are insufficient.	weakness
2020-1055	In particular, there is no comparison with a non-embodied control condition.	weakness
2020-1055	The reviewers point this out, and the authors propose a different control condition, which unfortunately is not sufficient to test the hypothesis. <sep>	rebuttal_process
2020-1055	This paper should be rejected in its current form, but the question is interesting and hopefully the authors will do the missing experiments and submit a new version of the paper.	decision

2020-1057	The paper presents a technique for learning RL agents to generalize well to unseen environments. <sep>	abstract
2020-1057	All reviewers and AC think that the paper has some potential but is a bit below the bar to be accepted due to the following facts: <sep> (a) Limited experiments, ie, consider more appealing baselines/scenarios and provide more experimental details. <sep>	decision
2020-1057	(b) The proposed method/idea is simple/reasonable, but not super novel, ie, not enough considering the *CONF* high standard (potentially enough for a workshop paper). <sep>	weakness
2020-1057	Hence, I think this is a borderline paper toward rejection.	decision

2020-1058	The authors propose a model which combines a neural machine translation system and a context-based machine translation model, which combines some aspects of rule and example based MT.	abstract
2020-1058	This paper presents work based on obsolete techniques, has relatively low novelty, has problematic experimental design and lacks compelling performance improvements.	weakness
2020-1058	The authors rebutted some of the reviewers claims, but did not convince them to change their scores.	rebuttal_process

2020-1060	All reviewers agree that the authors have done a great job identifying weaknesses with the current SOTA in super-resolution.	strength
2020-1060	However, there is also agreement that the proposed approach may be too simple to accurately capture a range of real camera distortions, and more comparisons to the SOTA are needed.	weakness
2020-1060	While this paper certainly has merits and opens the door for strong work in the future, there is not enough support to accept the paper in its current form.	decision

2020-1064	This paper formalizes the concept of buffer zones, and proposes a defense method based on a combination of deep neural networks and simple image transformations.	abstract
2020-1064	The authors argue that the proposed method based on buffer zones is robust against state-of-the-art black box attacks methods.This paper, however, falls short of (1) unjustified claims (eg, buffer zones are widened when the models are diverse); (2) incomplete literature survey and related work; (3) similar ideas are well-known in the literature, (4) unfair experimental evaluations and many others.	weakness
2020-1064	Even after author response, it still does not gather support from the reviewers.	rebuttal_process
2020-1064	Thus I recommend reject.	decision

2020-1068	This paper proposes performs an empirical study to evaluate CNN-based object classifier for the case where the object of interest is very small relative to the size of the image.	abstract
2020-1068	Two synthetic databases are used to conduct the experiments, through which the authors made a number of observations and conclusions.	abstract
2020-1068	The reviewers concern that the databases used are too structured or artificial, and one of the two databases is very small as well.	weakness
2020-1068	On top of that, only one network architecture is used for evaluation.	weakness
2020-1068	Furthermore, the conclusion from two databases seem inconsistent as well.	weakness
2020-1068	The authors provided detailed responses to the reviewers' comments but were not able to change the overall rating of the paper.	rebuttal_process
2020-1068	Given these concerns, as well as no methodological contribution, there are general concerns from all reviewers that the contributions of this work is not sufficient for *CONF*.	rating_summary
2020-1068	The ACs concur the concerns and the paper can not be accepted at its current state.	decision

2020-1069	This paper aims to estimate the 3D location and orientation of vehicle from a 2D image.	abstract
2020-1069	Instead of using a CNN-based 3D detection pipeline, the authors propose to detect the vehicle's wheel grounding points and then using the ground plane constraint for the estimation.	abstract
2020-1069	All three reviewers provided unanimous rating of rejection.	rating_summary
2020-1069	Many concerns are raised by the reviewers, including poor generalization to new situations, small improvement over prior work, low presentation quality, the lack of detailed description of the experiments, etc.	weakness
2020-1069	The authors did not respond to the reviewers' comments.	rebuttal_process
2020-1069	The AC agrees with the reviewers' comments, and recommend rejection.	decision

2020-1075	This paper proposes to address the high bandwidth cost when transferring data between server and user for machine learning applications.	abstract
2020-1075	The input data is augment with channel and spatial mask so that the file transfer cost is reduced.	abstract
2020-1075	While the reviewers agree that this is a well motivated and interesting problem to study, a number of concerns are raised, including loosely specified performance/size trade-off, how this work is compared to related work, low novelty relative to a few key missing references.	weakness
2020-1075	The authors respond to Reviewers' concerns but did not change the rating.	rebuttal_process
2020-1075	The ACs concur the concerns and the paper can not be accepted at its current state.	decision

2020-1077	The reviewers found the aim of the paper interesting (to connect representation quality with adversarial examples).	strength
2020-1077	However, the reviewers consistently pointed out writing issues, such as inaccurate or unsubstantiated claims, which are not appropriate for a scientific venue.	weakness
2020-1077	The reviewers also found the experiments, which are on simple datasets, unconvincing.	weakness

2020-1082	All reviewers agreed that this submission is still premature to be accepted to *CONF*2020. <sep>	rating_summary
2020-1082	We hope the review comments are useful for improving your paper for potential future submission.	misc

2020-1083	This paper proposes a new design space for initialization of neural networks motivated by balancing the singular values of the Hessian.	abstract
2020-1083	Reviewers found the problem well motivated and agreed that the proposed method has merit, however more rigorous experiments are required to demonstrate that the ideas in this work are significant progress over current known techniques.	weakness
2020-1083	As noted by Reviewer 2, there has been substantial prior work on initialization and conditioning that needs to be discussed as they relate to the proposed method.	weakness
2020-1083	The AC notes two additional, closely related initialization schemes that should be discussed [1,2].	weakness
2020-1083	Comparing with stronger baselines on more recent modern architectures would improve this work significantly. <sep>	suggestion
2020-1083	[1]: https://nips.cc/Conferences/2019/Schedule?showEvent=14216 <sep>	misc
2020-1083	[2]: https://arxiv.org/abs/1901.09321.	misc

2020-1089	There is insufficient support to recommend accepting this paper.	decision
2020-1089	Generally the reviewers found the technical contribution to be insufficient, and were not sufficiently convinced by the experimental evaluation.	weakness
2020-1089	The feedback provided should help the authors improve their paper.	suggestion

2020-1096	All three reviewers gave scores of Weak Reject.	rating_summary
2020-1096	Only a brief rebuttal was offered, which did not change the scores.	rebuttal_process
2020-1096	Thus the paper connect be accepted.	decision

2020-1099	The reviewers all believe that this paper is not yet ready for publication.	rating_summary
2020-1099	All agree that this is an important application, and an interesting approach.	strength
2020-1099	The methodological novelty, as well as other parts of exposition, involving related work, or further discussion of what this solution means for patients, is right now not completely convincing to reviewers.	weakness
2020-1099	My recommendation is to work on making sure the exposition best explains the methodology, and making sure this venue is the best for the submitted line of work.	suggestion

2020-1100	This paper introduces a realism metric for generated covariates and then leverage this metric to produce a novel method of interpolating between two real covariates.	abstract
2020-1100	The reviewers found the method novel and were satisfied with the response form the authors to their concerns.	rebuttal_process
2020-1100	However, Reviewer 4 did have reservations about the response to his/her points 3 and 4.	rebuttal_process
2020-1100	Moreover, in the discussion period it was decided that while the method was well justified by intuition and theory, the empirical evaluation—which is the what matters at the end of the day—was unconvincing.	rebuttal_process

2020-1102	This paper theoretically and empirically studies the inner and outer learning rate of the MAML algorithm and their role in convergence.	abstract
2020-1102	While the paper presents some interesting ideas and add to our theoretical understanding of meta-learning algorithms, the reviewers raised concerns about the relevance of the theory.	weakness
2020-1102	Further the empirical study is somewhat preliminary and doesn't compare to prior works that also try to stabilize the MAML algorithm, further bringing into question its usefulness.	weakness
2020-1102	As such, the current form of the paper doesn't meet the bar for *CONF*.	decision

2020-1107	The paper investigates how the softmax activation hinders the detection of out-of-distribution examples. <sep>	abstract
2020-1107	All the reviewers felt that the paper requires more work before it can be accepted.	rating_summary
2020-1107	In particular, the reviewers raised several concerns about theoretical justification, comparison to other existing methods, discussion of connection to existing methods and scalability to larger number of classes. <sep>	weakness
2020-1107	I encourage the authors to revise the draft based on the reviewers' feedback and resubmit to a different venue.	decision

2020-1113	The paper learns an embedding on the nodes of the graph, iteratively aligning the vector associated to a node with that of its neighbor nodes (based on the Hebbian rule). <sep>	abstract
2020-1113	The reviews state that the approach is interesting though very natural/straightforward, and that it might go too far to call it "Hebbian" (Rev#2) - you might want also to see it as a Self-Organizing Map for graphs. <sep>	strength
2020-1113	A main criticism was about the comparison with the state of the art (all reviewers).	weakness
2020-1113	The authors did add empirical comparisons with the suggested VGAE and SEAL, and phrase it nicely as "our algorithm outperforms SEAL on one out of four data sets".	rebuttal_process
2020-1113	Looking at the revised paper, this is true: the approach is outperformed by SEAL on 3 out of 4 datasets. <sep>	rebuttal_process
2020-1113	Another criticism regards the insufficient analysis of the results (eg through visualization, studying the clusters obtained along different runs, etc). <sep>	weakness
2020-1113	This aspect is not addressed in the revised version. <sep>	rebuttal_process
2020-1113	An excellent point is the scalability of the approach, which is worth emphasizing. <sep>	strength
2020-1113	I thus encourage the authors to rewrite and polish the paper, improving the positioning of the proposed approach wrt the state of the art, and providing a more thorough analysis of the results.	suggestion

2020-1120	The paper introduces a neat idea that an SGD update can be written as a solution of the linear least squares problem with a given backpropagated output; this is generalized to a larger batch size, giving a sort of "block" gradient-type update.	abstract
2020-1120	Some notes that the columns of Ot have to be scaled are made, but not clear why.	weakness
2020-1120	The paper then goes into the experiments, and then gets back to the fast approximation of DGB.	abstract
2020-1120	It really looks like bad organization of the paper, which was noted. <sep>	weakness
2020-1120	The reviewers agree that the actual computational improvements are marginal, and all recommend rejection.	rating_summary
2020-1120	As a recommendation, I would suggest to restructure the paper for a more coherent view, and also the improvements in Top-1 are not very stimulating.	suggestion
2020-1120	The general view is interesting, but it is not clear what insight it brings.	weakness

2020-1122	The reviewers have provided extensive comments, we encourage the authors to take them into account seriously in further iterations of this work.	suggestion

2020-1125	main summary: sparse time LSTM <sep>	abstract
2020-1125	discussions; <sep>	misc
2020-1125	reviewer 4: technical description of the proposed method insufficient, <sep>	weakness
2020-1125	reviewer 2, 3: same paper sent to *CONF* 2019 and rejected <sep>	rating_summary
2020-1125	recommendation: rejected, based on all reviewers comments	decision

2020-1132	This paper combines DQN and Randomized value functions for exploration. <sep>	abstract
2020-1132	All the reviewers agreed the paper is not yet ready for publication.	rating_summary
2020-1132	The experiments lack appropriate baselines and thus it is unclear how this new approach improves exploration in Deep RL.	weakness
2020-1132	The reviewers also found some of the algorithmic design decisions unintuitive and unexplained.	weakness
2020-1132	The authors main response was the objective was to improve and compare against vanilla DQN.	rebuttal_process
2020-1132	This could be a valid goal, but it requires clear motivation (perhaps the focus is on simply algorithms that are commonly used in applications or something).	rebuttal_process
2020-1132	Even then comparisons with other methods would be of interest to quantify how much the base algorithm is improved, and to justify empirically all the design decisions that went into building such an improvement (performance vs complexity of implementation etc). <sep>	suggestion
2020-1132	The reviewers gave nice suggestions for improvements.	misc
2020-1132	This is a good area of study: keep going!	misc

2020-1138	The paper does not provide theory or experiment to justify the various proposed relaxations.	weakness
2020-1138	In its current form, it has very limited scope.	weakness

2020-1146	This paper tackles the problem of transferring an RL policy learned in simulation to the real world (sim2real).	abstract
2020-1146	More specifically, the authors address the situation where the agent can access privileged information available during simulation, for example access to exact states instead of compressed representations.	abstract
2020-1146	They perform experiments in various simulated domains where different aspects of the environment are modified to evaluate generalization. <sep>	abstract
2020-1146	Major concerns remain following the rebuttal.	rebuttal_process
2020-1146	First, it is not clear how realistic it is to assume access to such privileged information in practice.	rebuttal_process
2020-1146	Second, the experiments are not convincing since the algorithms do not appear to have reached convergence in the presented results.	rebuttal_process
2020-1146	Finally, a sim2real work would highly benefit from real-world experiments. <sep>	rebuttal_process
2020-1146	In light of the above issues, I recommend to reject this paper.	decision

2020-1148	The paper considers the task of sequence to sequence modelling with multivariate, real-valued time series. <sep>	abstract
2020-1148	The authors propose an encoder-decoder based architecture that operates on fixed windows of the original signals. <sep>	abstract
2020-1148	The reviewers unanimously criticise the lack of novelty in this paper and the lack of comparison to existing baselines. <sep>	weakness
2020-1148	While Rev #1 positively highlights human evaluation contained in the experiments, they nevertheless do not think this paper is good enough for publication as is. <sep>	rating_summary
2020-1148	The authors did not submit a rebuttal. <sep>	rebuttal_process
2020-1148	I therefore recommend to reject the paper.	decision

2020-1150	The authors present a method for learning representations of remote sensing images from multiple views.	abstract
2020-1150	The main ideas is to use the InfoNCE loss to learn from multiple views of the data. <sep>	abstract
2020-1150	The reviewers had a few concerns about this work which were not adequately addressed by the authors.	rebuttal_process
2020-1150	I have summarised these below and would strongly recommend that the authors address these in subsequent submissions: <sep> 1) Experiments on a single dataset and a very specific task: Authors should present a more convincing argument about why the chosen dataset and task are challenging and important to demonstrate the main ideas presented in their work.	suggestion
2020-1150	Further, they should also report results on additional datasets suggested by the reviewers. <sep>	suggestion
2020-1150	2) Comparisons with existing works: The reviewers suggested several existing works for comparison.	suggestion
2020-1150	The authors agreed that these were relevant and important but haven't done this comparison yet.	rebuttal_process
2020-1150	Without such a comparison it is hard to evaluate the main contributions of this work. <sep>	weakness
2020-1150	Based on the above objections raised by the reviewers, I recommend that the paper should not be accepted.	decision

2020-1151	This paper performs event extraction from Amharic texts.	abstract
2020-1151	To this end, authors prepared a novel Amharic corpus and used a hybrid system of rule-based and learning-based systems. <sep>	abstract
2020-1151	Overall, while all reviewers admit the importance of addressing low-resource language and the value of the novel Amharic corpus, they are not satisfied with the quality of the current paper as a scientific work. <sep>	weakness
2020-1151	Most importantly, although the attempt of even extraction might be new on Amharic, there have been many works on other languages.	weakness
2020-1151	It should be clearly presented what are the non-trivial language-specific challenges on Amharic and how they are solved, otherwise it seems just an engineering of existing techniques on a new dataset also, all reviewers are fairly concerned about the presentation and clarity of the paper.	weakness
2020-1151	Unfortunately, no revised paper is uploaded and we cannot confirm how authors' response is reflected.	rebuttal_process
2020-1151	For those reasons, I would like to recommend rejection.	decision

2020-1153	This paper proposes a new normalization scheme that attempts to prevent all units in a ReLU layer from being dead.	abstract
2020-1153	The experimental results show that this normalization can effectively be used to train deep networks, though not as well as batch normalization.	abstract
2020-1153	A significant issue is that the paper does not sufficiently establish that their explanation for the success of Farkas layer is valid.	weakness
2020-1153	For example, do networks usually have layers with only inactive units in practice?	weakness

2020-1154	This submission has been assessed by three reviewers who scored it as 3/3/3.	rating_summary
2020-1154	The main criticism includes lack of motivation for sections 3.1 and 3.2, comparisons to mere regular self-attention without encompassing more works on this topic, a connection between Theorem 1 and the rest of the paper seems missing.	weakness
2020-1154	Finally, there exists a strong resemblance to another submission by the same authors which is also raises the questions about potentially a dual submission.	weakness
2020-1154	Even excluding the last argument, lack of responses to reviewers does not help this case.	rebuttal_process
2020-1154	Thus, this paper cannot be accepted by *CONF*2020.	decision

2020-1157	The authors study dropout for matrix sensing and deep learning, and show that dropout induces a data-dependent regularizer in both cases.	abstract
2020-1157	In both cases, dropout controls quantities that yield generalization bounds. <sep>	abstract
2020-1157	Reviewers raised several concerns, and several of these were vehemently rebutted.	rebuttal_process
2020-1157	The rhetoric of the back and forth slid into unfortunate territory, in my opinion, and I'd prefer not to see this sort of thing happen.	rebuttal_process
2020-1157	On the one hand, I can sympathize with the reviewers trying to argue that (un)related work is not related work.	rebuttal_process
2020-1157	On the other hand, it's best to be generous, or you run into this sort of mess. <sep>	rebuttal_process
2020-1157	In the end, even the expert reviewers were unswayed.	rebuttal_process
2020-1157	I suspect the next version of this paper may land more smoothly. <sep>	misc
2020-1157	While many of the technical issues are rebutted, one that caught my attention pertained to the empirical work.	rebuttal_process
2020-1157	Reviewer #4 noticed that the empirical evaluations do not meet the sample complexity requirements for the bounds to be valid (nevermind loose).	rebuttal_process
2020-1157	The response suggests this is simply a fact of making the bounds looser, but I suspect it may also change their form in this regime, potentially erasing the empirical findings.	rebuttal_process
2020-1157	I suggest the authors carefully consider whether all assumptions are met, and relay this more carefully to readers.	suggestion

2020-1161	The reviewers were unanimous that this submission is not ready for publication at *CONF* in its current form. <sep>	rating_summary
2020-1161	Concerns raised include a significant lack of clarity, and the paper not being self-contained.	weakness

2020-1166	This paper proposes an alternative explanation of the emergence of oriented bandpass filters in convolutional networks: rather than reflecting observed structure in images, these filters would be a consequence of the convolutional architecture itself and its eigenfunctions. <sep>	abstract
2020-1166	Reviewers agree that the mathematical angle taken by the paper is interesting, however they also point out that crucial prior work making the same points exists, and that more thorough insights and analyses would be needed to make a more solid paper. <sep>	weakness
2020-1166	Given the closeness to prior work, we cannot recommend acceptance in this form.	decision

2020-1167	This paper proposed a semi-supervised few-shot learning method, on top of Prototypical Networks, wherein a regularization term that involves a random walk from a prototype to unlabeled samples and back to the same prototype.	abstract
2020-1167	SotA results were obtained in several experiments by using this method.	abstract
2020-1167	All reviewers agreed that the novelty of the paper is not such high compared with Haeusser et al (2017) and the analysis and the experiments could be improved.	weakness

2020-1174	The paper is interested in multi-task learning.	abstract
2020-1174	It introduces a new architecture which condition the model in a particular manner: images features and task ID features are fed to a top-down network which generates task-specific weights, which are then used in a bottom-up network to produce final labels.	abstract
2020-1174	The paper is experimental, and the contribution rather incremental, considering existing work in the area.	weakness
2020-1174	Experimental section is currently not convincing enough, given marginal improvements over existing approaches - multiple runs as well as confidence intervals would help in that respect.	weakness

2020-1177	Both reviewers (we apologize for the lack of a 3rd review) did not feel the paper should be accepted.	rating_summary
2020-1177	The rebuttal offered did not change the reviewer scores.	rebuttal_process
2020-1177	So the paper cannot be accepted unfortunately.	decision
2020-1177	But the authors should use the feedback to improve their paper and resubmit.	suggestion

2020-1181	This paper provides an active-learning approach to improve the performance of an existing differentially private classifier with public labeled data.	abstract
2020-1181	Where the paper provides a new approach, there is a consensus among the reviewers that the paper does not provide a strong enough contribution for acceptance.	rating_summary
2020-1181	The authors can potentially improve the submission by including a more comprehensive comparison with the PATE framework and improving its overall presentation.	suggestion

2020-1185	The reviewers reached a unanimous consensus that the paper could not be accepted for publication in its current form.	rating_summary
2020-1185	There were a number of concerns raised regarding (1) the clarity of the writing; (2) the comparisons, especially to prior work; (3) the details of the experimental setup.	weakness

2020-1186	The reviewers agree that the technical innovations presented in this paper are not great enough to justify acceptance.	rating_summary
2020-1186	The authors correctly point out to the reviewers that the *CONF* CFP states that the topics of "implementation issues, parallelization, software platforms, hardware" are acceptable.	rebuttal_process
2020-1186	I would point out that most papers in these spaces describe *technical innovations* that enable improvements in "parallelization, software platforms, hardware" rather than implementations of these improvements.	rebuttal_process
2020-1186	However, it is certainly true that a software package is an acceptable (although less common) basis for a publication, provided is it sufficiently unique and impactful.	rebuttal_process
2020-1186	After pointing this out to the reviewers and collecting opinions, the reviewers do not feel the combined technical and software contributions of this paper are enough to justify acceptance.	rating_summary

2020-1188	This paper presents a very creative threat model for neural networks.	abstract
2020-1188	The proposed attack requires systems-level intervention by the attacker, which prompts the reviewers to question how realistic the attack is, and whether it is well motivated by the authors.	weakness
2020-1188	After conversing with the reviewers on this topic, they have not changed their mind about these issues.	rebuttal_process
2020-1188	As an AC, I think the threat model is both interesting and potentially realistic in some scenarios, however I agree with the reviewers that the motivation for the threat model could be more powerful.	weakness
2020-1188	For example the authors could focus more on realistic types of malicious behaviors that a developer could embed into a neural network.	suggestion
2020-1188	I also think there's lots of opportunities for a range of applications that exploit the type of "two nets in one" behavior that the authors study.	suggestion
2020-1188	Despite the interesting ideas in this paper, the post-rebuttal scores are not strong enough to accept it.	rating_summary
2020-1188	I encourage the authors to address some of these presentation issues, and resubmit this interesting paper to another venue.	decision

2020-1191	This paper presents a method for out-of-distribution detection under the condition of access to only a few positive labeled samples.	abstract
2020-1191	The main contribution as summarized by reviewers and authors is the new proposed benchmark and problem statement. <sep>	abstract
2020-1191	All reviewers are in agreement that this paper is not ready for publication in its current form.	rating_summary
2020-1191	The main concern is around the validity of the problem statement.	weakness
2020-1191	The reviewers seek more clarity motivating the proposed scenario.	weakness
2020-1191	Though the authors argue that as few-shot recognition is very difficult and may benefit from strategies like active learning, it is not directly clear how out of distribution detection is the best approach.	rebuttal_process
2020-1191	In addition, R3 seeks clarification on the similarity to existing work. <sep>	weakness
2020-1191	Considering the unanimous opinions of the reviewers and all author rebuttal text, the AC does not recommend acceptance of this work.	decision
2020-1191	We encourage the authors to focus their revisions on the explanation and motivation of this new benchmark and submit to a future venue.	decision

2020-1194	The work proposes a modification to existing architectures applied to predict taxonomic labels from metagenomic sequences.	abstract
2020-1194	Reviewers agreed that the problem was well motivated, but that current experiments lack comparisons with existing standard baselines in the area.	weakness
2020-1194	I recommend the authors update their work to included the additional experiments suggested by the reviewers.	suggestion

2020-1195	The paper investigates how to improve the performance of dropout and proposes an omnibus dropout strategy to reduce the correlation between the individual models. <sep>	abstract
2020-1195	All the reviewers felt that the paper requires more work before it can be accepted.	rating_summary
2020-1195	In particular, the reviewers raised several concerns about novelty of the method relative to existing methods, significance of performance improvements and clarity of the presentation. <sep>	weakness
2020-1195	I encourage the authors to revise the draft based on the reviewers' feedback and resubmit to a different venue.	decision

2020-1196	This paper presents a new view of latent variable learning as learning lattice representations. <sep>	abstract
2020-1196	Overall, the reviewers thought the underlying ideas were interesting, but both the description and the experimentation in the paper were not quite sufficient at this time.	weakness
2020-1196	I'd encourage the authors to continue on this path and take into account the extensive review feedback in improving the paper!	suggestion

2020-1198	The authors propose a way to produce uncertainty measures in graph neural networks.	abstract
2020-1198	However, the reviewers find that the methods proposed lack novelty and are incremental additions to prior work.	weakness

2020-1199	This paper presents a synthetic oversampling method for sequence-to-sequence classification problems based on autoencoders and generative adversarial networks. <sep>	abstract
2020-1199	All reviews reject the paper for two main reasons: <sep>	rating_summary
2020-1199	1 The novelty of the paper is not enough for *CONF* as the idea of utilizing GAN for data sampling is common now. <sep>	weakness
2020-1199	2 The experimental is not convincing as authors did not compare with other leading oversampling methods. <sep>	weakness
2020-1199	The rebuttal did not well answer these two questions; thus I choose to reject the paper.	decision

2020-1202	This paper proposes a way to lean context-dependent policies from demonstrations, where the context represents behavior labels obtained by annotating demonstrations with differences in behavior across dimensions and the reduced in 2 dimensions.	abstract
2020-1202	Results are conducted in the domain of StarCraft.	abstract
2020-1202	The main concerns from the reviewers related to the paper's novelty (as pointed by R2) and experiments (particularly the lack of comparison with other methods and the evaluation of only 4 out of the 62 behaviour clusters, as pointed by R3).	weakness
2020-1202	As such, I cannot recommend acceptance, as current results do not provide strong empirical evidence about the superiority of the method against other alternatives.	decision

2020-1206	The main contribution of this work is introducing the uncertainty-aware value function prediction into model-based RL, which can be used to balance the risk and return empirically. <sep>	abstract
2020-1206	The reviewers generally agree that this paper addresses an interesting problem, but there are some concerns that remain (see reviewer comments). <sep>	misc
2020-1206	I also want to highlight that in terms of empirical results, it is insufficient to present results for 3 different random seeds.	weakness
2020-1206	To highlight any kind of robustness, I suggest *at least* 10-20 different random seeds; otherwise the findings can/will be misleading.	suggestion

2020-1212	This paper proposes a modification of SGD to do distributionally-robust optimization of deep networks.	abstract
2020-1212	The main idea is sensible enough, however, the inadequate handling of baselines and relatively toy nature of the experiments means that this paper needs more work to be accepted.	decision

2020-1218	This paper proposes a training approach that orthogonalizes gradients to enable better learning across multiple tasks.	abstract
2020-1218	The idea is simple and intuitive. <sep>	strength
2020-1218	Given that there is past work following the same kind of ideas, it would be need to further: <sep> (a) expand the experimental evaluation section with comparisons to prior work and, ideally, demonstrate stronger results. <sep>	suggestion
2020-1218	(b) study in more depth the assumptions behind gradient orthogonality for transfer.	suggestion
2020-1218	This would increase impact on top of past literature by explaining, besides intuitions, why gradient orthogonality helps for transfer in the first place.	suggestion

2020-1220	This paper seeks to analyse the important question around why hierarchical reinforcement learning can be beneficial.	abstract
2020-1220	The findings show that improved exploration is at the core of this improved performance.	abstract
2020-1220	Based on these findings, the paper also proposes some simple exploration techniques which are shown to be competitive with hierarchical RL approaches. <sep>	abstract
2020-1220	This is a really interesting paper that could serve to address an oft speculated about result of the relation between HRL and exploration.	strength
2020-1220	While the findings of the paper are intuitive, it was agreed by all reviewers that the claims are too general for the evidence presented.	weakness
2020-1220	The paper should be extended with a wider range of experiments covering more domains and algorithms, and would also benefit from some theoretical results. <sep>	weakness
2020-1220	As it stands this paper should not be accepted.	decision

2020-1224	As the reviewers point out, this paper requires a major revision and fleshing out of the claimed contribution before it is suitable for conference presentation.	decision

2020-1225	This paper considers the problem of reinforcement learning with goal-conditioned agents where the agents do not have access to the ground truth state.	abstract
2020-1225	The paper builds on the ideas in hindsight experience replay (HER), a method that relabels past trajectories with a goal set in hindsight.	abstract
2020-1225	This hindsight mechanism enables indicator reward functions to be useful even with image inputs.	abstract
2020-1225	Two technical contributions are reward balancing (balancing positive and negative experience) and reward filtering (a heuristic for removing false negatives).	abstract
2020-1225	The method is tested on multiple tasks including a novel RopePush task in simulation. <sep>	abstract
2020-1225	The reviewers discussed strengths and limitations of the paper.	misc
2020-1225	One strength was that the writing was clear for the reviewers.	strength
2020-1225	One limitation was the paper's novelty, as most of these ideas are already present in HER with the exception of reward filtering.	weakness
2020-1225	Another major concern was that the experiments were not sufficiently informative.	weakness
2020-1225	The simulation tasks did not adequately distinguish the proposed method from the baseline (in two of the three tasks) and the third task (RopePush) was simplified substantially (using invisible robot arms).	weakness
2020-1225	The real world task did not require the pixel observations.	weakness
2020-1225	The analysis of the method was also found to be somewhat limited by the reviewers, though this was partially addressed by the authors. <sep>	rebuttal_process
2020-1225	This paper is not yet ready for publication since the proposed method has insufficient supporting evidence.	decision
2020-1225	A more thorough experiment could provide stronger evidence by showing a regime where the proposed method performs better than alternatives.	suggestion

2020-1232	This paper presents an analysis of the kind of knowledge captured by pre-trained word embeddings.	abstract
2020-1232	The authors show various kinds of properties like relation between entities and their description, mapping high-level commands to discrete commands etc.	abstract
2020-1232	The problem with the paper is that almost all of the properties shown in this work has already been established in existing literature.	weakness
2020-1232	In fact, the methods presented here are the baseline algorithms to the identification of different properties presented in the paper. <sep>	weakness
2020-1232	The term common-sense which is used often in the paper is mischaracterized.	weakness
2020-1232	In NLP literature, common-sense is something that is implicitly understood by humans but which is not really captured by language.	weakness
2020-1232	For example, going to a movie means you need parking is something that is well-understood by humans but is not implied by the language of going to the movie The phenomenon described by the authors is general language processing. <sep>	weakness
2020-1232	Towards the end the evaluation criteria for embedding proposed is also a well-established concept, its just that these metrics are not part of the training mechanism as yet.	suggestion
2020-1232	So if the contribution was on showing how those metrics can be integrated in training the embeddings, that would be a great contribution. <sep>	suggestion
2020-1232	I agree with the reviewer's critics and recommend a rejection as of now.	decision

2020-1243	This paper presents White Box Network (WBN), which allows for composing function blocks from a given set of functions to construct a target function.	abstract
2020-1243	The main idea is to introduce a selection layer that only selects one element of the previous layer as an input to a function block.	abstract
2020-1243	The reviewers were unanimous in their opinion that the paper is not suitable for publication at *CONF* in its current form.	rating_summary
2020-1243	There were significant concerns about the clarity in writing, and reviewers have provided detailed discussion should the authors wish to improve the paper.	weakness

2020-1246	This paper studies the evolution of the mean field dynamics of a two layer-fully connected and Resnet model.	abstract
2020-1246	The focus is in a realizable or student/teacher setting where the labels are created according to a planted network.	abstract
2020-1246	The authors study the stationary distribution of the mean-field method and use this to explain various observations.	abstract
2020-1246	I think this is an interesting problem to study.	strength
2020-1246	However, the reviewers and I concur that the paper falls short in terms of clearly putting the results in the context of existing literature and demonstrating clear novel ideas.	weakness
2020-1246	With the current writing of the paper is very difficult to surmise what is novel or new.	weakness
2020-1246	I do agree with the authors' response that clearly they are looking at some novel aspects not studied by the previous work but this was not revised during the discussion period.	rebuttal_process
2020-1246	Therefore, I do not think this paper is ready for publication.	decision
2020-1246	I suggest a substantial revision by the authors and recommend submission to future ML venues.	decision

2020-1253	This paper proposes to reintroduce bipartite attractor networks and update them using ideas from modern deep net architectures. <sep>	abstract
2020-1253	After some discussions, all three reviewers felt that the paper did not meet the *CONF* bar, in part because of an insufficiency of quantitative results, and in part because the extension was considered pretty straightforward and the results unsurprising, and hence it did not meet the novelty bar.	rating_summary
2020-1253	I therefore recommend rejection.	decision

2020-1254	The reviewers reached a consensus that the paper is preliminary and has a very limited contribution.	weakness
2020-1254	Therefore, I cannot recommend acceptance at this time.	decision

2020-1255	This paper proposes a model architecture and training procedure for multiple nested label sets of varying granularities and shows improvements in efficiency over simple baselines in the number of fine-grained training labels needed to reach a given level of performance. <sep>	abstract
2020-1255	Reviewers did not raise any serious concerns about the method that was presented, but they were also not convinced that it represented a sufficiently novel or impactful contribution to an open problem.	weakness
2020-1255	Without any reviewer advocating for the paper, even after discussion, I have no choice but to recommend rejection. <sep>	decision
2020-1255	I'm open to the possibility that there is substantial technical value here, but I think this work would be well served by more extensive comparisons and a potentially revamped motivation to try to make the case for it that value more directly.	suggestion

2020-1256	This submission addresses the problem of detecting malicious PDF files.	abstract
2020-1256	The proposed solution trains existing CNN architectures on a collected dataset and verifies improved performance over available antivirus software. <sep>	abstract
2020-1256	There were a number of concerns raised about this work.	misc
2020-1256	The main concern the reviewers had with this submission is lack of novelty.	weakness
2020-1256	The issue is that the paper tackles a standard supervised classification problem which has been extensively explored in the literature and applies an off-the-shelf classification model.	weakness
2020-1256	Though the particular application has seen less attention in the *CONF* community, the problem setting and solution are well known.	weakness
2020-1256	Thus, the contribution of the work is not sufficient for acceptance.	decision

2020-1259	The paper presents a new dataset, containing around 8k pictures of 30 horses in different poses.	abstract
2020-1259	This is used to study the benefits of pretraining for in- and out-of-domain images. <sep>	abstract
2020-1259	The paper is somewhat lacking in novelty.	weakness
2020-1259	Others have studied the same type of pre-training in the past using other datasets, which makes the dataset the main novelty.	weakness
2020-1259	But reviewers raised many questions about the dataset, in particular about how many of the frames of the same horse might be similar, and of how few horses there are; few enough to potentially not make the results statistically meaningful.	weakness
2020-1259	The authors replied to these questions more by appealing to standards in other fields than by explaining why this is a good choice.	rebuttal_process
2020-1259	Apart from these crucial weaknesses, however, the research appears good. <sep>	weakness
2020-1259	This is a pretty clear reject based on lack of novelty and oddities with the dataset.	decision

2020-1261	This submission proposes to combine the CutMix data augmentation of Yun et al 2019 with the standard consistency loss of  and the  structured consistency loss of Liu et al 2019 and applies the resulting approach to the Cityscapes dataset.	abstract
2020-1261	The reviewers were unanimous that the paper is not suitable for publication at *CONF* due to a lack of novelty in the method.	rating_summary
2020-1261	No rebuttal was provided.	rebuttal_process

2020-1262	This paper proposes a measure of inherent difficulty of datasets.	abstract
2020-1262	While reviewers agree that there are good ideas in this paper that is worth pursuing, several concerns has been risen by reviewers, which are mostly acknowledged by the authors.	rebuttal_process
2020-1262	We look forward to seeing an improved version of this paper soon!	misc

2020-1266	While the reviewers agreed that the problem of learning robust policies is an important one, there were a number of major concerns raised about the paper, and as a result I would recommend that the paper not be accepted at this time.	decision
2020-1266	The important points are: (1) limited novelty in light of prior work in this area (see R2 and R3); (2) a number of missing comparisons (see R2).	weakness
2020-1266	There is also a bit of confusion in the reviews, which I think stems from a somewhat unclear statement in the paper of the problem formulation.	weakness
2020-1266	While there is nothing wrong with assuming access to a parameterized simulator and studying robustness under parametric variation, this is of course a much stronger assumption than some prior work on robust reinforcement learning.	weakness
2020-1266	Clarity on this point is crucial, and there are a large number of prior methods that can likely do well in this setting (eg, based on system ID, etc.).	suggestion

2020-1269	This paper proposes the use of gradient of the loss evaluated at the example with respect to the model parameters as the feature representation of that example.	abstract
2020-1269	The authors performed an empirical analysis on anomaly detection benchmarks to demonstrate the practical benefits of the proposed method.	abstract
2020-1269	While the reviewers find the idea interesting, the consensus is that the proposed method lacks justification, and that the main claims were not substantiated.	weakness
2020-1269	While the reviewers proposed several key points of improvement, the raised issues were not addressed in the rebuttal.	rebuttal_process
2020-1269	I will hence recommend rejection of this paper.	decision

2020-1278	The reviewers all agreed that although there is a sensible idea here, the method and presentation need a lot of work, especially their treatment of related methods.	weakness

2020-1285	This paper studies the problem of certified robustness to adversarial examples.	abstract
2020-1285	It first demonstrates that many existing certified defenses can be viewed under a unified framework of regularization.	abstract
2020-1285	Then, it proposes a new double margin-based regularizer to obtain better certified robustness.	abstract
2020-1285	Overall, it has major technical issues and the rebuttal is not satisfying.	weakness

2020-1287	The authors propose a method to train a neural network that is robust to visual distortions of the input image.	abstract
2020-1287	The reviewers agree that the paper lacks justification of the proposed method and experimental evidence of its performance.	weakness

2020-1295	The paper is proposing uncertainty of the NN's in the training process on analog-circuits based chips.	abstract
2020-1295	As one reviewer emphasized, the paper addresses important and unique research problem to run NN on chips.	abstract
2020-1295	Unfortunately, a few issues are raised by reviewers including presentation, novelly and experiments.	weakness
2020-1295	This might be partially be mitigated by 1) writing motivation/intro in most lay person possible way 2) give easy contrast to normal NN (on computers) to emphasize the unique and interesting challenges in this setting.	suggestion
2020-1295	We encourage authors to take a few cycles of edition, and hope this paper to see the light soon.	suggestion

2020-1296	The article studies benefits of over-parametrization and theoretical properties at initialization in ReLU networks.	abstract
2020-1296	The reviewers raised concerns about the work being very close to previous works and also about the validity of some assumptions and derivations.	weakness
2020-1296	Nonetheless, some reviewers mentioned that the analysis might be a starting point in understanding other phenomena and made some suggestions.	strength
2020-1296	However, the authors did not provide a rebuttal nor a revision.	rebuttal_process

2020-1302	The reviewers attempted to provide a fair assessment of this work, albeit with varying qualifications.	misc
2020-1302	Nevertheless, the depth and significance of the technical contribution was unanimously questioned, and the experimental evaluation was not considered to be convincing by any of the assessors.	weakness
2020-1302	The criticisms are sufficient to ask the authors to further strengthen this work before it can be considered for a top conference.	decision

2020-1304	The paper proposes a tree search based policy optimization methods for continuous action state spaces.	abstract
2020-1304	The paper does not have a theoretical guarantee, but has empirical results. <sep>	abstract
2020-1304	Reviewers brought up issues such as lack of using other policy optimizations methods (SAC, RERPI, etc.	weakness
2020-1304	), sample inefficiency, and unclear difference with some other similar papers.	weakness
2020-1304	Even though the authors have provided a rebuttal to address these issues, all the reviewers remain negative.	rebuttal_process
2020-1304	So I can only recommend rejection at this stage.	decision

2020-1305	The paper proposes a contextual reasoning module following the approach proposed by the NIPS 2011 paper for object detection.	abstract
2020-1305	Although the reviewers find the proposed approach reasonable, the experimental results are weak and noisy.	weakness
2020-1305	Multiple reviewers believe that the paper will benefit from another review cycle, pointing out that the authors response confirmed that multiple additional (or redoing of) experiments are needed.	rebuttal_process

2020-1310	This paper proposed to use a compressive sensing approach for neural architecture search, similar to Harmonica for hyperparameter optimization. <sep>	abstract
2020-1310	In the discussion, the reviewers noted that the empirical evaluation is not comparing apples to apples; the authors could not provide a fair evaluation.	weakness
2020-1310	Code availability is not mentioned.	weakness
2020-1310	The proof of theorem 3.2 was missing in the original submission and was only provided during the rebuttal.	rebuttal_process
2020-1310	All reviewers gave rejecting scores, and I also recommend rejection.	decision

2020-1313	This paper proposes a deep RL framework that incorporates motivation as input features, and is tested on 3 simplified domains, including one which is presented to rodents. <sep>	abstract
2020-1313	While R2 found the paper well-written and interesting to read, a common theme among reviewer comments is that it's not clear what the main contribution is, as it seems to simultaneously be claiming a ML contribution (motivation as a feature input helps with certain tasks) as well as a neuroscientific contribution (their agent exhibited representations that clustered similarly to those in animals).	weakness
2020-1313	In trying to do both, it's perhaps doing both a disservice. <sep>	weakness
2020-1313	I think it's commendable to try to bridge the fields of deep RL and neuroscience, and this is indeed an intriguing paper.	strength
2020-1313	However any such paper still needs to have a clear contribution.	weakness
2020-1313	It seems that the ML contributions are too slight to be of general practical use, while the neuroscientific contributions are muddled somewhat.	weakness
2020-1313	The authors several times mentioned the space constraints limiting their explanations.	weakness
2020-1313	Perhaps this is an indication that they are trying to cover too much within one paper.	weakness
2020-1313	I urge the authors to consider splitting it up into two separate works in order to give both the needed focus. <sep>	suggestion
2020-1313	I also have some concerns about the results themselves.	weakness
2020-1313	R1 and R3 both mentioned that the comparison between the non-motivated agent and the motivated agent wasn't quite fair, since one is essentially only given partial information.	weakness
2020-1313	It's therefore not clear how we should be interpreting the performance difference.	weakness
2020-1313	Second, why was the non-motivated agent not analyzed in the same way as the motivated agent for the Pavlovian task?	weakness
2020-1313	Isn't this a crucial comparison to make, if one wanted to argue that the motivational salience is key to reproducing the representational similarities of the animals?	weakness
2020-1313	(The new experiment with the random fixed weights is interesting, I would have liked to see those results.)	suggestion
2020-1313	For these reasons and the ones laid out in the extensive comments of the reviewers, I'm afraid I have to recommend reject.	decision

2020-1316	This paper proposes to learn self-explaining neural networks using a feature leveling idea.	abstract
2020-1316	Unfortunately, the reviewers have raised several concerns on the paper, including insufficiency of novelty, weakness on experiments, etc.	weakness
2020-1316	The authors did not provide rebuttal.	rebuttal_process
2020-1316	We hope the authors can improve the paper in future submission based on the comments.	suggestion

2020-1319	The paper considers an important problem in medical applications of deep learning, such as variability/stability of  model's predictions in face of various perturbations in the model (eg, random seed), and evaluates different approaches to capturing model uncertainty.	abstract
2020-1319	However, it appears to be little innovation in terms of machine-learning methodology, so *CONF* might not be the best venue for this work, while perhaps other venues focused more on medical applications might be a better fit.	decision

2020-1320	The authors propose to use pruning to study/interpret learned CNNs.	abstract
2020-1320	The reviewers believed the results were not surprising and/or had no practical relevance.	weakness
2020-1320	Unlike in many cases, two of the reviewers acknowledged reading the rebuttals, but were unswayed.	rebuttal_process

2020-1324	This paper proposes to analyze the space of known sentence-to-vector functions by comparing the ways in which they induce nearest neighbor lists in a text corpus. <sep>	abstract
2020-1324	The primary results of the study are somewhat unclear, and the reviewers do not find the method to be novel enough—or sufficiently well motivated a priori—to warrant publication in spite of these results.	weakness

2020-1325	The paper introduces a variant of AMSGrad ("Optimistic-AMSGrad"), which integrates an estimate of the future gradient into the optimization problem.	abstract
2020-1325	While the method is interesting, reviewers agree that novelty is on the low side.	weakness
2020-1325	The motivation of the approach should also be clarified.	weakness
2020-1325	The experimental section should be made stronger; in particular, reporting convincing wall-clock running time advantages is critical for validating the viability of the proposed approach.	suggestion

2020-1337	The paper presents a model combining AC-GAN and StyleGAN for semi-supervised learning of disentangled generative adversarial networks.	abstract
2020-1337	It also proposes new datasets of 3d images as benchmarks.	abstract
2020-1337	The main claim is that the proposed model can achieve strong disentanglement property by using 1-5% of the annotations on the factors of variation.	abstract
2020-1337	The technical contribution is moderate but the architecture itself is not highly novel.	weakness
2020-1337	While the proposed method seems to work for controlled/synthetic datasets, overall technical contribution seems incremental and it's unclear whether it can perform well on larger-scale, real datasets.	weakness
2020-1337	The experimental results on CelebA don't look convincing enough.	weakness

2020-1339	This paper investigates the problem of building a program execution engine with neural networks.	abstract
2020-1339	While the reviewers find this paper to contain interesting ideas, the technical contributions, scope of experiments, and the presentation of results would need to be significantly improved in order for this work to reach the quality bar of *CONF*.	decision

2020-1348	This paper contributes to the recently emerging literature about applying reinforcement learning methods to combinatorial optimization problems. <sep>	abstract
2020-1348	The authors consider TSPs and propose a search method that interleaves greedy local search with Monte Carlo Tree Search (MCTS). <sep>	abstract
2020-1348	This approach does not contain learned function approximation for transferring knowledge across problem instances, which is usually considered the main motivation for applying RL to comb opt problems. <sep>	abstract
2020-1348	The reviewers state that, although the approach is a relatively straight-forward combination of two existing methods, it is in principle somewhat interesting. <sep>	strength
2020-1348	However, the experiments indicate a large gap to SOTA solvers for TSPs. <sep>	weakness
2020-1348	No rebuttal was submitted. <sep>	rebuttal_process
2020-1348	In absence of both SOTA results and methodological novelty, as assessed by the reviewers and my owm reading, I recommend to reject the paper in its current form.	decision

2020-1349	This paper offers a possibly novel approach to regularizing policy learning to make it suitable for large-scale divergence in the underlying domain.	abstract
2020-1349	Unfortunately all the reviewers are unanimous that the paper is not acceptable in present form.	rating_summary
2020-1349	Insufficient clarity regarding the contribution relative to several references, some of which were missing from the submitted version, is perhaps the most significant issue in the view of the AC.	weakness

2020-1351	This manuscript proposes feature selection inspired by knockoffs, where the generative models are implemented using modern deep generative techniques.	abstract
2020-1351	The resulting procedure is evaluated in a variety of empirical settings and shown to improve performance. <sep>	abstract
2020-1351	The reviewers and AC agree that the problem studied is timely and interesting, as knockoffs combined with generative models have recently shown promise for inferential problems.	strength
2020-1351	However, the reviewers were unconvinced about the motivation of the work, and the strength of the empirical evaluation results.	weakness
2020-1351	In the option of the AC, this work might be improved by focusing (both conceptually and empirically) on applications where inferential variable selection is most relevant eg causal settings, healthcare applications, and so on.	suggestion

2020-1352	This paper introduces a two-level hierarchical reinforcement learning approach, applied to the problem of a robot searching for an object specified by an image.	abstract
2020-1352	The system incorporates a human-specified subgoal space, and learns low-level policies that balance the intrinsic and extrinsic rewards.	abstract
2020-1352	The method is tested in simulations against several baselines. <sep>	abstract
2020-1352	The reviewer discussion highlighted strengths and weaknesses of the paper.	misc
2020-1352	One strength is the extensive comparisons with alternative approaches on this task.	strength
2020-1352	The main weakness is the paper did not adequately distinguish between which aspects of the system were generic to HRL and which aspects are particular to robot object search.	weakness
2020-1352	The paper was not general enough to be understood as a generic HRL method.	weakness
2020-1352	It was also ignoring much relevant background knowledge (robot mapping and navigation) if the paper is intended to be primarily about robot object search.	weakness
2020-1352	The paper did not convince the reviewers that the proposed method was desirable for either hierarchical reinforcement learning or for robot object search. <sep>	weakness
2020-1352	This paper is not ready for publication as the contribution was not sufficiently clear to the readers.	decision

2020-1358	The authors propose a regularized for convolutional kernels that seeks to improve adversarial robustness of CNNs and produce more perceptually aligned gradients.	abstract
2020-1358	While the topic studied by the paper is interesting, reviewers pointed out several deficiencies with the empirical evaluation that call into question the validity of the claims made by the authors.	weakness
2020-1358	In particular: <sep> 1) Adversarial evaluation protocol: There are several red flags in the way the authors perform adversarial evaluation.	weakness
2020-1358	The authors use a pre-defined adversarial attack toolbox (Foolbox) but are unable to produce successful attacks even for large perturbation radii - this suggests that the attack is not tuned properly.	weakness
2020-1358	Further, the authors present results over the best case performance over several attacks, which is dubious since the goal of adversarial evaluation is to reveal the worst case performance of the model. <sep>	weakness
2020-1358	2) Perceptual alignment: The claim of perceptually aligned gradients also does not seem sufficiently justified given the experimental results, since the improvement over the baseline is quite marginal.	weakness
2020-1358	Here too, the authors report failure of a standard visualization technique that has been successfully used in prior work, calling into question the validity of these results. <sep>	weakness
2020-1358	The authors did not participate in the rebuttal phase and the reviewers maintained their scores after the initial reviews. <sep>	rebuttal_process
2020-1358	Overall, given the significant flaws in the empirical evaluation, I recommend that the paper be rejected.	decision
2020-1358	I encourage the authors to rerun their experiments following the feedback from reviewers 1 and 3 and resubmit the paper with a more careful empirical evaluation.	suggestion

2020-1359	In this paper, the authors proposed a general framework, which uses an explicit function as an adjustment to the actual learning rate, and presented a more adaptive specific form Ada+.	abstract
2020-1359	Based on this framework, they analyzed various behaviors brought by different types of the function.	abstract
2020-1359	Empirical experiments on benchmarks demonstrate better performance than some baseline algorithms.	abstract
2020-1359	The main concern of this paper is: (1) lack of justification or interpretation for the proposed framework; (2) the performance of the proposed algorithm is on a par with Padam; (3) missing comparison with some other baselines on more benchmark datasets.	weakness
2020-1359	Plus, the authors did not submit response.	rebuttal_process
2020-1359	I agree with the reviewers' evaluation.	misc

2020-1366	The authors develop a certified defense for label-flipping attacks (where an adversary can flip labels of a small number of training set samples) based on the randomized smoothing technique developed for certified defenses to adversarial perturbations of the input.	abstract
2020-1366	The framework applies to least-squares classifiers acting on pretrained features learned by a deep network.	abstract
2020-1366	The authors show that the resulting framework can obtain significant improvements in certified accuracy against targeted label flipping attacks for each test example. <sep>	abstract
2020-1366	While the paper makes some interesting contributions, the reviewers had the following shared concerns regarding the paper: <sep> 1) Reality of threat model: The threat model assumes that the adversary has access to the model and all of the training data (so as to choose which labels to flip), which is very unlikely in practice. <sep>	weakness
2020-1366	2) Limitation to least squares on pre-trained features: The only practical instantiation of the framework presented in the paper is on least squares classifiers acting on pre-trained features learned by a deep network. <sep>	weakness
2020-1366	In the rebuttal phase, the authors clarified some of the more minor concerns raised by the reviewers, but the above concerns remained. <sep>	rebuttal_process
2020-1366	Overall, I feel that this paper is borderline - If the authors extend the applicability of the framework (for example relaxing the restriction on pre-training the deep features) and motivating the threat model more strongly, this could be an interesting paper.	suggestion

2020-1371	This paper proposes to speed up finetuning of pretrained deep image classification networks by predicting the success rate of a zoom of pre-trained  networks without completely running them on the test set.	abstract
2020-1371	The idea is that a sensible measure from the output layer might well correlate with the performance of the network.	abstract
2020-1371	All reviewers consider this is an important problem and a good direction to make the effort.	strength
2020-1371	However, various concerns are raised and all reviewers unanimously rate weak reject.	rating_summary
2020-1371	The major concerns include the unclear relationship between the metrics and the fine-tuning performance, non- comprehensive experiments, poor writing quality.	weakness
2020-1371	The authors respond to Reviewers' concerns but did not change the major concerns.	rebuttal_process
2020-1371	The ACs concur the concerns and the paper can not be accepted at its current state.	decision

2020-1372	The authors propose a multi-scale architecture for generative flows that can learn which dimensions to pass through more flow layers based on a heuristic that judges the contribution to the likelihood.	abstract
2020-1372	The authors compare the technique to some other flow based approaches.	abstract
2020-1372	The reviewers asked for more experiments, which the authors delivered.	weakness
2020-1372	However, the reviewers noted that a comparison to the SOTA for CIFAR in this setting was missing.	weakness
2020-1372	Several reviewers raised their scores, but none were willing to argue for acceptance.	rating_summary

2020-1374	This work explores how to leverage structure of this input in decision trees, the way this is done for example in convolutional networks. <sep>	abstract
2020-1374	All reviewers agree that the experimental validation of the method as presented is extremely weak.	weakness
2020-1374	Authors have not provided a response to answer the many concerns raised by reviewers. <sep>	rebuttal_process
2020-1374	Therefore, we recommend rejection.	decision

2020-1383	This paper considers an interesting theoretical question.	strength
2020-1383	However, it would add to the strength of the paper if it was able to meaningfully connect the considered model as well as derived methodology to the challenges and performance that arise in practice.	suggestion

2020-1384	This work investigates neural network pruning through the lens of its influence over specific exemplars (which are found to often be lower quality or mislabelled images) and how removing them greatly helps metrics. <sep>	abstract
2020-1384	The insight from the paper is interesting, as recognized by reviewers.	strength
2020-1384	However, experiments do not suggest that the findings shown in the paper would generalize to more pruning methods.	weakness
2020-1384	Nor do the authors give directions for tackling the "hard exemplar" problem.	weakness
2020-1384	Authors' response did provide justifications and clarifications, however the core of the concern remains. <sep>	rebuttal_process
2020-1384	Therefore, we recommend rejection.	decision

2020-1385	This paper presents a novel hierarchical reinforcement learning framework, based on learning temporal abstractions from past experience or expert demonstrations using recurrent variational autoencoders and regularising the representations. <sep>	abstract
2020-1385	This is certainly an interesting line of work, but there were two primary areas of concern in the reviews: the clarity of details of the approach, and the lack of comparison to baselines.	weakness
2020-1385	While the former issue was largely dealt with in the rebuttals, the latter remained an issue for all reviewers. <sep>	rebuttal_process
2020-1385	For this reason, I recommend rejection of the paper in its current form.	decision

2020-1386	This paper present a learning method for speeding up of LP, and apply it to the TSP problem. <sep>	abstract
2020-1386	Reviewers and AC agree that the idea is quite interesting and promising.	strength
2020-1386	However, I think the paper is far from being ready to publish in various aspects: <sep> (a) much more editorial efforts are necessary <sep>	weakness
2020-1386	(b) the TPS application of small scale is not super appealing <sep>	weakness
2020-1386	Hence, I recommend rejection.	decision

2020-1396	The paper focuses on attribute-object pairs image recognition, leveraging some novel "attractor network". <sep>	abstract
2020-1396	At this stage, all reviewers agree the paper needs a lot of improvements in the writing.	weakness
2020-1396	There are also concerns regarding (i) novelty: the proposed approach being two encoder-decoder networks; (ii) lack of motivation for such architecture (iii) possible flow in the approach (are the authors using test labels?)	weakness
2020-1396	and (iv) weak experiments.	weakness

2020-1397	The aper introduces simplicial complex networks, a new class of neural networks based on the idea of the subdivision of a simplicial complex.	abstract
2020-1397	The paper is interesting and brings ideas of algebraic topology to inform the design of new neural network architectures. <sep>	strength
2020-1397	Reviewer 1 was positive about the ideas of this paper, but had several concerns about clarity, scalablity and the sense that the paper might still be in an early phase.	weakness
2020-1397	Reviewer 2 had similar concerns about clarity, comparisons, and usefulness.	weakness
2020-1397	Although there were no responses form the author, the discussion explored the paper further, but continued to think the idea is still in its early phase. <sep>	rebuttal_process
2020-1397	The paper is not currently ready for acceptance, and we hope the authors will find useful feedback for their ongoing reasearch.	decision

2020-1400	Main summary: Novel rule for scaling learning rate, known as gain ration, for which the effective batch size is increased. <sep>	abstract
2020-1400	Discussion: <sep> reviewer 2: main concern is reviewer can't tell if it's better of worse than linear learning rate scaling from their experiment section. <sep>	weakness
2020-1400	reviewer 3: novlty/contribution is a bit too low for *CONF*. <sep>	weakness
2020-1400	reviewer 1: algorthmic clarity lacking. <sep>	weakness
2020-1400	Recommendation: all 3 reviewers recommend reject, I agree.	decision

2020-1405	The paper proposes an adaptive sampling mechanism for zeroth order optimization that samples perturbed points from a mixture distribution with asymptotic convergence guarantees.	abstract
2020-1405	The reviewers raised issues regarding the clarity of presentation, potential problems with the proofs, and simplicity of the experimental setup.	weakness
2020-1405	The authors did not provide a response.	rebuttal_process
2020-1405	Overall, the reviewers agree that the quality of the paper is not sufficient for publishing, and therefore I recommend rejection.	decision

2020-1412	All the reviewers pointed out issues with the experiments, which the rebuttal did not address.	rebuttal_process
2020-1412	The paper seems interesting, and the authors are encouraged to improve it.	suggestion

2020-1413	Several approaches can be used to feed structured data to a neural network, such as convolutions or recurrent network.	abstract
2020-1413	This paper proposes to combine both roads, by presenting molecular structures to the network using both their graph structured and a serialized representation (SMILES), that are processed by a framework combining the strenth of Graph Neural Network and the sequential transformer architecture. <sep>	abstract
2020-1413	The technical quality of the paper seems good, with R1 commenting on the performance relative to SOTA seq2seq based methods and R3 commenting on the benefits of using more plausible constraints.	strength
2020-1413	The problem of using data with complex structure is highly relevant for *CONF*. <sep>	strength
2020-1413	However, the novelty was deemed on the low side.	weakness
2020-1413	As a very competitive conference, this is one of the key aspects necessary for successful *CONF* papers.	misc
2020-1413	All reviewers agree that the novelty is too low for the current (high) bar of *CONF*.	weakness

2020-1414	As the reviewers point out, this paper has potentially interesting ideas but it is in too preliminary state for publication at *CONF*.	weakness

2020-1415	The paper proposes two approaches to topic modeling supervised by survival analysis.	abstract
2020-1415	The reviewers find some problems in novelty,  algorithm and experiments, which is not ready for publish.	rating_summary

2020-1418	The reviewers had a hard time fully identifying the intended contribution behind this paper, and raised concerns that suggest that the experimental results are not sufficient to justify any substantial contribution with the level of certainty that would warrant publication at a top venue.	weakness
2020-1418	The authors have not responded, and the concerns are serious, so I have no choice but to reject this paper despite its potentially valuable topic.	decision

2020-1424	This work proposes to use policy-gradient RL to learn to read and write actions over memory locations using as reward the entropy reduction of memory location distribution.	abstract
2020-1424	The authors perform experiments on NER in Stanford Dialogue task, that are framed though as few-shot learning.	abstract
2020-1424	The reviewers have pointed out shortcomings of the paper with regards to its novelty, narrow contribution in combination thin experimental setup (the authors only look into one dataset and one task with minimal comparison to previous work and no ablation studies as to understand the behaviour of the model) and clarity (method description seems to be lacking some crucial components of the model).	weakness
2020-1424	As such, I cannot recommend acceptance but I hope the authors will use the reviewers comments to transform this into a strong submission for a later conference.	decision

2020-1425	This paper was reviewed by 3 experts, who recommend Weak Reject, Weak Reject, and Reject.	rating_summary
2020-1425	The reviewers were overall supportive of the work presented in the paper and felt it would have merit for eventual publication.	rating_summary
2020-1425	However, the reviewers identified a number of serious concerns about writing quality, missing technical details, experiments, and missing connections to related work.	weakness
2020-1425	In light of these reviews, and the fact that the authors have not submitted a response to reviews, we are not able to accept the paper.	decision
2020-1425	However given the supportive nature of the reviews, we hope the authors will work to polish the paper and submit to another venue.	decision

2020-1430	The authors analyze the natural gradient algorithm for training a neural net from a theoretical perspective and prove connections to the K-FAC algorithm.	abstract
2020-1430	The paper is poorly written and contains no experimental evaluation or well established implications wrt practical significance of the results.	weakness

2020-1432	This paper provides an approach to improve the differentially private SGD method by leveraging a differentially private version of the lottery mechanism, which reduces the number of parameters in the gradient update (and the dimension of the noise vectors).	abstract
2020-1432	While this combination appears to be interesting, there is a non-trivial technical issue raised by Reviewer 3 on the sensitivity analysis in the paper.	weakness
2020-1432	(R3 brought up this issue even after the rebuttal.)	rebuttal_process
2020-1432	This issue needs to be resolved or clarified for the paper to be published.	decision

2020-1439	The authors present a way for generating adversarial examples using discrete perturbations, ie, perturbations that, unlike pixel ones, carry some semantics.	abstract
2020-1439	Thus, in order to do so, they assume the existence of an inverse graphics framework.	abstract
2020-1439	Results are conducted in the VKITTI dataset.	abstract
2020-1439	Overall, the main serious concern expressed by the reviewers has to do with the general applicability of this method, since it requires an inverse graphics framework, which all-in-all is not a trivial task, so it is not clear how such a method would scale to more "real" datasets.	weakness
2020-1439	A secondary concern has to do with the fact that the proposed method seems to be mostly a way to perform semantic data-augmentation rather than a way to avoid malicious attacks.	weakness
2020-1439	In the latter case, we would want to know something about the generality of this method (eg, what happens a model is trained for this attacks but then a more pixel-based attack is applied).	weakness
2020-1439	As such, I do not believe that this submission is ready for publication at *CONF*.	decision
2020-1439	However, the technique is an interesting idea it would be interesting if a later submission would provide empirical evidence about/investigate the generality of this idea.	suggestion

2020-1449	This paper is interested in finding salient areas in a deep learning image classification setting.	abstract
2020-1449	The introduced method relies on masking images using Gaussian Gaussian light and shadow (GLAS) and estimating its impact on output. <sep>	abstract
2020-1449	As noted by all reviewers, the paper is too weak for publication in its current form: <sep> - Novelty is very low. <sep>	weakness
2020-1449	- Experimental section not convincing enough, in particular some metrics are missing. <sep>	weakness
2020-1449	- The writing should be improved.	weakness

2020-1459	This paper proposes to further distill token embeddings via what is effectively a simple autoencoder with a ReLU activation.	abstract
2020-1459	All reviewers expressed concerns with the degree of technical contribution of this paper.	weakness
2020-1459	As Reviewer 3 identifies, there are simple variants (eg end-to-end training with the factorized model) and there is no clear intuition for why the proposed method should outperform its variants as well as the other baselines (as noted by Reviewer 1).	weakness
2020-1459	Reviewer 2 further expresses concerns about the merits of the propose approach over existing approaches, given the apparently small effect size of the improvement (let alone the possibility that the improvement may not in fact be statistically significant).	weakness

2020-1460	This work proposes new initialization and layer topologies for training a priori sparse networks.	abstract
2020-1460	Reviewers agreed that the direction is interesting and that the paper is well written.	strength
2020-1460	Additionally the theory presented on the toy matrix reconstruction task helped motivate the proposed approach.	strength
2020-1460	However, it is also necessary to validate the new approach by comparing with existing sparsity literature on standard benchmarks.	suggestion
2020-1460	I recommend resubmitting with the additional experiments suggested by the reviewers.	decision

2020-1464	Solid, but not novel enough to merit publication.	decision
2020-1464	The reviewers agree on rejection, and despite authors' adaptation, the paper requires more work and broader experimentation for publication.	rating_summary

2020-1467	This paper proposes to learn a visual tracking network for an object detection loss as well as the ordinary tracking objective for enhancing the reliability of the tracking network.	abstract
2020-1467	The reviewers were unanimous in their opinion that the paper should not be accepted to *CONF* in its current form.	rating_summary
2020-1467	A main concern is that the proposed method shows improvement over a relatively weak base system.	weakness
2020-1467	Although the author response proposed to include additional analysis, but the reviewers felt that without the additional analysis already included it was not possible to change the overall review score.	rebuttal_process

2020-1468	This paper proposes to use the GAN (ie, minimax) framework for adversarial training, where another neural network was introduced to generate the most effective adversarial perturbation by finding the weakness of the classifier.	abstract
2020-1468	The rebuttal was not fully convincing on why the proposed method should be superior to existing attacks.	rebuttal_process

2020-1469	The paper proposes a new recurrent unit which incorporates long history states to learn longer range dependencies for improved video prediction.	abstract
2020-1469	This history term corresponds to a linear combination of previous hidden states selected through a soft-attention mechanism and can be directly added to ConvLSTM equations that compute the IFO gates and the new state.	abstract
2020-1469	The authors perform empirical validation on the challenging KTH and BAIR Push datasets and show that their architecture outperforms existing work in terms of SSIM, PSNR, and VIF. <sep>	abstract
2020-1469	The main issue raised by the reviewers is the incremental nature of the work and issues in the empirical evaluation which do not support the main claims in the paper.	weakness
2020-1469	After the rebuttal and discussion phase the reviewers agree that these issues were not adequately resolved and the work doesn't meet the acceptance bar.	rating_summary
2020-1469	I will hence recommend the rejection of this paper.	decision
2020-1469	Nevertheless, we encourage the authors improve the manuscript by addressing the remaining issues in the empirical evaluation.	suggestion

2020-1471	This paper proposes a new training method for an end-to-end contract bridge bidding agent.	abstract
2020-1471	Reviewers R2 and R3 raised concerns regarding limited novelty and also experimental results not being convincing.	weakness
2020-1471	R2's main objection is that the paper has "strong SOTA performance with a simple model, but empirical study are rather shallow." <sep>	weakness
2020-1471	Based on their recommendations, I recommend to reject this paper.	decision

2020-1479	All three reviewers agreed that the paper should not be accepted.	rating_summary
2020-1479	No rebuttal was offered, thus the paper is rejected.	decision

2020-1485	This paper is concerned with warm-starting Bayesian optimization (ie starting with a better surrogate model) through transfer learning among related problems. <sep>	abstract
2020-1485	While the key motivation for warm-starting BO is certainly important (although not novel), there are important shortcomings in the way the method is developed and demonstrated.	weakness
2020-1485	Firstly, the reviewers questioned design decisions, such as why combine NNs and GPs in this particular way or why the posterior variance of the hybrid model is not calculated.	weakness
2020-1485	Moreover, there are issues with the experimental methodology that do not allow extraction of confident conclusions (eg repeating the experiments for different initial points is highly desirable).	weakness
2020-1485	Finally, there are presentation issues.	weakness
2020-1485	The authors replied only to some of these concerns, but ultimately the shortcomings seem to persist and hint towards a paper that needs more work.	rebuttal_process

2020-1497	This paper proposes a recurrent architecture based on a recursive gating mechanism.	abstract
2020-1497	The reviewers leaned towards rejection on the basis of questions regarding novelty, analysis, and the experimental setting.	rating_summary
2020-1497	Surprisingly, the authors chose not to engage in discussion, as all reviewers seems pretty open to having their minds changed.	rebuttal_process
2020-1497	If none of the reviewers will champion the paper, and the authors cannot be bothered to champion their own work, I see no reason to recommend acceptance.	decision

2020-1501	The paper has received all negative scores.	rating_summary
2020-1501	Furthermore, one of the reviewers identified an anonymity violation.	weakness
2020-1501	This is a reject.	decision

2020-1504	The authors tackle the questions of automatic metrics for assessing document similarity and propose the use of Transformed-based language models as a critic providing scores to samples.	abstract
2020-1504	As a note, ideas like these have been also adopted in Computer Vision with the use of the Inception score as a proxy the quality of generated images.	abstract
2020-1504	The authors ask great questions in the paper and they clearly tackle a very important problem, that of automatic measures for assessing text quality.	abstract
2020-1504	While their first indications are not negative, this paper lacks the rigor and depth of experiments of a conference paper that would convince the research community to abandon BLEU and ROUGE in lieu of some other metric.	weakness
2020-1504	It's perhaps a good workshop paper or a short paper at a *CL conference.	decision
2020-1504	Specifically, we would need more tasks where BLEU/ROUGE is the standard measure and so how the proposed measure correlates better with humans,  so cases where word overlap is in theory a good proxy of similarity assuming reference sentence (eg, logical entailment is not such a prototypical task).	weakness
2020-1504	MT is a first step towards that, but summarization is also a necessary I would say.	weakness
2020-1504	Other questions of interest relate to the type of LM (does it only need to be Roberta?)	weakness
2020-1504	and the quality of LM (what if i badly tune my LM?)	weakness
2020-1504	On a more personal note: We all know that BLEU is not a good metric (especially for document-level judgements) and every now and then there have been proposals to replace BLEU that do correlate better (eg, http://ccc.inaoep.mx/~villasen/bib/Regression%20for%20machine%20translation%20evaluation.pdf) .	weakness
2020-1504	However, BLEU is still here due to each simplicity.	weakness
2020-1504	Please keep pushing this research and I'm looking forward to seeing more experimental evidence.	misc

2020-1505	The paper presents an extension of FID for conditional generation settings.	abstract
2020-1505	While it's an important problem to address, the reviewers were concerned about the novelty and advantage of the proposed method over the existing methods.	weakness
2020-1505	The evaluation is reported on toy datasets, and the significance is limited.	weakness

2020-1507	This paper presents an energy-efficient architecture for quantized deep neural networks based on decomposable multiplication using MACs.	abstract
2020-1507	Although the proposed approach is shown to be somehow effective, two reviewers pointed out that the very similar idea was already proposed in the previous work, BitBlade [1].	weakness
2020-1507	As the authors did not submit a rebuttal to defend this critical point, I'd like to recommend rejection.	decision
2020-1507	I recommend authors to discuss and clarify the difference from [1] in the future version of the paper. <sep>	suggestion
2020-1507	[1] Sungju Ryu, Hyungjun Kim, Wooseok Yi, Jae-Joon Kim.	misc
2020-1507	BitBlade: Area and Energy-Efficient Precision-Scalable Neural Network Accelerator with Bitwise Summation.	misc
2020-1507	DAC'2019	misc

2020-1512	This paper proposes a multi-sample variant of dropout, claiming that it accelerates training and improves generalization.	abstract
2020-1512	CIFAR10/100, ImageNet and SVHN results are presented, along with a few ablations. <sep>	abstract
2020-1512	Reviewers were in agreement that the novelty of the contribution appears to be very limited, the evidence for the claims is not strong, and that the applicability of the method for achieving efficiency gains is limited to architectures that only apply dropout very late in processing, precluding applicability to models that employ dropout throughout.	weakness
2020-1512	Importantly, comparisons to Fast Dropout (Wang 2013) seem highly relevant and are missing. <sep>	weakness
2020-1512	While the reviewers acknowledged some of the criticisms, virtually no arguments were offered to rebut them and no updates were made to address them.	rebuttal_process
2020-1512	I therefore recommend rejection.	decision

2020-1513	The paper explores the idea of using implicit human feedback, gathered via EEG, to assist deep reinforcement learning.	abstract
2020-1513	This is an interesting and at least somewhat novel idea.	strength
2020-1513	However, it is not clear that there is a good argument why it should work, or at least work well.	weakness
2020-1513	The experiments carried are more exploratory than anything else, and it is not clear that much can be learned from the results.	weakness
2020-1513	It's a proof of concept more than anything else, of the type that would work well for a workshop paper.	weakness
2020-1513	More systematic empirical work would be needed for a good conference paper. <sep>	suggestion
2020-1513	The authors did not provide a rebuttal to reviewers, but rather agreed with their comments and that the paper needs more work.	rebuttal_process
2020-1513	In light of this, the paper should be rejected and we wish the authors best of luck with a new version of the paper.	decision

2020-1519	Main content: Proposes combining flexible activation functions <sep>	misc
2020-1519	Discussion: <sep> reviewer 1: main issue is unfamiliar with stock dataset, and CIFAR dataset has a bad baseline. <sep>	weakness
2020-1519	reviewer 2: main issue is around baselines and writing. <sep>	weakness
2020-1519	reviewer 3: main issue is paper does not compare with NAS. <sep>	weakness
2020-1519	Recommendation: All 3 reviewers vote reject.	rating_summary
2020-1519	Paper can be improved with stronger baselines and experiments.	weakness
2020-1519	I recommend Reject.	decision

2020-1521	This paper presents a method for merging a discriminative GMM with an ARD sparsity-promoting prior.	abstract
2020-1521	This is accomplished by nesting the ARD prior update within a larger EM-based routine for handling the GMM, allowing the model to automatically remove redundant components and improve generalization.	abstract
2020-1521	The resulting algorithm was deployed on standard benchmark data sets and compared against existing baselines such as logistic regression, RVMs, and SVMs. <sep>	abstract
2020-1521	Overall, one potential weakness of this paper, which is admittedly somewhat subjective, is that the exhibited novelty of the proposed approach is modest.	weakness
2020-1521	Indeed ARD approaches are now widely used in various capacities, and even if some hurdles must be overcome to implement the specific marriage with a discriminative GMM as reported here, at least one reviewer did not feel that this was sufficient to warrant publication.	rating_summary
2020-1521	Other concerns related to the experiments and comparison with existing work.	weakness
2020-1521	For example, one reviewer mentioned comparisons with Panousis et al, "Nonparametric Bayesian Deep Networks with Local Competition," ICML 2019 and requested a discussion of differences.	weakness
2020-1521	However, the rebuttal merely deferred this consideration to future work and provided no feedback regarding similarities or differences.	rebuttal_process
2020-1521	In the end, all reviewers recommended rejecting this paper and I did not find any sufficient reason to overrule this consensus.	decision

2020-1525	This paper introduces a probabilistic generative model which mixes a variational autoencoder (VAE) with an energy based model (EBM).	abstract
2020-1525	As mentioned by all reviewers (i) the motivation of the model is not well justified (ii) experimental results are not convincing enough.	weakness
2020-1525	In addition (iii) handling sets is not specific to the proposed approach, and thus claims regarding sets should be revised.	weakness

2020-1528	This paper proposes an improved (over Andrychowicz et al) meta-optimizer that tries to to learn better strategies for training deep machine learning models.	abstract
2020-1528	The paper was reviewed by three experts, two of whom recommend Weak Reject and one who recommends Reject.	rating_summary
2020-1528	The reviewers identify a number of significant concerns, including degree of novelty and contribution, connections to previous work, completeness of experiments, and comparisons to baselines.	weakness
2020-1528	In light of these reviews and since the authors have unfortunately not provided a response to them, we cannot recommend accepting the paper.	decision

2020-1529	All reviewers agree that the paper is to be rejected, provided strong claims that were not answered.	rating_summary
2020-1529	In this form (especially with such a title) it could not be published (it is more of a technical/engineering interest).	decision

2020-1538	This work starts with a decomposition of the adversarial risk into two terms: the first is the usual risk, while the second is a stability term, that captures the possible effect of an adversarial perturbation.	abstract
2020-1538	The insight of this work is that this second term can be dealt with using unlabelled data, which is often in plentiful supply.	abstract
2020-1538	Unfortunately, the same ideas was developed concurrently and independently by several groups of authors. <sep>	weakness
2020-1538	The reviewer all agreed that this particular version was not ready for publication.	rating_summary
2020-1538	In two cases, the authors compared the work unfavorably with concurrent independent work.	weakness
2020-1538	I will note that the main bound somewhat ignores the issue of overfitting that the second term deals with via the Rademacher bound.	weakness
2020-1538	Unless one assumes one has unlimited unlabeled data, could one not get an arbitrarily biased view of robustness from the sample.	weakness
2020-1538	Seems like a gap to fill.	weakness

2020-1544	This paper presents a rigorous mathematical framework for knowledge graph embedding.	abstract
2020-1544	The paper received 3 reviews.	misc
2020-1544	R1 recommends Weak Reject based on concerns about the contributions of the paper; the authors, in their response, indicate that R1 may have been confused about what the contributions were meant to be.	rating_summary
2020-1544	R2 initially recommended Reject, based on concerns that the paper was overselling its claims, and on the clarity and quality of writing.	rebuttal_process
2020-1544	After the author response, R2 raised their score to Weak Reject but still felt that their main concerns had gone unanswered, and in particular that the authors seemed unwilling to tone down their claims.	rebuttal_process
2020-1544	R3 recommends Weak Reject, indicating that they found the paper difficult to follow and gave some specific technical concerns.	rating_summary
2020-1544	The authors, in their response, express confusion about R3's comments and suggest that R3 also did not understand the paper.	rebuttal_process
2020-1544	However, in light of these unanimous Weak Reject reviews, we cannot recommend acceptance at this time.	decision
2020-1544	We understand that the authors may feel that some reviewers did not properly understand or appreciate the contribution, but all three reviewers are researchers working at highly-ranked institutions and thus are fairly representative of the attendees of *CONF*; we hope that their points of confusion and concern, as reflected in their reviews, will help authors to clarify a revision of the paper for another venue.	misc

2020-1548	This work proposes a robust variant of GAN, in which the generator and discriminator compete with each other in a worst-case setting within a small Wasserstein ball.	abstract
2020-1548	Unfortunately, the reviewers have raised some critical concerns in terms of theoretical analysis and empirical support.	weakness
2020-1548	The authors did not submit rebuttals in time.	rebuttal_process
2020-1548	We encourage the authors to improve the work based on reviewer's comments.	suggestion

2020-1550	This paper proposes Conv-TT-LSTM for long-term video prediction.	abstract
2020-1550	The proposed method saves memory and computation by low-rank tensor representations via tensor decomposition and is evaluated in Moving MNIST and KTH datasets. <sep>	abstract
2020-1550	All reviews argue that the novelty of the paper does not meet the standard of *CONF*.	rating_summary
2020-1550	In the rebuttal, the authors polish the experiment design, which fails to change any reviewer's decision. <sep>	rebuttal_process
2020-1550	Overall, the paper is not good enough for *CONF*.	decision

2020-1551	This paper concerns a training procedure for neural networks which results in sparse connectivity in the final resulting network, consisting of an "early era" of training in which pruning takes place, followed by fixed connectivity training thereafter, and a study of tradeoffs inherent in various approaches to structured and unstructured pruning, and an investigation of adversarial robustness of pruned networks. <sep>	abstract
2020-1551	While some reviewers found the general approach interesting, all reviewers were critical of the lack of novelty, clarity and empirical rigour.	weakness
2020-1551	R2 in particular raised concerns about the motivation, evaluation of computational savings (that FLOPS should be measured directly), and felt that the discussion of adversarial robustness was out of place and "an afterthought". <sep>	weakness
2020-1551	Reviewers were unconvinced by rebuttals, and no attempts were made at improving the paper (additional experiments were promised, but not delivered).	rebuttal_process
2020-1551	I therefore recommend rejection.	decision

2020-1552	This work proposes a new architecture for abstract visual reasoning called "Attention Relation Network" (ARNe), based on Transformer-style soft attention and relation networks, which the authors show to improve on the "Wild Relation Network" (WReN).	abstract
2020-1552	The authors test their network on the PGM dataset, and demonstrate a non-trivial improvement over previously reported baselines. <sep>	abstract
2020-1552	The paper is well written and makes an interesting contribution, but the reviewers expressed some criticisms, including technical novelty, unfinished experiments (and lack of experimental details), and somewhat weak experimental results, which suggest that the proposed ARNe model does not work well when training with weaker supervision without meta-targets.	weakness
2020-1552	Even though the authors addressed some concerns in their revised version (namely, they added new experiments in the extrapolation split of PGM and experiments on the new RAVEN dataset), I feel the paper is not yet ready for publication at *CONF*.	decision

2020-1554	There has been significant discussion in the literature on the effect of the properties of the curvature of minima on generalization in deep learning.	abstract
2020-1554	This paper aims to shed some light on that discussion through the lens of theoretical analysis and the use of a Bayesian Jeffrey's prior.	abstract
2020-1554	It seems clear that the reviewers appreciated the work and found the analysis insightful.	strength
2020-1554	However, a major issue cited by the reviewers is a lack of compelling empirical evidence that the claims of the paper are true.	weakness
2020-1554	The authors run experiments on very small networks and reviewers felt that the results of these experiments were unlikely to extrapolate to large scale modern models and problems.	weakness
2020-1554	One reviewer was concerned about the quality of the exposition in terms of the writing and language and care in terminology.	weakness
2020-1554	Unfortunately, this paper falls below the bar for acceptance, but it seems likely that stronger empirical results and a careful treatment of the writing would make this a much stronger paper for future submission.	decision

2020-1555	This paper introduces a new clustering method, which builds upon the work introduced by Lee et al, 2019 - contextual information across different dataset samples is gathered with a transformer, and then used to predict the cluster label for a given sample.	abstract
2020-1555	All reviewers agree the writing should be improved and clarified.	weakness
2020-1555	The novelty is also on the low side, given the previous work by Lee et al Experiments should be more convincing.	weakness

2020-1556	This paper addresses the problem of unsupervised domain adaptation and proposes explicit modeling of the source and target feature distributions to aid in cross-domain alignment. <sep>	abstract
2020-1556	The reviewers all recommended rejection of this work.	rating_summary
2020-1556	Though they all understood the paper's position of explicit feature distribution modeling, there was a lack of understanding as to why this explicit modeling should be superior to the common implicit modeling done in related literature.	weakness
2020-1556	As some reviewers raised concern that the empirical performance of the proposed approach was marginally better than competing methods, this experimental evidence alone was not sufficient justification of the explicit modeling.	weakness
2020-1556	There was also a secondary concern about whether the two proposed loss functions were simultaneously necessary. <sep>	weakness
2020-1556	Overall, after reading the reviewers and authors comments, the AC recommends this paper not be accepted.	decision

2020-1557	The paper proposes a neurally inspired model that is a variant of conv-LSTM called V1net.	abstract
2020-1557	The reviewers had trouble gleaning the main contributions of the work.	weakness
2020-1557	Given that it is hard to obtain state of art results in neurally inspired architectures, the bar is much higher to demonstrate that there is value in pursuing these architectures.	weakness
2020-1557	There are not enough convincing results in the paper to show this.	weakness
2020-1557	I recommend rejection.	decision

2020-1561	This paper proposes a new active learning algorithm based on clustering and then sampling based on an uncertainty-based metric.	abstract
2020-1561	This active learning method is not particular to deep learning.	weakness
2020-1561	The authors also propose a new de-noising layer specific to deep learning to remove noise from possibly noisy labels that are provided.	abstract
2020-1561	These two proposals are orthogonal to one another and its not clear why they appear in the same paper. <sep>	weakness
2020-1561	Reviewers were underwhelmed by the novelty of either contribution.	weakness
2020-1561	With respect to active learning, there is years of work on first performing unsupervised learning (eg, clustering) and then different forms of active sampling. <sep>	weakness
2020-1561	This work lacks sufficient novelty for acceptance at a top tier venue.	decision
2020-1561	Reject	decision

2020-1563	The submission is concerned with providing a transport based formulation for generative modeling in order to avoid the standard max/min optimization challenge of GANs.	abstract
2020-1563	The authors propose representing the divergence with a fluid flow model, the solution of which can be found by discretizing the space, resulting in an alignment of high dimensional point clouds. <sep>	abstract
2020-1563	The authors disagreed about the novelty and clarity of the work, but they did agree that the empirical and theoretical support was lacking, and that the paper could be substantially improved through better validation and better results - in particular, the approach struggles with MNIST digit generation compared to other methods. <sep>	weakness
2020-1563	The recommendation is to not accept the submission at this time.	decision

2020-1564	The paper received Weak Reject scores from all three reviewers.	rating_summary
2020-1564	The AC has read the reviews and lengthy discussions and examined the paper.	misc
2020-1564	AC feels that there is a consensus that the paper does not quite meet the acceptance threshold and thus cannot be accepted.	decision
2020-1564	Hopefully the authors can use the feedback to improve their paper and resubmit to another venue.	decision

2020-1570	The paper proposes combining paired attention with co-attention.	abstract
2020-1570	The reviewers have remarked that the paper is will written and that the experiments provide some new insights into this combination.	strength
2020-1570	Initially, some additional experiments were proposed, which were addressed by the authors in the rebuttal and the new version of the paper.	rebuttal_process
2020-1570	However, *CONF* is becoming a very competitive conference where novelty is an important criteria for acceptance, and unfortunately the paper was considered to lack the novelty to be presented at *CONF*.	decision

2020-1574	In this paper the authors propose a wrapper feature selection method that selects features based on 1) redundancy, ie the sensitivity of the downstream model to feature elimination, and 2) relevance, ie how the individual features impact the accuracy of the target task.	abstract
2020-1574	The authors use a combination of the redundancy and relevance scores to eliminate the features. <sep>	abstract
2020-1574	While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: <sep> (1) all reviewers agreed that the proposed approach lacks theoretical justification or convincing empirical evaluations in order to show its effectiveness and general applicability -- see R1's and R2's requests for evaluation with more datasets/diverse tasks to assess the applicability and generality of the proposed model; see R1's, R4's concerns regarding theoretical analysis; <sep>	weakness
2020-1574	(2) all reviewers expressed concerns regarding the technical issue of combining the redundancy and relevance scores -- see R4's and R2's concerns regarding the individual/disjoint calibration of scores; see R1's suggestion to learn to reweigh the scores; <sep>	weakness
2020-1574	(3) experimental setup requires improvement both in terms of clarity of presentation and implementation -- see R1's comment regarding the ranker model, see R4's concern regarding comparison with a standard deep learning model that does feature learning for a downstream task; both reviewers also suggested to analyse how autoencoders with different capacity could impact the results. <sep>	weakness
2020-1574	Additionally R1 raised a concern regarding relevant recent works that were overlooked. <sep>	weakness
2020-1574	The authors have tried to address some of these concerns during rebuttal, but an insufficient empirical evidence still remains a critical issue of this work.	rebuttal_process
2020-1574	To conclude, the reviewers and AC suggest that in its current state the manuscript is not ready for a publication.	decision
2020-1574	We hope the reviews are useful for improving and revising the paper.	misc

2020-1576	This paper proposed to improve the quality of underwater images, specifically color distortion and haze effect, by an unsupervised generative adversarial network (GAN).	abstract
2020-1576	An end-to-end autoencoder network is used to demonstrate its effectiveness in comparing to existing works, while maintaining scene content structural similarity.	abstract
2020-1576	Three reviewers unanimously rated weak rejection.	rating_summary
2020-1576	The major concerns include unclear difference with respect to the existing works, incremental contribution, low quality of figures, low quality of writing, etc.	weakness
2020-1576	The authors respond to Reviewers' concerns but did not change the rating.	rebuttal_process
2020-1576	The ACs concur the concerns and the paper can not be accepted at its current state.	decision

2020-1579	This paper proposes to use GMM as the latent prior distribution of GAN.	abstract
2020-1579	The reviewers unanimously agree that the paper is not well motivated, explanations are lacking and writing needs to be substantially improved.	weakness

2020-1584	The paper proposed and analyze a k-NN method for identifying corrupted labels for training deep neural networks. <sep>	abstract
2020-1584	Although a reviewer pointed out that the noisy k-NN contribution is interesting, I think the paper can be much improved further due to the followings: <sep> (a) Lack of state-of-the-art baselines to compare. <sep>	weakness
2020-1584	(b) Lack of important recent related work, ie, "Robust Inference via Generative Classifiers for Handling Noisy Labels" from ICML 2019 (see https://arxiv.org/abs/1901.11300).	weakness
2020-1584	The paper also runs a clustering-like algorithm for handling noisy labels, and the authors should compare and discuss why the proposed method is superior. <sep>	weakness
2020-1584	(c) Poor write-up, eg, address what is missing in existing methods from many different perspectives as this is a quite well-studied popular problem. <sep>	weakness
2020-1584	Hence, I recommend rejection.	decision

2020-1586	The paper identifies the limitation of graph neural networks and proposed new variants of graph neural works.	abstract
2020-1586	However, the reviewers feel that the theory of the paper have some problems: <sep> 1. A major concern is that the theoretical analyses in this paper are limited to graphs sampled from the SBM model.	weakness
2020-1586	It is unclear how these analyses can be generalized to real graphs. <sep>	weakness
2020-1586	2. The robustness definition is inconsistent. <sep>	weakness
2020-1586	Furthermore, more extensive experiments on more datasets will also be helpful.	weakness

2020-1604	This paper proposes BOSH-attack, a meta-algorithm for decision-based attack, where a model that can be accessed only via label queries for a given input is attacked by a minimal perturbation to the input that changes the predicted label.	abstract
2020-1604	BOSH improves over existing local update algorithms by leveraging Bayesian Optimization (BO) and Successive Halving (SH).	abstract
2020-1604	It has valuable contributions.	strength
2020-1604	But various improvements as detailed in the review comments can be made to further strength the manuscript.	suggestion

2020-1606	This paper develops a method for sample selection that exploits the memorization effect.	abstract
2020-1606	While the paper has been substantially improved from its original form, the paper still does not meet the quality bar of *CONF* in terms of presentation of the results and experimental validation.	decision
2020-1606	The paper will benefit from a revision and resubmission to another venue.	decision

2020-1608	This paper proposes an approach for abstractive summarization of multi-domain dialogs, called SPNet, that incrementally builds on previous approaches such as pointer-generator networks.	abstract
2020-1608	SPNet also separately includes speaker role, slot and domain labels, and is evaluated against a new metric, Critical Information Completeness (CIC), to tackle issues with ROUGE.	abstract
2020-1608	The reviewers suggested a set of issues, including the meaningfulness of the task, incremental nature of the work and lack of novelty, and consistency issues in the write up.	weakness
2020-1608	Unfortunately authors did not respond to the reviewer comments.	rebuttal_process
2020-1608	I suggest rejecting the paper.	decision

2020-1609	This papers proposed a solution to the problem of disease density estimation using satellite scene images.	abstract
2020-1609	The method combines a classification and regression task.	abstract
2020-1609	The reviewers were unanimous in their recommendation that the submission not be accepted to *CONF*.	rating_summary
2020-1609	The main concern was a lack of methodological novelty.	weakness
2020-1609	The authors responded to reviewer comments, and indicated a list of improvements that still remain to be done indicating that the paper should at least go through another review cycle.	rebuttal_process

2020-1614	The paper computes an "approximate" generalization bound based on loss curvature.	abstract
2020-1614	Several expert reviewers found a long list of issues, including missing related work and a sloppy mix of formal statements and heuristics, without proper accounting of what could be gleaned from some many heuristic steps.	weakness
2020-1614	Ultimately, the paper needs to be rewritten and re-reviewed.	decision

2020-1615	This paper considers adversarial attacks in deep reinforcement learning, and specifically focuses on the problem of identifying key steps to attack.	abstract
2020-1615	The paper poses learning these key steps as an RL problem with a cost for the attacker choosing to attack. <sep>	abstract
2020-1615	The reviewers agreed that this was an interesting problem setup, and the ability to learn these attacks without heuristics is promising.	strength
2020-1615	The main concern, which was felt was not adequately addressed in the rebuttals, was that the results need to be more than just competitive with heuristic approaches. <sep>	rebuttal_process
2020-1615	The fact that the attack ratio cannot be reliably changed, even with varying λ still presents a major hurdle in the evaluation of the proposed method. <sep>	rebuttal_process
2020-1615	For the aforementioned reasons, I recommend rejecting this paper.	decision

2020-1617	This paper proposes to use Graph Convolutional Networks (GCNs) in Bayesian optimization for neural architecture search.	abstract
2020-1617	While the paper title includes multi-objective, this component appears to only be a posthoc evaluation of the Pareto front of networks evaluated using a single-objective search -- this could be performed for any method that evaluates more than one network.	abstract
2020-1617	Performance on NAS-Bench-101 appears to be very good. <sep>	abstract
2020-1617	In the private discussion of reviewers and AC, several issues were raised, including whether the approach is compared fairly to LaNAS and whether the GCN will predict well for large search spaces.	weakness
2020-1617	Also, unfortunately, no code is provided, making it unclear whether the work is reproducible.	weakness
2020-1617	The reviewers unanimously agreed on a weak rejection score. <sep>	rating_summary
2020-1617	I concur with this assessment and therefore recommend rejection.	decision

2020-1618	This work is interesting because it's aim is to push the work in intrinsic motivation towards crisp definitions, and thus reads like an algorithmic paper rather than yet another reward heuristic and system building paper.	strength
2020-1618	There is some nice theory here, integration with options, and clear connections to existing work. <sep>	strength
2020-1618	However, the paper is not ready for publication.	decision
2020-1618	There were were several issues that could not be resolved in the reviewers minds (even after the author response and extensive discussion).	weakness
2020-1618	The primary issues were: (1) There was significant confusion around the beta sensitivity---figs 6,7,8 appear misleading or at least contradictory to the message of the paper.	weakness
2020-1618	(2) The need for x,y env states.	weakness
2020-1618	(3) The several reviewers found the decision states unintuitive and confused the quantitative analysis focus if they given the authors primary focus is transfer performance.	weakness
2020-1618	(4) All reviewers found the experiments lacking.	weakness
2020-1618	Overall, the results generally don't support the claims of the paper, and there are too many missing details and odd empirical choices. <sep>	weakness
2020-1618	Again, there was extensive discussion because all agreed this is an interesting line of work.	misc
2020-1618	Taking the reviewers excellent suggestions on board will almost certainly result in an excellent paper.	suggestion
2020-1618	Keep going!	misc

2020-1619	This paper presents a continuous CNN model that can handle nonuniform time series data.	abstract
2020-1619	It learns the interpolation kernel and convolutional architectures in an end-to-end manner, which is shown to achieve higher performance compared to naïve baselines. <sep>	abstract
2020-1619	All reviewers scored Weak Reject and there was no strong opinion to support the paper during discussion.	rating_summary
2020-1619	Although I felt some of the reviewers' comments are missing the points, I generally agree that the novelty of the method is rather straightforward and incremental, and that the experimental evaluation is not convincing enough.	weakness
2020-1619	Particularly, comparison with more recent state-of-the-art point process methods should be included.	suggestion
2020-1619	For example, [1-3] claim better performance than RMTPP.	suggestion
2020-1619	Considering that the contribution of the paper is more on empirical side and CCNN is not only the solution for handing nonuniform time series data, I think this point should be properly addressed and discussed.	weakness
2020-1619	Based on these reasons, I'd like to recommend rejection. <sep>	decision
2020-1619	[1] Xiao et al, Modeling the Intensity Function of Point Process via Recurrent Neural Networkss, AAAI 2017. <sep>	misc
2020-1619	[2] Li et al, Learning Temporal Point Processes via Reinforcement Learning, NIPS 2018. <sep>	misc
2020-1619	[3] Turkmen et al, FastPoint: Scalable Deep Point Processes, ECML-PKDD 2019.	misc

2020-1620	This paper discusses new methods to perform adversarial attacks on salience maps. <sep>	abstract
2020-1620	In its current form, this paper in its current form has unfortunately has not convinced several of the reviewers/commenters of the motivation behind proposing such a method.	weakness
2020-1620	I tend to share the same opinion.	misc
2020-1620	I would encourage the authors to re-think the motivation of the work, and if there are indeed solid use cases to express them explicitly in the next version of the paper.	suggestion

2020-1629	This paper proposes a self-attention-based autoregressive model called Axial Transformers for images and other data organized as high dimensional tensors.	abstract
2020-1629	The Axial Attention is applied within each axis of the data to accelerate the processing. <sep>	abstract
2020-1629	Most of the authors claim that main idea behind Axial Attention is widely applicable, which can be used in many core vision tasks, such as detection and classification.	abstract
2020-1629	However, the revision fails to provide more application for Axial attention. <sep>	rebuttal_process
2020-1629	Overall, the idea behind this paper is interesting but more convincing experimental results are needed.	weakness

2020-1630	The authors propose TD updates for Truncated Q-functions and Shifted Q-functions, reflecting short- and long-term predictions, respectively.	abstract
2020-1630	They show that they can be combined to form an estimate of the full-return, leading to a Composite Q-learning algorithm.	abstract
2020-1630	They claim to demonstrated improved data-efficiency in the tabular setting and on three simulated robot tasks. <sep>	abstract
2020-1630	All of the reviewers found the ideas in the paper interesting, however, based on the issues raised by Reviewer 3, everyone agreed that substantial revisions to the paper are necessary to properly incorporate the new results.	weakness
2020-1630	As a result, I am recommending rejection for this submission at this time.	decision
2020-1630	I encourage the authors to incorporate the feedback from the reviewers, and believe that after that is done, the paper will be a strong submission.	suggestion

2020-1636	There is insufficient support to recommend accepting this paper.	decision
2020-1636	The authors provided detailed responses, but the reviewers unanimously kept their recommendation as reject.	rating_summary
2020-1636	The novelty and significance of the main contribution was not made sufficiently clear, given the context of related work.	weakness
2020-1636	Critically, the experimental evaluation was not considered to be convincing, lacking detailed explanation and justification, and a sufficiently thorough comparison to strong baselines, The submitted reviews should help the authors improve their paper.	weakness

2020-1640	The article studies universal approximation for the restricted class of equivariant functions, which can have a smaller number of free parameters.	abstract
2020-1640	The reviewers found the topic important and also that the approach has merits.	strength
2020-1640	However, they pointed out that the article is very hard to read and that more intuitions, a clearer comparison with existing work, and connections to practice would be important.	weakness
2020-1640	The responses did clarify some of the differences to previous works.	rebuttal_process
2020-1640	However, there was no revision addressing the main concerns.	rebuttal_process

2020-1641	This paper is very different from most *CONF* submissions, and appears to be addressing interesting themes.	strength
2020-1641	However the paper seems poorly written, and generally unclear.	weakness
2020-1641	The motivation, task, method and evaluation are all unclear.	weakness
2020-1641	I recommend that the authors add explicit definitions, equations, algorithm boxes, and more examples to make their paper clearer.	suggestion

2020-1642	The paper seems technically correct and has some novelty, but the relevance of the paper is questionable.	weakness
2020-1642	Considering the selectiveness of *CONF*, I cannot recommend the paper for acceptance at this point. <sep>	decision
2020-1642	In more detail: the authors propose a technique for estimating density rations between a target distribution of real samples and a distribution of samples generated by the model, without storing samples.	abstract
2020-1642	The method seems to be technically well executed and verified.	strength
2020-1642	However, there was major concerns among multiple reviewers that the addressed problem does not seem relevant to the *CONF* community.	weakness
2020-1642	The question addressed seemed artificial, and it was not considered realistic (by R2 and also by R1 in the confidential discussion).	weakness
2020-1642	R3 also expressed doubts at the usefulness of the method. <sep>	weakness
2020-1642	Furthermore, some doubts were expressed regarding clarity (although opinions were mixed on that) and on the justification of the modification of the VAE objective to the continual setting.	weakness

2020-1651	This paper presents a language model for Amharic using HMMs and incorporating POS tags.	abstract
2020-1651	The paper is very short and lacks essential parts such as describing the exact model and the experimental design and results.	weakness
2020-1651	The reviewers all rejected this paper, and there was no author rebuttal.	rating_summary
2020-1651	This paper is clearly not appropriate for publication at *CONF*.	decision

2020-1656	This manuscript proposes an approach for fair and robust training of predictive modeling -- both of which are implemented using adversarial methods, ie, an adversarial loss for fairness and an adversarial loss for robustness.	abstract
2020-1656	The resulting model is evaluated empirically and shown to improve fairness and robustness performance. <sep>	abstract
2020-1656	The reviewers and AC agree that the problem studied is timely and interesting, as there is limited work on joint fairness and robustness.	strength
2020-1656	However, the reviewers were unconvinced about the novelty and clarity of the conceptual and empirical results.	weakness
2020-1656	In reviews and discussion, the reviewers also noted insufficient motivation for the approach.	weakness

2020-1659	A nice idea: the latent prior is replaced by a GAN.	strength
2020-1659	A general agreement between all four reviewers to reject the submission, based on a not thorough enough description of the approach, and possibly not being novel.	rating_summary

2020-1668	This paper investigates using "curiosity" to improve representation learning.	abstract
2020-1668	This paper is not ready for publication.	decision
2020-1668	The main issues was the reviewers found the paper did not support the claim contributions in terms of (1) evaluating the new representations and improvement due to the representation, and (2) the novelty of the method compared to the long literature in this area.	weakness
2020-1668	In general the reviewers found the empirical evidence unconvincing, and the too many missing details. <sep>	weakness
2020-1668	The results in this paper have many issues: claims of performance based on three runs; undefined error measures; bolding entries in tables which appear not significantly better without explanation; unclear/informal meta-parameter tuning. <sep>	weakness
2020-1668	Finally, there are some terminology issues in this paper.	weakness
2020-1668	I suggest an excellent paper on the topic: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3858647/	suggestion

2020-1670	Summary: This paper casts the problem of step-size tuning in the Runge-Kutta method as a meta learning problem.	abstract
2020-1670	The paper gives a review of the existing approaches to step size control in RK method.	abstract
2020-1670	Deriving knowledge from these approaches the paper reasons about appropriate features and loss functions to use in the meta learning update.	abstract
2020-1670	The paper shows that the proposed approach is able to generalize sufficiently enough to obtain better performance than a baseline. <sep>	abstract
2020-1670	The paper was lacking in advocates for its merits, and needs better comparisons with other baselines before it is ready to be published.	decision

2020-1671	This paper presents a neural topic model with the goal of improving topic discovery with a PLSA loss.	abstract
2020-1671	Reviewers point out major limitations including the following: <sep> 1) Empirical comparison is done only with LDA when there are many newer models that perform much better. <sep>	weakness
2020-1671	2) Related work section is incomplete, especially for the newer models. <sep>	weakness
2020-1671	3) Writing is unclear in many parts of the paper. <sep>	weakness
2020-1671	For these reasons, I recommend that the authors make major improvements to the paper before resubmitting to another venue.	decision

2020-1672	The reviewers have reached consensus that while the paper is interesting, it could use more time.	weakness
2020-1672	We urge the authors to continue their investigations.	suggestion

2020-1679	The reviewers all agreed that the proposed modification was minor.	rebuttal_process
2020-1679	I encourage the authors to pursue in this direction, as they mentioned in their rebuttal, before resubmitting to another conference.	decision

2020-1681	The consensus amongst the reviewers is that the paper discusses an interesting idea and shows significant promise, but that the presentation of the initial submission was not of a publishable standard.	rating_summary
2020-1681	While some of the issues were clarified during discussion, the reviewers agree that the paper lacks polish and is therefore not ready.	rating_summary
2020-1681	While I think Reviewer #3 is overly strict in sticking to a 1, as it is the nature of *CONF* to allow papers to be improved through the discussion, in the absence of any of the reviewers being ready to champion the paper, I cannot recommend acceptance.	decision
2020-1681	I however have no doubt that with further work on the presentation of what sounds like a potentially fascinating contribution to the field, the paper will stand a chance at acceptance at a future conference.	misc

2020-1682	This paper a theoretical interpretation of separation rank as a measure of a recurrent network's ability to capture contextual dependencies in text, and introduces a novel bidirectional NLP variant and tests it on several NLP tasks to verify their analysis. <sep>	abstract
2020-1682	Reviewer 3 found that the paper does not provide a clear description of the method and that a focus on single message would have worked better.	weakness
2020-1682	Reviewer 2 made a claim of several shortcomings in the paper relating to lack of clarity, limited details on method, reliance on a 'false dichotomy', and failure to report performance.	weakness
2020-1682	Reviewer 1 found the goals of the work to be interesting but that the paper was not clear, that the proofs were not rigorous enough, and clarity of experiments.	weakness
2020-1682	The authors responded to the all the comments.	rebuttal_process
2020-1682	The reviewers felt that their comments were still valid and did not adjust their ratings. <sep>	rebuttal_process
2020-1682	Overall, the paper is not yet ready in its current form.	decision
2020-1682	We hope that the authors will find valuable feedback for their ongoing research.	misc

2020-1687	The authors propose a novel metric to detect distributional discrepancy for text generation models and argue that these can be used to explain the failure of GANs for language generation tasks.	abstract
2020-1687	The reviewers found significant deficiencies with the paper, including: <sep> 1) Numerous grammatical errors and typos, that make it difficult to read the paper. <sep>	weakness
2020-1687	2) Mischarcterization of prior work on neural language models, and failure to compare with standard distributional discrepancy measures studied in prior work (KL, total variation, Wasserstein etc.).	weakness
2020-1687	Further, the necessity of the complicated procedure derived by the authors is not well-justified. <sep>	weakness
2020-1687	3) Failure to run experiments on standard banchmarks for image generation (which are much better studied applications of GANs) and confirm the superiority of the proposed metrics relative to standard baselines. <sep>	weakness
2020-1687	The reviewers were agreed on the rejection decision and the authors did not participate in the rebuttal phase. <sep>	rating_summary
2020-1687	I therefore recommend rejection.	decision

2020-1703	This paper proposes to use the grey level co-occurrence matrix method (GLCM) for both the performance evaluation metric and an auxiliary loss function for single image super resolution.	abstract
2020-1703	Experiments are conducted on X-ray images of rock samples.	abstract
2020-1703	Three reviewers provide comments.	misc
2020-1703	Two reviewers rated reject while one rated weak reject.	rating_summary
2020-1703	The major concerns include the lack of clear and detailed description, low novelty, limited experiment on only one database, unconvincing improvement over the prior work, etc.	weakness
2020-1703	The authors agree that the limited experiment on one database does not demonstrate the generalization capability of the proposed method.	rebuttal_process
2020-1703	The AC agrees with the reviewers' comments, and recommend rejection.	decision

2020-1709	The submission studies the problem of geolocalizing a city based on geometric information encoded in so called "lean" images.	abstract
2020-1709	The reviewers were unanimous in their opinion that the submission does not meet the threshold for publication at *CONF*.	rating_summary
2020-1709	Concerns included quality of writing, novelty with respect to existing literature (in particular see Review #2), and limited validation on one geographic area.	weakness
2020-1709	No rebuttal was provided.	rebuttal_process

2020-1711	The paper investigates out-of-distribution detection for regression tasks. <sep>	abstract
2020-1711	The reviewers raised several concerns about novelty of the method relative to existing methods, motivation & theoretical justification and clarity of the presentation  (in particular, the discussion around regression vs classification). <sep>	weakness
2020-1711	I encourage the authors to revise the draft based on the reviewers' feedback and resubmit to a different venue.	decision

2020-1712	This paper presents a differentially private mechanism, called Noisy ArgMax, for privately aggregating predictions from several teacher models.	abstract
2020-1712	There is a consensus in the discussion that the technique of adding a large constant to the largest vote breaks differential privacy.	rebuttal_process
2020-1712	Given this technical flaw, the paper cannot be accepted.	decision

2020-1713	The paper proposes a new, stable metric, called Area Under Loss curve (AUL) to recognize mislabeled samples in a dataset due to the different behavior of their loss function over time.	abstract
2020-1713	The paper build on earlier observations (eg by Shen & Sanghavi) to propose this new metric as a concrete solution to the mislabeling problem. <sep>	abstract
2020-1713	Although the reviewers remarked that this is an interesting approach for a relevant problems, they expressed several concerns regarding this paper.	strength
2020-1713	Two of them are whether the hardness of a sample would also result in high AUL scores, and another whether the results hold up under realistic mislabelings, rather than artificial label swapping / replacing.	weakness
2020-1713	The authors did anecdotally suggest that neither of these effects has a major impact on the results.	weakness
2020-1713	Still, I think a precise analysis of these effects would be critically important to have in the paper.	weakness
2020-1713	Especially since there might be a complex interaction between the 'hardness' of samples and mislabelings (an MNIST 1 that looks like a 7 might be sooner mislabeled than a 1 that doesn't look like a 7).	weakness
2020-1713	The authors show some examples of 'real' mislabeled sentences recognized by the model but it is still unclear whether downweighting these helped final test set performance in this case. <sep>	weakness
2020-1713	Because of these issues, I cannot recommend acceptance of the paper in its current state.	decision
2020-1713	However, based on the identified relevance of the problem tackled and the identified potential for significant impact I do think this could be a great paper in a next iteration.	strength

2020-1715	This paper proposes an algorithm to produce well-calibrated uncertainty estimates.	abstract
2020-1715	The work accomplishes this by introducing two loss terms: entropy-encouraging loss and an adversarial calibration loss to encourage predictive smoothness in response to adversarial input perturbations. <sep>	abstract
2020-1715	All reviewers recommended weak reject for this work with a major issue being the presentation of the work.	rating_summary
2020-1715	Each reviewer provided specific examples of areas in which the paper text, figures, equations etc were unclear or missing details.	weakness
2020-1715	Though the authors have put significant effort into responding to the specific reviewer mentions, the reviewers have determined that the manuscript would benefit from further revision for clarity. <sep>	rebuttal_process
2020-1715	Therefore, we do not recommend acceptance of this work at this time and instead encourage the authors to further iterate on the manuscript and consider resubmission to a future venue.	decision

2020-1719	This paper presents an approach to enforce statistical fairness notions using adversarial networks.	abstract
2020-1719	The reviewers point out several issues of the paper, including 1) their approach does not provably enforce criteria such as demographic parity, 2) lack of novelty and 3) poor presentation.	weakness

2020-1722	This paper studies adversarial training in the linear classification setting, and shows a rate of convergence for adversarial training of o(1/log T) to the hard margin SVM solution under a set of assumptions. <sep>	abstract
2020-1722	While 2 reviewers agree that the problem and the central result is somewhat interesting (though R3 is uncertain of the applicability to deep learning, I agree that useful insights can often be gleaned from studying the linear case), reviewers were critical of the degree of clarity and rigour in the writing, including notation, symbol reuse, repetitions/redundancies, and clarity surrounding the assumptions made. <sep>	weakness
2020-1722	No updates to the paper were made and reviewers did not feel their concerns were addressed by the rebuttals.	rebuttal_process
2020-1722	I therefore recommend rejection, but would encourage the authors to continue refining their paper in order to showcase their results more clearly and didactically.	decision

2020-1724	The paper proposes a new method for improving generative properties of VAE model.	abstract
2020-1724	The reviewers unanimously agree that this paper is not ready to be published, particularly being concerned about the unclear objective and potentially misleading claims of the paper.	rating_summary
2020-1724	Multiple reviewers pointed out about incorrect claims and statements without theoretical or empirical justification.	weakness
2020-1724	The reviewers also mention that the paper does not provide new insights about VAE model as MDL interpretation of VAE it is not new.	weakness

2020-1726	Main content: <sep> [Blind review #3] The authors propose a metric based model for few-shot learning.	abstract
2020-1726	The goal of the proposed technique is to incorporate a prior that highlight better the dissimilarity between closely related class prototype.	abstract
2020-1726	Thus, the proposed paper is related to prototypical neural network (use of prototype to represent a class) but differ from it by using inner product scoring  as a similarity measure instead of the use of euclidean distance.	abstract
2020-1726	There is also close similarity between the proposed method and matching network. <sep>	abstract
2020-1726	[Blind review #2] The stated contributions of the paper are: (1) a method for performing few-shot learning and (2) an approach for building harder few-shot learning datasets from existing datasets.	abstract
2020-1726	The authors describe a model for creating a task-aware embedding for different novel sets (for different image classification settings) using a nonlinear self-attention-like mechanism applied to the centroid of the global embeddings for each class.	abstract
2020-1726	The resulting embeddings are used per class with an additional attention layer applied on the embeddings from the other classes to identify closely-related classes and consider the part of the embedding orthogonal to the attention-weighted-average of these closely-related classes.	abstract
2020-1726	They compare the accuracy of their model vs others in the 1-shot and 5-shot setting on various datasets, including a derived dataset from CIFAR which they call Hierarchical-CIFAR. <sep>	abstract
2020-1726	-- <sep>	misc
2020-1726	Discussion: <sep> All reviews agree on a weak reject. <sep>	rating_summary
2020-1726	-- <sep>	misc
2020-1726	Recommendation and justification: <sep> While the ideas appear to be on a good track, the paper itself is poorly written - as one review put it, more like notes to themselves, rather than a well-written document to the *CONF* audience.	weakness

2020-1729	There is insufficient support to recommend accepting this paper.	decision
2020-1729	Although the authors provided detailed responses, none of the reviewers changed their recommendation from reject.	rebuttal_process
2020-1729	One of the main criticisms, even after revision, concerned the quality of the experimental evaluation.	rebuttal_process
2020-1729	The reviewers criticized the lack of important baselines, and remained unsure about adequate hyperparameter tuning in the revision.	rebuttal_process
2020-1729	The technical exposition lacked a sober discussion of limitations.	rebuttal_process
2020-1729	The paper would be greatly strengthened by the addition of a theoretical justification of the proposed approach.	suggestion
2020-1729	In the end, the submitted reviews should be able to help the authors strengthen this paper.	misc

2020-1747	The paper makes broad claims, but the depth of the experiments is very limited to a narrow combination of algorithms.	weakness

2020-1749	The authors consider the problem of program induction from input-output pairs. <sep>	abstract
2020-1749	They propose an approach based on a combination of imitation learning from an auto-curriculum for policy and value functions and alpha-go style tree search. <sep>	abstract
2020-1749	It is a applied to inducing assembly programs and compared to ablation baselines.<sep>	abstract
2020-1749	This paper is below acceptance threshold, based on the reviews and my own reading. <sep>	decision
2020-1749	The main points of concern are a lack of novelty (the proposed approach is similar to previously published approaches in program synthesis), missing references to prior work and a lack of baselines for the experiments.	weakness

2020-1750	This paper aims to address transfer learning by importance weighted ERM that estimates a density ratio from the given sample and some auxiliary information on the population.	abstract
2020-1750	Several learning bounds were proven to promote the use of importance weighted ERM. <sep>	abstract
2020-1750	Reviewers and AC feel that the novelty of this paper is modest given the rich relevant literature and the practical use of this paper may be limited.	weakness
2020-1750	The discussion with related theoretical work such as generalization bound of PU learning can be expanded significantly.	weakness
2020-1750	The presentation can be largely improved, especially in the experiment part.	weakness
2020-1750	The rebuttal is somewhat subjective and unconvincing to address the concerns. <sep>	rebuttal_process
2020-1750	Hence I recommend rejection.	decision

2020-1752	This paper proposes a noise-aware knowledge graph embedding (NoiGAN) by combining KG completion and noise detection through the GANs framework.	abstract
2020-1752	The reviewers find that the idea is interesting, but the comparison to SOTA is largely missing.	weakness
2020-1752	The paper can be improved by addressing the reviewer comments.	suggestion

2020-1753	The proposed paper presents low-rank compression method for DNNs.	abstract
2020-1753	This topic has been around for a while, so the contribution is limited.	weakness
2020-1753	Lebedev et al paper in *CONF* 2015 used CP-factorization to compress neural networks for Imagenet classification; in 2019, the idea has to be really novel in order to be presented on CIFAR datasets.	weakness
2020-1753	The latency is not analyzed. <sep>	weakness
2020-1753	So, I agree with reviewers.	misc

2020-1756	This paper tackles an important problem: understanding if different NN solutions are similar or different.	abstract
2020-1756	In the current form, however, the main motivation for the approach, and what the empirical results tell us, remains unclear.	weakness
2020-1756	I read the paper after the updates and after reading reviews and author responses, and still had difficulty understanding the goals and outcomes of the experiments (such as what exactly is being reported as test accuracy and what is meant by: "High test accuracy means that assumptions are reasonable.").	rebuttal_process
2020-1756	We highly recommend that the authors revisit the description of the motivation and approach based on comments from reviewers; further explain what is reported as test accuracy in the experiments; and more clearly highlight the insights obtain from the experiments.	suggestion

2020-1761	The proposed algorithm is found to be a straightforward extension of the previous work, which is not sufficient to warrant publication in *CONF*2020.	decision

2020-1762	This paper received all negative reviewers, and the scores were kept after the rebuttal.	rating_summary
2020-1762	The authors are encouraged to submit their work to a computer vision conference where this kind of work may be more appreciated.	decision
2020-1762	Furthermore, including stronger baselines such as Acuna et al is recommended.	suggestion

2020-1764	The paper proposes a new way to learn a disentangled representation by embedding the latent representation z into an explicit learnt orthogonal basis M. While the paper proposes an interesting new approach to disentangling, the reviewers agreed that it would benefit from further work in order to be accepted.	abstract
2020-1764	In particular, after an extensive discussion it was still not clear whether the assumptions of Theorem 1 applied to VAEs, and whether Theorem 1 was necessary at all.	weakness
2020-1764	In terms of experimental results, the discussions revealed that the method used supervision during training, while the baselines in the paper are all unsupervised.	weakness
2020-1764	The authors are encouraged to add supervised baselines in the next iteration of the manuscript.	suggestion
2020-1764	For these reasons I recommend rejection.	decision

2020-1773	This paper studies the effect of various data augmentation methods on image classification tasks.	abstract
2020-1773	The authors propose the structural similarity as a measure of the magnitude of the various types of data augmentation noise they consider and argue that it is outperforms PSNR as a measure of the intensity of the noise.	abstract
2020-1773	The authors performed an empirical analysis showing that speckle noise leads to improved CNN models on two subsets of ImageNet.	abstract
2020-1773	While there is merit in thoroughly analysing data augmentation schemes for training CNNs, the reviewers argued that the main claims of the work were not substantiated and the raised issues were not addressed in the rebuttal.	rebuttal_process
2020-1773	I will hence recommend rejection of this paper.	decision

2020-1774	This paper proposes a CNN that is invariant to input transformation, by making two modifications on top of the TI-pooling architecture: the input-dependent convolutional filters, and a decoder network to ensure fully transformation invariant.	abstract
2020-1774	Reviewer #1 concerns the limited novelty, unconvincing experimental results.	weakness
2020-1774	Reviewer #2 praises the paper being well written, but is not convinced by the significance of the contributions.	weakness
2020-1774	The authors respond to Reviewer #2 but did not change the rating.	rebuttal_process
2020-1774	Reviewer #3 especially concerns that the paper is not well positioned with respect to the related prior work.	weakness
2020-1774	Given these concerns and overall negative rating (two weak reject and one reject), the AC recommends reject.	decision

2020-1776	This paper proposes and evaluates using graph convolutional networks for semi-supervised learning of probability distributions (histograms).	abstract
2020-1776	The paper was reviewed by three experts, all of whom gave a Weak Reject rating.	rating_summary
2020-1776	The reviewers acknowledged the strengths of the paper, but also had several important concerns including quality of writing and significance of the contribution, in addition to several more specific technical questions.	weakness
2020-1776	The authors submitted a response that addressed these concerns to some extent.	rebuttal_process
2020-1776	However, in post-rebuttal discussions, the reviewers chose not to change their ratings, feeling that quality of writing still needed to be improved and that overall a significant revision and another round of peer review would be needed.	rebuttal_process
2020-1776	In light of these reviews, we are not able to recommend accepting the paper, but hope the authors will find the suggestions of the reviewers helpful in preparing a revision for another venue.	decision

2020-1778	This paper proposes an automatic tuning procedure for the learning rate of SGD.	abstract
2020-1778	Reviewers were in agreement over several of the shortcomings of the paper, in particular its heuristic nature.	weakness
2020-1778	They also took the time to provide several ways of improving the work which I suggest the authors follow should they decide to resubmit it to a later conference.	decision

2020-1780	This paper combines PEARL with HAC to create a hierarchical meta-RL algorithm that operates on goals at the high level and learns low-level policies to reach those goals.	abstract
2020-1780	Reviewers remarked that it's well-presented and well-organized, with enough details to be mostly reproducible.	strength
2020-1780	In the experiments conducted, it appears to show strong results. <sep>	strength
2020-1780	However there was strong consensus on two major weaknesses that render this paper unpublishable in its current form: 1) the continuous control tasks used don't seem to require hierarchy, and 2) the baselines don't appear to be appropriate.	weakness
2020-1780	Reviewers remarked that a vital missing baseline is HER, and that it's unfair to compare to PEARL, which is a more general meta-RL algorithm.	weakness
2020-1780	The authors don't appear to have made revisions in response to these concerns. <sep>	rebuttal_process
2020-1780	All reviewers made useful and constructive comments, and I urge the authors to take them into consideration when revising for a future submission.	suggestion

2020-1783	In this paper, the authors draw upon online convex optimization in order to derive a different interpretation of Adam-Type algorithms, allowing them to identify the functionality of each part of Adam.	abstract
2020-1783	Based on these  observations, the authors derive a new Adam-Type algorithm,  AdamAL and test it in 2 computer vision datasets using 3 CNN architectures.	abstract
2020-1783	The main concern shared by all reviewers is the lack of novelty but also rigor both on the experimental and theoretical justification provided by the authors.	weakness
2020-1783	After having read carefully the reviews and main points of the paper, I will side with the reviewers, thus not recommending acceptance of this paper.	decision

2020-1784	This paper proposes an extension of Gradient Episodic Memory (GEM) namely support examples, soft gradient constraints, and positive backward transfer.	abstract
2020-1784	The authors argue that experiments on MNIST and CIFAR show that the proposed method consistently improves over the original GEM. <sep>	abstract
2020-1784	All three reviewers are not convinced with experiments in the paper.	weakness
2020-1784	R1 and R3 mentioned that the improvements over GEM appear to be small.	weakness
2020-1784	R2 and R3 also have some concerns without results with multiple runs.	weakness
2020-1784	R3 has questions about hyperparameter tuning.	weakness
2020-1784	The authors also appears to be missing recent developments in this area (eg, A-GEM).	weakness
2020-1784	The authors did not provide a rebuttal to these concerns. <sep>	rebuttal_process
2020-1784	I agree with the reviewers and recommend rejecting this paper.	decision

2020-1793	This paper proposes a semi-supervised method for reconstructing 3D faces from images via a disentangled representation.	abstract
2020-1793	The method builds on previous work by Tran et al (2018, 2019).	abstract
2020-1793	While some results presented in the paper show that this method works well, all reviewers agree that the authors should have provided more experimental evidence to convincingly demonstrate the benefits of their method.	weakness
2020-1793	The reviewers are also unconvinced by how computationally expensive this method is or by the contributions of the unlabelled data to the performance of the proposed model.	weakness
2020-1793	Given that the authors did not address the reviewers' concerns, and for the reasons stated above, I recommend rejecting this paper.	decision

2020-1794	The authors propose a learning framework to reframe non-stationary MDPs as smaller stationary MDPs, thus hopefully addressing problems with contradictory or continually changing environments.	abstract
2020-1794	A policy is learned for each sub-MDP, and the authors present theoretical guarantees that the reframing does not inhibit agent performance. <sep>	abstract
2020-1794	The reviewers discussed the paper and the authors' rebuttal.	rebuttal_process
2020-1794	They were mainly concerned that the submission offered no practical implementation or demonstration of feasibility, and secondarily concerned that the paper was unclearly written and motivated.	weakness
2020-1794	The authors' rebuttal did not resolve these issues. <sep>	rebuttal_process
2020-1794	My recommendation is to reject the submission and encourage the authors to develop an empirical validation of their method before resubmitting.	decision

2020-1798	This paper examines the interplay between the related ideas of invariance and robustness in deep neural network models.	abstract
2020-1798	Invariance is the notion that small perturbations to an input image (such as rotations or translations) should not change the classification of that image.	abstract
2020-1798	Robustness is usually taken to be the idea that small perturbations to input images (eg noise, whether white or adversarial) should not significantly affect the model's performance.	abstract
2020-1798	In the context of this paper, robustness is mostly considered in terms of adversarial perturbations that are imperceptible to humans and created to intentionally disrupt a model's accuracy.	abstract
2020-1798	The results of this investigation suggests that these ideas are mostly unrelated: equivariant models (with architectures designed to encourage the learning of invariances) that are trained with data augmentation whereby input images are given random rotations do not seem to offer any additional adversarial robustness, and similarly using adversarial training to combat adversarial noise does not seem to confer any additional help for learning rotational invariance.	abstract
2020-1798	(In some cases, these types of training on the one hand seem to make invariance to the other type of perturbations even worse.) <sep>	abstract
2020-1798	Unfortunately, the reviewers do not believe the technical results are of sufficient interest to warrant publication at this time.	rating_summary

2020-1802	The paper presents a method for increasing the "model compatibility" of Generative Adversarial Networks by adding a term to the loss function relating to classification boundaries.	abstract
2020-1802	The reviewers recognized the importance of the problem, but several concerns were raised about the clarity of the paper, as well as the significance of the experimental results.	weakness

2020-1803	Thanks for your detailed responses to the reviewers, which helped us a lot to better understand your paper. <sep>	misc
2020-1803	However, given that the current manuscript still contains many unclear parts, we decided not to accept the paper.	decision
2020-1803	We hope that the reviewers' comments help you improve your paper for potential future submission.	misc

2020-1808	The paper proposes a mechanism for obtaining diverse policies for solving a task by posing it as a multi-agent problem, and incentivizing the agents to be different from each other via maximizing total variation. <sep>	abstract
2020-1808	The reviewers agreed that this is an interesting idea, but had issues with the placement and exact motivations -- precisely what kind of diversity is the work after, why, and what accordingly related approaches does it need to be compared to. <sep>	weakness
2020-1808	Some reviewers also found the technical and exposition clarity to be lacking. <sep>	weakness
2020-1808	Given the consensus, I recommend rejection at this time, but encourage the authors to take the reviewers' feedback into account and resubmit to another venue.	decision

2020-1809	This paper proposes an application of capsule networks to code modeling. <sep>	abstract
2020-1809	I see the potential in this approach, but as the reviewers pointed out, in the current draft there are significant issues with respect to both clarity of motivating the work, and in the empirical results (which start at a much lower baseline than previous work).	weakness
2020-1809	I am not recommending acceptance at this time, but would encourage the reviewers to clarify the issues raised in the reviews for future submission.	decision

2020-1812	This paper proposes a method for semi-supervised semantic segmentation through consistency (with respect to various perturbations) regularization.	abstract
2020-1812	While the reviewers believe that this paper contains interesting ideas and that it has been substantially improved from its original form, it is not yet ready for acceptance to *CONF*-2020.	decision
2020-1812	With a little bit of polish, this paper is likely to be accepted at another venue.	misc

2020-1814	The reviewers have reached consensus that while the paper is interesting, it could use more time.	weakness
2020-1814	We urge the authors to continue their investigations.	suggestion

2020-1816	The paper examines the idea that real world data is highly structured / lies on a low-dimensional manifold.	abstract
2020-1816	The authors show differences in neural network dynamics when trained on structured (MNIST) vs. unstructured datasets (random), and show that "structure" can be captured by their new "hidden manifold" generative model that explicitly considers some low-dimensional manifold. <sep>	abstract
2020-1816	The reviewers perceived a lack of actionable insights following the paper, since in general these ideas are known, and for MNIST to be a limited dataset, despite finding the paper generally clear and correct. <sep>	weakness
2020-1816	Following the discussion, I must recommend rejection at this time, but highly encourage the authors to take the insights developed in the paper a bit further and submit to another venue.	decision
2020-1816	eg trying to improve our algorithms by considering the inductive bias of structure of the hidden manifold, or developing a systematic and quantifiable notion of structure for many different datasets that correlate with difficulty of training would both be great contributions.	suggestion

2020-1818	The paper proposes a variant of the max-sliced Wasserstein distance, where instead of sorting, a greedy assignment is performed.	abstract
2020-1818	As no theory is provided, the paper is purely of experimental nature. <sep>	weakness
2020-1818	Unfortunately the work is too preliminary to warrant publication at this time, and would need further experimental or theoretical strengthening to be of general interest to the *CONF* community.	decision

2020-1820	The authors propose a framework for estimating "global robustness" of a neural network, defined as the expected value of "local robustness" (robustness to small perturbations) over the data distribution.	abstract
2020-1820	The authors prove the the local robustness metric is measurable and that under this condition, derive a statistically efficient estimator.	abstract
2020-1820	The authors use gradient based attacks to approximate local robustness in practice and report extensive experimental results across several datasets. <sep>	abstract
2020-1820	While the paper does make some interesting contributions, the reviewers were concerned about the following issues: <sep> 1) The measurability result, while technically important, is not surprising and does not add much insight algorithmically or statistically into the problem at hand.	weakness
2020-1820	Outside of this, the paper does not make any significant technical contributions. <sep>	weakness
2020-1820	2) The paper is poorly organized and does not clearly articulate the main contributions and significance of these relative to prior work. <sep>	weakness
2020-1820	3) The fact that the local robustness metric is approximated via gradient based attacks makes the final results void of any guarantees, since there are no guarantees that gradient based attacks compute the worst case adversarial perturbation.	weakness
2020-1820	This calls into question the main contribution claim of the paper on computing global robustness guarantees. <sep>	weakness
2020-1820	While some of the technical aspects of the reveiwers' concerns were clarified during the discussion phase, this was not sufficient to address the fundamental issues raised above. <sep>	rebuttal_process
2020-1820	Hence, I recommend rejection.	decision

2020-1824	This paper proposes a graphon-based search space for neural architecture search.	abstract
2020-1824	Unfortunately, the paper as currently stands and the small effect sizes in the experimental results raise questions about the merits of actually employing such a search space for the specific task of NAS.	weakness
2020-1824	The reviewers expressed concerns that the results do not convincingly support graphon being a superior search space as claimed in the paper.	weakness

2020-1830	This paper offers a novel method for semi-supervised learning using GMMs.	abstract
2020-1830	Unfortunately the novelty of the contribution is unclear, and the majority of the reviewers find the paper is not acceptable in present form.	rating_summary
2020-1830	The AC concurs.	decision

2020-1839	This paper develops ideas for enabling the data generation with GANs in the presence of structured constraints on the data manifold.	abstract
2020-1839	This problem is interesting and quite relevant to the *CONF* community.	strength
2020-1839	The reviewers raised concerns about the similarity to prior work (Xu et al '17), and missing comparisons to previous approaches that study this problem (eg Hu et al '18) that make it difficult to judge the significance of the work.	weakness
2020-1839	Overall, the paper is slightly below the bar for acceptance.	decision

2020-1841	This paper tackles the problem of detection out-of-distribution (OoD) samples.	abstract
2020-1841	The proposed solution is based on a Bayesian variational autoencoder.	abstract
2020-1841	The authors show that information-theoretic measures applied on the posterior distribution over the decoder parameters can be used to detect OoD samples.	abstract
2020-1841	The resulting approach is shown to outperform baselines in experiments conducted on three benchmarks (CIFAR-10 vs SVNH and two based on FashionMNIST). <sep>	abstract
2020-1841	Following the rebuttal, major concerns remained regarding the justification of the approach.	rebuttal_process
2020-1841	The reason why relying on active learning principles should allow for OoD detection would need to be clarified, and the use of the effective sample size (ESS) would require a stronger motivation.	rebuttal_process
2020-1841	Overall, although a theoretically-informed OoD strategy is indeed interesting and relevant, reviewers were not convinced by the provided theoretical justifications.	weakness
2020-1841	I therefore recommend to reject this paper.	decision

2020-1842	This paper presents two new architectures that model latent intermediate utilities and use non-additive utility aggregation to estimate the set utility based on the computed latent utilities.	abstract
2020-1842	These two extensions are easy to understand and seem like a simple extension to the existing RNN model architectures, so that they can be implemented easily.	strength
2020-1842	However, the connection to Choquet integral is not clear and no theory has been provided to make that connection.	weakness
2020-1842	Hence, it is hard for the reader to understand why the integral is useful here.	weakness
2020-1842	The reviewers have also raised objection about the evaluation which does not seem to be fair to existing methods.	weakness
2020-1842	These comments can be incorporated to make the paper more accessible and the results more appreciable.	suggestion

2020-1843	This paper claims to present a model-agnostic continual learning framework which uses a queue to work with delayed feedback.	abstract
2020-1843	All reviewers agree that the paper is difficult to follow.	weakness
2020-1843	I also have a difficult time reading the paper. <sep>	weakness
2020-1843	In addition, all reviewers mentioned there is no baseline in the experiments, which makes it difficult to empirically analyze the strengths and weaknesses of the proposed model.	weakness
2020-1843	R2 and R3 also have some concerns regarding the motivation and claim made in the paper, especially in relation to previous work in this area. <sep>	weakness
2020-1843	The authors did not respond to any of the concerns raised by the reviewers.	rebuttal_process
2020-1843	It is very clear that the paper is not ready for publication at a venue such as *CONF* at the current state, so I recommend rejecting the paper.	decision

2020-1845	The paper takes the perspective of "reinforcement learning as inference", extends it to the multi-agent setting and derives a multi-agent RL algorithm that extends Soft Actor Critic.	abstract
2020-1845	Several reviewer questions were addressed in the rebuttal phase, including key design choices.	rebuttal_process
2020-1845	A common concern was the limited empirical comparison, including comparisons to existing approaches.	weakness

2020-1847	This paper addresses the extension of path-space-based SGD (which has some previously-acknowledged advantages over traditional weight-space SGD) to handle batch normalization.	abstract
2020-1847	Given the success of BN in traditional settings, this is a reasonable scenario to consider.	abstract
2020-1847	The analysis and algorithm development involved exploits a reparameterization process to transition from the weight space to the path space.	abstract
2020-1847	Empirical tests are then conducted on CIFAR and ImageNet. <sep>	abstract
2020-1847	Overall, there was a consensus among reviewers to reject this paper, and the AC did not find sufficient justification to overrule this consensus.	rating_summary
2020-1847	Note that some of the negative feedback was likely due, at least in part, to unclear aspects of the paper, an issue either explicitly stated or implied by all reviewers.	weakness
2020-1847	While obviously some revisions were made, at this point it seems that a new round of review is required to reevaluate the contribution and ensure that it is properly appreciated.	misc

2020-1853	The paper proposed a parameterized convolution layer using predefined filterbanks.	abstract
2020-1853	It has the benefit of less parameters to optimize and better interpretability.	abstract
2020-1853	The original submission failed to inlcude many related work into the discussion which was addressed during the rebutal. <sep>	rebuttal_process
2020-1853	The main concerns for this paper is the limited novelty and insufficient experimental validation and comprisons: <sep>	weakness
2020-1853	* There have been existing work using sinc parameterized filters, learnable Gammatones etc, which are very similar to the proposed method.	weakness
2020-1853	Also in the rebutal, the authors acknowledged that "We did not claim that cosine modulation was the novelty in our paper" and it is "just a way of simplifying implementation and dealing with real values instead of complex ones" and "addressing the question of convergence of parametric filter banks to perceptual scale". <sep>	rebuttal_process
2020-1853	* Although the authors addressed the missing related work problem by including them into discussions, the expeirmental sections need more work to include comparisons to those methods and also more validations on difference datasets to address the concern on the generalization of the proposed method.	rebuttal_process

2020-1857	This paper presents an ensemble method for reinforcement learning.	abstract
2020-1857	The method trains an ensemble of transition and reward models.	abstract
2020-1857	Each element of this ensemble has a different view of the data (for example, ablated observation pixels) and a different latent space for its models.	abstract
2020-1857	A single (collective) policy is then trained, by learning from trajectories generated from each of the models in the ensemble.	abstract
2020-1857	The collective policy makes direct use of the latent spaces and models in the ensemble by means of a translator that maps one latent space into all the other latent spaces, and an aggregator that combines all the model outputs.	abstract
2020-1857	The method is evaluated on the CarRacing and VizDoom environments. <sep>	abstract
2020-1857	The reviewers raised several concerns about the paper.	misc
2020-1857	The evaluations were not convincing with artificially weak baselines and only worked well in one of the two tested environments (reviewer 2).	weakness
2020-1857	The paper does not adequately connect to related work on model-based RL (reviewer 1 and 2).	weakness
2020-1857	The paper does not motivate its artificial setting (reviewer 2 and 1).	weakness
2020-1857	The paper's presentation lacks clarity from using non-standard terminology and notation without adequate explanation (reviewer 1 and 3).	weakness
2020-1857	Technical aspects of the translator component were also unclear to multiple reviewers (reviewers 1, 2 and 3).	weakness
2020-1857	The authors found the review comments to be helpful for future work, but provided no additional clarifications. <sep>	rebuttal_process
2020-1857	The paper is not ready for publication.	decision

2020-1864	The paper proposes a framework for generating evaluation tests for feature-based explainers.	abstract
2020-1864	The framework provides guarantees on the behaviors of each trained model in that non-selected tokens are irrelevant for each prediction,  and for each instance in the pruned dataset, one subset of clearly relevant tokens is selected. <sep>	abstract
2020-1864	After reading the paper, I think there are a few issues with the current version of the paper: <sep> (1) the writing can be significantly improved: the motivation is unclear, which makes it difficult for readers to fully appreciate the work.	weakness
2020-1864	It seems that each part of the paper is written by different persons, so the transition between different parts seems abrupt and the consistency of the texts is poor.	weakness
2020-1864	For example, the framework is targeted at NLP applications, but in the introduction the texts are more focused on general purpose explainers.	weakness
2020-1864	The transition from the RCNN approach to the proposed framework is not well thought-out, which makes the readers confused about what exactly is the proposed framework and what is the novelty. <sep>	weakness
2020-1864	(2) the claimed properties of the proposed framework are rather straightforward derivations.	weakness
2020-1864	The technical novelty is not as high as claimed in the paper. <sep>	weakness
2020-1864	(3) The experiment results are not fully convincing. <sep>	weakness
2020-1864	All the reviewers have read the authors' feedback and responded.	rebuttal_process
2020-1864	It is agreed that the current version of the paper is not ready for publication.	decision

2020-1866	The paper is about exploration in deep reinforcement learning.	abstract
2020-1866	The reviewers agree that this is an interesting and important topic, but the authors provide only a slim analysis and theoretical support for the proposed methods.	weakness
2020-1866	Furthermore, the authors are encouraged to evaluate the proposed method on more than a single benchmark problem.	suggestion

2020-1871	There is insufficient support to recommend accepting this paper.	decision
2020-1871	The reviewers unanimously criticize the quality of the exposition, noting that many key elements in the main development and experimental set up are not clear.	weakness
2020-1871	The significance of the contribution could be made stronger with some form of theoretical analysis.	weakness
2020-1871	The current paper lacks depth and insufficient justification for the proposed approach.	weakness
2020-1871	The submitted comments should be able to help the authors improve the paper.	misc

2020-1874	This paper studies the problem of federated learning for non-i.i.d.	abstract
2020-1874	data, and looks at the hyperparameter optimization in this setting.	abstract
2020-1874	As the reviewers have noted, this is a purely empirical paper.	weakness
2020-1874	There are certain aspects of the experiments that need further discussion, especially the learning rate selection for different architectures.	weakness
2020-1874	That said, the submission may not be ready for publication at its current stage.	decision

2020-1877	This submission investigates the properties of the Jacobian matrix in deep learning setup.	abstract
2020-1877	Specifically, it splits the spectrum of the matrix into information (large singulars) and ``nuisance (small singulars) spaces.	abstract
2020-1877	The paper shows that over the information space learning is fast and achieves zero loss.	abstract
2020-1877	It also shows that generalization relates to how well labels are aligned with the information space. <sep>	abstract
2020-1877	While the submission certainly has encouraging analysis/results, reviewers find these contributions limited and it is not clear how some of the claims in the paper can be extended to more general settings.	weakness
2020-1877	For example, while the authors claim that low-rank structure is suggested by theory, the support of this claim is limited to a case study on mixture of Gaussians.	weakness
2020-1877	In addition, the provided analysis only studies two-layer networks.	weakness
2020-1877	As elaborated by R4, extending these arguments to more than two layers does not seem straighforward using the tools used in the submission.	weakness
2020-1877	While all reviewers appreciated author's response, they were not convinced and maintained their original ratings.	rebuttal_process

2020-1891	This paper studies when hidden units provide local codes by analyzing the hidden units of trained fully connected classification networks under various architectures and regularizers.	abstract
2020-1891	The reviewers and the AC believe that the paper in its current form is not ready for acceptance to *CONF*-2020.	decision
2020-1891	Further work and experiments are needed in order to identify an explanation for the emergence of local codes.	suggestion
2020-1891	This would significantly strengthen the paper.	suggestion

2020-1892	This paper advocates for the application of entanglement entropy from quantum physics to understand and improve the inductive bias of neural network architectures for question answering tasks.	abstract
2020-1892	All reviewers found the current presentation of the method difficult to understand, and as a result it is difficult to determine what exactly the contribution of this work is.	weakness
2020-1892	One suggestion for improving the manuscript is to minimize the references to quantum entanglement (where currently is it asserted without justification that entanglement entropy is a relevant concept for modeling question-answering tasks).	suggestion
2020-1892	Instead, presenting the method as applications of tensor decompositions for parameterizing neural network architectures would make the work more accessible to a machine learning audience, and help clarify the contribution with respect to related works [1]. <sep>	suggestion
2020-1892	1. http://papers.nips.cc/paper/8495-a-tensorized-transformer-for-language-modeling.pdf	misc

2020-1893	The paper discusses the relevant topic of unsupervised meta-learning in an RL setting.	abstract
2020-1893	The topic is an interesting one, but the writing and motivation could be much clearer.	weakness
2020-1893	I advise the authors to make a few more iterations on the paper taking into account the reviewers' comments and then resubmit to a different venue.	decision

2020-1897	The paper provides a nice approach to optimizing marginals to improve exploration for RL agents.	abstract
2020-1897	The reviewers agree that its improvements wrt the state of the art do not merit a publication at *CONF*.	rating_summary
2020-1897	Furthermore, additional experimentation is needed for the paper to be complete.	weakness

2020-1901	The paper propose to analyze bitcoin addresses using graph embeddings.	abstract
2020-1901	The reviewers found that the paper was too incomplete for publication.	rating_summary
2020-1901	Important information such as a description of datasets and metrics was omitted.	weakness

2020-1902	The paper presents a generative approach to learn an image representation along a self-supervised scheme. <sep>	abstract
2020-1902	The reviews state that the paper is premature for publication at *CONF* 2020 for the following reasons: <sep>	rating_summary
2020-1902	* the paper is unfinished (Rev#3); in particular the description of the approach is hardly reproducible (Rev#1); <sep>	weakness
2020-1902	* the evaluation is limited to ImageNet and needs be strenghtened (all reviewers) <sep>	weakness
2020-1902	* the novelty needs be better explained (Rev#1). <sep>	weakness
2020-1902	It might be interesting to discuss the approach wrt "Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles", Noroozi and Favaro. <sep>	suggestion
2020-1902	I recommend the authors to rewrite and better structure the paper (claim, state of the art, high level overview of the approach, experimental setting, discussion of the results, discussion about the novelty and limitations of the approach).	suggestion

2020-1903	This paper studies the problem of out-of-distribution (OOD) detection for semantic segmentation. <sep>	abstract
2020-1903	Reviewers and AC agree that the problem might be important and interesting, but the paper is not ready to publish in various aspects, eg,  incremental contribution and less-motivated/convincing experimental setups/results. <sep>	decision
2020-1903	Hence, I recommend rejection.	decision

2020-1904	Thanks for clarifying several issues raised by the reviewers, which helped us understand the paper. <sep>	misc
2020-1904	After all, we decided not to accept this paper due to the weakness of its contribution.	decision
2020-1904	I hope the updated comments by the reviewers help you strengthen your paper for potential future submission.	misc

2020-1906	This paper provides a new theoretical framework for domain adaptation by exploring the compression and adaptability. <sep>	abstract
2020-1906	Reviewers and AC generally agree that this paper discusses about an important problem and provides new insight, but it is not a thorough theoretical work.	weakness
2020-1906	The reviewers identified several key limitations of the theory such as unrealistic condition and approximation.	weakness
2020-1906	Some important points still require more work to make the framework practical for algorithm design and computation.	weakness
2020-1906	The presentation could also be improved. <sep>	weakness
2020-1906	Hence I recommend rejection.	decision

2020-1911	This paper proposes to train and compose neural networks for the purposes of arithmetic operations.	abstract
2020-1911	All reviewers agree that the motivation for such a work is unclear, and the general presentation in the paper can be significantly improved.	weakness
2020-1911	As such, I cannot recommend this paper in its current state for publication.	decision

2020-1913	This paper discusses the (lack of) correlation between the image semantics and the likelihood assigned by flow-based models, and implications for out-of-distribution (OOD) detection. <sep>	abstract
2020-1913	The reviewers raised several important questions: <sep> 1) precise definition of OOD: definition of semantics vs typicality (cf.	weakness
2020-1913	definition in Nalisnick et al 2019 pointed by R1) <sep>	weakness
2020-1913	There was a nice discussion between authors and the reviewers.	rebuttal_process
2020-1913	At a high level, there was some agreement in the end, but lack of precise definition may cause confusion.	weakness
2020-1913	I think adding a precise definition will add more clarity and improve the paper. <sep>	suggestion
2020-1913	2) novelty: similar observations have been made in earlier papers cf.	weakness
2020-1913	Nalisnick et al 2018.	weakness
2020-1913	R3 also pointed a recent paper by Ren et al 2019 which showed that likelihood can be dominated by background pixels.	weakness
2020-1913	Older work has shown that the likelihood and sample quality are not necessarily correlated.	weakness
2020-1913	The reviewers appreciate that this paper provides additional evidence, but weren't convinced that the new observations in this paper qualified for a full paper. <sep>	weakness
2020-1913	3) experiments on more datasets <sep>	weakness
2020-1913	Overall, while this paper explores an interesting direction, it's not ready for publication as is.	decision
2020-1913	I encourage the authors to revise the paper based on the feedback and submit to a different venue.	decision

2020-1914	While the reviewers generally appreciated the ideas presented in the paper and found the overall aims and motivation of the paper to be compelling, there were too many questions raised about the experiments and the soundness of the technical formulation to accept the paper at this time, and the reviewers did not feel that the authors had adequately addressed these issues in their responses.	decision
2020-1914	The main concerns were (1) with the correctness and rigor of the technical derivation, which the reviewers generally found to be somewhat questionable -- while the main idea seems reasonable, the details have a few too many question marks; (2) the experimental results have a number of shortcomings that make it difficult to fully understand whether the method really works, and how well.	weakness

2020-1915	The paper proposes a method to learn cross-lingual representations by aligning monolingual models with the help of a parallel corpus using a three-step process: transform, extract, and reorder.	abstract
2020-1915	Experiments on XNLI show that the proposed method is able to perform zero-shot cross-lingual transfer, although its overall performance is still below state-of-the-art jointly trained method XLM. <sep>	abstract
2020-1915	All three reviewers suggested that the proposed method needs to be evaluated more thoroughly (more datasets and languages).	weakness
2020-1915	R2 and R4 raise some concerns around the complexity of the proposed method (possibly could be simplified further).	weakness
2020-1915	R3 suggests a more thorough investigation on why the model saturates at 250,000 parallel sentences, among others. <sep>	suggestion
2020-1915	The authors acknowledged reviewers' concerns in their response and will incorporate them in future work. <sep>	rebuttal_process
2020-1915	I recommend rejecting this paper for *CONF*.	decision

2020-1917	This provides a new method, called DPAutoGAN, for the problem of differentially private synthetic generation.	abstract
2020-1917	The method uses private auto-encoder to reduce the dimension of the data, and apply private GAN on the latent space.	abstract
2020-1917	The reviewers think that there is not sufficient justification for why this is a good approach for synthetic generation.	weakness
2020-1917	They also think that the presentation is not ready for publication.	rating_summary

2020-1919	The paper proposes an interesting setting in which the effect of different optimization parameters on the loss function is analyzed.	abstract
2020-1919	The analysis is based on considering cross-entropy loss with different softmax parameters, or hinge loss with different margin parameters.	abstract
2020-1919	The observations are interesting but ultimately the reviewers felt that the experimental results were not sufficient to warrant publication at *CONF*.	rating_summary
2020-1919	The reviews unanimously recommended rejection, and no rebuttal was provided.	rating_summary

2020-1921	This paper investigates the properties of deep neural networks as they learn, and how they may relate to human visual learning (eg how learning develops across regions of the infant brain).	abstract
2020-1921	The paper received three reviews, all of which recommended Weak Reject.	rating_summary
2020-1921	The reviewers generally felt the topic of the paper was very interesting, but overall felt that the insights that the paper revealed were relatively modest, and had concerns about the connections between DNN and human learning (eg, the extent to which DNNs are biologically plausible -- including back propagation, batch normalization, random initialization, etc.	weakness
2020-1921	-- and whether this matters for the conclusions of the present study).	weakness
2020-1921	In response to comments, the authors undertook a significant revision to try to address these points of confusion.	rebuttal_process
2020-1921	However, the reviewers were still skeptical and chose to keep their Weak Reject scores. <sep>	rebuttal_process
2020-1921	The AC agrees with reviewers that investigations of the similarity -- or not!	strength
2020-1921	-- between infant and deep neural networks is extremely interesting and, as the authors acknowledge, is a high risk but potentially very high reward research direction.	strength
2020-1921	However, in light of the reviews with unanimous Weak Reject decisions, the AC is not able to recommend acceptance at this time.	decision
2020-1921	I strongly encourage authors to continue this work and submit to another venue; this would seem to be a perfect match for CogSci conference, for example.	suggestion
2020-1921	We hope the reviews below help authors to improve their manuscript for this next submission.	misc

2020-1923	This paper argues that incorporating unsupervised/semi-supervised learning into the training process can dramatically increase the performance of models.	abstract
2020-1923	In particular, its incorporation can result in performance gains that dwarf the gains obtained by collecting data actively alone.	abstract
2020-1923	The experiments effectively demonstrate this phenomenon. <sep>	abstract
2020-1923	The paper is written with a tone that implicitly assumes that "active learning for deep learning is effective" and therefore it is a surprise and a challenge to the status quo that using unlabelled data in intelligent ways alone gets such a boost.	weakness
2020-1923	On the contrary, reviewers found that active learning not working very well for deep learning is a well-known state of affairs.	weakness
2020-1923	This is not surprising because the most effective theoretically justifiable active learning algorithms rely on finite capacity assumptions about the model class, which deep learning disobeys. <sep>	weakness
2020-1923	Thus, the reviewers found the conclusions to lack novelty as the power of semi-supervised and unsupervised learning is well known.	weakness
2020-1923	Reject.	decision

2020-1925	This submission proposes an interesting experiment/modification of CNNs.	abstract
2020-1925	However, it looks like this contribution overlaps significantly with prior work (that the authors initially missed) and the comparison in the (revised) manuscript seem to not clearly delineate and acknowledge the similarities and differences. <sep>	weakness
2020-1925	I suggest the authors improve this aspect and try submitting this work to next venue.	decision

2020-1926	The paper explores the use of RL (actor-critic) for planning the expansion of a metro subway network in a City.	abstract
2020-1926	The reviewers felt that novelty was limited and there was not enough motivation on what is special about this application, and what lessons can be learned from this exercise.	weakness

2020-1927	The paper has major presentation issues.	weakness
2020-1927	The rebuttal clarified some technical ones, but it is clear that the authors need to improve the reading substantially, ,so the paper is not acceptable in its current form.	decision

2020-1934	This paper tackles the problem of safe exploration in RL.	abstract
2020-1934	The proposed approach uses an imaginative module to construct a connectivity graph between all states using forward predictions.	abstract
2020-1934	The idea then consists in using this graph to plan a trajectory which avoids states labelled as "unsafe". <sep>	abstract
2020-1934	Several concerns were raised and the authors did not provide any rebuttal.	rebuttal_process
2020-1934	A major point is that the assumption that the approach has access to what are unsafe states, which is either unreasonable in practice or makes the problem much simpler.	weakness
2020-1934	Another major point is the uniform data collection about every state-action pairs.	weakness
2020-1934	This can be really unsafe and defeats the purpose of safe exploration following this phase.	weakness
2020-1934	These questions may be due to a miscomprehension, indicating that the paper should be clarified, as demanded by reviewers.	weakness
2020-1934	Finally, the experiments would benefit from additional details in order to be correctly understood. <sep>	weakness
2020-1934	All reviewers agree that this paper should be rejected.	rating_summary
2020-1934	Hence, I recommend reject.	decision

2020-1942	The paper predicts properties of quantum states through RNNs.	abstract
2020-1942	The idea is nice, but the results are very limited and require more work.	weakness
2020-1942	It seems to be more suited for a conference focussing on quantum ML---even when the authors have an ML background. <sep>	weakness
2020-1942	All reviewers agree on a rejection, and their arguments are solid.	rating_summary
2020-1942	The authors offered no rebuttal.	rebuttal_process

2020-1945	This paper proposes a regularization scheme for reducing meta-overfitting.	abstract
2020-1945	After the rebuttal period, the reviewers all still had concerns about the significance of the paper's contributions and the thoroughness of the empirical study.	rebuttal_process
2020-1945	As such, this paper isn't ready for publication at *CONF*.	decision
2020-1945	See the reviewer's comments for detailed feedback on how to improve the paper.	suggestion

2020-1946	The reviewers were not convinced about the significance of this work.	weakness
2020-1946	There is no empirical or theoretical result justifying why this method has advantages over the existing methods.	weakness
2020-1946	The reviewers also raised concerns related to the scalability of the proposal.	weakness
2020-1946	Since none of the reviewers were enthusiastic about the paper, including the expert ones, I cannot recommend acceptance of this work.	decision

2020-1947	The two main concerns raised by reviewers is that whether the results are significant, and a potential issue in the proof.	weakness
2020-1947	While the rebuttal clarified some steps in the proof, the main concerns about the significance remain.	rebuttal_process
2020-1947	The authors are encouraged to make this significance more clear. <sep>	rebuttal_process
2020-1947	Note that one reviewer argued theoretical papers are not suitable for *CONF*.	weakness
2020-1947	This is false, as a theoretical understanding of neural networks remains a key research area that is of wide interest to the community.	ac_disagreement
2020-1947	Consequently, this review was not considered in the final evaluation.	ac_disagreement

2020-1957	This paper proposes using first order logic to rule out superficial information for improved natural language inference.	abstract
2020-1957	While the topic is of interest, reviewers find that the paper misses much of the previous literature on semantics which is highly relevant. <sep>	weakness
2020-1957	I thank the authors for submitting this paper to *CONF*.	misc
2020-1957	Please take the reviewers' comments, especially recommended references, to improve the paper for future submission.	suggestion

2020-1959	The paper proposes a method to speed up training of deep nets by re-weighting samples based on their distance to the decision boundary.	abstract
2020-1959	However, they paper seems hastily written and the method is not backed by sufficient experimental evidence.	weakness

2020-1961	This paper proposed to use Gumbel softmax to optimize the routing matrix in routing network for multitask learning.	abstract
2020-1961	All reviewers have a consensus on rejecting this paper.	rating_summary
2020-1961	The paper did not clearly explain how and why this method works, and the experiments are not sufficient.	weakness

2020-1969	The authors present a combination of few-shot learning with one-class classification model of problems.	abstract
2020-1969	The authors use the existing MAML algorithm and build upon it to present a learning algorithm for the problem.	abstract
2020-1969	As pointed out by the reviewers, the technical contributions of the paper are quite minimal and after the author response period the reviewers have not changed their minds.	rebuttal_process
2020-1969	However, the authors have significantly changed the paper from its initial submission and as of now it needs to be reviewed again.	rebuttal_process
2020-1969	I recommend authors to resubmit their paper to another conference.	decision
2020-1969	As of now, I recommend rejection.	decision

2020-1971	The paper addresses  an important problem of self-supervised learning in the context of time-series classification.	abstract
2020-1971	However, all reviewers raised major concerns regarding the novelty of the approach and the quality of empirical evaluation, including insufficient comparison with the state-of-art and reproducibility issues.	weakness
2020-1971	The reviewers agree that the paper, in its current state, does not path the *CONF* acceptance threshold, and encourage the authors to improve the paper based on the provided suggestions.	rating_summary

2020-1973	Three reviewers recommend rejection.	rating_summary
2020-1973	After a good rebuttal, the first reviewer is more positive about the paper yet still feels the paper is not ready for publication.	rating_summary
2020-1973	The authors are encouraged to strengthen their work and resubmit to a future venue.	decision

2020-1974	While reviewers find this paper interesting, they raised number of concerns including the novelty, writing, experiments, references and clear mention of the benefit.	weakness
2020-1974	Unfortunately, excellent questions and insightful comments left by reviewers are gone without authors' answers.	rebuttal_process

2020-1979	The paper investigates the trainability and generalization of deep networks as a function of hyperparameters/architecture, while focusing on wide nets of large depth; it aims to characterize regions of hyperparameter space where networks generalize well vs where they do not; empirical observations are demonstrated to support theoretical results.	abstract
2020-1979	However, all reviewers agree that, while the topic of the paper is important and interesting, more work is required to improve the readability and clarify the exposition to support the proposed theoretical results.	weakness

2020-1994	Paper proposes a method for active learning on graphs.	abstract
2020-1994	Reviewers found the presentation of the method confusing and somewhat lacking novelty in light of existing works (some of which were not compared to).	weakness
2020-1994	After the rebuttal and revisions, reviewers minds were not changed from rejection.	rating_summary

2020-1997	The paper proposes to use transformers to do lossless data compression.	abstract
2020-1997	The idea is simple and straightforward (with adding n-gram inputs).	strength
2020-1997	The initial submission considered one dataset, a new dataset was added in the rebuttal.	rebuttal_process
2020-1997	Still, there is no runtime in the experiments (and Transformers can take a lot of time to train).	rebuttal_process
2020-1997	Since this is more an experimental paper, this is crucial (and the improvements reports are very small and it is difficult to judge if there are significant). <sep>	rebuttal_process
2020-1997	Overall, there was a positive discussion between the authors and the reviewers.	rebuttal_process
2020-1997	The reviewers commented that concerns have been addressed, but did not change the evaluation which is  unanimous reject.	rating_summary

2020-1998	The authors propose a novel algorithm for batch RL with offline data.	abstract
2020-1998	The method is simple and outperforms a recently proposed algorithm, BCQ, on Mujoco benchmark tasks. <sep>	abstract
2020-1998	The main points that have not been addressed after the author rebuttal are: <sep>	rebuttal_process
2020-1998	* Lack of rigor and incorrectness of theoretical statements.	weakness
2020-1998	Furthermore, there is little analysis of the method beyond the performance results. <sep>	weakness
2020-1998	* Non-standard assumptions/choices in the algorithm without justification (eg, concatenating episodes). <sep>	weakness
2020-1998	* Numerous sloppy statements / assumptions that are not justified. <sep>	weakness
2020-1998	* No comparison to BEAR, making it challenging to evaluate their state-of-the-art claims. <sep>	weakness
2020-1998	The reviewers also point out several limitations of the proposed method.	rebuttal_process
2020-1998	Adding a brief discussion of these limitations would strengthen the paper. <sep>	suggestion
2020-1998	The method is interesting and simple, so I believe that the paper has the potential to be a strong submission if the authors incorporate the reviewers suggestions in a future submission.	strength
2020-1998	However, at this time, the paper falls below the acceptance bar.	decision

2020-2001	This paper provides a method (loss function) for training GAN model for generation of discrete text token generation.	abstract
2020-2001	The aim of this loss method to control the trade off between quality vs diversity while generating the text data. <sep>	abstract
2020-2001	The paper is generally well written, but the experimental section is not overly good: Interpretation of the results is missing; error bars are missing.	weakness

2020-2008	This paper presents a multi-view generative model which is applied to multilingual text generation.	abstract
2020-2008	Although all reviewers find the overall approach is important and some results are interesting, the main concern is about the novelty.	weakness
2020-2008	At the technical level, the proposed method is the extension of the original two-view KERMIT to multiviews, which I have to say incremental.	weakness
2020-2008	At a higher level, multi-lingual language generation itself is not a very novel idea, and the contribution of the proposed method should be better positioned comparing to related studies.	weakness
2020-2008	(for example, Dong et al, ACL 2015 as suggested by R#3).	weakness
2020-2008	Also, some reviewers pointed out the problems in presentation and unconvincing experimental setup.	weakness
2020-2008	I support the reviewers' opinions and would like to recommend rejection this time. <sep>	decision
2020-2008	I recommend authors to take in the reviewers' comments and polish the work for the next chance.	suggestion

2020-2009	The idea of integrating causality into an auto-encoder is interesting and very timely.	strength
2020-2009	While the reviewers find this paper to contain some interesting ideas, the technical contributions and mathematical rigor, scope of the method, and the presentation of results would need to be significantly improved in order for this work to reach the quality bar of *CONF*.	weakness

2020-2010	This paper proposes a certified defense under the more general threat model beyond additive perturbation.	abstract
2020-2010	The proposed defense method is based on adding noise to the classifier's outputs to limit the attacker's knowledge about the parameters, which is similar to differential privacy mechanism.	abstract
2020-2010	The authors proved the query complexity for any attacker to generate a successful adversarial attack.	abstract
2020-2010	The main objection of this work is (1) the assumption of the attacker and the definition of the query complexity (to recover the optimal classifier rather than generating an adversarial example successfully) is uncommon, (2) the claim is misleading, and (3) the experimental evaluation is not sufficient (only two attacks are evaluated).	weakness
2020-2010	The authors only provided a brief response to address the reviewers' comments/questions without submitting a revision.	rebuttal_process
2020-2010	Unfortunately none of the reviewer is in support of this paper even after author response.	rating_summary

2020-2016	This paper proposes a differentiable version of CEM, allowing CEM to be used as an operator within end-to-end training settings.	abstract
2020-2016	The reviewers all like the idea -- it is simple and should be of interest to the community.	strength
2020-2016	Unfortunately, the reviewers also are in consensus that the experiments are not sufficiently convincing.	weakness
2020-2016	We encourage the authors to expand the empirical analysis, based on the reviewer's specific comments, and resubmit the paper to a future venue.	decision

2020-2017	As the reviewers point out, the core contribution might be potentially important but the current execution of the paper makes it difficult to gauge this importance.	weakness
2020-2017	In the light of this, this paper does not seem ready for appearance in a conference like *CONF*.	decision

2020-2018	The paper shows how meta-learning contains hidden incentives for distributional shift and how a technique called context swapping can help deal with this.	abstract
2020-2018	Overall, distributional shift is an important problem, but the contributions made by this paper to deal with this, such as the introduction of unit-tests and context-swapping, is not sufficiently clear.	weakness
2020-2018	Therefore, my recommendation is a reject.	decision

2020-2020	This manuscript studies scaling distributed stochastic gradient descent to a large number of nodes.	abstract
2020-2020	Specifically, it proposes to use algorithms based on population analysis (relevant for large numbers of distributed nodes) to implement distributed training of deep neural networks. <sep>	abstract
2020-2020	In reviews and discussions, the reviewers and AC note missing or inadequate comparisons to previous work on asynchronous SGD, and possible lack of novelty compared to previous work.	weakness
2020-2020	The reviewers also mentioned the incomplete empirical comparison to closely related work.	weakness
2020-2020	On the writing, reviewers mentioned that the conciseness of the manuscript could be improved.	weakness

2020-2023	This paper proposes to reduce the number of variational parameters for mean-field VI.	abstract
2020-2023	A low-rank approximation is used for this purpose.	abstract
2020-2023	Results on a few small problems are reported. <sep>	abstract
2020-2023	As R3 has pointed out, the main reason to reject this paper is the lack of comparison of uncertainty estimates.	rating_summary
2020-2023	I also agree that, recent Adam-like optimizers do use preconditioning that can be interpreted as variances, so it is not clear why reducing this will give better results. <sep>	weakness
2020-2023	I agree with R2's comments about missing the "point estimate" baseline.	weakness
2020-2023	Also the reason for rank 1,2,3 giving better accuracies is unclear and I think the reasons provided by the authors is speculative. <sep>	weakness
2020-2023	I do believe that reducing the parameterization is a reasonable idea and could be useful.	strength
2020-2023	But it is not clear if the proposal of this paper is the right one.	weakness
2020-2023	Due to this reason, I recommend to reject this paper.	decision
2020-2023	However, I highly encourage the authors to improve their paper taking these points into account.	suggestion

2020-2024	This paper proposes a graph neural network based approach for scaling up imitation learning (eg, of swarm behaviors).	abstract
2020-2024	Reviewers noted key limitations in the discussion of related work, size of the proposed contribution in terms of model novelty, and evaluation / comparison to strong baselines.	weakness
2020-2024	Reviewers appreciated the author replies which resolved some concerns but agree that the paper is overall not ready for publication.	rating_summary

2020-2025	This paper proposes to combine FMs and GNNs.	abstract
2020-2025	All reviewers voted reject, as the paper lacks experiments (eg ablation studies) and novelty.	rating_summary
2020-2025	Writing can be significant improved - some information is missing.	weakness
2020-2025	Authors did not respond to reviewers questions and concerns.	rebuttal_process
2020-2025	For this reason, I recommend reject.	decision

2020-2029	This paper studies spread divergence between distributions, which may exist in settings where the divergence between said distributions does not.	abstract
2020-2029	The reviewers feel this work does not have sufficient technical novelty to merit acceptance at this time.	rating_summary

2020-2030	This paper aims to estimate the parameters of a projectile physical equation from a small number of trajectory observations in two computer games.	abstract
2020-2030	The authors demonstrate that their method works, and that the learnt model generalises from one game to another.	abstract
2020-2030	However, the reviewers had concerns about the simplicity of the tasks, the longer term value of the proposed method to the research community, and the writing of the paper.	weakness
2020-2030	During the discussion period, the authors were able to address some of these questions, however many other points were left unanswered, and the authors did not modify the paper to reflect the reviewers' feedback.	rebuttal_process
2020-2030	Hence, in the current state this paper appears more suitable for a workshop rather than a conference, and I recommend rejection.	decision

2020-2037	Although the reviewers appreciated the novelty of this work, they unanimously recommended rejection.	rating_summary
2020-2037	The current version of the paper exhibits weak presentation quality and lacks sufficient technical depth.	weakness
2020-2037	The experimental evaluation was not found to be sufficiently convincing by any of the reviewers.	weakness
2020-2037	The submitted comments should help the authors improve their paper.	misc

2020-2044	This paper proposes to add constraints to the RL problem within a variational method.	abstract
2020-2044	The hope is to specify a safe vs non-safe states.	abstract
2020-2044	The reviewers were not convinced that this paper makes the cut for *CONF*.	rating_summary
2020-2044	Moreover, there was no rebuttal from the authors, so it didn't give the reviewer a chance to reconsider their opinion.	rebuttal_process
2020-2044	Based on the current ratings, I recommend to reject this paper.	decision

2020-2048	A method is introduced to estimate the hidden state in imperfect information in multiplayer games, in particular Bridge.	abstract
2020-2048	This is interesting, but the paper falls short in various ways.	weakness
2020-2048	Several reviewers complained about the readability of the paper, and also about the quality and presentation of the interesting results. <sep>	weakness
2020-2048	It seems that this paper represents an interesting idea, but is not yet ready for publication.	decision

2020-2050	This paper proposes a channel pruning approach based one-shot neural architecture search (NAS).	abstract
2020-2050	As agreed by all reviewers, it has limited novelty, and the method can be viewed as a straightforward combination of NAS and pruning.	weakness
2020-2050	Experimental results are not convincing.	weakness
2020-2050	The proposed method is not better than STOA on the accuracy or number of parameters.	weakness
2020-2050	The setup is not fair, as the proposed method uses autoaugment while the other baselines do not.	weakness
2020-2050	The authors should also compare with related methods such as Bayesnas, and other pruning techniques.	weakness
2020-2050	Finally, the paper is poorly written, and many related works are missing.	weakness

2020-2053	There is insufficient support to recommend accepting this paper.	decision
2020-2053	The authors provided detailed responses to the reviewer comments, but the reviewers did not raise their evaluation of the significance and novelty of the contributions as a result.	rebuttal_process
2020-2053	The feedback provided should help the authors improve their paper.	misc

2020-2059	This paper addresses the problem of rotation estimation in 2D images.	abstract
2020-2059	The method attempted to reduce the labeling need by learning in a semi-supervised fashion.	abstract
2020-2059	The approach learns a VAE where the latent code is be factored into the latent vector and the object rotation. <sep>	abstract
2020-2059	All reviewers agreed that this paper is not ready for acceptance.	rating_summary
2020-2059	The reviewers did express promise in the direction of this work.	strength
2020-2059	However, there were a few main concerns.	misc
2020-2059	First, the focus on 2D instead of 3D orientation.	weakness
2020-2059	The general consensus was that 3D would be more pertinent use case and that extension of the proposed approach from 2D to 3D is likely non-trivial.	weakness
2020-2059	The second issue is that minimal technical novelty.	weakness
2020-2059	The reviewers argue that the proposed solution is a combination of existing techniques to a new problem area. <sep>	weakness
2020-2059	Since the work does not have sufficient technical novelty to compare against other disentanglement works and is being applied to a less relevant experimental setting, the AC does not recommend acceptance.	decision

2020-2072	This paper proposes to overcome some fundamental limitations of normalizing flows by introducing auxiliary continuous latent variables.	abstract
2020-2072	While the problem this paper is trying to address is mathematically legitimate, there is no strong evidence that this is a relevant problem in practice.	weakness
2020-2072	Moreover, the proposed solution is not entirely novel, converting the flow in a latent-variable model.	weakness
2020-2072	Overall, I believe this paper will be of minor relevance to the *CONF* community.	decision

2020-2073	This paper proposes a smoothing-based certification against various forms of transformations, such as  rotations, translations.	abstract
2020-2073	The reviewers have concerns on the novelty of the work and several technical issues.	weakness
2020-2073	The authors have made efforts to address some of issues, but the work may still significantly benefit from a throughout improvement in both presentation and technical contribution.	rebuttal_process

2020-2075	While the reviewers generally appreciated the idea behind the method in the paper, there was considerable concern about the experimental evaluation, which did not provide a convincing demonstration that the method works in interesting and relevant problem settings, and did not compare adequately to alternative approach.	weakness
2020-2075	As such, I believe this paper is not quite ready for publication in its current form.	decision

2020-2087	The paper proposes two methods for interactive panoptic segmentation (a combination of semantic and instance segmentation) that leverages scribbles as supervision during inference.	abstract
2020-2087	Reviewers had concerns about the novelty of the paper as it applies existing algorithms for this task and limited empirical comparison with other methods.	weakness
2020-2087	Reviewers also suggested that *CONF* may not be a good fit for the paper and I encourage the authors to consider submitting to a vision oriented conference.	decision

2020-2090	The paper proposes a representation learning objective that makes it amenable to planning, <sep>	abstract
2020-2090	The initial submission contained clear holes, such as missing related work and only containing very simplistic baselines.	rebuttal_process
2020-2090	The authors have substantially updated the paper based on this feedback, resulting in a clear improvement. <sep>	rebuttal_process
2020-2090	Nevertheless, while the new version is a good step in the right direction, there is some additional work needed to fully address the reviewers' complaints.	rebuttal_process
2020-2090	For example, the improved baselines are only evaluated in the most simple domain, while the more complex domains still only contain simplistic baselines that are destined to fail.	rebuttal_process
2020-2090	There are also some unaddressed questions regarding the correctness of eq 4.	rebuttal_process
2020-2090	Finally, the substantial rewrites have given the paper a less-than-polished feel. <sep>	rebuttal_process
2020-2090	In short, while the work is interesting, it still needs a few iterations before it's ready for publication.	decision

2020-2091	This paper suggests a Bayesian approach to make inference about latent variables for image inference tasks.	abstract
2020-2091	While the idea in the paper seems elegant and simple, reviewers pointed out a few concerns, including lack of comparisons, missing references, and requested for more extensive validations.	weakness
2020-2091	While a few comments might have been misunderstandings (eg lack of quantification - seems to be resolved by author's comments), other comments are not (eg equation (8) needs further justification even if the final results don't use it).	weakness
2020-2091	We encourage authors to carefully review comments and edit the manuscript (perhaps some appendix items should be in the main to reduce confusion) for resubmitting to future conferences.	decision

2020-2093	This paper investigates the task of learning to synthesize tools for specific tasks (in this case, a simulated reaching task).	abstract
2020-2093	The paper was reviewed by 3 experts and received Reject, Weak Reject, and Weak Reject opinions.	rating_summary
2020-2093	The reviews are very encouraging of the topic and general approach taken by the paper -- eg R3 commenting on the "coolness" of the problem and R1 calling it an "important problem from a cognitive perspective" -- but also identify a number of concerns about baselines, novelty of proposed techniques, underwhelming performance on the task, whether experiments support the conclusions, and some missing or unclear technical details.	weakness
2020-2093	Overall, the feeling of the reviewers is that they're "not sure what I am supposed to get out of the paper" (R3).	weakness
2020-2093	The authors posted responses that addressed some of these issues, in particular clarifying their terminology and contribution, and clearing up some of the technical details.	rebuttal_process
2020-2093	However, in post-rebuttal discussions, the reviewers still have concerns with the claims of the papers.	rebuttal_process
2020-2093	In light of these reviews, we are not able to recommend acceptance at this time, but I agree with reviewers that this is a "cool" task and that authors should revise and submit to another venue.	decision

2020-2094	The authors present a physics-aware models for inpainting fluid data.	abstract
2020-2094	In particular, the authors extend the vanilla U-net architecture and add losses that explicitly  bias the network towards physically meaningful solutions. <sep>	abstract
2020-2094	While the reviewers found the work to be interesting, they raised a few questions/objections which are summarised below: <sep> 1) Novelty: The reviewers largely found the idea to be novel.	strength
2020-2094	I agree that this is indeed novel and a step in the right direction. <sep>	strength
2020-2094	2) Experiments: The main objection was to the experimental methodology.	weakness
2020-2094	In particular, since most of the experiments were on simulated data the reviewers expected simulations where the test conditions were a bit more different than the training conditions.	suggestion
2020-2094	It is not very clear whether the training and test conditions were different and it would have been useful if the authors had clarified this in the rebuttal.	weakness
2020-2094	The reviewers have also suggested a more thorough ablation study. <sep>	suggestion
2020-2094	3) Organisation: The authors could have used the space more effectively by providing additional details and ablation studies. <sep>	weakness
2020-2094	Unfortunately, the authors did not engage with the reviewers and respond to their queries.	rebuttal_process
2020-2094	I understand that this could have been because of the poor ratings which would have made the authors believe that a discussion wouldn't help.	misc
2020-2094	The reviewers have asked very relevant Qs and made some interesting suggestions about the experimental setup.	misc
2020-2094	I strongly recommend the authors to consider these during subsequent submissions. <sep>	suggestion
2020-2094	Based on the reviewer comments and lack of response from the authors, I recommend that the paper cannot be accepted.	decision

2020-2098	The paper presents a model for learning spiking representations.	abstract
2020-2098	The basic model is a a deep autoencoder trained end-to-end with a biophysical generative model and results are presented on EMG and sEMG data, with the aim to motivate further research in self-supervised learning. <sep>	abstract
2020-2098	The reviewers raised several points about the paper.	misc
2020-2098	Reviewer 1 raised concerns about lack of context on surrounding work, clarity of the model itself and motivating the loss.	weakness
2020-2098	Reviewer 2 pointed out strengths of the paper in its simplicity and the importance of this problem, but also raised concerns about the papers clarity, again motivations on the loss function and sensibility of design choices.	weakness
2020-2098	The authors responded to the feedback from reviewer 1, but overall the reviewer did not think their scores should be changed. <sep>	rebuttal_process
2020-2098	The paper in its current form is not yet ready for acceptance, and we hope there has been useful feedback from the reviewing process for their future research.	decision

2020-2099	The submission presents an approach to speed up network training time by using lower precision representations and computation to begin with and then dynamically increasing the precision from 8 to 32 bits over the course of training.	abstract
2020-2099	The results show that the same accuracy can be obtained while achieving a moderate speed up. <sep>	abstract
2020-2099	The reviewers were agreed that the paper did not offer a signficant advantage or novelty, and that the method was somewhat ad hoc and unclear.	weakness
2020-2099	Unfortunately, the authors' rebuttal did not clarify all of these points, and the recommendation after discussion is for rejection.	decision

2020-2100	The paper proposes a cycle-consistent GAN architecture with measuring the reconstruction error of time series for anomaly detection. <sep>	abstract
2020-2100	The paper aims to address an important problem, but the current version is not ready for publication.	decision
2020-2100	We suggest the authors consider the following aspects for improving the paper: <sep> 1. The novelty of the proposed model: motivate the design choices and compare them with state-of-art methods <sep>	suggestion
2020-2100	2. Evaluation: formalize the target anomalies and identify datasets/examples where the proposed model can significantly outperform existing solutions.	suggestion

2020-2102	The article studies the behaviour of binary and full precision ReLU networks towards explaining differences in performance and suggests a random bias initialisation strategy.	abstract
2020-2102	The reviewers agree that, while closing the gap between binary networks and full precision networks is an interesting problem, the article cannot be accepted in its current form.	rating_summary
2020-2102	They point out that more extensive theoretical analysis and experiments would be important, as well as improving the writing.	weakness
2020-2102	The authors did not provide a rebuttal nor a revision.	rebuttal_process

2020-2105	The author responses and notes to the AC are acknowledged.	misc
2020-2105	A fourth review was requested because this seemed like a tricky paper to review, given both the technical contribution and the application area.	misc
2020-2105	Overall, the reviewers were all in agreement in terms of score that the paper was just below borderline for acceptance.	rating_summary
2020-2105	They found that the methodology seemed sensible and the application potentially impactful.	strength
2020-2105	However, a common thread was that the paper was hard to follow for non-experts on MRI and the reviewers weren't entirely convinced by the experiments (asking for additional experiments and comparison to Zhang et al).	weakness
2020-2105	The authors comment on the challenge of implementing Zhang is acknowledged and it's unfortunate that cluster issues prevented additional experimental results.	weakness
2020-2105	While *CONF* certainly accepts application papers and particularly ones with interesting technical contribution in machine learning, given that the reviewers  struggled to follow the paper through the application specific language it does seem like this isn't the right venue for the paper as written.	decision
2020-2105	Thus the recommendation is to reject.	decision
2020-2105	Perhaps a more application specific venue would be a better fit for this work.	decision
2020-2105	Otherwise, making the paper more accessible to the ML audience and providing experiments to justify the methodology beyond the application would make the paper much stronger.	suggestion

2020-2109	Main content: <sep> Blind review #1 summarizes it well: <sep> his paper claims to be the first to tackle unconditional singing voice generation.	abstract
2020-2109	It is noted that previous singing voice generation approaches leverage explicit pitch information (either of an accompaniment via a score or for the voice itself), and/or specified lyrics the voice should sing.	abstract
2020-2109	The authors first create their own dataset of singing voice data with accompaniments, then use a GAN to generate singing voice waveforms in three different settings: <sep>	abstract
2020-2109	1) Free singer - only noise as input, completely unconditional singing sampling <sep>	abstract
2020-2109	2) Accompanied singer - Providing the accompaniment *waveform* (not symbolic data like a score - the model needs to learn how to transcribe to use this information) as a condition for the singing voice <sep>	abstract
2020-2109	3) Solo singer - The same setting as 1 but the model first generates an accompaniment then, from that, generates singing voice <sep>	abstract
2020-2109	-- <sep>	misc
2020-2109	Discussion: <sep> The reviews generally point out that while a lot of new work has been done, this paper bites off too much at once: it tackles many different open problems, in a generative art domain where evaluation is subjective. <sep>	weakness
2020-2109	-- <sep>	misc
2020-2109	Recommendation and justification: <sep> This paper is a weak reject, not because it is uninteresting or bad work, but because the ambitious scope is really too large for a single conference paper.	decision
2020-2109	In a more specialized conference like ISMIR, it would still have a good chance.	decision
2020-2109	The authors should break it down into conference sized chunks, and address more of the reviewer comments in each chunk.	suggestion

2020-2110	The reviewers have provided thorough reviews of your work.	rating_summary
2020-2110	I encourage you to read them carefully should you decide to resubmit it to a later conference.	decision

2020-2115	All reviewers rated this paper as a weak reject. <sep>	rating_summary
2020-2115	The author response was just not enough to sway any of the reviewers to revise their assessment. <sep>	rebuttal_process
2020-2115	The AC recommends rejection.	decision

2020-2120	The paper proposes a novel method for embedding sequences of states and actions into a latent representation that enables efficient estimation of empowerment for an RL system.	abstract
2020-2120	They use empowerment as intrinsic reward for safe exploration.	abstract
2020-2120	While the reviewers agree that this paper has promise, they also agree that it is not quite ready for publication in its current state.	rating_summary
2020-2120	In particular, the paper is lacking a theoretical justification for the proposed approach, the definition of empowerment used by the authors raised questions, and the manuscript would benefit from more clear and detailed description of the method.	weakness
2020-2120	For these reasons I recommend rejection.	decision

2020-2129	The paper adapts a previously proposed modular deep network architecture (SHDL) for supervised learning in a continual learning setting.	abstract
2020-2129	One problem in this setting is catastrophic forgetting.	abstract
2020-2129	The proposed solution replays a small fraction of the data from old tasks to avoid forgetting, on top of a modular architecture that facilitates fast transfer when new tasks are added.	abstract
2020-2129	The method is developed for image inputs and evaluated experimentally on CIFAR-100. <sep>	abstract
2020-2129	The reviews were in agreement that this paper is not ready for publication.	rating_summary
2020-2129	All the reviews had concerns about the lack of explanation of the proposed solution and the experimental methods.	weakness
2020-2129	The reviewers were concerned about the choice of metrics not being comparable or justified: Reviewer4 wanted an apples-to-apples comparison, Reviewer1 suggested the paper follow the evaluation paradigm used in earlier papers, and Reviewer2 described the absence of an explained baseline value.	weakness
2020-2129	Two reviewers (Reviewer4 and Reviewer2) described the lack of details on the parameters, architecture, and training regime used for the experiments.	weakness
2020-2129	The paper did not not justify which aspects of the modular system contributed to the observed performance (Reviewer4 and Reviewer1).	weakness
2020-2129	Several additional concerns were also raised. <sep>	misc
2020-2129	The authors did not respond to any of the concerns raised by the reviewers.	rebuttal_process

2020-2137	This paper aims to study the effect of data augmentation of generalization performance.	abstract
2020-2137	The authors put forth a measure of rugosity or "roughness" based on the tangent Hessian of the function reminiscent of a classic result by Donoho et al The authors show that this measure changes in tandem with how much data augmentation helps.	abstract
2020-2137	The reviewers and I concur that the rugosity measure is interesting.	strength
2020-2137	However, as the reviewer mention the main draw back of this paper is that this measure of rugosity when made explicit does not improve generalization.	weakness
2020-2137	This is the main draw back of the paper.	misc
2020-2137	I agree with the authors that this measure is interesting in itself.	strength
2020-2137	However, I think in its current form the paper is not ready for prime time and recommend rejection.	decision
2020-2137	That said, I believe this paper has a lot of potential and recommend the authors to rewrite and carry out more careful experiments for a future submission.	suggestion

2020-2139	The submission proposes to use CNN for Amharic Character Recognition.	abstract
2020-2139	The authors used a straight forward application of CNNs to go from images of Amharic characters to the corresponding character.	abstract
2020-2139	There was no innovation on the CNN side.	abstract
2020-2139	The main contribution of the work is the Amharic handwriting dataset and the experiments that were performed. <sep>	abstract
2020-2139	The reviewers indicated the following concerns: <sep> 1. There was no innovation to the method (a straight forward CNN is used) and is likely not of interest to the *CONF* community <sep>	weakness
2020-2139	2. The dataset was divided into train/val split and does not contain a held-out test set.	weakness
2020-2139	Thus it was impossible to determine the generalization of the model. <sep>	weakness
2020-2139	3. The paper is poorly written with the initial version having major formatting issues and missing references.	weakness
2020-2139	The revised version has fixed some of the formatting issues.	rebuttal_process
2020-2139	The paper still need to having more paragraph breaks to help with the readability of the paper (for instance, the introduction is still one big long paragraph).	suggestion
2020-2139	The terminology and writing can also be improved.	weakness
2020-2139	For instance, in section 2.3, the authors write that "500 dataset for each character were collected".	suggestion
2020-2139	It would be clearer to say that "500 images for each character were collected". <sep>	suggestion
2020-2139	The submission received low reviews overall (3 rejects), which was unchanged after the rebuttal.	rating_summary
2020-2139	Due to the general consensus, there was limited discussion.	rebuttal_process
2020-2139	There were also major formatting issues with the initial submission.	rebuttal_process
2020-2139	The revised version was improved to have proper inclusion of Amharic characters in the text, missing figures, and references.	rebuttal_process
2020-2139	However, even after the revision, the paper still had the above issues with methodology (as noted by R4) and is likely of low interest for the *CONF* community. <sep>	rebuttal_process
2020-2139	The Amharic handwriting data and experiments using a CNN can be of interest to the different community and I would recommend the authors work on improving their paper based on reviewer comments and submit to different venue (such as a workshop focused on character recognition for different languages).	decision

2020-2142	This paper describes how they extend a previous phrase-based neural machine translation model to incorporate external dictionaries.	abstract
2020-2142	The reviewers mention the small scale of the experiments, and the lack of clarity in the writing, and missing discussion on computational complexity.	weakness
2020-2142	Even though the method seems to have the potential to impact the field, the paper is currently not strong enough for publication.	decision
2020-2142	The authors have not engaged in the discussion at all.	rebuttal_process

2020-2143	The paper presents an SGD-based learning of a Gaussian mixture model, designed to match a data streaming setting. <sep>	abstract
2020-2143	The reviews state that the paper contains some quite good points, such as <sep> * the simplicity and scalability of the method, and its robustness wrt the initialization of the approach; <sep>	strength
2020-2143	* the SOM-like approach used to avoid degenerated solutions; <sep>	strength
2020-2143	Among the weaknesses are <sep> * an insufficient discussion wrt the state of the art, eg for online EM; <sep>	weakness
2020-2143	* the description of the approach seems yet not mature (eg, the constraint enforcement boils down to considering that the πk are obtained using softmax; the discussion about the diagonal covariance matrix vs the use of local principal directions is not crystal clear); <sep>	weakness
2020-2143	* the fact that experiments need be strengthened. <sep>	weakness
2020-2143	I thus encourage the authors to rewrite and polish the paper, simplifying the description of the approach and better positioning it wrt the state of the art (in particular, mentioning the data streaming motivation from the start).	suggestion
2020-2143	Also, more evidence, and a more thorough analysis thereof, must be provided to back up the approach and understand its limitations.	suggestion

2020-2150	The paper presents a new semi-supervised boosting approach. <sep>	abstract
2020-2150	As reviewers pointed out and AC acknowledge, the paper is not ready to publish in various aspects: (a) limited novelty/contribution, (b) reproducibility issue and (c) arguable assumptions. <sep>	decision
2020-2150	Hence, I recommend rejection.	decision

2020-2151	The work this paper presents is interesting, but it is not quite ready yet for publication at *CONF*.	decision
2020-2151	Specifically, the motivation of particular choices could be better, such as summing over quantiles, as indicated by Reviewer 1.	weakness
2020-2151	The inherent trade-off between safety and speed of adaptation and how this relates to the proposed method could also use a clearer exposition.	weakness

2020-2156	This paper gave a general L2O convergence theory called Learned Safeguarded KM (LSKM).	abstract
2020-2156	The reviewers found flaws both in theory and in experiments.	weakness
2020-2156	While all the reviewers have read the authors' rebuttal and gave detailed replies, they all agree to reject this paper.	rating_summary
2020-2156	I agree also.	decision

2020-2162	There is insufficient support to recommend accepting this paper.	decision
2020-2162	The reviewers unanimously recommended rejection, and did not change their recommendation after the author response period.	rating_summary
2020-2162	The technical depth of the paper was criticized, as was the experimental evaluation.	weakness
2020-2162	The review comments should help the authors strenghen this work.	misc

2020-2166	In this work, the authors address a multi-task learning setting and propose to enhance the estimation of task dependency with an attention mechanism capturing sample-dependant measure of task relatedness.	abstract
2020-2166	All reviewers and AC agree that the current manuscript lacks clarity and convincing empirical evaluations that clearly show the benefits of the proposed approach wrt state-of-the-art methods.	weakness
2020-2166	Specifically, the reviewers raised several important concerns that were viewed by AC as critical issues: <sep> (1) the empirical evaluations need to be significantly strengthened to show the benefits of the proposed methods over SOTA -- see R2's request to empirically compare with the related recent work [Taskonomy, 2018] and R4's request to compare with the work [End-to-end multi-task learning with attention, 2018].	weakness
2020-2166	R4 also suggested to include an ablation study to assess the benefits of the attention mechanism.	weakness
2020-2166	Pleased to report that the authors addressed the ablation study in their rebuttal and confirmed that the proposed attention mechanism plays an important role in the performance of the proposed method. <sep>	rebuttal_process
2020-2166	(2) All reviewers see an issue with the presentation clarity of the conceptual and technical contributions  -- see R4's and R2's detailed comments and questions regarding technical contributions; see R3's and R4's comments that the distinction between the general task dependency and the data-driven dependency is either not significant or is not clearly articulated; finding better examples to illustrate the difference (instead of reiterating the current ones) would strengthen the clarity and conceptual contributions. <sep>	weakness
2020-2166	A general consensus among reviewers and AC suggests, in its current state the manuscript is not ready for a publication.	decision
2020-2166	It needs more clarifications, empirical studies and polish to achieve the desired goal.	suggestion

2020-2171	This article studies the effects of BN on robustness.	abstract
2020-2171	The article presents a series of experiments on various datasets with noise, PGD adversarial attacks, and various corruption benchmarks, that show a drop in robustness when using BN.	abstract
2020-2171	It is suggested that a main cause of vulnerability is the tiling angle of the decision boundary, which is illustrated in a toy example. <sep>	abstract
2020-2171	The reviewers found the contribution interesting and that the effect will impact many DNNs.	strength
2020-2171	However, they the did not find the arguments for the tiling explanation convincing enough, and suggested more theory and experimental illustration of this explanation would be important.	weakness
2020-2171	In the rebuttal the authors maintain that the main contribution is to link BN and adversarial vulnerability and consider their explanation reasonable.	rebuttal_process
2020-2171	In the initial discussion the reviewers also mentioned that the experiments were not convincing enough and that the phenomenon could be an effect of gradient masking, and that more experiments with other attack strategies would be important to clarify this.	rebuttal_process
2020-2171	In response, the revision included various experiments, including some with various initial learning schedules.	rebuttal_process
2020-2171	The revision clarified some of these issues.	rebuttal_process
2020-2171	However, the reviewers still found that the reason behind the effect requires more explanations.	rebuttal_process
2020-2171	In summary, this article makes an important observation that is already generating a vivid discussion and will likely have an impact, but the reviewers were not convinced by the explanations provided for these observations.	rating_summary

2020-2172	This paper presents FinBERT, a BERT-based model that is further trained on a financial corpus and evaluated on Financial PhraseBank and Financial QA.	abstract
2020-2172	The authors show that FinBERT slightly outperforms baseline methods on both tasks. <sep>	abstract
2020-2172	The reviewers agree that the novelty is limited and this seems to be an application of BERT to financial dataset.	weakness
2020-2172	There are many cases when it is okay to not present something entirely novel in terms of model as long as a paper still provides new insights on other things.	weakness
2020-2172	Unfortunately, the new experiments in this paper are also not convincing.	weakness
2020-2172	The improvements are very minor on small evaluation datasets, which makes the main contributions of the paper not enough for a venue such as *CONF*. <sep>	weakness
2020-2172	The authors did not respond to any of the reviewers' concerns.	rebuttal_process
2020-2172	I recommend rejecting this paper.	decision

2020-2173	The paper presents a linear classifier based on a concatenation of two types of features for protein function prediction.	abstract
2020-2173	The two features are constructed using methods from previous papers, based on peptide sequence and protein-protein interactions. <sep>	abstract
2020-2173	All the reviewers agree that the problem is an important one, but the paper as it is presented does not provide any methodological advance, and weak empirical evidence of better protein function prediction.	weakness
2020-2173	Therefore the paper would require a major revision before being suitable for *CONF*.	decision

2020-2176	The paper presents a quantization method that generates per-layer hybrid filter banks consisting of full-precision and ternary weight filters for MobileNets.	abstract
2020-2176	The paper is well-written.	strength
2020-2176	However, it is incremental.	weakness
2020-2176	Moreover, empirical results are not convincing enough.	weakness
2020-2176	Experiments are only performed on ImageNet.	weakness
2020-2176	Comparison on more datasets and more model architectures should be performed.	weakness

2020-2177	This paper uses unsupervised learning to create useful representations to improve the performance of models in predicting protein-ligand binding.	abstract
2020-2177	After reviewers had time to consider each other's comments, there was consensus that the current work is too lacking in novelty on the modeling side to warrant publication in *CONF*.	rating_summary
2020-2177	Additionally, current experiments are lacking comparisons with important baselines.	weakness
2020-2177	The work in its current form may be better suited for a domain journal.	decision

2020-2179	This paper is a clear reject.	decision
2020-2179	The paper is very poorly written and contains zero citations.	weakness
2020-2179	Also, the reviewers have a hard time understanding what the paper is about.	weakness

2020-2181	This paper presents a VAE approach where the model learns representation while disentangling the location and appearance information.	abstract
2020-2181	The reviewers found issues with the experimental evaluation of the paper, and have given many useful feedback.	weakness
2020-2181	None of the reviewers were willing to change their score during the discussion period.	rebuttal_process
2020-2181	with the current score, the paper does not make the cut for *CONF*, and I recommend to reject this paper.	decision

2020-2183	This paper examines learning problems where the network outputs are intended to be invariant to permutations of the network inputs.	abstract
2020-2183	Some past approaches for this problem setting have enforced permutation-invariance by construction.	abstract
2020-2183	This paper takes a different approach, using a recurrent neural network that passes over the data.	abstract
2020-2183	The paper proves the network will be permutation invariant when the internal state transition function is associative and commutative.	abstract
2020-2183	The paper then focuses on the commutative property by describing a regularization objective that pushes the recurrent network towards becoming commutative.	abstract
2020-2183	Experimental results with this regularizer show potentially better performance than DeepSet, another architecture that is designed for permutation invariance. <sep>	abstract
2020-2183	The subsequent discussion of the paper raised several concerns with the current version of the paper.	misc
2020-2183	The theoretical contributions for full permutation-invariance follow quickly from the prior DeepSet results.	weakness
2020-2183	The paper's focus on commutative regularization in the absence of associative regularization is not compelling if the objective is really for permutation invariance.	weakness
2020-2183	The experimental results were limited in scope.	weakness
2020-2183	These results lacked error bars and an examination of the relevance of associativity.	weakness
2020-2183	The reviewers also identified several related lines of work which could provide additional context for the results that were missing from the paper. <sep>	weakness
2020-2183	This paper is not ready for publication due to the multiple concerns raised by the reviewers.	decision
2020-2183	The paper would become stronger by addressing these concerns, particularly the associativity of the transition function, empirical results, and related work.	suggestion

2020-2186	Main summary:  Design an effective and economical model which spots keywords about pests and disease from community radio data in Luganda and English. <sep>	abstract
2020-2186	Discussions: <sep> all reviewers vote on rejecting the paper, due to lack of generalizability, training and evaluation discussion need work <sep>	rating_summary
2020-2186	Recommendation: Reject	decision

2020-2187	The paper proposes a LSTM-based meta-learning approach that learns how to update each neuron in another model for best few-shot learning performance. <sep>	abstract
2020-2187	The reviewers agreed that this is a worthwhile problem and the approach has merits, but that it is hard to judge the significance of the work, given limited or unclear novelty compared to the work of Ravi & Larochelle (2017) and a lack of fair baseline comparisons. <sep>	weakness
2020-2187	I recommend rejecting the paper for now, but encourage the authors to take the reviewers' feedback into account and submit to another venue.	decision

2020-2190	This paper explores the practice of using lower-dimensional embeddings to perform Bayesian optimization on high dimensional problems.	abstract
2020-2190	The authors identify several issues with performing such an optimization on a lower-dimensional projection and propose solutions leading to better empirical performance of the optimization routine.	abstract
2020-2190	Overall the reviewers found the work well written and enjoyable.	strength
2020-2190	However, the reviewers were concerned primarily about the connection to existing literature (R2) and the empirical analysis (R1, R3).	weakness
2020-2190	The authors claim that their method outperforms state-of-the-art on a range of problems but the reviewers did not feel there was sufficient empirical evidence to back up this claim. <sep>	weakness
2020-2190	Unfortunately, as such the paper is not quite ready for publication.	decision
2020-2190	The authors claim to have significantly expanded the experiments in the response period, however, which will likely make it much stronger for a future submission.	rebuttal_process

2020-2195	The general consensus amongst the reviewers is that this paper is not quite ready for publication.	rating_summary
2020-2195	The reviewers raised several issues with your paper, which I hope will help you as you work towards finding a home for this work.	misc

2020-2196	The authors consider the problem of predicting DNA folding patterns. <sep>	abstract
2020-2196	They use a range of simple, linear models and find that a bi-LSTM architecture yielded best performance.<sep>	abstract
2020-2196	This paper is below acceptance. <sep>	decision
2020-2196	Reviewers pointed out strong similarity to previously published work. <sep>	weakness
2020-2196	Furthermore the manuscript lacked in clarity, leaving uncertain eg details about experimental details.	weakness

2020-2201	This work looks at ways to fill in incomplete data, through two different energy terms. <sep>	abstract
2020-2201	Reviewers find the work interesting, however it is very poorly written and nowhere near ready for publication.	rating_summary
2020-2201	This comes on top of poorly stated motivation and insufficient comparison to prior work. <sep>	weakness
2020-2201	Authors have chosen not to answer the reviewers' comments. <sep>	rebuttal_process
2020-2201	We recommend rejection.	decision

2020-2202	The paper leverages variational auto-encoders (VAEs) and disentanglement to generate data representations that hide sensitive attributes.	abstract
2020-2202	The reviewers have identified several issues with the paper, including its false claims or statements about differential privacy, unclear privacy guarantee, and lack of related work discussion.	weakness
2020-2202	The authors have not directly addressed these issues.	rebuttal_process

2020-2204	This paper incorporates phrases within the transformer architecture. <sep>	abstract
2020-2204	The underlying idea is interesting, but the reviewers have raised serious concerns with both clarity and the trustworthiness of the experimental evaluation, and thus I cannot recommend acceptance at this time.	decision

2020-2206	This paper proposes to measure the distance of the generator manifold to the training data.	abstract
2020-2206	The proposed approach bears significant similarity to past studies that also sought to analyze the behavior of generative models that define a low-dimensional manifold (eg Webster 2019, and in particular, Xiang 2017).	weakness
2020-2206	I recommend that the authors perform a broader literature search to better contextualize the claims and experiments put forth in the paper. <sep>	suggestion
2020-2206	The proposed method also suffers from some limitations that are not made clear in the paper.	weakness
2020-2206	First, the measure depends only on the support of the generator, but not the density.	weakness
2020-2206	For models that have support everywhere (exact likelihood models tend to have this property by construction), the measure is no longer meaningful.	weakness
2020-2206	Even for VAEs, the measure is only easily applicable if the decoder is non-autoregressive so that the procedure can be applied only to the mean decoding. <sep>	weakness
2020-2206	In this current state, I do not recommend the paper for submission. <sep>	decision
2020-2206	Xiang (2017).	misc
2020-2206	On the Effects of Batch and Weight Normalization in Generative Adversarial Networks Webster (2019).	misc
2020-2206	Detecting Overfitting of Deep Generative Networks via Latent Recovery	misc

2020-2207	This paper analyzes neural recording data taken from rodents performing a continual learning task using demixed principal component analysis, and aims to find representations for behaviorally relevant variables.	abstract
2020-2207	They compare these features with those of a deep RL agent. <sep>	abstract
2020-2207	I am a big fan of papers like this that try to bridge between neuroscience and machine learning.	misc
2020-2207	It seems to have a great motivation and there are some interesting results presented.	strength
2020-2207	However the reviewers pointed out many issues that lead me to believe this work is not quite ready for publication.	decision
2020-2207	In particular, not considering space when analyzing hippocampal rodent data, as R2 points out, seems to be a major oversight.	weakness
2020-2207	In addition, the sample size is incredibly small (5 rats, only 1 of which was used for the continual learning simulation).	weakness
2020-2207	This seems to me like more of an exploratory, pilot study than a full experiment that is ready for publication, and therefore I am unfortunately recommending reject. <sep>	decision
2020-2207	Reviewer comments were very thorough and on point.	misc
2020-2207	Sounds like the authors are already working on the next version of the paper with these points in mind, so I look forward to it.	misc

2020-2210	This paper proposes to use mixture distributions to improve uncertainty estimates in BNNs.	abstract
2020-2210	Ensemble methods are interpreted as a Bayesian mixture posterior approximation.	abstract
2020-2210	To reduce the computation, a modification to BBB is provided based on a concrete mixture distribution. <sep>	abstract
2020-2210	Both R1 and R3 have given useful feedback.	misc
2020-2210	It is clear that interpretation of ensemble as a Bayesian posterior is well known, and some of them also have theoretical issues.	weakness
2020-2210	The experiment to clearly comparing proposed mixture posterior to more commonly used mixture distribution is also necessary. <sep>	weakness
2020-2210	Due to these reasons, I recommend to reject this paper.	decision
2020-2210	I encourage the authors to use reviewers feedback to improve the paper.	suggestion

2020-2211	The authors proposes a generative model with a hierarchy of latent variables corresponding to a scene, objects, and object parts. <sep>	abstract
2020-2211	The submission initially received low scores with 2 rejects and 1 weak reject.	rating_summary
2020-2211	After the rebuttal, the paper was revised and improved, with significant portions of the paper completely rewritten (the description of the model was rewritten and a new experiment comparing the proposed model to SPAIR was added).	rebuttal_process
2020-2211	While the reviewers acknowledged the improvement in the paper and accordingly adjusted their score upward, the paper is still not sufficiently strong enough to be accepted (it currently has 3 weak rejects). <sep>	rebuttal_process
2020-2211	The reviewer expressed the following concerns: <sep> 1. The experiments uses only a toy dataset that does not convincingly demonstrate the generalizability of the method to more realistic/varied scenarios.	weakness
2020-2211	In particular, the reviewers voiced concern that the dataset is tailored to the proposed method <sep>	weakness
2020-2211	2. Lack of comparisons with baseline methods such as AIR/SPAIR and other work on hierarchical generative models such as SPIRAL. <sep>	weakness
2020-2211	In the revision, the author added an experiment comparing to SPAIR, so this is partially addressed.	rebuttal_process
2020-2211	As a whole, the paper is still weak in experimental rigor.	rebuttal_process
2020-2211	The authors argue that as their main contribution is the design and successful learning of a probabilistic scene graph representation, there is no need for ablation studies or to compare against baselines because their method "can bring better compositionality, interpretability, transferability, and generalization".	rebuttal_process
2020-2211	This argument is unconvincing as in a scientific endeavor, the validity of such claims needs to be shown via empirical comparisons with prior work and ablation studies. <sep>	rebuttal_process
2020-2211	3. Limited novelty <sep>	weakness
2020-2211	The method is a fairly straightforward extension of SPAIR with another hierarchy layer.	weakness
2020-2211	This would not be a concern if the experimental aspects of the work was stronger. <sep>	weakness
2020-2211	The AC agrees with the issues pointed by the reviewers.	misc
2020-2211	In addition, the initial presentation of the paper was very poor.	rebuttal_process
2020-2211	While the paper has been improved, the changes are substantial (with the description of the method and intro almost entirely rewritten).	rebuttal_process
2020-2211	Regardless, despite the improvements in writing, the paper is still not strong enough to be accepted.	decision
2020-2211	I would recommend the authors improve the evaluation and resubmit.	decision

2021-871	The paper considers new notions of adversarial accuracy and risk which are called "genuine" with an aim to fix issues with the existing definitions in the literature.	abstract
2021-871	A number of issues in the paper, including lack of motivation and intuition, and poor formalism were identified by the reviewers.	weakness
2021-871	The paper also fails to cite some of the previous literature that has identified similar issues.	weakness
2021-871	The authors have only responded to some of the questions raised by the reviewers.	rebuttal_process

2021-887	This work considers an apparent problem with current approaches to compositional generalisation (CG) in neural networks.	abstract
2021-887	The problem seems to be roughly: <sep> prior work in CG aims to extract 'compositional representations' from the training distribution <sep> 	weakness
2021-887	work on CG, the training set and the test set are drawn from different distributions <sep>	weakness
2021-887	therefore we don't know whether these models can also extract compositional representations from the test distribution<sep>	weakness
2021-887	All four expert reviewers were, to differing degrees, confused by this problem framing, largely because they consider the premise (1) to be false. <sep>	weakness
2021-887	I am also aware of a large body of recent work on CG in neural networks (see those papers listed by R2) and, as far as i know, none of it involves extracting 'compositional representations' from the training set.	weakness
2021-887	Rather, it involves learning something (from the training set) that enables strong performance on a test set that differs from the training set in a way that is informed by ideas of compositionaity. <sep>	weakness
2021-887	As far as I know, there are very few  studies that try to identify compositionality by considering the internal representations of neural networks, so it feels incorrect to claim this is standard practice.	weakness
2021-887	Any work that goes down this route ought to have a very thorough treatement of the various thorny philosophical and theoretical treatments of compositionality in the literature.	weakness
2021-887	As pointed out by R4, the work in its current form does not do this. <sep>	weakness
2021-887	In summary, this work attempts to solve a problem that none of the four expert reviewers consider to be in need of a solution.	weakness

2021-897	This work is attempting to develop a new way to train models that are robust to (l_p-bounded) adversarial perturbations and to do so in a way that departs from the tools successfully used for this purpose in the past.	abstract
2021-897	This is a worthwhile aspiration, however, as pointed out in the comments/reviews, there are significant problems with the methodology of evaluating the proposed approach (and some well-founded skepticism that this approach is indeed successful).	weakness
2021-897	As such, this paper cannot be accepted in its current form.	decision

2021-977	The reviewers pointed out that the claims made in this submission have already appeared (in even stronger forms) before, to which the authors seem to agree.	weakness
2021-977	Therefore, this submission is not ready for publication in its current form.	decision

2021-1018	While the paper studies an interesting and important problem, namely the language generation, it is poorly written, which makes it difficult to judge its value.	weakness
2021-1018	The reviewers also expressed concern over the scope of the evaluation and the lack of comparison to SOTA.	weakness

2021-1026	This paper proposes a controllable text generation model conditioned on desired structures, converting a text into structure information such as part of speech (POS) and participial construction (PC).	abstract
2021-1026	It proposes a "Structure Aware Transformer" (SAT) to generate text and claims better  PPL and BLEU compared with GPT-2.	abstract
2021-1026	Reviewers pointed out that limited novelty of this paper - SAT is essentially a transformer run on multiple sequences of structure information, with sums of structure embeddings as input embeddings -  the proposed method essentially infuses structure information as features, rather than "controlling" text generation.	weakness
2021-1026	Some references are also missing, most prominently: <sep> 	weakness
2021-1026	Zhang X, Yang Y, Yuan S, et al Syntax-infused variational autoencoder for text generation[J].	misc
2021-1026	arXiv preprint arXiv:1906.02181, 2019. <sep>	misc
2021-1026	Casas N, Fonollosa J A R, Costa-jussà M R. Syntax-driven Iterative Expansion Language Models for Controllable Text Generation[J].	misc
2021-1026	arXiv preprint arXiv:2004.02211, 2020. <sep>	misc
2021-1026	Wu S, Zhou M, Zhang D. Improved Neural Machine Translation with Source Syntax[C]//IJCAI.	misc
2021-1026	2017: 4179-4185. <sep>	misc
2021-1026	Unfortunately, no answers are provided by the authors to the questions asked by the reviewers, which makes me recommend rejection.	decision

2021-1052	The paper proposed a novel RL-based solution to the optimal partial of DNNs which is interesting to readers. <sep>	abstract
2021-1052	However, the paper is not well presented and hard to follow.	weakness
2021-1052	The lack of comparisons agains existing solutions and inconsistencies in the writing as pointed out by the reviewers largely weakens the submission. <sep>	weakness
2021-1052	There's also no updates to the paper based on reviewers' comments. <sep>	rebuttal_process
2021-1052	The main reason for the decision is lack of clarity and significance justifications.	weakness

2021-1061	Thank you for your submission to *CONF*.	misc
2021-1061	The reviewers and I unanimously felt, even after some of the clarifications provided, that while there was some interesting element to this work, ultimately there were substantial issues with both the presentation and content of the paper.	rebuttal_process
2021-1061	Specifically, the reviewers largely felt that the precise problem being solved was somewhat poorly defined, and the benefit of the proposed preimage technique wasn't always clear.	rebuttal_process
2021-1061	And while the ACAS system was a nice application, it seems to be difficult to quantify the real benefit of the proposed method in this setting (especially given that other techniques can similarly be used to verify NNs for this size problem).	rebuttal_process
2021-1061	The answer that this paper provides seems to be something along the lines of "ease of visual interpretation" of the pre-image conditions, but this needs to be quantified substantially more to be a compelling case.	rebuttal_process

2021-1095	The paper tries to argue the value of making ensembles more reproducible through the use of a correlation loss to try to make components as different as possible.	abstract
2021-1095	The paper is tough to follow and the high level motivation is unclear.	weakness
2021-1095	As one of the reviewers points out, don't ensembles provide an estimate of uncertainty and calibration?	weakness
2021-1095	Further, the experiments were quite limited.	weakness
2021-1095	Studying the proposed approach in a small, controlled setting might also be revealing.	weakness

2021-1154	The paper proposes a constituent-based transformer for aspect-based sentiment analysis.	abstract
2021-1154	The approach allows conducting aspect-based sentiment analysis to leverage the syntactic information without pre-specified dependency parse trees. <sep>	abstract
2021-1154	Overall, the idea is interesting.	strength
2021-1154	However, all the reviewers shared the following concerns: <sep> Paper descriptions of methodology and experiments are not clear and require significant rewriting and reorganization. <sep> 	weakness
2021-1154	The proposed approach is not well-justified by the empirical study presented in the paper.	weakness
2021-1154	Especially, a more detailed ablation study is required to justify the design.<sep>	weakness
2021-1154	We would suggest the authors addressing the feedback from the reviewers to improve the paper.	suggestion

2021-1162	As discussed by several reviewers the paper is an application of classical ML approaches for a very relevant problem of calibration of radio interferometers.	abstract
2021-1162	The application is interesting but lacks novelty in terms of ML methodology and the experiments do not provide a meaningful comparison between the state of the art and the proposed approach or justification for the choice of predictors and their parameters.	weakness
2021-1162	This paper in clearly not a good fit for a general ML conference.	decision

2021-1165	Thank you for your submission to *CONF*.	misc
2021-1165	The reviewers unanimously felt that there were substantial issues with this work, owing to the fact that both the techniques and applications have been considered in a great deal of previous work.	weakness
2021-1165	Furthermore, the manuscript itself needs substantial amounts of revision before being suitable for publication.	decision
2021-1165	As there was no response to these points during the rebuttal period, it seems clear that the paper can't be accepted in its current form.	decision

2021-1168	This work appears to be a promising start to a research direction.	strength
2021-1168	However, as the reviewers noted, the work does not compare to alternative approaches and the presentation of the work overall is incomplete.	weakness

2021-1178	The reviewers have a strong consensus towards rejection here, and I agree with this consensus , although I think some of the reviewers' concerns are misplaced.	decision
2021-1178	For example, the paper does not appear to use a magnitude upper bound that would be vacuous together with a strong convexity assumption (although variance bounds + strong convexity do cover only a small fraction of strongly convex learning tasks, these assumptions aren't vacuous).	ac_disagreement
2021-1178	Some feedback I have that perhaps was not covered by the reviewers: <sep> Pros: <sep> Studying the setting where the number of bits varies dynamically is very interesting (although, as Reviewer 3 points out, not entirely novel).	strength
2021-1178	There is significant possibility for improvement from this method, and your theory seems to back this up.<sep>	strength
2021-1178	Cons: <sep> The experimental setup is weak, and is measuring the wrong thing.	weakness
2021-1178	When we run SGD to train a model, what we really care about is when the training finishes: the total wall clock time to train on some system.	weakness
2021-1178	For compression methods with fixed compression rates, it's fine to use the number of bits transmitted as a proxy, because (when the number of bits transmitted is uniform over time) this will be monotonic in the wall-clock time.	weakness
2021-1178	However, when the bits transmitted per iteration can change over time, this can have a difficult-to-predict effect on the wall-clock time, because of the potential for overlap between communication and computation (where below a certain number of bits sent, the system is not communication-bound).	weakness
2021-1178	Wall-clock time experiments comparing against other more modern compression methods would significantly improve this paper.	suggestion

2021-1184	This is a clear reject.	decision
2021-1184	None of the reviewers supports publication of this work.	rating_summary
2021-1184	The concerns of the reviewers are largely valid.	misc

2021-1190	This paper introduces an important and interesting problem and a potentially interesting approach.	abstract
2021-1190	Unfortunately, the reviewers agree that the current version isn't appropriate for *CONF* in its current form.	rating_summary
2021-1190	However, hopefully the feedback will be useful for the authors in revising and resubmitting this paper to another venue.	decision

2021-1206	The manuscript presents an approach for identifying sources of uncertainty in object classification tasks by disentangling representations in latent spaces. <sep>	abstract
2021-1206	Three reviewers agreed that the manuscript is not ready for publication. <sep>	rating_summary
2021-1206	Some of the concerns are conceptual flaws, weak evaluation protocol, and an incorrect interpretation of experiment results. <sep>	weakness
2021-1206	There is no author response.	rebuttal_process

2021-1212	Although the paper presents some interesting ideas, in general the reviewers agree that the paper lacks clear results and is not an easy read.	weakness
2021-1212	The paper proposes a factorisation of value functions, a topic that has received quite some attention in the literature (eg QPLEX), and it seems that their is not sufficient innovation in the proposed method in the paper.	weakness
2021-1212	There are also a number of claims in the paper (eg partial observability etc.)	weakness
2021-1212	with which some of the reviewers disagree, and should be discussed more carefully in a revised version of the article, that all in all seems to need more work.	weakness

2021-1268	The paper has been discussed by the reviewers that have acknowledged the rebuttal and the authors' responses.	rebuttal_process
2021-1268	However, the reviewers still had the following weaknesses and concerns (not solved post rebuttal): <sep> 	rebuttal_process
2021-1268	Expensive procedure (eg, exhaustive enumeration before finding Pareto frontier) <sep>	rebuttal_process
2021-1268	The experiments should be more rigorous, with more realistic real-world problems. <sep>	rebuttal_process
2021-1268	Missing comparison with baselines (unanimously acknowledged by the reviewers). <sep>	rebuttal_process
2021-1268	No explanations and insights provided as to why the method should work well <sep>	rebuttal_process
2021-1268	Clarity of the presentation<sep>	rebuttal_process
2021-1268	As a result, the paper is recommended for rejection.	decision
2021-1268	The detailed comments of the reviewers provide an actionable list of items to improve the paper for a future resubmission.	decision

2021-1295	All Reviewers and myself agree that the paper presents several major issues that require important rethinking of the research done, as well as a full rewriting of the manuscript.	weakness
2021-1295	Hence, my recommendation is to REJECT the paper.	decision
2021-1295	As a brief summary, I highlight below some pros and cons that arose during the review and meta-review processes. <sep>	misc
2021-1295	Pros: <sep> Code is available and clarifies parts of the approach. <sep> 	strength
2021-1295	Use of publicly-available data sets. <sep>	strength
2021-1295	Samples are provided. <sep>	strength
2021-1295	Interesting problem.<sep>	strength
2021-1295	Cons: <sep> There are several problems with language and writing.	weakness
2021-1295	Sometimes there is also incorrect terminology. <sep>	weakness
2021-1295	There are several problems with the description of the approach, which makes it opaque and hard to understand. <sep>	weakness
2021-1295	Proposed model not addressing basic limitations in the existing literature. <sep>	weakness
2021-1295	Insufficient evaluation. <sep>	weakness
2021-1295	No clear indication of successful results. <sep>	weakness
2021-1295	Potential lack of broad impact/interest to the *CONF* community. <sep>	weakness
2021-1295	Unclear contribution. <sep>	weakness
2021-1295	Unconvincing samples.	weakness

2021-1521	This paper proposes a new quantum machine learning framework which is evaluated on the MNIST dataset.	abstract
2021-1521	While the paper was relatively well written, reviewers noted that most of the ideas are already well established and used in quantum machine learning community.	weakness
2021-1521	Thus it was not clear what novelty is provided relative to related work.	weakness

2021-1693	The reviewers appreciate the simplicity of the approach, but found the exposition lacking.	weakness
2021-1693	There were also concerns about strong similarities to CascadeRCNN, which were not resolved in the rebuttal. <sep>	rebuttal_process
2021-1693	In the end all reviewers recommend rejection.	rating_summary
2021-1693	The AC sees no reason to overturn this recommendation.	decision

2021-2106	The focus of the submission is to define divergences on discrete probability measures.	abstract
2021-2106	Particularly, the authors propose a common generalization of the well-known concept of maximum mean discrepancy and kernel Stein discrepancy. <sep>	abstract
2021-2106	As summarized by the reviewers the submission is in a rather preliminary form: <sep>	weakness
2021-2106	1)The work lacks motivation. <sep>	weakness
2021-2106	2)Literature review (there are 4 references in total) and numerical illustrations are missing. <sep>	weakness
2021-2106	3)The submission lacks proper mathematical formulation/rigor. <sep>	weakness
2021-2106	I highly recommend the authors to not submit similar draft manuscripts in the future.	suggestion

2021-2516	This is a clear reject.	decision
2021-2516	None of the reviewers supports publication of this work.	rating_summary
2021-2516	The concerns of the reviewers are largely valid.	misc

2021-2573	The authors propose a method for attacking neural NLP models based on individual word importance ("WordsWorth" scores).	abstract
2021-2573	This is an interesting, timely topic and there may be some interesting ideas here, but at present the paper suffers from poor presentation which makes it difficult to discern the contribution.	weakness
2021-2573	Presentation issues aside, it seems that the experimental setup is missing key baselines (an issue not sufficiently addressed by the author response).	weakness

