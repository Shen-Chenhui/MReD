This paper proposes a method to train neural networks with low precision. %%% Following the authors response %%%
This is a set up that has been used in a large amount of previous work, and the authors summarize some of this work. Minimally I think it is necessary to calculate a null distribution for the statistics that are reported.
2) I'm not sure, and I haven't seen evidence in the paper (or other references) that SNN is the only (optimal?) method for this context. They apply this approach to multi-modal (several "intentions") imitation learning and demonstrate for a real visual robotics task that the proposed framework works better than deterministic neural networks and stochastic neural networks. This reviewer is a bit sceptical to the methodology. For me, this is not the pain point in this tasks. The scheme is motivated by the fact that this estimator has a lower variance than pure sampling from the prior. Even the control task is very similar to the current proposed task in this paper. I know how hard is to make robotic tasks work...
This modification combines the reduction of multiplications achieved by the Winograd convolution algorithm with weight pruning in the following way: - weights are pruned after the Winograd transformation, to prevent the transformation from filling in zeros, thus preserving weight sparsity The resulting Winograd-ReLU CNN shows strong performance in three scenarios (CIFAR10 with VGG, CIFAR100 with ConvPool-CNN-C, and ImageNEt with ResNet-18). I only have a couple of questions/comments: 1) I'm not familiar with the term m-specific ("Matrices B, G and A are m-specific.") and didn't find anything that seemed related in a very quick google search. Or is it almost exactly the same as for general Winograd CNNs? A general limitation of the proposed method is the network architecture inconsistency with the ordinary CNNs. Due to the location change of ReLUs, it is unclear how to transform a pretrained ordinary CNNs to the new architectures accurately. Rastegari, Mohammad, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. 3123-3131. 2015. Lin, Zhouhan, Matthieu Courbariaux, Roland Memisevic, and Yoshua Bengio. 2) Although small filters are the norm, you could add a note, describing up to what filter sizes this method is applicable.
However, while results on convex hull task are good, k-means ones use a single, artificial problem (and do not test DCN, but rather a part of it), and on TSP DCN performs significantly worse than baselines in-distribution, and is better when tested on bigger problems than it is trained on. This could be done by visually showing the partition constructed or seeing how the model learned to merge solutions. It would also be nice to observe failure cases of the model.
Since it is not known in advance what might be a good set of transformations, it is not clear what is the behaviour of the model when the large portion of transformations are not encoding the latent representation of clusters. Thanks to the reviewer for clarifying this. For instance, in the case of MNIST, rotations with different degrees are applied. The main idea is to exploit a schema of semisupervised learning based on ACOL and GAR for an unsupervised learning task.
In Hoffman & Johnson, it is shown that KL(q(z) | p(z)) is in fact buried in ELBO, and the inequality gap in Eq (3) is basically a mutual information term between z and n (the index of the data point). Cons: - I am yet to be fully convinced how well the approach works. --------------------------- ---- UPDATE ---------- --------------------------- I have increased my score after reading the revised version of the manuscript. All in all I find this paper interesting but would hope that a more careful technical justification and derivation of the model would be presented given that it seems to not be an empirically overwhelming change.
This needs to be analyzed very thoroughly because some experiments seem to imply that Flip and NoFlip are giving same performance (Fig 2(b)). In Section 4 they provide quite varied empirical analysis: they confirm their theoretical results on four architectures; they show its use it to regularise on language models; they apply it on large minibatch settings where high variance is a main problem; and on evolution strategies. Clarity: Ideas/Reasons are clearly presented. While it is a rather simple idea which could be summarised much earlier in the  single equation (3), I really like the thoroughness and the clarity of the exposure of the idea.
There is also a strong correlation between (binarized weights)*activations and (binarized weights)*(binarized activations). I think the length of the proof won't matter a lot since it is already in the appendix, but it makes the reader a lot easier to understand it. This is claimed to entail that the continuous weights of the binarized neural net approximate the continuous weights of a non-binarized neural net trained in the same manner. The first observation is interesting, is explained clearly and convincingly, and is novel to the best of my knowledge. e. It is not completely clear to me that batch-normalization takes care of the scale constant (if so, then why did XNOR-NET needed an additional scale constant?), perhaps this should be further clarified. Indeed, Courbariaux, Hubara et al. (2016) is a good and pioneered work on the binary network. %%% After Author's response %%% Some typos and minor issues are listed in the "Cons" part below.
out of the sample space of the training distribution. Algorithm 1. is called "minimization for detection and generating out of distribution (samples)", but this is only gradient descent, right? The KL divergence in (a) of (3) should always be approximately 0 no matter what samples are generated. Suppose that theta is set appropriately so that p_theta (y|x) gives a uniform distribution over labels for out of distribution samples. As out of distribution samples are hard to obtain, authors also propose to use GAN generating "boundary" samples as out of distribution samples. The problem setting is new and objective (1) is interesting and reasonable. The generator is trained to produce images that (1) fools a standard GAN discriminator and (2) has high entropy (as enforced with the pull-away term from the EBGAN). This paper is clearly written, proposes a simple model and seems to outperform current methods. Questions: - Could the authors comment on cases where such a strong within-sample assumption may adversely affect performance?
Extractiveness analysis: I would also have liked to see more analysis of how extractive the Wikipedia articles actually are, as well as how extractive the system outputs are. This is a very nice contribution. For example, Figure 5-7 show variable sizes of the generated outputs. With a fixed reference/target Wikipedia article, if different models generate variable sizes of output, ROUGE evaluation could easily pose a bias on a longer output as it essentially counts overlaps between the system output and the reference. In general, the paper is well-written and the main ideas are clear. This paper is quite original and clearly written. This paper proposes an approach to generating the first section of Wikipedia articles (and potentially entire articles). It is claimed that the transformer decoder makes optimization easier but no complete explanation or justification of this is given.
The paper devises a sparse kernel for RNNs which is urgently needed because current GPU deep learning libraries (e.g., CuDNN) cannot exploit sparsity when it is presented and because a number of works have proposed to sparsify/prune RNNs so as to be able to run on devices with limited compute power (e.g., smartphones). The paper describes the use additional mechanisms for synchronization and memory loading.
Originality The paper proposes a path consistency learning method with a new combination of entropy regularization and relative entropy. Pros: - The paper is well-written and clear. - Even though the paper claims Trust-PCL (on-policy) is close to TRPO, the initial performance of TRPO looks better in HalfCheetah, Hopper, Walker2d and Ant.
- There are parts of the papers which are confusing or not well-written. PROS P.1 Joint training for both compression and classification. - As it is mentioned in the paper, solving a Vision problem directly from a compressed image, is not a novel method (e.g: DCT coefficients were used for both vision and audio data to solve a task without any decompression). 3. Experimental setup part is long but not well-explained and is not self-contained particularly for the evaluation metrics. An effort of compression would be advisable, moving some of the non-core results to the appendixes.
One argument that I am not sure would be applicable perhaps and could be used by adversarial attacks is as follows: If the defence uses image quilting for instance and obtains an image P that approximates the original observation X, it could be possible to use a model based approach that obtains an observation Q that is close to P which can be attacked using adversarial attacks. Minor issues: Typo on p7: to change*s* Strong points: * To my knowledge, the proposed defense strategy is novel (even if the idea of transformation has been introduced at https://arxiv.org/abs/1612.01401). The evaluation is carried out on ImageNet dataset with large number of examples. * In a white-box scenario, the adversary knows about the transformation and the classification model. 60% of attacks are countered in this last most difficult setting. Comments: The paper is well written, the proposed methods are well adapted to the task and lead to satisfying results.
The task of reducing computation by skipping RNN inputs is interesting, and the proposed method is novel, interesting, and clearly explained. On permuted MNIST, Table 2 could include results from [1-4].
This paper shows that residual networks can be viewed as doing a sort of iterative inference, where each layer is trained to use its "nonlinear part" to push its values in the negative direction of the loss gradient. This paper investigates residual networks (ResNets) in an empirical way.
Contribution: - This paper proposes a new object counting module which operates on a graph of object proposals. Comments - It is not clear if the value of count "c" is same with the final answer in counting questions. Weaknesses - Although the proposed model is helpful to model counting information in VQA, it fails to show improvement with respect to a couple of important baselines: prediction from image representation only and from the combination of image representation and attention weights. The paper didn't study what is the recall of the proposals and how sensitive the threshold is. 2. The technique is built on a lot of heuristics without theoretical consideration. Clarity: - The paper is well written and clarity is good.
But it seems that this is not used in the experiment and that the authors consider that the introduction of the embedding is a substitution for this. The step of going from G(S_y) to S_(G(y)) seems delicate...
The examples (Table 3 and Figure 6) show that the skimming process is appropriately performed (skimmed unimportant words while fully read relevant words etc.) The heavy-weight and the light-weight RNN each controls a portion of the hidden state. Summary: The paper proposes a learnable skimming mechanism for RNN.
The application is straightforward and thus technical novelty of this paper is limited. This paper focuses on accelerating RNN by applying the method from Blelloch (1990). The paper provides argument and experimental evidence against the rotation used typically in RNNs. While this is an interesting insight, and worthy of further discussion, such a claim needs backing up with more large-scale experiments on real datasets.
can it be a trainable parameter? I'm not convinced that it is the best example, especially that is it the one having significantly better results, i.e. scores ~ 0.9 vs. 2. Is there a theoretical justification for computing the mixture memberships for the GMM using a neural network?
This is, however, not the case in this paper (at least not in the current manuscript) due to its over-simplified experiments. It seems that the only difference between the unstructured (entangled) and the structured (disentangled) visual VAE is the color space of the input (RGB vs HSV). This suggests the network is likely to overfit the data and learn a straightforward mapping from input to the code. It would also be helpful to see a more extensive evaluation of the model's ability to learn logical recombination operators, since this is their main contribution.
+/-  this work builds largely on previous work. In this paper, the authors studied the problem of semi-supervised few-shot classification, by extending the prototypical networks into the setting of semi-supervised learning with examples from distractor classes. Overall, I would like to vote for a weakly acceptance regarding this paper.
It is unclear how the phase information in the input waveform is transformed into the phase of the complex activations in the network (because I think it is implied that this is what happens). However, I feel that the observation that CReLU works best out of the 3 proposed alternatives contradicts this somewhat. Comments: - The related work section is comprehensive but a bit unstructured, with each new paragraph seemingly describing a completely different type of work. Then again, the major contribution of this work is not advancing the state-of-the-art on many benchmark tasks, but constructing a solid framework that will enable stable and solid application and research of these well-motivated models. In this work, the complex equivalent of many of these basics tools are developed, such as a number of complex activation functions, complex batch normalization, complex convolution, discussion of complex differentiability, strategies for complex weight initialization, complex equivalent of a residual neural network. The image recognition results are mostly inconclusive, which makes it hard to assess the benefit of this approach. Regarding the CIFAR results, I may have read over it, but I think it would be good to state even more clearly that these experiments constitute a sanity check, as both reviewer 1 and myself were seemingly unaware of this.
Pros: - The nice thing about this method is that average pooling is in some sense a special case of this method, so we can see a clear connection. I think this paper presents an interesting take on feature pooling. In many of the experiments, the manuscript stresses the overfitting behavior of max pooling.
Algorithm 2 is more heuristic approach, with a couple of parameters to tune it. Realistic DNN systems are very complex, and evaluating the method in a simple setting would help a lot in determining what if anything is novel about the method. 4. It said that the algorithm is hyperparameter free except for learning rate. E.g. there is no results of Algorithm 1. how sensitive is the algorithm for different choices of those parameters?
As a summary, the authors presented a method that successfully attacks other existing defense methods, and present a method that can successfully defend this attack. Authors are suggested to discuss in more detail. Wether balls are in L2 or L_\\infty, or another norm makes a big difference in defense and attacks, given that they are only equivalent to a multiplicative factor of sqrt(d) where d is the dimension of the space, and we are dealing with very high dimensional problems. The authors essentially develop an attack targeted to the region cls defense. The authors also miss the most standard defense, training with adversarial examples. Designing an attack for a specific defense is very well established in the literature, and the fact that the attack fools this specific defense is not surprising.
Overall, I think this is a good paper that provides a novel way of looking at and solving problems in GANs. I just had a couple of points in the paper that I would like some clarification on : * In section 2.2.1 : The notion of the generated a_i not disappearing is something I did not follow. It is technically rigorous and empirically convincing. and this directly extends to the continuity equation in (2). Ideally, it should contain all the functions formed with Plummer kernel, but not too large (otherwise, it will increase the sample complexity.). Optimizing this formulation using gradient descent can be proven to yield only one optimal global Nash equilibrium, which the authors claim allows Coulomb GANs to overcome the "mode collapse" issue.
This is a fairly strong paper. Summary of paper: The paper proposes an RNN-based neural network architecture for embedding programs, focusing on the semantics of the program rather than the syntax. - Figure 5 seems to suggest that dependencies are only enforced at points in a program where assignment is performed for a variable, is this correct? 3) Treatment of related work is lacking. Significance: This work can be very useful for an educational platform though a limitation is the need for adding instrumentation print statements by hand. However the application to program repair is novel (as far as I know). 2) Terms used in the paper are not defined/explained.
The fundamental contribution of this article, when put into the context of the many recent publications on the topic of automatic neural architecture search, is the introduction of a hierarchy of architectures as a way to build the search space. This is a general comment over this kind of approach, but I think it should be addressed. Overall, the paper is well-written, clear in its exposition and technically sound. The omission is conspicuous. Just test it and report. "Evolutionary Strategies", at least as used in Salimans 2017, has a specific connotation of estimating and then following a gradient using random perturbations which this paper does not do. This is a gross overstatement. While some hyperparameter and design choices could perhaps have been justified in greater detail, the paper is mostly self-contained and provides enough information to be reproducible.
The idea is to  build a lattice of workflows from demonstration and randomly sample sequence of actions from this lattice that satisfy the current goal. Note that the work of Ross and Bagnell, 2010, 2011 (cited in the paper) establish theoretically that Behavior Cloning does not work in such situations due to the non-iid data generation process in such sequential decision-making settings (the mistakes grow quadratically in the length of the horizon). WGE is aiming to do the same: explore near demonstration states. - Therefore would be good to have Dagger or a similar imitation learning algorithm be used as a baseline in the experiments. Workflows are defined through a DSL unique to the domain. Dagger and related methods like Aggrevate provide sample-efficient ways of exploring the environment near where the initial demonstrations were given. The paper is clear, very well written, and well-motivated.
These works also involve a "student" being trained using sensitive data with queries being answered in a differentially private manner. The extension of an approach for learning with privacy to make it scalable is of merit. It would be great to discuss and show experimental results for utility-privacy tradeoff with different variances of Laplace and Gaussian noise. In any case, this is an important issue that needs to be clarified, as it is not clear to me how this is resolved. It is demonstrated that sampling from a Gaussian distribution (instead from a Laplacian distribution) facilitates the aggregation of teacher votes in tasks with large number of output classes. It would be helpful to add a comparison. 2. It would be great to have an intuitive explanation about differential privacy and selective aggregation mechanisms with examples. On this basis, I think the paper should be accepted. The authors mention that the original model PATE was applied to medical record and census data with the UCI diabetes and adult data set. This data-dependent privacy guarantee is likely to be much tighter than the data-independent guarantee. The algorithm in this work is similar to the so-called median mechanism [ https://www.cis.upenn.edu/~aaroth/Papers/onlineprivacy.pdf ] and private multiplicative weights [ http://mrtz.org/papers/HR10mult.pdf ]. minor comments: Figure 2, legend needs to be outside the Figure, in the current Figure a lot is covered by the legend This paper considers the problem of private learning and uses the PATE framework to achieve differential privacy. Intuitively, if teacher ensemble does not answer, it seems that it would reveal the fact that teachers do not agree, and thus spend some privacy cost. Summary: In this work, PATE, an approach for learning with privacy,  is modified to scale its application to real-world data sets.
Especially works related to pool based active learning, and landmark results on labell complexity of agnostic active learning. The authors use a variant of the greedy algorithm along with bisection search to solve a series of feasibility problems to obtain a good cover of the dataset each time.
The ideas are presented often out of order and are repeated in cycles, with some critical details that are needed to understand the method revealed only in the later cycles. The method has minimal dependence on prior knowledge and is thus expected to have wide applicability, and is found to be sufficiently successful on data collected from a real world context.
In this paper, the expressive power of neural networks characterized by tensor train (TT) decomposition, a chain-type tensor decomposition, is investigated. In addition, I would like to see the performance of RNNs and MLPs with the same number of units/rank in order to validate the analogy between these networks. Though I enjoyed reading this paper, I have several concerns. Finally the authors show that almost all tensor train networks (exluding a set of measure zero) require exponentially large width to represent in CP networks, which is analogous to shallow networks. (b) Standard RNNs do not use the multilinear units shown in Figure 3, but use a simple addition of an input and the output from the previous layer (i.e., h_t = f(Wx_t + Vh_{t-1}), where h_t is the t-th hidden unit, x_t is the t-th input, W and V are weights, and f is an activation function.) Such experiments will improve persuasiveness of the main result presented in this paper.
The idea is to learn a second (kind of) Q function, which could be called E-function, which captures the value of exploration (E-value). This provides a nice story for a simple (in a positive sense) approach to tackle the exploration-exploitation tradeoff. This bonus term is shown to be equivalent counter-based methods for finite MDPs when the discount factor of the E-MDP is set to 0. The experimental results demonstrate this is a sufficient number of domains. - Add a minimal description of the initial setup for E-value neural network to section 4.1 (i.e. how the initializing is achieved to have a constant value for all state-action pairs as described in the appendix).
Given that much of the paper is devoted to 1-dev, it's a bit disappointing that this issue is not analyzed in more detail, and furthermore the results are mostly hidden in the appendix. I imagine that it could somehow work out using a bandit algorithm with adversarial guarantees, but I can also imagine it not working out. -- What happens if we don't have a good way to generate x and it must be learned as well? -- I find it curious that there's no notion of future reward learning in the learning algorithm. page 5 "and MTR" -> "and DR"
Another observation is that it seems from figure 2 that a lot of the weights are quantized with around 10 bits, and it is not clear how the compromise accuracy/memory can be turned to less memory, if possible. The quantization is quite cheap to compute and the results are similar to other state-of-the-art quantization methods. - few typos: *psi -> \\psi in section 2.3 This needs to be clarified. - Page 1: It is a little hard to follow the motivation against existing methods. Quantization has some bookkeeping associated with it: In a per-parameter quantization setup it will be necessary to store not just the quantized parameter, but also the number of bits used in the quantization (takes e.g. 4-5 extra bits), and there will be some metadata necessary to encode how the quantized value should be converted back to floating point (e.g., for 8-bit quantization of a layer of weights, usually the min and max are stored).
It would be interesting to see what are values of \\gamma(\\phi) and L(\\phi) for some distributions (e.g. Gaussian, uniform in hypercube, etc.) to give more intuitions. It will be even better if one can get a simplified set of assumptions.
This paper introduces a method for learning new tasks, without interfering previous tasks, using conceptors. Nevertheless, the authors show that their method indeed reduce the interference generated by a new task on the old learned tasks. Being less grandiose would make the value of this article nicely on its own. The fact that additional conceptors can be trained does not appear new for the approach described here.
It is well conceived and articulated, and provides an interesting and potentially powerful new direction to improve GANs in practice.
3: In section 4.2, the authors claim this is the theoretical explanation of the generalization capability of the proposed model (also appear in topic effect analysis). Topics are extracted from questions using similar words in question-answer pairs. What are ac_t and em_t? More details are necessary about how exactly Kim's and Liu's models are used to get question types and topics. This paper presents a neural network-based approach to generate topic-specific questions with the motivation that topical questions are more meaningful in practical applications like real-world conversations. Although the main contributions are clear, the paper contains numerous typos, grammatical errors, incomplete sentences, and a lot of discrepancies between text, notations, and figures making it ambiguous and difficult to follow. [Summary] a topic-based question generation method, which requires the input of target topic in addition to the descriptive text. However, as I pointed out above, there are several weaknesses in the paper. A sequence classifier is also used to tag the presence of topic words. Where are the bi-LSTMs in the figure?
It doesn't seem to be relevant to the results of this paper (because the NN architecture proposed in this paper is rather small). 3. It is not clear from the text whether the setting is already considered in Brutzkus and Globerson, 2017. This paper considers a special deep learning model and shows that in expectation, there is only one unique local minimizer. In the abstract the authors state that it has to do with a two-layer RELU network with two hidden units (per layer? In general I found this paper clearly written and technically sound. In this paper the authors studied the theoretical properties of manifold descent approaches in a standard regression problem, whose regressor is a simple neural network. Furthermore, it is important to discuss the technical assumptions on the
This is a theory paper. Their improvement over previous work is that the required overparameterization is fairly moderate, and that the network that they considered is similar to ones used in practice. The authors are aware of this point and mention it as a disadvantage. parameters)  and d1 =< N
Hence a local minima of l(F(W)) is a local minima of l(s) when s=F(W) is a locally open map. al., the paper does not seem to have strong implications for matrix completion. However I am not convinced that the paper is able to show stronger results about the geometry of linear/neural networks. This is easy to fix, but not correct as written.
The model is evaluated on two sets of datasets and the tree-to-tree model outperforms seq2tree and seq2seq models significantly for the program translation problem. This paper presents a tree-to-tree neural network for translating programs written in one Programming language to another. Questions/Comments for authors: The current examples are generated using a manually developed rule-based system.
The search space is combination of a set of unary and binary functions. While a new activation function is not exiting, improving basic building blocks is still important for the community. Distribution of learned b in Swish for different layers of a network can interesting to observe. The properties of Swish like allowing information flow on the negative side and linear nature on the positive have been proven to be important for better optimization in the past by other functions like LReLU, PLReLU etc.
That suggests that proportions that are closer to 1:1 are chosen more often than "extreme" partitions, but how? Then it trains (RL) the attacker, and finally trains the attacker and the defender (each a separate model) jointly/concurrently. In fact this should read from levels K to l. All of this leads me to think that a linear baseline is a must-have in most of the plots, not just Figure 15 in the appendix on one task, moreso as the environment (game) is new. • As the authors state, this paper is an empirical evaluation, and the theorems presented are derived from earlier work. And how is this done. This feels a little under-justified. • There are a number of ambiguities and errors which places difficulties on the interpretation (and potential replication) of the experiments. What is meant by this? They should also indicate why this then justifies their proof (namely that phi(S0)-0.5 >= 0.5). The authors could be clearer and more targetted with respect to this question. In ny case:) that 3 random seeds are sometimes not enough to derive strong conclusions, in particular in Figure 9. - In the experimental section, it seems (due transparent coloring in plots, that I understand to be the minimum and maximum values as said in the text in section 4.1, or is that a confidence interval or standard deviation(s)?
This paper investigates human priors for playing video games. Overall, I find this interesting. Given recent advances in RL and ML that eschew all manner of structured representations, I believe this is a well-timed reminder that being able to transfer know-how from human behaviour to artificially-intelligent ones. This issue could be easily fixed. This would give at least some proxy to study the importance of priors about "how video games are generally constructed" rather than priors like "objects are special". This is much more supported by the data, but still I think very particular to this situation. I would recommend that the authors triple the sample size and be more clear about reporting the outcomes in each of the conditions. So it cannot be concluded that the change of performances is due to human priors. My hypothesis would be that performance would fall drastically as semantic priors would quickly lead people in that direction. They conduct a series of experiments that systematically elides visual cues that humans can use in order to reason about actions and goals in a platformer game that they have a high degree of control over. Thus, I think the authors' claim needs to be qualified quite a bit. Considering a simple video game, where an agent receives a reward when she completes a game board, this paper starts by stating that: - Firstly, the humans perform better than an RL agent to complete the game board. Overall: I really enjoyed reading this paper and think the question is super important.
The idea is that in the sample being sequenced there would also be circulating tumor DNA (ctDNA) so such mutations could be captured in the sequencing reads. The paper is well written (up to a few misprints), the introduction and the biological background very accurate (although a bit technical for the broader audience) and the bibliography reasonably complete. In this paper the author propose a CNN based solution for somatic mutation calling at ultra low allele frequencies. Further, I  would also have liked to see the use of standard benchmark datasets for mutation calling ( https://www.nature.com/articles/ncomms10001). If the entire point is to classify mutations versus errors it would make sense to combine their read based calls from multiple reads per mutations (if more than a single read for that mutation is available) - but the authors do not discuss/try that. For example, Snooper which uses a RandomForest  (https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-016-3281-2) and hence would be of interest as another machine learning framework. It appears that the proposed method (Kittyhawk) has a steep decrease in PPV and enrichment for low tumor fraction which are presumably the parameter of greatest interest. Many terms are not defined or defined after being introduced (e.g. CIGAR, MF, BQMQ). Yet Sec. 2 "Results" p. The authors should explore this behavior in greater detail. The method is validated on simulations as well as in cfDNA and is s hown to provide increased precision over competing methods. One more sample is used for testing and an additional cancer control which is not lung cancer is also used to evaluate performance. Finally, performance itself did not seem to improve significantly compared to previous methods/simple filters, and the novelty in terms of ML and insights about learning representations seemed limited. Overall, I rate this manuscript in the top 50% of the accepted papers.
After Mutation section: Remind readers that "N_g" is number of generations This paper proposes an evolutionary algorithm for solving the variational E step in expectation-maximization algorithm for probabilistic models with binary latent variables. This seems a fundamental expression. Why not compare to this?
I still recommend rejection for the paper, and as I said in the first review, the paper is not mature enough. No concrete practical algorithm specification is given (only a couple of ideas to inject noise listed), only a qualitative one on a 2-dimensional latent space in MNIST, and an inconclusive one using the much-doubted Parzen window KDE method. The authors claimed that they used techniques in [6] in which I am not an expert for this.
In the paper, the authors discuss several GAN evaluation metrics. The paper evaluates popular GAN evaluation metrics to better understand their properties. This would not be a surprising result as the ultimate goal of GAN is mimicking the data distribution. Thanks for an interesting paper. This paper introduces a comparison between several approaches for evaluating GANs. The authors consider the setting of a pre-trained image models as generic representations of generated and real images to be compared. I think this paper tackles an interesting and important problem, what metrics are preferred for evaluating GANs. In particular, the authors showed that Inception Score, which is one of the most popular metric, is actually not preferred for several reasons. The "novelty" of this paper is a bit hard to assess. The paper is well written, clear, organized and easy to follow. This paper has some interesting insights and a few ideas of how to validate an evaluation method. If the authors release their code as promised, the off-the-shelf tool would be a very valuable contribution to the GAN community. Specifically, the authors pointed out some desirable properties that GANS evaluation metrics should satisfy. Second, it could benefit from a deeper (maybe theoretical analysis) of some of the questions. They analyzed discriminability, mode collapsing and dropping, robustness to transformations, efficiency and overfitting. However, the result is supported by exhaustive experiments making the result highly convincing.
The authors propose a method for graph classification by combining graph kernels and CNNs. In a first step patches are extracted via community detection algorithms. Finally, it is not also clear to me the what are the communities reported in Table 2 for the  bioinformatics datasets. - In addition to the above point, how are parameters for GR and RW? In contrast, parameters (number of epochs and the learning rate) are tuned in the proposed method. The paper presents a method of using convolution neural networks for classifying arbitrary graphs.
There is a (non-negative) importance weight associated with each state and a collection of states has weight that is simply the product of the weights. This article focuses on the calculation of gradient for write network, and provides some mathematical clues for that. And they give a cute online algorithm for this purpose. This paper proposes one RL architecture using external memory for previous states, with the purpose of solving the non-markov tasks.
This paper describes DReLU, a shift version of ReLU. As a result, the activations outputted by DReLU can have a mean closer to 0 and a variance closer to 1 than the standard ReLU. 2) I believe the control experiments are encouraging, but I do not agree that other techniques like Dropouts are not useful. This paper proposes an activation function, called displaced ReLU (DReLU), to improve the performance of CNNs that use batch normalization. The approach of using BN after non-linearity is termed "standardization layer" (https://arxiv.org/pdf/1301.4083.pdf). Although DReLU's expectation is smaller than expectation of ReLU, but it doesn't explain why DReLU is better than very leaky ReLU, ELU etc. Statistical tests are performed for many of the experimental results, which is solid. The DReLU is supposed to remedy the problem of covariate shift better.
I agree that in practice this effect can be mitigated at that the strategy can be correct in the contextual case (but then I'd like to the dependancies on x to be clear) Some rewriting is needed there to make this paper better understandable in my opinion. It is clearly not sufficient to me, as it does not gives insights about why such proposal is done. 2 using eq. 3 and 6" => "and 4". * As an example using O(1000) and O(1M) in the figure one. The only positioning argument that is given in that section is the final sentence "In this paper we model measurement noise using a Gaussian model and combine it with a MDN". My other concerns of this paper include: 1. It looks like the training data uses empirical CTR of (t,c) as ground truth. * The papers never mentions whats is a scalar, a vector or a matrix. An other option would be to use some counterfactual estimates (See Leon Bottou &all and Thorsten Joachims &all) * None of the experiments is done on public data which lead to an impossible to reproduce paper
The paper proves the separation by constructing a very specific function that cannot be approximated by 2-layer networks. There is nothing new technically in the paper and I find the results uninteresting given the spate of results of this kind. The paper shows that there are functions that can be represented by depth 3 sigmoidal neural networks (with polynomial weights and polynomially many units), but sigmoidal networks of depth 2 with polynomially bounded weights require exponentially many units.
This is an experimental/methods paper that proposes a new algorithm, explained only in general details, and backs up it up with two reasonable experiments (that do a good job of convincing me of point (1) above). This paper would be much stronger if it offered some way to exploit this connection. Originality: this paper introduces block diagonal matrices to structure the weights of a neural network.
The paper focuses on two topics: 1.  Developing a general formalism for neural computers which includes both the Neural Turing Machine (NTM) and the Neural Random Access Machine (NRAM), as well as a model for providing partial supervision to this general architecture. This is not obvious from Appendix B either.
On the positive side, it is nice to read a paper that focuses on understanding what an agent is learning. But, it also could mean that their technique acts differently for equivalent situated and non-situated models. It's interesting that the encoder is actually a BOW model. By adapting experimental methodology from psychology to test that have been used to understand and explain the internal workings of the mind, the authors approach the problem in a novel and innovative manner. Concerning the attention analysis, it seems to me that all it's saying is that lower layers of a CNN detect lower-level properties such as colors, higher layers detect more complex properties, such as shapes characterizing objects. This, however, is not addressed in the paper. 5. The section on layerwise attention claims to give a "computational level" explanation, but this is a misleading term to use — it is not a computational level explanation in the sense introduced by David Marr which is the standard use of this term in cognitive science. They examined a few key phenomena: shape/color bias, learning negation concepts, incremental learning, and how learning affects the representation of objects via attention-like processes. It would be better to report proportions. One analysis that would have helped convince me is a comparison to an equivalent non-grounded deep learning model (e.g., a CNN trained to make equivalent classifications), and show how this would not help us understand human behavior. - propensity to select o_2: rather o_1?
However, when RL is applied to navigation problems it is tempting to evaluate the agent on unseen maps in order to assess weather the agent has learned a generic mapping & planning policy. I therefore recommend not to accept this paper in its current form. Second, the title of the submission, "Do Deep Reinforcement Learning Algorithms Really Learn to Navigate" makes a broad statement [e] that cannot be logically invalidated by only one particular set of experiments on a particular model and environment, particularly since it directly targets one specific paper (out of several recent papers that have addressed navigation) and one specific architecture from that paper, NavA3C+D1D2L (incidentally, not the best-performing one, according to table 1 in that paper). By the way to me results presented in figure 5 are not enough to claim that the agent trained on random map is implementing a purely reactive wall-following strategy.
- The papers lacks a more in-depth theoretical analysis. This paper investigates the effect of adversarial training. - The visualizations of universal perturbations as they change during AT are nice. The robustness results in the paper are interesting and seem to indicate that interesting things are happening with adversarial training despite adversarial training not fixing the adversarial examples problem.
15) This work is related to (though clearly different)  that of LISTA (Learned ISTA) type of networks, proposed in: Gregor, K., & LeCun, Y. This is particularly critical in super-resolution as to apply the algorithms to videos and reconstruction time is vital. This requires better discussion and examples.
Just because a network performs averaging of different paths and individual paths perform worse than sets of paths doesn't imply that ensembling as a mechanism is in fact the cause of the performance of the entire architecture. Why not adopt it in CrescendoNet? Hence, using ensembling in deep networks is not a significant contribution. CrescendoNets do not extend beyond this design principle.
And crudely speaking, you can think of a class weight to be the expectation of its sample weights and you will end up in a similar setup. In Line 3 of the paragraph below Equation 5, "classe" should be "class". 2) comparisons to using normal AdaBoost on more complex methods haven't been studied (other than the MNIST)
There is no (multiplicative) gating as in Highway Networks. I do not understand why we would like to assume (1), (2), (3).
These results are in line with several of the observations made by Zhang et al (2017), which showed that neural networks are able to both (a) fit random data, and (b) generalize well; It seems to me that this particular use of "learnability" is original, even though PAC learnability was defined a while ago. Review Summary: The primary claim that there is "a strong correlation between small generalization errors and high learnability" is correct and supported by evidence, but it doesn't provide much insight for the questions posed at the beginning of the paper or for a general better understanding of theoretical deep learning. Further, the evaluations in Tables 3-6 need more attention since we are interested in the TLP=1 vs. - Helps explain one way in which large networks are in fact "simple" A small network (N1 = 16 neurons) with low test accuracy results in a low learnability, while a large network (N1 = 1024 neurons) gets a higher test accuracy and higher learnability.
Summary This paper introduced a method to learn a compressed version of a neural network such that the loss of the compressed network doesn't dramatically change. It is necessary to employ the proposed method on benchmark datasets to verify its effectiveness, e.g., ImageNet. 1.
This is, i beleive, the field of "statistics" or "probability" for correlated variables. * http://iopscience.iop.org/article/10.1088/0305-4470/27/6/016/meta * https://arxiv.org/pdf/q-bio/0701042.pdf * http://www.lps.ens.fr/~derrida/PAPIERS/1987/gardner-zippelius-87.pdf * http://iopscience.iop.org/article/10.1088/0305-4470/21/1/030/meta
Cons: * Not a clear paper As a result I kind of question the impact of this result. For example, the new energy function in equation (4) larges achieves similar goal as the original energy (1) proposed by Zhao et. Based on its incremental nature and weak experiments, I'm on the margin with regards to its acceptance. Quality and significance: This is quite a technical paper, written in a very compressed form and is a bit hard to follow.
While some of the proposed regularizers are applied to weights, most are applied to hidden representations of neural networks. I find this worrying -- is there a case (in these datasets that have been around for so long and so widely tested), there is a commmunity-wide hill climbing on the test set Noise introduced in the process is not due to a faulty channel but due to the quality of the learned representations themselves.
Another broader question I have is in the distinction between lower and upper layers (those referred to as "feature extracting" and "classification" in this paper). For example, to distinguish MNIST 1 vs 7 vs 9, it is most important to see the top-left:  whether it is empty, has a horizontal line, or a loop. Heuristics for distributing connections among windows/groups and a measure called "scatter" are introduced to construct the connectivity masks, and evaluated experimentally on CIFAR-10 and -100, MNIST and Morse code symbols. But here it seems just to indicate the number of "CL" layers: 2. I've described many of the points I was confused by in more detailed comments below.
In particular, the paper presents a counterargument to "How NOT To Evaluate Your Dialogue System..." where Wei et al argue that automatic metrics are not correlated or only weakly correlated with human eval on dialogue generation. iii) About the scatter plot Figure 3, the authors should include more points with a bad metric score (similar to Figure 1 in Liu 2016). 4. The paper's conclusion naturally suggests the question of whether these results extend to more difficult dialog generation datasets. 3. What happens to the correlation coefficients when exact reference matches (a significant component of the highly-rated upper right clusters) are removed?
What is the size of the database?
The clustered representations are the visual concepts. The used Visual Concepts (VCs) were already introduced by other works (Wangt'15), and is not a novelty. Positives: - The three properties of visual concepts described in the paper are interesting. The paper is very easy to follows, and the results are explained in a very simple way. My main concern for this paper is that the description of the Visual Concepts is completely unclear for me.
- What is a "sequence-level variant of CTC"? - I am confused by the references in the caption of Table 3 - surely the Waibel reference is meant to be for TDNNs (and should appear earlier in the paper), while p-norm came later (Povey used it first for ASR, I think) and is related to Maxout There are also quite a few misspellings. [8] A Graves, A Mohamed, G Hinton, Speech recognition with deep recurrent neural networks, 2013 In the last paragraph of section 3.2, why is there a huge difference in real-time factors between the clean and other set? - what is the relationship of the presented ASG criterion to MMI? Discriminative training is not invented to overcome the lack of manual segmentations, and is equally applicable to the case where we have manual segmentations.
It's also difficult for me to understand how this interacts with the other terms in the objective (quantization error and loss). B(i) is discrete. The update rule seems to be clearly wrong. (2) The introduction and related work are well written.
The reason I have decided not to raise it beyond that, is that I still feel that for a paper like this, which studies an existing technique in detail, the experimental side needs to be significantly stronger. This increased robustness is definitely useful and I think this is also adequately demonstrated in the experiments.
Will this work in larger domains? But the experimental validation of the approach is a bit thin, and I'm not ready to accept the paper in its current form. Only based on this signal? What is the distribution of rules in those sums?
This is compared to 25 rollouts of MCTS that make the decision for the baseline. This seems risky, and I suspect that UCB and more statistically principled approaches would be more robust in this regard? This paper designs a deep learning architecture that mimics the structure of the well-known MCTS algorithm. In overall, it is a nice idea to use DNN to represent all update operators in MCTS. I know that many of them can be solved by A* search with a decent heuristic. The authors propose to train this using policy gradient in which data of optimal state-action pairs is generated by a standard MCTS with a large number of simulations. I'm a bit worried about the idea of learning to trade off exploration and exploitation. I find it difficult to understand the details of the experimental setup, and maybe some of these experiments are reported. I enjoyed reading this paper. If I understand them correctly, the comparison is between a neural network that has been learned on 250,000 trajectories of 60 steps each where each step is decided by a ground truth close-to-optimal algorithm, say MCTS with 1000 rollouts (is this mentioned in the paper). I suspect that generating the training data and learning the model takes an enormous amount of CPU time, while 25 MCTS rollouts can probably be done in a second or two.
If that is not the case, Significance: There is some value in the experimental results, and it's great to see you were able to find bugs in existing methods.
The structured deep-in factorization machines allow higher-level interactions in embedding learning which allows the authors to learn embeddings for heterogeneous set of features. The authors introduced a new compatibility function between features and, as in the skipgram approach, they propose a variation of negative sampling to deal with structured features. This paper provides a clean way of learning embeddings for structured features that can be discrete -- indicating presence / absence of a certain quality. Comments: The paper is well written and addresses an important problem of learning word embeddings when there is inherent structure in the feature space. ---------- OVERALL JUDGMENT The paper is not clear and thus I am not sure what I can learn from it. Perhaps the authors should consider combining the two papers into one complete paper? SUMMARY. The paper presents an extension of word2vec for structured features. Finally, the most striking flaw of this paper is the lack of references to previous works on word embeddings and feature representation, I would suggest the author check and compare themselves with previous work on this topic.
Two proposals in the paper are: (1) Using a learning rate decay scheme that is fixed relative to the number of epochs used in training, and The second motivation, w.r.t. IB seems interesting but this should be empirically motivated(e.g. figures) in the subsection 2.1, and this is not done. Finally, extracting features is mainly useful on ImageNet (for realistic images) and this is not reported here. I am not sure how to interpret this paper. Furthermore, this supervised technique is only compared to unsupervised or predefined methods, which is is not fair and the training time of the Scattering Transform is not reported, for example.
The paper doesn't frame the work in prior research at all and the six papers it cites are only referred to in the context of describing the architecture. Presenting sequential data in a windowed format is a standard procedure and not a new idea either. In this sense, further elaborations from that perspective would be very beneficial since some networks already employ such a mechanism. The paper describes how existing methods are applied to a specific data set. Figure 2 indicates that reconstructing fewer dimensions of this dataset leads to lower MSE scores.
The paper proposes a feature learning technique for molecular prediction using reinforcement learning. The inability to choose the optimal number of atoms is a major drawback of the method, and the experimental section could be improved. This paper also would probably be more suitable for a chemoinformatics journal, where the rationale learning would be highly appreciated. Both parts are based on conv nets for molecular graphs, and this framework is a kind of 'self-supervised' scheme compared to the standard situations that the environment provides rewards. Also, it is widely known that we can even perform a wrapper approach for supervised learning from graphs simultaneously with searching all relevant subgraphs as seen in Kudo+ NIPS 2004, Tsuda ICML 2007, Saigo+ Machine Learning 2009, etc. The model is experimented on two small datasets of few thousand of molecules, and compared to a state-of-the-art DeepTox, and also to some basic baselines (RF/SVM/logreg).
2. On-line settings to train parameters ( guaranteed convergence in a single pass of the data) ( As proposed model is a deep model, the lack of comparison with deep methods is dubious) What is the interest of predicting baseline (or 6 months at best) cognitive scores (relatively low-cost and part of any routine clinical assessment) from brain imaging data (high-cost and not routine)? This work proposes a multi task learning framework for the modeling of clinical data in neurodegenerative diseases. If this is due to space limitation in the main text, they may want to provide a complete proof in the appendix. Conclusion: Though with a quite novel idea on solving multi-task censored regression problem, the experiments conducted on synthetic data and real data are not convincing enough to ensure the contribution of the Subspace Network. For this reason the Gaussian assumption for the cost function used in the method is still not appropriate for the proposed application. Other remarks. - In section 2.2 and 4 there is some confusion between iteration indices and samples indices "i". In particular, due to the nonlinear nature of (1), all the competing linear models are expected to perform poorly in this kind of setting.
The authors tackle the problem of estimating risk in a survival analysis setting with competing risks. - One of the main motivations of the authors is to propose a model that is specially design to avoid the nonidentifiability issue in an scenario with competing risks. - The competitive gain of the authors method in comparison with other competing methods is minor. This paper introduces siamese neural networks to the competing risks framework of Fine and Gray. However, afterwards the objective does combine time-dependent discrimination indices of several competing risks, with different denominator values.
For example, just say "We distill a parent model to a child model with a subset of the labels." There are some symbols in the legend that do not appear in the graph, and others (baselines only) that appear multiple times, but it is not clear what they represent. The proposed approach is simple and easy to understand.
1) those independent transformations; and 2) inverse transformations that map data from transformed distributions to their corresponding canonical distribution. Another direction I think would be interesting, is how few examples are needed in the canonical distribution? The different handwriters of the digits, and sampling and scanning process, may themselves constitute in-the-wild transformations that might be inverted to single (or few) canonical examples --- Is this possible with this mechanism? Are the samples from the canonical distribution always available in practice?
What is interesting about other recent theoretical works, which show (subject to various assumptions) that local minima are roughly equivalent to the global minimum, is that they compare local minima across all regions of the parameter space and show they are similar. Part (1) of this corollary is obvious. Most seriously though, Part (3) only considers critical points (i.e., derivative equal to zero), not local minima occurring at non-differentiable locations.
The novelty in the paper is implementing such a regression in a layered network. Notes to authors: I'm not familiar with 3BE but the fact that it is used outside of its intended use case for the stock data is worrying. The width of the network is bounded by the two input distributions, so is this network just incredibly deep? This is an intriguing paper on running regressions on probability distributions: i.e. a target distribution is expressed as a function of input distributions.
The paper tries to build an interpretable and accurate classifier via stacking a supervised VAE (SVAE) and a differentiable decision tree (DTT). Moreover, I like the qualitative experiment (Figure 2) in which the tree is used to vary a latent dimension to change the digit's class. However, I understand that there have been various work on probabilistic decision tree, Bayesian decision tree, and Mondrian tree.
I(C;Y) = H(Y) - H(Y|C). In that case, the representation of I(X;Y) in terms of entropies is not valid Moreover, why is it a good idea to _minimize_ I(C;Y) in the first place?
However, we strongly recommend keeping the paper at 8 pages, plus 1 page for the references and as many pages as needed in an appendix section (all in a single pdf). Consequently my overall impression is that this work is not yet ready for acceptance to *CONF*. Since the authors are trying to address a problem that does not actually exist, I am not sure what the contributions of the paper are.
The proof states that Y -> T -> X forms a Markov chain, but this implies that T is a function of
Strengths: - Generating graphs is an interesting problem, and the proposed approach seems like an easy-to-implement, mostly reasonable way of approaching the problem. The main challenges of generating graphs as opposed to text or images are said to be the following: (a) Graphs are discrete structures, and incrementally constructing them would lead to non-differentiability (I don't agree with this; see below) Based on this motivation, the paper decides to generate a graph in "one shot", directly  outputting node and edge existence probabilities, and node attribute vectors. A downside to the algorithm is that it has complexity O(k^4) for graphs with k nodes, but the authors argue that this is not a problem when generating small graphs. Experimentally, generative models of chemical graphs are trained on two datasets. This work proposed an interesting graph generator using a variational autoencoder. No baseline results are presented. A cross entropy loss is developed to measure the loss between generated A, E, and F and corresponding targets. However, there are some significant weaknesses. I would have at least liked to see a comparison to a method that generated SMILES format in an autoregressive manner (similar to previous work on chemical graph generation), and would ideally have liked to see an attempt at solving the alignment problem within an autoregressive formulation (e.g., by greedily constructing the alignment as the graph was generated). Moreover, the notations are a little confusing. d) the graph matching procedure proposed is a rough patch for a much deeper problem People do this all the time with sequence data and non-differentiability is not an issue. - some of the main issues with graph generation are acknowledged (e.g. the problem of invariance to node permutation) and a solution is proposed (the binary assignment  matrix) b) the boundaries between a feasible and an infeasible graph are sharp: one edge or one label can be sufficient for acting the transition independently of the graph size, this makes it a difficult task for a continuous model. Qualitative results and ELBO values are reported as the dimensionality of the embeddings is varied.
To sum up, I can not recommend the paper to acceptance, because (a) an important baseline is missing (b) there are serious writing issues. In summary, I'm not convinced that the fact that ML optimizes a different objective than the blue score is a problem with the ML estimator. For example, 1.1 The q(.|.) distribution in Eq. In addition, I don't see at all why this discrepancy is a discrepancy between training and testing data. Unfortunately, I do not understand main points made in this paper and am thus not able to give an accurate evaluation of the technical content of this paper. From the context, I guess the authors mean "empirical training distribution"? First, the model is *not* trained on the true distribution which is unknown. (b) Sampling distribution discrepancy: The model is trained using samples from true distribution but evaluated using samples from the learned distribution Some minor comments: 1. In page 2, 6th line after eq (1), "… these two problems" --> "… these three problems" 1. The idea is a good one and is great incremental research building on the top of previous ideas. (b) Experimental Results 2. The performance of the proposed method is not significantly better than other models in MT task. Crucially, there is no comparison to a trivial linear combination of ML and RL, which in one way or another was used in almost all prior work, including GNMT, Bahdanau et al, Ranzato et al. The paper does not argue why alpha divergence is better that the aforementioned combination method and also does not include it in the comparison.
It is definitely surprising that a simple method like this ends up working this well. This indicates that common heuristics to divide capacity over the layers of a network are suboptimal, as they tend to put most parameters in later layers.
The contribution of this paper is of two-fold: 1) the authors extend the results from Cortes's paper to derive a new surrogate objective function, and 2) they show how this objective can be approximated by f-GAN techniques. So I find it a bit misleading to suggest that the learned policy are not being improved when the logging policy is more deterministic. To exactly calculate \\lambda either requires the size of the policy class (when the policy class is finite), or the complexity constants (which exists in C_1 and C_2 in equation 7, but it is not clearly defined in this paper).
Finally, for small networks, they formulate finding linear regions as solving a linear program, and use this method to compute the number of linear regions on small networks during training on MNIST The improved lower bound given in Theorem 6 is very modest but neat. Overall, while the paper is well written and makes some interesting points, it presently isn't a significant enough contribution to warrant acceptance. **************** I had reduced my score based on the observation made by Reviewer 1 regarding the talk Montufar at SampTA. Here it would be interesting to run more experiments to see how the number of regions might relate to the quality of the trained hypotheses.
The authors propose to combine nonlinear bijective transformations and flexible density models for density estimation. Most results in the paper are comparisons of toy conditional models. Whilst the paper provides no definitive solutions, this is not the point of the work which seeks to provide a description of a general class of potentially useful models.
This is clear in Fig. 1 and in the explanation in Sect. Quality and significance: The proposed method is a combination of the binarised neural network (BNN) architecture of Courbariaux et al. (2015; 2016) with a network growing scheme to reduce the number of bits per weight.
This randomization does not account for the many experiments that were required to find this range. While I believe that raising this issue is important and that the method proposed is a step in the right direction, I have a number of concerns which I will list below.
- The Gaussian relaxation (Eq. (2) and (3)) defines a particular length scale, \\sigma. This is a great paper and should be accepted. The paper is well-written, with clear explanations of the desired properties of the model and a concise set of experiments that are easy to follow. Specifically, the paper builds on a a geometrically inspired embedding method using box representations. This paper presents a novel, theoretically well-justified idea with excellent results, and is likely going to be a high-impact paper. The paper should clarify that the \\prod in 3.3. The paper does not comment on running times, some kind of scalability comparison should be included since the paper claims that the model is easier to train. The key contribution of the paper is facilitating optimization of these models by gradient based methods, which eventually leads to improved accuracy on relevant benchmark data (on par or beyond SOTA).
As a minor note, "generalization accuracy" as a term is not that common and might be a bit confusing, so it is better to write "test accuracy". It can be summarized that there exists a sparse network that can be trained well only provided with certain weight initialization.The winning tickets can only be found via iterative pruning of the trained network. My comment here is intended to be constructive criticism, I think that the paper has enough "juice" and novelty for being accepted The paper thoroughly investigates the existence of such "winning-tickets" on MNIST and CIFAR-10 on both, fully connected but also convolutional neural networks. Are they a consequence of batch-wise, gradient-based optimization, or an inherent feature of neural networks, or is it the loss functions commonly used, …? Is it because the original initialization is not far from the pruned solution?
Given (variance scaled) initial weights, SNIP finds the architecturally important parameters in the network, then the pruned network is established and trained in the standard way. My main concern is that paper differentiates between weights and connections (both terms are introduced on page iv to differentiate from earlier work). - df/dc = df/d(cw) d(cw)/dc = df/d(cw) * w - How does it compare to a distillation - it does not involve many cycles of retraining and can speed up inference time too It is worth pointing out that [1] is also discussed in one of the other citations of this work, namely [2]. Please relate to it. Fundamentally, if you decouple weight pruning from initialization it also means that: - the first layer will be pruned out of connections to constant pixels (which is seen in the visualizations), this remains meaningful even after a reinitialization Finally, I liked the paper and wanted to give it a higher score, but reduced it because of the occurrence of many broad claims made in the paper, such as: 1) method works on MNIST => abstract claims it generally works on vision datasets Thus we can trivially remove connections, without removing weights. In experiments they show that this method can offer competitive results while being much simpler to implement than other methods in the literature. In fact OBD uses a diagonal approximation to the hessian, which is computed with complexity similar to the gradient, although it is typically not supported by deep learning toolkits. Clarity: Well written, easy to follow Authors introduce  a criterion to be used for identifying important parts of the network (connection sensitivity), that does not depend on the magnitude of the weights for neurons: they start by introducing a set of binary weights (one per a weight from a neuron) that indicate whether the connection is on or off and can be removed.
I have several concerns about the paper: 1. It is necessary to explain why the second-stage VAE can have its latent variable more closely resemble N(u|0,I). (1) I would mention [2] which in a way used a very similar approach, where the aggregate posterior of the implicit generative model was modeled with a separate implicit generative model. I believe it has the potential to provide strong value to the community interested in using VAEs with an explicit and simple parameterization of the approximate posterior and likelihood as Gaussian.
These include identifying a matching face in a set of faces (1,2 or N faces) for a given voice, or vice versa. In my opinion, this calls into question the hypothesis that what drives the improved performance is the fact that these models are trained to predict the covariates. - Table 4 - column ID results are not convincing (maybe are not clear for me). Authors aim to reveal relevant dependencies between voice and image data (under a cross-modal matching framework) through common covariates (gender, ID, nationality). It does, however, require inputs that are labeled with the same covariates across modalities.
I also find the claim of section 4.1 to be a bit mis-leading because it is claimed that weight decay applied with SGD and batch normalization only has benefits due to batch-norm dynamics, and not due to complexity control even though in Fig 2 and 4, there is a noticeable difference between training without weight decay, and training with weight decay only on last layer. If the authors mean that regularization just changes the learning rate in some case, that is true.
However in the actual model, the authors make a sequence of variational approximations -- (a) reduction of eq2 to eq1 with a variation lower bound on posterior p(c|c,\\tau) and then replace the prior p(c) with q(c|c,\\tau) in eq 5. The idea of using directed information for GAIL is novel and very interesting. This amounts to learning the option segments and the policies simultaneously. * The paper is very well-written the goal and motivation of the paper is quite clear. There are much more complicated and modern continuous control environments such as control suite [1] or manipulation suite [2]. Hence the directed info flow is required to solve the problem.
The authors propose a novel method for learning graph convolutional networks. This is a very good paper. This paper proposes to use a Lanczos alogrithm, to get approximate decompositions of the graph Laplacian, which would facilitate the computation and learning of spectral features in graph convnets. - what is the complexity of the proposed methods? The authors propose two ways to include the Lanczos algorithm.
This makes the contribution of this paper in terms of the method hard to judge. that can or that did discover? The authors propose a scheme based on a graph representation of the robot structure, and a graph-neural-network as controllers. However, the original performance of the hand-engineered design is surprisingly bad (see first data point in any plot in Figure-4). This is rather subject, and I would tend to disagree. using ES. Given that, the novelty of the paper is fairly incremental as it uses NerveNet to evaluate fitness and ES for the main design search. Moreover, the same limitations that apply to other algorithms to make them successful, in my opinion, apply to your proposed algorithm (e.g., difficulty to move from simulated to real-world). The most popular approach to doing this has been evolutionary methods which work by evolving morphology of agents in a feed-forward manner using a propagation and mutation rules. #3 is so generic that a large part of the previous literature on the topic fall under this category -- not new. The results in this paper are impressive, and the paper seems free of technical errors. speed up what? why is this a trade-off? Overall, this is a reasonable paper but experimental section needs much more attention. - Sec 4.1:  would argue that computational cost is rarely a concern among evolutionary algorithms. - The digression at the bottom of the first page about neural architecture search seem out of context and interrupts the flow of the introduction. This expedites the score function evaluation improving the time complexity of the evolutionary process. This baseline can be thought of a shared parameter graph with no message passing. The approach is evaluated only in three cases: fish, walker, cheetah.
Or put it another way, this is a hyperparameter that the authors can tune to match their chosen benchmarks. The authors address this with  an analytical method to predict the number of mantissa bits needed for partial summations during the forward, delta and gradient computation ops for convolutional and fully connected layers. This is surprising to me, as quantization is usually modeled as _adding_ noise, leading to an _increase_ in variance (Mc Kinstry et al. 2018), so this is a nice counterexample to that intuition. The authors should make this more clear. Having said this, I appreciate the authors' effort in formally studying this problem.
General: In general, this is a well-written paper. Authors propose to augment a conditional GAN model with an unsupervised branch for spanning target manifold and show better performance than the conditional GAN in natural scene generation and face generation. 2. In the paper authors claim that skip connection makes it harder to train the longer path, which is kind of contradictory to what is commonly done in tasks of image classification, semantic segmentation and depth estimation. %%%%%%%% After rebuttal %%%%%%%% I appreciate authors' efforts to address my comments and am satisfied with their response. i.e. optimizing the high-dimensional covariance matrix seems a problem to me. Different components of the final loss function can be removed and analyzed one at a time! To achieve robustness, the authors replace the single pathway in the generator with two different pathways that partially share weights.
- In page 8 (discussion following Theorem 3) the claim - I believe the cardinality of Q should be (K + D - 1) choose (D - 1), as we need to choose positive j's to sum up to (K+D) in the definition of Q. Finally {\\bf Theorem 3} is presented, which provides a lower bound for the Rademacher complexity of a class of neural networks, and such bound is compared with existing lower bounds. In summary, I think this is a strong paper. - The paper is readable and the notation is consistent throughout. - The problem studied is not new, but to my knowledge the presented bounds are novel and the concepts of capacity and impact are new.
In this work, they study the convergence behaviors of a wide array of ML models and algorithms under delayed updates, and propose a new convergence analysis of asynchronous SGD method for non-convex optimization. Does it mean that it is a grid network?
This work is appropriate for *CONF*. This is a hybrid paper, making contributions on two related fronts: 1. the paper proposes a performance metric for sequence labeling, capturing salient qualities missed by other metrics, and
It is proved that Tucker decomposition of that tensor gives us all words embeddings together with tensor T. The main appeal is the idea of using T to model syntactic interactions, and the algorithm for learning T. One would at least expect an after-the-fact interpretation for the weighted tensor term and what this implies with regard to their method and syntactic embedding compositions in general. Their lack of willingness to ground their claims or decisions is even more apparent in two other cases. Pros: - theoretical justification is given for their assumption that the higher-order interactions can be modeled by a tensor The topic is fitting with *CONF*, and some attendees will find the results interesting.
2. The finding that there are center-surround or asymmetric (non-gabor) RFs in mouse V1 is not novel and not specific to this model (e.g. Antolik et al., 2016). Visual stimuli are presented and the responses of the neurons recorded.
The dataset is then used to evaluate a number of recurrent models (LSTM, LSTM+attention, transformer); these are very powerful models for general sequence-sequence tasks, but they are not explicitly tailored to math problems. I think that the dataset generation process is well-thought-out. Strengths: I am happy to see the proposal of a very large dataset with a lot of different axes for measuring and examining the performance of models. Also, is there an option for "unsolvable"? I view it as borderline, but I'm willing to change my mind based on the discussion. - The authors divide dataset construction into crowdsourcing and synthetic. This paper presents a new synthetic dataset to evaluate the mathematical reasoning ability of sequence-to-sequence models. For example, EMLNP 2017 paper "Deep Neural Solver for Math Word Problems" mentions a size 60K problem dataset. The main contribution is a synthetically generated dataset that includes a variety of types and difficulties of math problems; it is both larger and more varied than previous datasets of this type. A 40-question exam for 16 year olds is probably far too challenging for the current state of general recurrent models. - I didn't understand the motivation for testing only very general-purpose models (this is described in Section 3). The paper is relatively well-written, although the description of the neural models can be improved. - The general methodology of generating questions and ensuring that no question is too rare or too frequent and the test set is sufficiently different---these are important questions and I commend the authors for providing a strong methodology.
The Bayesian GAN defines a posterior distribution for the generator that is proportional to the likelihood that the discriminator assigns to generated samples. This is a somewhat minor point, and should not in anyway influence worth of the paper ... My educated guess is, that this conceptually adds up to the momentum term in SGHMC and thus slows down the exploration of the parameter space and results in better coverage.
This paper is well written. At least this limitation should be pointed out in the paper. Given that you observed that SVHN has higher likelihood on all three model types (PixelCNN, VAE, Glow), why investigate a component specific to just flow-based models (the volume term)? In 3/4 of the pairs the author tried, this phenomenon is not there. Their criteria also accounts for the variance in model log-likelihoods and is hence slightly different.
The authors need to describe in detail the algorithmic novelty of their work. The paper shows that there is an alternating optimization-based algorithm for this problem that under standard assumptions provably converges exactly to the true dictionary and the true coefficients x (up to some negligible bias). [1] Arora, S. Ge, R., Ma, T. and Moitra, A. Simple, Efficient, and Neural Algorithms for Sparse Coding. Also, it is clear in the experiments the superiority with respect to Arora in terms of iterations (and error), but what about computational time?
3)It may be better to mention explicitly that "it is possible to have bad local min" –perhaps in abstract and/or introduction. --In fact, in the 1st round read, I do not have a strong impression of "strict". Also, the statement "one of the following conditions" is unclear. Assumption 3.1.2 says "there exists N neurons satisfying…" and then the first bullet point says "for all j = 1, …, M". 2) Data augmentation. "Note that the rand algorithm cannot be used with data augmentation in a straightforward way and thus we skip it for this part." Why? Apart from its technicality in the proof, the statement of Lemma 3.2 is just as expected and gives me little surprise, because having more than N hidden nodes connected directly to the output looks morally "equivalent" to having a layer as wide as N, and it is known that in such settings (e.g. Nguyen & Hein 17') it is easy to attain global minima.
- fig 1: it's very confusing that the generator, that is described first is represented at the right. Most of it becomes clearer later in the paper - but I feel it would be good to put this into proper context here (or not mention it) Minor comments: - abstract: why is it like "dreaming" -> I do agree with the rest of that statement, but I don't see the connection to dreaming I think this work is a great companion to existing work such as Sketch-RNN and SPIRAL. Original review: Summary: they propose a differentiable learning algorithm that can output a brush stroke that can approximate a pixel image input, such as MNIST or Omniglot. What does this method offer that my description fails to offer? Below are a few of my suggestions that I hope will help the authors improve their work, for either this conference, or if it gets rejected, I encourage the authors to try the next conference with these improvements: 1) multiple strokes, longe strokes. - the entire evaluation of this paper is purely qualitative (and that is not quite very convincing either). This has also been done in [2].
Section 4 is potentially very interesting, but I don't seem to understand why it's good news that TRE correlates with I(x;\\theta). Reviewer 2's comments also remind me that, from a perspective of learning composition-ready primitives, Fyshe et al. (2015) is a relevant reference here, as it similarly learns primitive (word) representations to be compatible with a chosen composition function. While the paper is very clear with respects to results, I found the presentation of the proposed measure overly confusing (and somewhat more exaggerated that what is really going on). However, I feel that clarity is being traded-off for formality. This in an interesting study and attacks a very fundamental question; tracking compositionality in representations could pave the way towards representations that facilitate transfer learning and better generalization. Do the authors think that this restricts their experiments (especially the natural languages ones)? Baroni and Zamparelli (2010) Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space The paper tackles a very interesting problem about representations, especially of the connectionist kind
This could be useful in particular in the following perspective: - Mathematical side note: the "gradient" of a functional is not a uniquely-defined object in that it depends on the metric chosen in the tangent space. It is possible to favor other kind of deformations (not just smooth ones, but for instance rigid ones, etc. The paper introduces an iterative method to generate deformed images for adversarial attack. - for instance, what about generating adversarial examples for which the network would be fully (wrongly) confident? Pros: - The way of constructing deformation adversarial is interesting and novel - the idea of deforming images is new (if we forget about [Xiao and al.]) and simple; Also, the final overshoot factor (1+eta) is not very elegant, and not guaranteed to perform well if tau* starts being not small compared to the second derivative (i.e. g''.tau^2 not small) while I guess that for image intensities, spatial derivatives can be very high if no intensity smoothing scheme is used. Minor: - The paper is a bit nationally convoluted for no good reason, the general idea is straightforward. Here is my back of envelope conversion of 0.59 which is probably off: 299 (# pixels of the smaller axis 299 for the Inception) x 1/2 (image are centered) x 0.59 =  88 pixels - The related adversarial training problem remains largely unaddressed. - The paper is mostly clearly organized and presented. - question: does the algorithm converge? Such seemingly conflicting rules for estimating the deformation makes the proposed method less rigorous in math.
So I do not know which is better and whether I should use this method or use the original STL with flexible posterior distribution to tighten the evidence lower bound. I think author want to point that when K=1, STL is unbiased with respect to the 1 ELBO, but when k>1, it is biased with respect to IWAE estimator. The whole paper is written in a clean way and the method is effective. I know that motivation is a bit different for STL and proposed method but some comparisons are needed. Thus I recommend this paper to be accepted in its current form. I checked all the derivations, and they seem to be correct. This paper applies a reparameterization trick to estimate the gradients objectives encountered in variational autoencoder based frameworks with continuous latent variables. Especially the authors use this double reparameterization trick on Importance Weighted Auto-Encoder (IWAE) and Reweighted Wake-Sleep (RWS)  methods. In Figure 3, the left figure, what each color means?
The reward function is not completely zero-sum, as the tracked agent's reward vanishes when it gets too far from a reference point in the maze. Both agents are standard convnet + LSTM neural architectures trained using A3C and are evaluated in 2D and 3D environments. Experiments are conducted using two baselines for the target agent, one a random walk and another an agent that navigates to a target according to a shortest path planning algorithm. This is in a visual active tracking application. It would be better if some theoretical support can be provided for such design. This paper presents a simple multi-agent Deep RL task where a moving tracker tries to follow a moving target. In addition, the explanation about importance of the tracker awareness to the target network seems not sufficient. A training mechanism in which tracker and the target serve as mutual opponents is derived to learning the active tracker. Originality: Most of the components are pretty standard, however I value the part that seems pretty novel to me - which is the "partial zero-sum" idea.
This work uses progressive bounds tightening approach to determine bounds for inputs to units. In particular, the paper has the following strengths: - Clarity: the paper is well-written and easy to read.
To  alleviate these problems, this paper proposes a novel idea: instead of fully reconstructing in the original space, the authors create reconstructions in projected spaces. Is it possible that any network at all would be okay? This isn't damning, but it seems like the piecewise-constant estimators are a sort of regularizer, and that's where we really get the benefits. This is theoretically motivated by classical work (Omohundro'89) and has the further advantage that the low-res reconstructions are interpretable. The core novelty of this paper is the portion that uses a neural network to calculate a projection onto a random Delaunay triangulation.
The first weakness of the approach is that it assumes that a learned goal-conditioned policy is already available, and that the representation extracted from it can only be useful for learning "downstream tasks" in a second step. But thinking further to the case where goals and states are different (or at least goals are only a subset of states), probably they would end-up with a different intuitive presentation of their framework. The two main flaws in the paper are the lack of details and missing important experimental comparisons. - most importantly, in Section 6.4, 6.5 and 6.6, much too few details are given. Should run and show on a longer horizon. How many clusters and what clustering algorithm? Also, the results described in Fig. 5 are interesting. 2. Use D to estimate a model/goal-directed policies and consequenttly features F. - I found Fig.6 very interesting and useful, very nice visual help. A study of the effect of various optimization effort on these goal-conditioned policies might also be of interest. The main idea is that two states should be distinguished *functionally* in terms of the actions that are needed to reach them, Though the purpose of these works is often to supply for additional reward signals in the sparse reward context, then are often concerned with learning efficient representations such as predictive ones. The idea is novel (to the best of my knowledge), interesting and the experiments seem promising. - in Section 6.3, about the pushing experiment, I would like to argue against the fact that the block position is the important factor and the end-effector position is secundary. typos: p1: that can knows => know p7: euclidean => Euclidean I'm clearly in favor of the first option.
The experimental results are sufficient for simulating liquids/smoke, except I would like to also see a comparison to using deformation field network only, without its predecessor. The precomputed deformations are applied in a recurrent manner. 1. The primary novelty here is in the problem formulation (e.g., defining cost function etc.) where two networks are used, one for learning appropriate deformation parameters and the other to generate the actual liquid shapes. This is primarily an application paper on simulating liquids in controlled scenes using nets and appears novel in that narrow domain. More importantly, it would be very helpful is to try this approach for modeling deforming object and body shapes for which there are many datasets (e.g. Shapenet). The interpolation model composes two components -- given these conditions, it first regresses weights combining a set of precomputed deformation fields, and then a second model regresses dense volumetric deformation corrections -- these are helpful as some events are not easily modeled with a set of basis deformations. This was done for Fig 6, but would be nice to also see it numerically in ablation in Fig. 4. First, it would be good to discuss why the current network design is desired. What is the tradeoff between using more basis for the first network and increasing the complexity of the second network? If that's added it will strengthen the paper. Also, many simulations use adaptive sampling (high-resolution near the surface and low-residual in the interior). For visualization, it would also good to show the 3D grid. The results are impressive from the perspective of the current abilities of deep neural networks. Overall, it is good paper to see at *CONF*. Another useful experiment would be to vary the number of bases and/or the resolution of the deformation correction network and see the effects. 3. In terms of practical applications, to the best of my knowledge there are sophisticated physics-based and graphics based approaches that perform very fast fluid simulations. For example, when designing the first network, can we also design another neural network that applies the deformation backwards and enforce some consistency to improve the results?
From the formulae(eq. (4),(5)), it seems to be that the policy is unaware of the input variables. And in this case it's not clear to me if this would still result in a variance reduction in the policy update. And when we would expect to see a bigger difference. Can you compare to Clavera et al 2018?
Rigor: What are meaningful comparisons for all for the AE and DA portions? The contributions are well described, the limitation of CCA and KL are convincing and are supported by the experimental results. (I appreciate this is a broader topic relevant to the BMI field beyond just this paper, but it would be helpful to get some thinking on this in the rebuttal). Domain adaptation via CCA/KLDM/ADAM. Of course a paper can explore multiple ideas, but in this case the comparisons and controls for both are not adequate.
Periodically compare the validation BLEU score of the multilingual model with that of each individual model, and turn off distillation for language pairs where the multilingual model is better. Did you consider applying sequence knowledge distillation (Kim and Rush, 2016)
The reviewer guidelines (https://*CONF*.cc/Conferences/2019/Reviewer_Guidelines) say that "the overall time to read a paper should be comparable to that of a typical 8-page conference paper. This paper explores an approximate inference solution to the challenging problem of Bayesian inference of phylogenetic trees. This paper is well written, appears to be well executed, and the results look good.
Is it correct assumption? If so, H2 is not (ST−AT)(S+A). Minor Comment: First paragraph in Section 2.2, "It is highly undesirable to converge to Nash in this game" -> Nash equilibria This paper introduces a new algorithm for differential game, where the goal is to find a optimize several objective functions simultaneously in a game of n players. The authors then show the LOLA algorithm (Foerster et al. (2018)) fails to preserve fixed points by explicitly constructing an instance (the tandem game). However, LookAhead does not have the capacity to exploit opponent dynamics and encourage cooperation. Remark D.5 refers to S as the symmetric part of G, and asserts that S is not positive definite.
This work adds to a growing literature on biologically plausible (BP) learning algorithms. The results are generally clear (though there is an incomplete experiment, I agree with the authors that it is unlikely for the preliminary results to change). Instead, I would suggest keeping black (or gray) for backpropagation (the baseline), and then using two hues of one color (e.g. light blue and dark blue) for the two sign-symmetry models. Minor: refs are not homogeneous, first names citations are not consistent. They do not disagree in the sense that this paper also finds that feedback alignment alone is insufficient to train large models on ImageNet. Building off a study by Bartunov et al. that shows the deficiencies of some BP algorithms when scaled to difficult datasets, the authors evaluate a different algorithm, sign-symmetry, and conclude that there are indeed situations in which BP algorithms can scale. These will be enumerated below. - Figure 1: I was expecting to see a curve for performance of feedback alignment on AlexNet I believe that there is enough detail for this work to be reproducible.
This provides a model able to achieve good results on image inpainting and feature imputation tasks. The complexity of data considered is simplistic (and may not make use of the expressivity of the deep generative model). The paper presents a model for learning conditional distribution when arbitrary partitioning the input to observed and masked parts. The question is whether the model can generalize well in this regime? Beyond that: (a) was there any comparison to how classification performance behaves when using another neural network based imputation baseline (e.g. the method in Yoon et. The writing is clear and the model is easy to understand. While not the first model to try to handle modeling data with missing features, it is still a fairly original and elegant formulation. Clarity This is a poorly written paper. Inference in this latent variable model is achieved through the use of an inference network which conditions on the set of "missing" (to the generative model) features. The text describes a heuristic used in learning GSNNs only to say that the loss function used by GSNNs is not used in the experimental section for this paper -- this renders most of 4.3.2 redundant. Table 5 claims negative log-likelihood numbers on MNIST as low as 61 and 41 (I assume nats...).
It is a interesting idea. The approach assumes a distribution on the hyperparameters, governed by a parameter, which is adapted during the course of the training to achieve a compromise between the flexibility of the best-response function and the quality of its local approximation around the current hyperparameters.
(-)  The batch size shown in Table 2 and 3 may be intended to show the batch-independent property of the proposed method, but BN is also doing well in those tables. pros) (+) The authors provide a theoretical ground. The ENorm presentation is 4 pages long (which is quite a lot). A baseline with 1 layer only reaches ~54 % test accuracy and your method needs a 11 layer model to increase this baseline performance of about ~0.5 % only. - Typo: Annex A (on p.5). The authors propose a new regularization method for neural networks. Detailed Comments: 1. Differences with Weight Normalization: I have trouble seeing the difference between the proposed method and Weight Normalization (WN), or the more advanced Normalization Propagation (NP). The method is validated on 3 tasks (MLP on CIFAR10, CNN on CIFAR10, Reidual Network on ImageNet). Conclusion: All in all, I find that this work is a bit too incremental, missing some important comparisons with other techniques and its experimental setup could definitely be improved.
While for \\eta \\in (0, 1) implicit and extrapolation are similar, adding the remark that implicit method is stable for any \\eta > 0 (and therefore can lead to an arbitrary fast convergence) would give a more balanced view. For this reason, the authors suggest using gradients from past as the "extragradient" in the extragradient method. This paper looks at solving optimization problems that arise in GANs, via a variational inequality perspective (VIP). The authors show in a simple example (a bilinear function) these exhibit better performance than Adam and a basic gradient method. By doing so, they are able to profit from the corresponding literature and propose a few methods that are variants of SGD. First are simultaneous updates, and the other is alternated updates. This extra-gradient method is a close approximation to Euler's method, though far more computationally efficient. + The theory for optimization of VIs with stochastic gradients (though only in monotone setting) was very interesting to me and contains some novel results (Theorem 2, Theorem 4)
Thus, one has to be careful when defining the mutual information I(X,Y), which explains the problems with the IB information curve (which should asymptotically converge to I(X;Y) as I(X;T) gets large. Further pros and cons: Pros: - The discussion is generally well written. - A side remark about applying IB to neural networks: What about neural networks that are not a "linear" chain of layers (i.e. most networks now)? - These are demonstrated with experiments conducted on the MNIST dataset for concreteness. The motivation and impact of this work studying deterministic rules is therefore not completely convincing. - The fact that the entire IB curve is not explored point by point by the IB Lagrangian is not necessarily an issue for learning. In practice, besides a few recent propositions (Kolchinsky et al., 2017; Alemi et al., 2016; Chalk et al., 2016) the IB Lagrangian is not a usual objective function for supervised learning. - information bottleneck is a topic of prime interest in the community these days; For instance the T_alpha in equation (5) are not reachable anymore; the optimization space for the IB Lagrangian is different; etc. In particular, I would argue that digit recognition problems like MNIST so not have deterministic labels, since there will always be images of handwritten characters that will give room for interpretation... estimates or lower bounds as here). - they show that for large enough value of beta, zero error is reached. I have not seen these papers cited in the article, nor discussed (nor used); Maybe rephrase some expressions that might be wrongly perceived?
What is more interesting is that a heuristic labeling function is sufficient to label macro-intents that lead to learning realistic basketball offenses and swarm behavior. The generative models are hierarchical, and these latent variables correspond to higher level goals in agent behavior. In general, the paper is well written and the overall framework captures the essence of the problem that the authors are trying to solve.
This paper deals with an interesting problem as learning an interpretable representation in time series data is important in areas such as health care and business. I guess that the optimisation stability may be also quite sensitive to this trade-off, and it would be important to provide more details about this aspect. The clustering is obtained by leveraging on the idea of self-organising maps (SOM). This is one of the best papers I have reviewed in a while. I was curious why not use the clustering accuracy as well? Some concerns/questions as below: 1) As the paper is based on SOM, some illustration of this method would be helpful for readers to understand the idea and learn the major contribution; Within this setting, the data is mapped into a 2D lattice where each coordinate point represents the center of an inner cluster.
agree that the user study could be biased (and that "It would be a tremendous effort to find a completely fair experimental setting"), but, if this is the case, the argument that the method reaches human-level performance is brittle. p. 8: "nearly perfect" -> "nearly perfectly" reimplementations involve some suboptimal choices, relative to the methods used by the originators of those methods.
All this is not to say that the paper is without merit, just that the main claims about exploration are not valid and consequently it needs to be repositioned. (4) Text in legends and axes of Figure 1 and Figure 2 plots is very small. I presume the title of this paper is a homage to the recent 'Boltzmann Exploration Done Right' paper, however, though the paper is cited, it is not discussed at all. Summary: This work demonstrates that, although the Boltzmann softmax operator is not a non-expansion, a proposed dynamic Boltzmann operator (DBS) can be used in conjunction with value iteration and Q-learning to achieve convergence to V* and Q*, respectively. There are also a number of experimental details that are missing. In this case, I find a disconnect between the stated goal (to trade off exploration and exploitation) and the results.
[Summary] This paper proposes a Graph-Sequence-to-Sequence (GraphSeq2Seq) model to fuse the dependency graph among words into the traditional Seq2Seq framework. (6)-(9). This paper proposes a seq2seq model which incorporates dependency parse information from the source side by embedding each word's subgraph (according to a predetermined dependency parse) using the Graph2Seq model of Song et al. (2018); the authors propose two variants for achieving an encoded source-side representation from the subgraph embeddings, involving bidirectional lstms. I think that many NMT researchers will find this work interesting. Motivation and goal are clear. This fact may discourage some readers. In particular, while we might expect the en-de and en-vi results to be good because dependency parsers for English are relatively good, how much does performance degrade when considering languages with less good dependency parsers?
For a fair comparison, the step sizes used for PGD should also be (approximately) tuned. So it is not clear that there is a large gap in difficulty. Why is that? - The authors state that JSMA (Papernot et al., 2016) is one of the earliest works that use gradient information for constructing adversarial examples. The authors provide theoretical guarantees (local convergence) and a broad set of experiments. Finally, the experimental results do not show any significant advantage over PGD, either in running time (they are slower) or norm perturbation. Moreover, it is not clear why PGD is only used for an l_inf comparison and not a l_2 comparison. The proofs provided by the authors assume that convexity and many assumptions, which makes it not very useful for the real world case. At its core, Rosen's algorithm (instantiated for adversarial examples) alternates between moving towards the set of misclassified points and moving towards the original data point (while ensuring that we do not move too far away from the set of misclassified points). The authors spend two paragraphs in the introduction trying to draw a distinction but I am still not convinced. What would have been helpful is to show the accuracy of their margin for simple binary toy 2D problems, where the true margin and their approximation can be visualized.
Is there any strategy helping us to select suitable regularizers for specific tasks? between neurons in different channels? My main concern is that the power of Graph-based regularizer has been well-known in the ML community for a long time. For more challenging cases, how to build the Laplacian graph reasonably? By adding edges one can impose a structure upon nodes in one layer and add for example a Laplacian regularizer rather than simple L2 norm regularizer to force the activations to follow the imposed structure. The authors state that the usual bottleneck for autoencoders is composed of 2/3 Each element in the feature map represents the input surrounding that location in a k dimensional space. Pros: Interesting idea for bringing some benefits of graphical models into Neural Networks using a regularizer.
I found (2) to be a surprising assumption, but it does seem to be supported by the experiments. 3. the use of a multi-way encoding results in a weaker correlation in gradients between models One could train a classification model where the final fully connected layer (C inputs K output logits) were a frozen matrix (updates disabled) of K orthogonal basis vector (ie, the same as the C_{RO}) codebook they propose. I am not familiar with the broader literature in this area, so giving myself low confidence.
This paper considers parameterizing Dirichlet, Dirichlet-multinomial, and Beta distributions with the outputs of a neural network. I think that the authors are on their way to achieving (1), but do not achieve (2). The authors briefly argue that the proposed methods are superior because they provide uncertainty estimates for the output distributions. - It is not clear what the authors are trying to show in section 4.1. As the authors note, parameterizing an exponential family distribution with the outputs of a neural network is not a novel contribution (e.g. Rudolph et al. (2016) and David Belanger's PhD thesis (2017)) and though I have never personally seen the Dirichlet, Dirichlet-multinomial, and Beta distributions used, the conceptual leap required is small. Their transformation from real-valued network output to, say, strictly positive concentration parameters in a Dirichlet are worth studying; but they don't analyze this in any detail. Most of section 2 is dedicated to writing down, simplifying, and deriving gradient equations for these three distributions.
This is an approach that has been tried[1,2] (even with the addition of entropy regularization) and studied [1-5] extensively. Typos: Eq (1) and (2): when taken over the set of all Lipschitz-1 functions, the max should be a sup The paper proposed to use the exact empirical Wasserstein distance to supervise the training of generative model. Cuturi, M., & Doucet, A. (2014, January). Fast computation of Wasserstein barycenters. The bias of the empirical Wasserstein estimate requires an exponential number of samples as the number of dimensions increases to reach a certain amount of error [2-6].
This paper present a study on efficient acoustic modeling using neural networks-based model. The findings presented in this paper are interesting and quite useful when one wants to implement a LSTM-based acoustic model on mobile devices. The evaluation is done on ASR task using WSJ and in phoneme classification task using the TIMIT corpus. 4. A more general comment on the work explored  in the paper. Honestly, I don't even think this performance is better than well-trained GMM-HMM acoustic models using a Viterbi decoder. The paper well describes the problem of the current LSTM, especially focusing on the recurrent connection matrix operations, which is a bottle neck in this scenario, and introduces variants of RNNs (e.g., QRNN).
This paper propose an extension of the Neural Theorem Provers (NTP) system that addresses the main issues of this method. 3) Section 2 on the NTP framework is not very helpful for a reader that has not read the previous paper on NTP (in particular, the part on training and rule learning). I wonder if this would still work for more realistic (and thus longer) sentences. It is a standard and well-known technique to restrict the search to a neighborhood, widely used in any applications of word embedding (e.g. in Khot et el's Markov Logic Networks for Natural Language Question Answering). The argument that performance is given up for interpretability needs more discussion, and the effect of each addition to the system should be discussed as well. However, it seems to me that, in this particular case, these mentions are very short sentences. The contributions of this paper allow to use this model on real-word datasets by reducing the time and space complexity of the NTP model. [Comments] - For reproducibility: it is unclear whether evaluation in FB15k-237 is carried out on the KB+Text, KB, or Text portions of the dataset. Without further explanation, the claim that scores are competitive with SOTA seems unjustified, at least for FB15k-237 since the model performs significantly worse than the baselines which seem to be worse than previously reported. The same can be said for the use of mentions. Minor issues: -Page 1: In particular [...] (NLU) and [...] (MR) in particular, ...
1) First of all, it is hard to say there is a contribution to the idea of sentence discriminator and sentence reader — people have used this framework for large-scale QA a lot. (3) (Cont'd from point 2) Second, the proposed SSL and CSL are not compared with any decent baselines.
- similarly for (I, strategy) - It is not clear how the initialisation (10) is implemented. However, the games that are used for evaluation are very small, in fact I believe they have fewer states than the number of parameters in their network (the number of network parameters is not provided but I assume >1000). (since the mapping from regrets -> strategy is non-linear) As a result, in my opinion this work fails to address the important challenges for function approximation in CFR, namely: - Can function approximation allow for *generalization across infosets* in order to reduce sample complexity of CFR (i.e. an unsupervised abstraction)?
o This is to assess the generalization level of the DiffraNet dataset patterns' fine-tuned classification algorithms to real-life obtained patterns (relates to the previously stated representability of the samples). • Were the pattern images pre-processed in any manner before being classified? Only a limited readership will be interested in this specific problem. Nota: In table 6, use no-crystal class as in Figure 2 for consistency.
The presentation of the new forget gate in "System 2" is clear in terms of being able to implement it, but it's not intuitive to me what this actually looks like.
How are the instructions generated in this task? The first of two modules is responsible for learning a goal embedding of a given instruction using a learned distance function. While this works for the simple environments considered in this paper, it cannot generalize to real-world instruction-following scenarios where the number of distinct goal configurations is too large to tractably enumerate. - The captions for Figures 3 and 4 are copied from Figure 1. - The submission requires proof-reading, there are several typos in the manuscript (some are listed below), some of them make it very difficult to understand the setting.
The work presented in this paper relates to the impact of the dataset on the performance of contextual embedding (namely ELMO in this paper) on many downstream tasks, including GLUE tasks, but also alternative NLP tasks. Training sentence representation in an unsupervised manner is hence crucial for real-world NLP applications. I'm confused by what this means, and how this is different from just training on that task. Only a handful of NLP tasks have an ample amount of labeled data to get state-of-the-art results without using any form of transfer learning. This paper represents an impressive amount of experimentation. Minor details: Page 1: "can yield very strong performance on NLP tasks" is a very busy way to express the fact that Sentence Encoders work well in practice. Contextualized word representations have gained a lot of interest in recent years and the NLP and ML community could benefit from such detailed comparison of such methods. One clarification question I have is about what the "Single-task" pre-training means. I do understand the computational limitations of the authors (as they mention on HYPERPARAMETER TUINING) and I do agree with their statement " The choice not to tune limits our ability to diagnose the causes of poor performance when it occurs". This paper's biggest strength is the experimental setting. The field evolves quickly and ELMO has now a competitive models called BERT (arXiv.org > cs > arXiv:1810.04805).
The submission proposes to increase the variety of generated samples from GANs by a) using an ensemble of discriminators, and b) tasking them with distinguishing not only fake from real samples, but also their fake samples from the fake samples given to the respective other discriminators. 1. What is the equilibrium of the proposed objective? Different schedules are demonstrated, but optimality of either is not guaranteed. - MicroGAN does not compare favorably to many of the compared to methods in Table 2. The inception score and FID of the proposed approach clearly lack behind state-of-the-art approaches.
- SupportNet is a method to use some of the previous data. Additionally, they show that overfitting for the real training data (a chosen subset of old data and the new data) is a problem for the competition iCaRL and affects SupportNet to a much lesser degree. (3) In section 2.1 Deep Learning and SVM: In the line before Eq. 4. (-) Lack of related work on recent catastrophic forgetting - What kind of NNs is used for each dataset? (-) Limited comparing results (-) Limited analysis of feature regularizers
The agent is given an additional shaping reward that penalizes it for violating these constraints. In fact, this seems like analysis that several other works have done for a very similar problem (see below). This approach assumes that the developer has knowledge of what are good/bad behavior for a specific task and that the behavior can be checked by hand-coded DFAs or PDAs. McIlraith. "Decision-making with non-markovian rewards: From LTL to automata-based reward shaping." In Proceedings of the Multi-disciplinary Conference on Reinforcement Learning and Decision Making (RLDM), pp.
Likewise for Tables 3-6. 3. Under this interpretation of the tables---again, correct me if I'm wrong---the proper comparison would be "IEA (ours)" versus "Ensemble of models using CNL", or  "(m=3, k=1)" versus "(m=1, k=3)" in my notation. Secondly, only MNIST and CIFAR-10 is not convincing that this structure change will be widely useful. The author claims using this IAE op is able to improve CNN classification performance. Is the performance boost greater than simply using an ensemble of m networks directly (resulting in the equivalent number of parameters overall)? This fundamental idea of ensembles combined with simple functions has been explored in detail in Maxout (Goodfellow et. In addition, there are a number of non-image settings where CNNs are used (text or audio), and showing this idea works on multiple domains would also be good. - and again, comparisons to activations learned by Maxout and followups would make this inspection much stronger. In any case, the lack of data augmentation may account for this disparity, but can easily be remedied.
In the meanwhile, the proposed approach learns the encoding and the decoding for the architecture characteristics. They show better Cifar10 results than a few baselines - I am not aware whether this is SOTA for that parameter budget, and the authors do not specify. Having a huber loss with scale 1 for this part of the loss function was also surprising, it would be good to have some justification for this (ie, what range are the p^* values in for typical networks?) In summary, I think this paper is not ready to be published. This seems to preclude even basic architectural advancement like skip connections / ResNet - the authors even mention this in section 3.1, and point to experiments on resnets in section 4.4, but the words "skip" and "resnet" do not appear anywhere else in the paper. Surely the fact that the architecture is represented as a 5xT tensor, and practically there are upper limits to kernel size, stride etc beyond which an increase has no effect, already implies a finite space? It's not obvious why there's not just a 'normal' monotonic decrease.
It is more difficult to measure output quality for such attacks, but that doesn't seem like a good reason for excluding them from what is intended to be a general framework. Finally, they show that adversarial training with the attack most consistent with the introduced meaning-preservation criteria results in improved robustness to this type of attack without degradation in the non-adversarial setting. The paper proposes two ways of achieving that: (a) kNN - substituting word with nearest neighbors from the word embedding space, and (b) character swapping. A first experiment measures correlation with human judgements of similarity between original and perturbed sentences, and concludes that chrF is better than BLEU and METEOR for this purpose. (c) No separate section 3.1.2 required as it can be merged with 3.1.1 and would be more easy to understand without confusing the readers that there's some context change.
Based on this reason, I think the main contribution of this paper is the discussion on two novel learning settings, which related to the super-classes. However due to the omission of key references and incomplete comparison to prior work, the paper is not suitable for publication in its current form. This paper proposes a new soft negative log-likelihood loss formulation for multi-class classification problems. POOR WRITING The paper is difficult to follow, with confusing notation and many spelling and grammatical errors. The proposed method instead constructs a target distribution which places probability mass not only on leaf category nodes but also on their neighbors in a known semantic hierarchy of labels, then penalizes the KL-divergence between a model's predicted distribution and this target distribution.
Weaknesses: - The claim that reusing the same training data used for training the teacher model in model compression can lead to overfitting of student model is not very obvious and needs more experimental evidence in my opinion. However, I still think it is borderline for several reasons. ii) Related to i), In figure 1 (a), how many data and iteration for each epoch? I like the authors' explanation on why GAN is particularly good in a student-teacher setting. I suspect there is a lot of slack there.
- If it is the former, how does this compare to existing approaches for optimizing F1 metric. The paper proposes a label assignment policy for determining the appropropriate positioning of a document in a hierarchy. For instance, the dataset available under LSHTC3 is in the raw format, and it would be really competitive to evaluate this method against other such as Flat SVM, and HRSVM[4] on this dataset, and those from the challenge. It is 81.66/56.56 vs 72.8/38.6 reported in this paper. I'm happy to see that it was possible to - in addition to above, there is the standard issue of using different #parameters across models which increases/decreases model capacity.
While the overall concept of graph regularization is appealing, the exact relationship between the proposed regularization and robustness to adversarial examples is unclear. Overall, very interesting and nice work, which might be better positioned (especially in terms of experiments) wrt to other recent methods that propose to improve robustness in NNs. Compared to the previous version, this paper made a good improvement in its experimental results, by adding two different robustness settings in section 4.1 and section 4.3, and also include DeepFool as a strong attack method for testing adversarial robustness. It would be very helpful if the computation process and the discussions can be separated here, maybe with a pseudo-code for computing the regularizer. The paper proposes to use a regularization which preserves nearest-neighbor smoothness from layer to layer. strengths: - practical proposal to use graph regularization for neural network regularization
A lot of typos/wrong phrasing/wrong claims and here are some of them: (a) Page 1, "lead to the misrecognition of those common replies as grammatically corrected patterns"? - it would be interesting to know for the trivial questions if the performance was impacted by the deemphasizing (one that do result in universal replies) This paper presents a framework for understanding why seq2seq neural response generators prefer "universal"/generic replies. Firstly, the use of word "marginal" instead of "margin" seems quite wrong to say the least. Also there seems to be a discrepancy in figure 3 with the baseline output for first query having two "Where is your location?" outputs.
It is not clear to me why DL2/training is implemented in PyTorch and DL2/querying in TensorFlow. Second, it allows users to search for specific inputs that satisfy specified conditions. PSL by construction produces convex loss functions, and so the constraint that all outputs for a group of classes is either high OR low would probably not work well. If \\epsilon is the threshold that can often be used in the query, it is not obvious that every query contains exactly one \\epsilon. It is not clear that this affects the findings of the semi-supervised learning experiment significantly, although I would appreciate a clarification of the authors. How many layers does it have?
The paper applies multi-armed bandits for choosing the size of the minibatch to be used in each training epoch of a standard CNN. In other words, their result does *not* show that their algorithm is close to outperforming a fixed choice of batch size (for that to hold, the comparator would need to be \\sum_t y(w(b^*,...,b^*),b^*)). In the experiments, the Exp3 bandit algorithm is run with Adam and Adagrad on MNIST, CIFAR-10, and CIFAR-100. I am pretty familiar wit bandit literature. The idea itself is a simple and relatively straightforward application of bandits. The paper could have gained strength if bandits had been considered in wider context of parameter/model selection in deep learning.
(11). In particular, it would be nice to show the variance of the two terms separately (for both DiCE and this paper), to show that the reduction in variance is isolated to the second term (I get that this must be the case, given the math, but would be nice to see some verification of this). Variational inference for Monte Carlo objectives. Thank you for an interesting read. Finn, Chelsea, Pieter Abbeel, and Sergey Levine. "Model-agnostic meta-learning for fast adaptation of deep networks." ICML 2017.
That being said, sampling initial states from demonstrations is a tried-and-true strategy in RL, and the manually designed curriculum is also not particularly novel. A good convincing assessment would be to report success rate against the same starting point for all methods preferably not from the starting point of the demonstrations to assess generalisation of these methods for which authors briefly report unsuccessful results. Pommerman is a much more compelling task and shows more promising improvements from backflip. I am also not clear on why Standard method is terminated at epoch 450 while other methods are trained until epoch 550. The method is demonstrated on a maze navigation task and a challenging game Pommerman. However since that work was not published, it should not be held against this paper. The experiments were conducted only on discrete grid world tasks, and additional experiments in continuous domains could be valuable.
In a weighted voting game each agent is given a weight and the agents attempt to form teams. And thus how might it be useful? It's not alone in this category (e.g., paper compare to theoretically optimal baselines if they can), but it is interesting to see another example of this kind of evaluation. The work builds upon a substantial and growing literature on reinforcement learning for multiagent competitive and cooperative games. * What does it mean to distribute/share a reward across agents? 3) A popular result in cooperative game theory predicts how effective agents should be.
This is not unreasonable and indeed common in mean-field analyses. Minor comments: * when introducing T{i,:,:} the <> notation is not clear.
Moreover, the reviewer felt that the authors could have built on those findings to ask (and hopefully answer) a few interesting questions, such as: -- Nowhere in the paper there is a discussion about critical Nyquist sampling and the need to reduce the bandwidth of a signal prior to downsampling it in order to avoid aliasing. The work does an analysis of impact of different pooling strategies on image classification with deformations. It is often argued that one of the roles of pooling is to increase the stability of neural networks to deformations. Cons: i) Results on CIFAR 10 show pooling has little effect but is it unnecessary for harder problems as well? Average pooling provably does it, and learnt filters do it provided they indeed become bandlimited. (i) the benefits of pooling in terms of deformation stability can be achieved through supervised learning the filters instead (sec
Other comments: * In the introduction, an adversarial criterion is referred to as a "discriminative objective", but "adversarial" (i.e. featuring a discriminator) and "discriminative" mean different things. Summary ------- This paper describes a model for musical timbre transfer which builds on recent developments in domain- and style transfer. The proposed method is designed to be many-to-many, and uses a single pair of encoders and decoders with additional conditioning inputs to select the source and target domains (timbres). In the definition of the RBF kernel (page 4), why is there a summation? * Higgins et al. (2016) specifically discuss the case where beta in formula (1) is larger than one. However, the more pressing issue is that evaluation is done either sample-wise within-domain (reconstruction), or distribution-wise across domains (transfer). I think the wording is a bit too strong here. Is this a typo? * The differences between UNIT (GAN; C-po) and UNIT (MMD; C-po) in Table 1 seem very small and I'm not convinced that they are significant. It would be better if the authors were a little more careful in their use of terminology here. While I understand that quantifying performance in this application is difficult, I do find the results difficult to interpret.
(1) a smiling expression and Experiments are nice, since for one of the first times provide facial images which are pleasant to see. 2) As co-segmentation is proposed to "capture the regions of a common object existing in multiple input images", why does the co-segmentation network only capture the eye and mouth part in Figure 2 and 3, why does it capture the mouth of different shape and style in the third macro column in Figure 4 instead of eyes? My initial rating is weakly reject. [1] Multimodal Unsupervised Image-to-Image Translation Is the model easy to extend to novel styles for image translation? Minor-- There are several typos, e.g., lightinig.
The discriminator is training to distinguish between generated and real samples and hence is able to discriminate between normal data (=real) and anomalous data (=generated, in low density areas of the normal data). On a conceptual level it seems to me that for a data-generating distribution corresponding to a low-dimensional manifold embedded in a high-dimensional space the complementary distribution will essentially be uniform random noise, and in that case it's unclear to me how it's supposed to "simulate anomalies". Conclusion - the idea is interesting - how do we model Q(c|x)?
Review ------ Although improving optimization methods is certainly important for the machine learning community, the reviewer have strong concerns about this paper. p 7: the dimension d could be larger than T when training large-scale neural networks: how does it relate to comparing sqrt(dT) to (dT)^s ? A regret analysis is proposed in the convex case, while a vanishing bound on the gradient is derived in the non-convex smooth case. However, the authors report only the results for the best q, with non significant differences (and not quantified, there is no result tables).
A feature of this paper is that the method is relatively simple compared to some prior LAL methods, and also that it learns policies that can transfer successfully across diverse heterogenous datasets. - Why is there a disparity between the results for the SVM in table 2 and the discussion in the first paragraph of section 4.3? Sec 3 presents the method in a clear and straightforward manner. Of note, only the average performance for each method is reported.
Summary: The paper presents a method for "learning an optimizer"(also in the literature Learning to Learn and a form of Meta-Learning) by using a Variational Optimization for the "outer" optimizer loss. Hence, it is also unclear if it retains its stability after letting it run for longer.
This paper proposed a general framework, DeepTwist, for model compression. Since SGD is used for training, several minibatches are needed to achieve a relatively stable solution for projection using the proximal function, which is exactly the proposed framework in Fig. 1. They used different model compression techniques in this framework to show the effectiveness of the proposed method. Pros: - The proposed method is shown to work with existing methods like weight pruning, low-rank compression and quantization. In this way, we can easily see that the proposed framework is a stochastic version of proximal gradient descent. This paper proposes a framework intending to use fewer hardware resources without compromising the model accuracy. A model compression framework, DeepTwist, was proposed which makes the weights zero if they are small in magnitude. Therefore, it is not clear how the proposed framework is helping the model compression techniques.
The paper demonstrated the method on MNIST and CIFAR10, and evaluates it against a number of adversarial attacks. Also, the adversary may attack an ensemble of PPD models for different random permutations (i.e. expectation over random permutations). In summary the authors propose a  simple and intuitive method to improve the defense on adversarial attacks by combining random permutations and using a 2d DFT. While the security of a model against adversarial attacks is important, a defense should not sacrifice clean accuracy to such an extent. My main points of critique are: 1. The test accuracy on Cifar10 seems to be quite low,  due to the permutation of the inputs. This paper explores the idea of utilizing a secret random permutation in the Fourier phase domain to defense against adversarial examples. This makes me question  how favorable the trade-off between robustness vs performance is. 2. The authors state "We believe that better results on clean images automatically translate to better results on adversarial examples" arXiv preprint arXiv:1611.03530. This paper proposes Permutation Phase Defense (PPD), a novel image hiding method to resist adversarial attacks.
Specifically, they showed that when features (parameters of DQN) are trained in one environment (default flavour/mode) and then used as an initialization for the same model but for a slightly different environment ( i.e. still captures key concepts of the original environment ) can boost the performance of the model in the new flavour/environment. And I think this on its own is valuable. In summary, I found this paper is interesting but my concern is about the experiments. To that end I think this paper enters in that unresolved dispute of what generalization should be versus what is transfer. During training, if I do not see car accelerating, I think it makes no sense to expect to generalize to a new game that has this property as it is out-of-distribution.
The paper proposes a sampling-based method that aims at accelerating Batch Normalization (BN) during training of a neural network. In summary, the method proposed in the paper is reasonable but could be limited in practice due to only 20% maximum gain can be achieved. pros) (+) The paper is clearly written and easy to follow. But the idea of uniform-sampling seems     rather straight-forward, and more important, I do not see its justification from reading the paper; the other technique introduced, Virtual Dataset Normalization, seems to be a direct application of Virtual Batch Normalization (Salimans et al 16). cons) (-) Any motivations or insights into NS, BS, and FS are not provided. - Did the author compared against cuDNN's native version of BN?
What is learned in the automata? This method provides a structured solution for reusing learned skills (with scTLTL formulas), and can also help when new skills need to be involved in original tasks. With more explanations (perhaps an algorithm box?), I would consider increasing my score.
The model is a simple combination of GCN and existing framework for community detection. Stochastic blockmodels and community structure in networks. I have couple of minor issues to discuss: 1. For the sake of generality, I would recommend to use the general formula instead of particular 3-layer case in equation 3.
2565-2573). ACM. This paper describes a recurrent model (LSTM specifically, but generalizable) which can produce variable-wise hidden states that can be further used for two types of attentions: 1) variable importance for the importance of each variable (not accounting for time), and If the authors could explain this a little bit, I would appreciate it. Furthermore, the authors develop a mixture attention mechanism and a summarization methods to quantify the temporal and variable importance in the data.
- Figure 3, could it be that the use of hierarchical latent variables (H) accounts for the visual difference? - The approximate posterior used was used first in (Bayer & Osendorfer, "Learning stochastic recurrent networks", 2014) not (Chen 2018). - Related to the point above, the implications of using the model in eq.
The task is the following one: - consider a set of pairs of binary values (-1 or +1); Summary of the paper: This paper studies using a three-layer convolutional neural network for the XOR detection problem. Isn't this too restrictive? For any two reasonable learning algorithms, there often exists a particular scenario (i.e., labeling function and distribution) that the first one could do better than the other. Furthermore, the entire analysis is highly tailored to this toy problem and it is very hard to see how it can be generalized to more practical settings like real-valued input.
(2) They show improvements on dialogue generation (in terms of empathy, but also relevance and fluency) using a multi-task objective, ensemble of encoders, and a more ad-hoc technique that consists of prepending inferred emotion labels to the input. From this I am assuming that each speaker/listener worker pair had to write about all 32 emotions – is this correct? The problem with prompting workers for specific emotions is that this assumes they are good actors and this is likely to produce exchanges that are rather cliché and overdone (e.g., Table 1: the label "afraid" yields a situation that is rather spooky and unlikely in the real world, and the conversations themselves are rather cliché and incorporate little details that would make them sound real). (one for each emotion) or 64?
ECCV 2018. Summary: This paper proposes a technique for quantizing the weights and activations of a CNN. The main idea is to use 'nest' clustering for weight quantization, more specifically, it partitions the weight values by recurring partitioning the weights by arithmetic means and negative of that of that weight clustering. 3) Activation quantization in Section 4 is a standard way for quantization, but I am curious how to filter out the outliner, and how to set the clipping interval? - The notation in section 3.1 overly complicated, could probably be simplified a bit for readability. All these kinds of questions are hard to answer without an ablation study. Batch normalization is also considered in the activation quantization. I just list two references in the latest vision and learning literature: [Ref1] X. Lin et al. Towards accurate binary convolutional neural network.
This paper proposed a new method for image restoration based a task-discriminator in addition to the GAN network. 4. The proposed method is not compared with other super-resolution methods. 3. It is not clear how much data is used to train the super-resolution model and whether there is overlap between training data for super-resolution task and test data for recognition task. For medical image reconstruction and image super-resolution, the proposed method was not compared with any of the state-of-the-art methods, but only with the same method without a task-discriminator as a baseline. For example, a simple L1/L2 or perceptual loss probably leads to better PSNR than the GAN loss, which is not compared at all. 2. Actually, as the authors mentioned, GAN is not an appropriate model for image restoration when  accurate image completion is required. In CVPR 2017. Johnson, J., Alahi, A. However, the novelty is limited and not well explained. 1. The idea of adding a task-specific branch has been proposed in Huang et al's work.
The paper presents a convergence analysis for manifold gradient descent in complete dictionary learning. *) The Riemannian gradient algorithm is not stated in this paper.
Comparative results are presented on miniImageNet (5-way, 1-shot). This paper proposes a mixture of MAMLs (Finn et al., 2017) by exploiting the interpretation of MAML as a hierarchical Bayesian model (Grant et al. 2018). More discussions and explanations on this experiment are clearly required. This is even though better performing methods, like Versa, are much cheaper to run The first is artificial, and surely does not need an algorithm of this complexity. Important questions, such as how to make this faster, are not addressed. This is quite elaborate, and uses further approximations (ICM, instead of Gibbs sampling). These results are not near the state-of-the art anymore, and some of the state-of-art methods are simpler and faster than even MAML. In the case of infinite mixtures, it is not clear what is done in the end in the experiments. The proposed method is tested in a few-shot learning setup on miniImagenet, on a synthetic continual learning problem, and an evolutionary version of miniImagenet. If expensive gradient-based meta-learning methods are to be consider in the future, the authors have to provide compelling arguments why the additional computations pay off. In Algorithm 2, how do you avoid that there is always one more (L -> L+1) components?
The details and motivations of the Hypervolume Maximization  (HVM) method (especially as it relates to and interacts with the slack method of picking the nadir point) were a bit harder to follow intuitively given the standalone information in the paper. However, this idea (methods along this line) is not popular in GAN applications, like image-to-image translation. Training multiple discriminators (in this paper up to 24) significantly increases compute cost and effective model size. Why is this not just a visualization of FID score as a function of wallclock time? Pros: + The work provides a clear overview of previous work on approaches using multiple discriminators.
There is no evidence that the method can scale to and work well on large-scale tasks, where improving the sample efficiency becomes truly crucial and challenging. Cons: * To my knowledge, all text classification tasks used in 5.2 are quite small.
In this setting, it is unclear (in its intuition) why it is possible to assign a cluster index to its true class labels. - In the first paragraph of page 5, "cycle-consistency loss z C(D(G(z))) and backward cycle consistency loss x G(C(D(x)))" does not read well.
7) Experiments How would you estimate the range of suitable step sizes (for both a and w) for BNGD for a neural network? First of all, understanding the properties of batch normalization is an important topic in the machine learning community so in that sense, contributions that tackle this problem are of interest for the community.
It may not be that it changes in the first time step (for obvious reasons), but it is essentially showing it many configurations of the expert. However, this task requires the learning to be interactive and thus the demonstrator needs to be present during the learning. In reality, for sufficiently difficult tasks, a human would be the demonstration agent (as is done in most robotics tasks). essentially, a learner agent learns how to probe a demonstrator agent to provide more information about what's being demonstrated and prevent over-fitting to a set of fixed demonstrations. + Cool experiments for applicability. Minor points: "differs from this in two folds" Since this is for ILCR, I think the authors should have taken a deeper dive into examining those latent representations and potentially visualizing those distances and how they correspond to different policy behaviors. 1) Summary This paper proposes a method for learning an agent by interacting and probing an expert agents behavior.
Rather than using pixel-wise loss for an action-conditioned video prediction model ("Forward Model"), they use an adversarial loss combined with mutual-information loss (from InfoGAN) and content loss (based on difference in convnet features of VGG network, rather than pixels). It is hard to obtain a coherent understanding about the proposed approach. Although the work is promising, I can only give it a score of 4 at the moment.
Inspired by these networks, the authors propose weight initialization schemes for finite width networks. This has only been done for two layers before, and the authors derive how to do this for more than two hidden layers using RKHSs. This initialization is called Win-Win, and is compared to different initializations on a few different datasets. Summary: The paper attempts to proposal a weight initialization scheme to enable infinite deep infinite-width networks. Response to rebuttal: The authors have addressed my question about the weights being still in the same RKHS.
The paper tries to describe SGD from the point of view of the distribution p(y',y) where y is (a possibly corrupted) true class-label and y' a model prediction. Here are some pros and cons. My issues with this paper are: a/ The main result is a simulation. b/ Meaning of this trajectory. I understand that these questions may not be clearly answerable, but the authors should make this paper more inspiring such that other researchers can think deeper after reading this paper.
This is a minor innovation. (3)). This is also empirically reflected in Table 1, which shows the proposed PDAS is similar to ENAS both in terms of efficiency and performance. This paper presents a joint optimization approach for the continuous weights and categorical structures of neural networks.
(3) Some details are missing, resulting in the fact that it is hard for other researchers to fully capture the mechanism of the proposed algorithm. In equations (2) and (3), what is theta_v? The paper proposed a new framework for session-based recommendation system that can optimize for sparse and delayed signal like purchase. Minor comments: (1) It would be better if the authors can test the proposed model on more datasets. (2) State-of-the-art reinforcement learning algorithms were not taken into account for baselines in the experiments. It seems that the proposed algorithm is built based on and combined by existing algorithms such as A3C. It looks like a loss from a previous paper, but it's kind hard to track what it is exactly. "where Tj,τ is the τ-th imagined item, φ(·) is the input encoder shared by π (for joint feature learning), AE is the autoencoder that reconstructs the input feature, and the discounting factor γ is used to mimic Bellman type operations. (3) Robustness to cold-start scenario was tested and evaluated in the experiments. Even though the author has promised to release their implementation upon acceptance, I still think the paper needs a major change to make the proposed algorithm more accessible and easier for reproduce. The motivations of integrating A3C (Asynchronous Advantage Actor-Critic) but not other techniques into the proposed model are not convinced to me as well. (3) the imagination-augmented executor (IAE) that aggregates the internal data resulting from imagination and external rewarding data to update its action policy. What are the relationships among \\mathcal{L}_{A3C}, \\mathcal{L}_{IRN} and the one defined in equation (4)? Considering a deterministic policy, using LSTMs which already encode sequentiality of states in addition to another component for planning, seem to undermine the role of RL. The proposed algorithm with an innovative IRN architecture was intriguing. Usually, users tend to search quite a lot before converging; hence, longer sessions possibly better reflect user interests. (4) The contributions of the paper in terms of theory are somewhat not significant. Is it because reinforcement learning based methods work better than traditional machine learning based ones? This renders the empirical part exceptionally strong. With this level of clarity, I don't think it's easy for other people to reproduce the results in this paper, especially in section 4, where I expect more details about the description of the proposed new architecture.
The authors aim at training a VAE that has disentangled latent representations in a "synergistically" maximal way. The main concepts of synergy are not developed in this paper and the used penalization term is straight forward. Writing like this serves no purpose even when it justified, and it certainly is not here. The paper proposes a new objective function for learning disentangled representations in a variational framework, building on the beta-VAE work by Higgins et al, 2017. As you say in the first line of your own introduction, hierarchy and composition are key parts of learning effective and interpretable representations and this is exactly what you are discouraging. In other words, representations where there is no information conveyed by combinations of latents that is not conveyed by considering each latent in isolation. However, it is a long way short of this in its current state.
The fact that SNAIL (TCML Mishra et al. (2017)) consistently outperforms this method puts a question mark on the significance of this work. Firstly, I guess the algorithm should somehow encourage to match more points between the images. While understanding why a blackbox matching network is making a mistake and improving, is  harder. They main idea is to benefit from binary maps between the query image and the support set (for the case of few-shot learning for the sake of discussion here) to guide the similarity measure. - Aside from the above (so basically regularizing norm(C) somehow), one wonders why matching a point to several others (as done according to matrix C) is the right choice. The use of hyper column descriptors is an effective workaround to achieve good performance even though this approximation. The self-regularization allows the model to have a performance improvement, and it is considered one of the contribution of this work. Some examples, -p2 bandwidth signal than the traditional label-only signal : I am very confused by how bandwidth comes to the picture and how this can be measured/justified
For example in this statement, robots aren't a requirement for evaluating intrinsic motivation. " —> significantly more (?) sample efficient ? To do this, they augment the "curiosity" algorithm of Pathak et al with a differentiable approximation to the reward prediction model. However, there are several important places where this paper falls down: - In a paper that posits a new, groundbreaking, real-world application of "exploration" there is remarkably little discussion of the key issues of "efficient exploration". Was this annealed as in other work?
(6) Typo of "Accurcay" in Table 4(a). (2) Another major one is why the word sequence generator is introduced in the proposed model. The second evaluation task of text generation is not explained enough. It is not so convincing to just use VAE+Wgan-gp as a baseline model. There is not much work in this line and this paper proposes a model that seems to be working. (3) Some of the experiment settings are not provided, for example, the number of topics, the value of \\alpha and \\lambda in the proposed model, the hyperparameters of LDA, which are crucial for the results. I would expect more comparisons than classification accuracy, such as topic coherence and perplexity (for topic modelling) and with more advanced conventional models. In conventional topic models, usually a topic is a distribution of words, so that top words can be selected by their weights. But I did not see something similar in the proposed model. 4. As you mentioned in this paper "your model can be easily combined with any current text generation models", have you done any experiments for demonstrating the original text generation model will get better performance after applying your framework? Another sentence from the same paragraph states that their "model outperforms LDA because LDA is a statistical model, while our generator is a deep generative model." This argument also seems flawed and without concrete evidence. Perplexity (table 3) shows similar results for DBPedia and worse results (than WGAN-gp) for Gigaword.
Imitation learning is only briefly mentioned in the related work (section-2), it would be helpful to elaborate on this. This may not be true in general, e.g., learning the set of relevant functions may require a larger space than learning the reward functions. 3) T^{tr} seems to be typo in (11) This is mostly because of the careless use of notation in derivation on p 15 in the appendix (the last equation), in which the subscript i is missed for the second term.
That is, comparison of CPO and Lagrangian constraint based RL with Lyapunov based method proposed depends on a lot of factors (such as those just mentioned) that are not systematically explored by the paper.
This is achieved by using a generative adversarial network (GAN) to generate high-entropy samples that are then used by a nearest neighbor method to pick samples from a pool, that are closest to the generated samples. For example: - For the two-class MNIST you use classes "5" and "7" and for the two-class (2) evaluations look reasonable and fair O(N)), this benefit is mainly due to GAAL (Zhu & Bento 2017). I perceive this as a smoothness assumption on the decision boundary of the classifier and I do not know how true is may be for deep neural networks, but I can see how it may be true for logistic regression models and support vector machines (SVMs), depending on the kernel used.
Cons: - RAML and SPG have not been established as important methods in practice. Furthermore, the MLE interpretation discussed is contained within the RAML paper, and the reductions to RAML and SPG are straightforward by design, and so do not really provide much new insight. Also, a paper on essentially the same approach was submitted and rejected from *CONF* 2018(https://openreview.net/pdf?id=H1Nyf7W0Z), although this paper is better written, and puts the method more fully in context with existing work, I think that several of the concerns with that paper apply here as well. Update after author responses: -------------------------------------------- Authors, thank you for your feedback. Which brings me to point Having access to these experimental results is important, since it would enable the reader to understand whether the benefits of the new approach are subsumed by regularisation or not. 2) A weighted (weight alpha) reverse KL divergence of the parametric policy and a non-parameteric policy q,
To combat this they use the noise-regularized mutual information estimator (I(X; L+eps)). In general the paper does a poor job of distinguishing between the Shwartz-Ziv & Tishby paper and the rest, but this is a distinction that should be maintained. This is novel and theoretical sounding. Doing this ensured that their estimator diverged in the zero noise limit as expected. This paper fits into what is an increasingly large discussion in the literature, surrounding Information Bottleneck. They claim that Figure 5 (a) is more 'quantized' than (b) and "has reduced entropy". Not too surprising, this additive noise works as a ridge-type (or weight-decay) regularizer, just as a Gaussian prior in regression. Just plugging in the Discriminator for the objective (equation (7)) is flawed. This paper provides a method to do explicit IB functional estimation for deep neural networks inspired from the recent mutual information estimation method (MINE). [1]  Ver Steeg et al. Maximally Informative Hierarchical Representations of High-Dimensional Data.
This paper proposes a hybrid machine learning algorithm using Gradient Boosted Decision Trees (GBDT) and Deep Neural Networks (DNN). It seems heavily dependent on GBDT.
For example sharpness and attending to details is not typically a challenge in MNIST generation where in other datasets this is usually the first challenge to be addressed. Since the presented metrics do not show a significant difference between the VAE and Vanilla GAN model, the question remains whether evaluating on MNIST is a good proxy for the performance of the model on colored images with backgrounds or not. 2. Extracting morphological properties of the image is straight-foward for MNIST kind of objects. I'm not convinced that ability of a model in disentangling thickness correlates to their ability in natural image generation. Their tools are a handy addition to the analytical surveys in several applications (e.g. how classification fails), but not convincingly for generation. * Providing benchmark data for tasks such disentanglement is important but I am not sure generating data is sufficient contribution for a paper. However, when the entire image is subject to the generative model, it learns multiple properties from the image apart from shape too - such as texture and color. However, this paper lacks in terms of experimental evaluation and has some technical flaws. Additionally, there are lot of low level pixel relations that the model learns to fit the distribution of the given images. They perform a thorough study regarding MNIST. Authors present a set of criteria to categorize MNISt digists (e.g. slant, stroke length, ..) and a set of interesting perturbations (swelling, fractures, ...) to modify MNIST dataset. Since their method is manually designed for MNIST, the manuscript would benefit from a justification or discussion on the  common pitfalls and the correlation between MNIST generation and more complex natural image generation tasks. The operation is done using binary morphological operations. 3. Now assuming that my GAN model has learnt good representation in Morpho-MNIST dataset, is it guaranteed to learn good representations in other datasets as well?
For network compression, it is common to add L1 Penalty to loss function. If so, it should be specified. 3. It is also unclear how the trade-off in point (b) of the abstract is justified in the experiments. Of course, it can be easily pruned if the model is too much capacity for a simple dataset.
There is not much on that. Method: - It is not clear to me why the notion of binary parameters gamma is necessary. On the other hand, the two matrices A_{l-1} and DS_l needed in the method for a fully-connected layer already have size 81M and 16M respectively. Please comment on that - I am not sure if I understand the statement on 'pruning methods can not handle multiple layers'. 2. The method is theoretically sound and outperforms state-of-the-art by a large margin in terms of compression ratio. - Compute time is not provided.
The paper proposes a method for using auxiliary tasks to support the optimization with respect to a main task. Although these methods addresses the case of all tasks being important, it is a valid baseline and need to be compared. In summary, the paper is proposing a sensible method for an important problem. In other words, auxiliary task performance is not of interest. Instead, paper uses set of toy experiments. The paper is generally well written and the results are fairly clearly presented. - Does the theory still hold for loss functions which are not Lipschitz as the Cauchy's gradient method requires that for convergence The method is simple and easy to implement. The paper studies the problem of how to measure the similarity between an auxiliary task and the target tasks, and further decide when to use the auxiliary loss in the training epoches. Method should be experimented with some of those setups. Hence, it has a potential to be useful for the community. Example of these methods are: [GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks, ICML 2018] and [Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics, CVPR 2018]. However, it is only tested for toy problems although there are interesting existing setups which would be ideal for the method to be tested.
\\Question In page 4,  the variance of the p(y|x) and p_\\theta(y|z) are set to be the same. The application of upper bounds to general f-divergences for training generative models is novel as far as I know. In my opinion, a more rigorous and thorough experimental exploration would increase the value, but the paper demonstrates that training with alternative f-divergences is feasible. 2) "RKL" and "JS" are not defined. Forward KL and standard KL are both used in the paper. Detailed comments are listed below.
3. Does the proposed model use the word embeddings of the labels? 8. Page 7: in text you mention generation accuracy and in Table 1 the same value is defined as Generation Correctness (%).
Once a layer is chosen, mixup occurs with a random proportion λ∈(0,1) (sampled from a Beta(α,α) distribution). The tone of the paper is notably scientific, as the authors clearly state the assumptions and all observations, whether positive or negative. The paper proposes a novel method called Manifold Mixup, which linearly interpolating (with a careful selected mixing ratio) two feature maps in latent space as well as their labels during training, aiming at regularizing deep neural networks for better generalization and robust to adversarial attacks. 2. Why not using Cifar100, but with a new dataset SVHN for the semi-supervised learning in section 5.2?
The proof idea is to reduce this problem to the problem of learning a single non-linear neuron in the case that the covariance matrix of the data is well-conditioned. NIPS 2011. -------------- I would be maintaining the same score. While I find there is a lot of interesting and good work in this paper, I am not completely convinced about this last point. 5. In Theorem F.1, it is claimed that all rows of E are equal. Should this assumption be included in the statement? Though system identification was for many decades a large and active area in the control community, the understanding of system identification from a modern statistical perspective (understanding sample complexity and computational complexity simultaneously) is surprisingly lacking.
In this, paper a GANs-based framework for additive (image) denoising and demixing is proposed. It seems like a noveel approach to demixing which is exciting. The problem is solved via gradient descent and theoretical analysis on the converge of the algorithm is not provided. Since the authors "main contribution" (their words) is demixing, I'm surprised that they did not compare with other demixing approaches, or try on a harder problem. Quality is good, just a handful of typos. Experiments results on MNIST dataset are presented. On one hand this paper seems novel and clearly contributes to the field. ********************* Update after author response: I think the Fashion-MNIST experiments and comparisons with ICA are many times more compelling than the original experiments.
Minor comments: 1. The generative model for Variational dropout is the same than the generative model for the "conditional model", eq. Authors try to provide a theoretical foundation for using dropout when making predictions. (6), E_w p(w|\\Theta) p(y|x,w) is a typo.
Given that rxr is a small constant sized matrix and that matrix-vector multiplication can be efficiently computed on GPUs, this matrix adapted SGD can be made scalable. This is a really nice trick. Instead, it is a low-rank approximation to the full matrix. In Appendix B.1, they report mixed results in terms of wall-clock time, and I strongly feel that these results should be in the main body of the paper. However, because this matrix turns out to be a pxp matrix where p is the number of parameters in the model, maintaining and performing linear algebra with this pxp matrix is computationally intensive. Why mention it here, if it's not being defined. Overall, I think that this is an elegant idea and I'm convinced that it's a good algorithm, at least on a per-iteration basis. The latter may be important in practice, but it is orthogonal to the full matrix theory.
The submission describes a method for smoothing a non-differentiable machine learning pipeline (such as the Faster-RCNN detector), so that gradient-based methods may be applied to jointly train all the parameters of the pipeline. However, I think this paper could have explained more clearly which part exactly is a novelty of this paper, and where it separates from the rest. Similar efforts in this direction, namely making various modules of the Faster R-CNN pipeline differentiable, have shown little gains as well.
I think the significance of this work lies in the fact that this can be a starting point for several interesting future works in this direction. This paper proposes a generalization of variational auto-encoders to account for meta-data (attributes), learning new ones, in a way that these can be controlled to generate new samples. Given that the ground truth attribute decomposition for MNIST is not known, even the qualitative results are impossible to evaluate. The paper should be self-contained and the authors should not assume that their readers will read the information presented in the Appendix, which is always optional. This paper seems relevant Esser, Patrick, Ekaterina Sutter, and Björn Ommer.
- Experiments are using Parzen window for estimating likelihood which  are known to be unreliable in high dimensions. With regards to the technical assessment of this work, the idea of using a nearest neighbors objective for learning a generative model is both intriguing and appealing. -  Even for sample quality, there has been a lot of research in designing and improving metrics. It would be good to have empirical evidence to back this claim. Summary: This paper proposes a nearest-neighbor-based algorithm for implicit maximum likelihood. Most of the facts discussed in that section are generally well understood, so conciseness is very appreciated in this case. It seems like having experiments of this nature is far more convincing than a long justification for why the results are not necessarily state-of-the-art.
To "plug" the holes, one includes adversarial examples in the training, called "adversarial training." The new thing is that the authors found that quantization of activation function improves robustness, and the approach can be naturally combined with FGSM adversarial training.
A pair of sentences from a weak document pair are used as training data if their cosine similarity exceeds c1, and the similarity between this sentence pair is c2 greater than any other pair in the documents, under sentence representations formed from word embeddings trained with MUSE. The notation of eq. 7 is quite unclear because of the overloading (e.g., P refers to both the model and the empirical distribution). The method consists of a) mining documents that refer to the same topic, The major issue in this paper is that the "new direction" in this paper has been explored before [1]. Comments - Koehn et al. (2003) is not an example of any kind of neural network architecture. I think the measurement of the alignment accuracy and more experiments with different settings of \\alpha and \\beta are needed.
A cluster assignment matrix assigns each node in the original graph to a cluster in the new graph. Although the proposed approach is interesting and works well on different datasets,  one strong concern I have is the high computational complexity of the algorithm, which is as high as o(n^3) (n is the number of nodes). Strength: -- An interesting idea to use CRF idea to cluster the nodes on a graph for pooling purpose
- The authors do not describe their baselines for several experiments. This, unsurprisingly, limits the applications of DPPs, and has driven a lot of research focused on improving DPP overhead. If it is not (using a DPP-based formulation as a regularizer does not require a distribution), the authors should clarify that fact;
It is not explained why the authors chose to pretrain on ImageNet, since ImageNet does not have any image classes that are comparable to the dataset the authors use. it illustrates how model interpretability and human intuition and domain knowledge can be useful. It is important to note that researchers in the field of AI and deep learning are themselves aware of the fallacies of deep learning, and are striving everyday to overcome these themselves. it is also able to detect the use of experimental artifacts, whose removal improves predictive performance. The conclusion has many repeated points from previous sections, but it is a good summary. BACKGROUND: Hypothesis: Prey movements in zebrafish are characterized by specific motions, that are triggered by a specific pathway involving an area called AF7. It makes for a very good quality practitioner-level case study on video understanding, which may also be useful for people studying zebra fish or related simple life forms. This itself is a notable achievement and a good use of significant research time. Good to know that the authors will share their code. This is evident in this paper with the authors calling CNNs "black box" and the learnings of a neural network "cheating".
4) The result in this paper is quite incremental from the one in Vaswani et al 2019, "Fast and Faster Convergence of SGD for Over-Parameterized Models (and an Accelerated Perceptron)". The work may be potential, but in order to convince people to trust this algorithm, rigorous theory must be provided. Need to explain more clearly this part.
In particular, it reduces GNN to a distributed computing model CONGEST and adapt the impossibility result from distributed computing to GNNs. However, this is not true in GraphSAGE [2] where the aggregation is a LSTM rather than a simple sum. In this paper, results in distributed computing are reformulated in a GNN framework mapping the number of rounds required by a local algorithm to the depth of the GNN in order to solve a given graph problem in a worst case scenario.
However, it is not clear that using features from a pre-trained semantic segmentation network is necessary. And I also think consideration should be given to the fact that in a deployment setting, new objects not previously seen in the semantic categories (UFO) may appear and one ought to understand if the semantic network might decrease performance (because of the unseen class). This work proposes to leverage a pre-trained semantic segmentation network to learn semantically adaptive filters for self-supervised monocular depth estimation. What does a RMSE difference of 2.3 mean in the context of depth estimation?
This paper studies the emergence of compositional language in neural agents. Authors claim that compositional languages are easier to be learned and that they allow listeners to more easily understand provided messages. I do have concerns for this paper around utility and novelty.
It is missing a bit of understanding and intuition on the reasons why this technique should be used. * What is the performance/accuracy on the pre-training tasks? This paper proposed a pre-trainable generic representation for visual-linguistic tasks call VL-BERT. - One of the pre-training tasks is masked ROI classification but it assigns a hard label to each ROI feature.
The paper proposes a metric for unsupervised model (and hyperparameter) selection for VAE-based models. Equation (3) looks problematic. Note that it is possible to train a Bidirectional Generative Adversarial Network (BiGAN) that can generate complex images based on a uniform distribution (Donahue et al., 2016). The computational process of UDR is heuristic and somewhat arbitrary. I am inclined to accept the paper for the following reasons: 1. The proposed approach is clear and easy enough to understand and well motivated The encoder might simply be the inverse of the decoder under a certain scenario.
The second modification is adding a learned data augmentation strategy, and adapting the method to work with strong data augmentation. Another paper, [2], reports very competitive results on CIFAR-10 for 4k labels. What is the reason for the difference?
I should note that, although I am a speech researchers, I am not a TTS expert, and my review can be weighed accordingly. Strengths: The proposed approach is interesting.
I appreciate the straight through estimator might ameliorate this, but it is not made entirely clear to me in the text that this is the reason for using it. - LSTMs are sensitive to noise: Is there an explanation for this observation? I do have a range of questions & requests for clarification (see below) but I believe the experiments as presented, plus some additions before camera ready, will make for a good paper of wide interest.
(2) In Section 3.1, "Batch Normalization has a disparity in function between training inference". The authors refer to this baseline as "idealized Batch Normalization". The paper performs an empirical study of four batch-normalization improvements and proposes a new normalization technique for small batch sizes, based on group and batch normalizations. [1] "Decorrelated Batch Normalization." CVPR, 2018. The techniques seem effective. The paper mentions "theory" multiple times, but lacks sufficient justification to support these "theories".
Are the results averaged over multiple trials (if yes how many?), and is there a difference in variance between the methods? Nevertheless, while I found this is very interesting work, I have a number of issues with the experiments, which I'll go into below. The paper is well written and clearly articulates a contribution to the literature. The paper is well-written and provides insightful figures to showcase the strengths of the present method.
This paper proposes a combined architecture for image-text modeling. The authors also incorporate a deep topic model, a ladder-structured image encoder, and StackGAN++ into their framework for improved photo-realistic images. My chief criticisms come for the density of the paper - while it is difficult to dilute such a complex model to 8 pages, and the included appendix clarifies many questions in the text body, it would be worth further passes through the main paper with a specific focus on clarity and brevity, to aid in the accessibility of this work. The model also functions for tagging and annotating images - performing well compared to models designed *only* for this task. As usual, more experiments are always welcome, and given the strengths of GAN based generators for faces a text based facial image generator could have been a great addition. attnGAN (CVPR18), b. TA-GAN (NIPS18), c. Object-GAN (CVPR19). The motivation for the paper is not clear.
For example, what are the game description, game feedback are in this case? I think it is more convincing to have a baseline which leverages the same entity extraction and template-action space. If the model is merely trained on one map as shown in figure 5, it may just memorizes it in the knowledge graph and overfit to this map. Ideas are simple and incremental, even if i rely upon literature overview provided by the authors in the related work section. Under the general framework of A2C, the core contribution of the paper is to apply a graph attention network on the knowledge graph to help learn better representation of the game state and reduce the action space.
Overall, I think the idea in this paper is interesting. This work proposes a regularization strategy for learning optimal policy for a dynamic control problem in a latent low-dimensional domain.
in this paper. While this is perfectly adequate in the sense of connected components being a particular concept from topology, I would expect this to be clarified much earlier in the paper. - The manifold assumption is that data lie _on_ a manifold or _close to_ - I would not state that the main goals of the experiments are to I really want a discussion about that before I make a final decision. On a more abstract level, could it also be summarised as 'the inclusion of prior knowledge is a necessary condition for robustness'?
- In Table 4 it would be better to have results for FSNet-1 too (without quantization). I expect it to be a general and standard component for model compression and acceleration. - It is experimentally showed that architecture search works for proposed convolution. - For illustrations (figs 1, 2, 3) of input and filters packing it would be very helpful to mark where are channel and spatial dimensions on the figure for simpler understanding the packing.
For a large tensor, this additional reduction to compute statistics may be expensive (in memory bandwidth and computation), particularly since this is done with FP32. Could be very useful for many embedded applications. These determine (in log-space) a scale and an offset for the 8-bit numbers (eq 1). Such ``tricks'' can be difficult to tune for each problem. I'm not a hardware expert but can see why this would be Useful. There has been a great deal of interest and research into reduced numerical precision of weights, activations and gradients of neural networks. This should definitely be discussed in depth in this paper where the main contribution is an algorithm to be implemented in hardware.
It would be a good idea to re-run this experiment with a binary classification problem (e.g. only two digits of MNIST) and see if this phenomenon still occurs. 6. In the analysis of JSMA, as noted before,, it's rather dubious to claim that sleep had any kind of significant effect on the attack success rate (or distance) for CUB-200. 1) converting the trained ANN to a "spike" neural network (SNN), It seems very arbitrary. Sectioin 4: Sleep algorithm It's confusing that the format changes (unless I am missing something and it's actually a different variable). Furthermore, the authors state that "this represents the direction to change each pixel in the original input in order to decrease the loss function." But this doesn't make sense.
I believe this paper should be accepted. The authors find that GANs do not converge to local Nash equilibria, that each player ends at a saddle point, and state evidence for "rotational behavior" in GAN dynamics.
This paper studies the situation in which a two-layer CNN with RELU nonlinearity is fit to a single image and the observation that it is able to fit a "natural" image in fewer iterations than a "noisy" image. Proceedings of the IEEE, 66(1), 51-83. * Some comments on the empirical results reported in Figure 2: (i) how are hyper-parameters chosen?
Any insight here? (4) The setting of SEMI-SUPERVISED LEARNING OF 3D OBJECT DETECTION is quite unclear and sloppy. Having said that, the proposed approach is pretty generic, can be applied to RGB-D (more common in ML), and require few expert knowledge in vision (only the Egomotion module). This paper deals with turning a 2.5D video representation into a 3D representation of an environment or a scene. 3) outperforms the view regression baseline and a 3D motion flow-based baseline on 3D moving object detection (measured through precision-recall curves and mAP); From this description, it is not clear how much variation of unobserved vs observed surfaces exists in the training and test data. The whole paper is very well written, and organized. They explored the link of view predictive learning and the emergence of 3D perception in computational models of perception, on mobile agents in static and dynamic scenes. I appreciated the limitation section, which is transparent and honest, and clearly states the strength and weaknesses (such as image downscaling) of the approach.
I think the most important direction both in theory and experiments about the robustness to label noise of the 0-1 loss is that 0-1 loss satisfies a "symmetric property", i.e., \\ell(z)+\\ell(-z) = Constant for a margin-based loss function in binary classification. [2] Ghosh et al.: Making risk minimization tolerant to label noise Neurocomputing 160 (2015): 93-107. And the following paper that was also cited in the submitted work and compared: [7] Zhang and Sabuncu: Generalized cross-entropy loss for training deep neural networks with noisy labels, NeurIPS2018
Then results in easy games and other games are presented. I am confused if the paper is making a narrow point that (1) dont focus on Montezuma's revenge OR (2) is it admitting a broader point that focussing on even ATARI is probably not a good choice. To support their claim, the authors firstly compare bonus exploration methods, noisy networks, and epsilon-greedy on hard exploration games. I can understand that might not be the aim of the paper but still. I think this is a-ok paper in that it does what it says it does. The paper is clear and well-written.
I think the paper is well written and provides a nice discussion about how quantum computing can be applied to CNNs. I appreciate that both the forward and backward passes are studied although most of the technical details are in appendices. Sometimes one is using a parametrized version of ReLU that has a small positive slope for negative values. It looks to me that the same algorithm could be used for fully connected or even attention based systems, as it is just a matrix multiplication as well. - Maybe define what you mean by "tomography" for ML folks without the quantum background?
Overall I find the method is effective and experiments convincing and I recommend weak accept in my rating. But it is also interesting to see that this naive method works, and actually beat some of the more advanced alternatives in Section 4. This paper provides a new technique to adapt a source neural network performed well on classification task to image segmentation and objective detection tasks via the author called parameter-remapping trick. I like the direction this paper takes, NAS is too expensive and we need faster methods through meta learning/transfer learning. If the authors faithfully compared with state-of-the-art methods in search det/seg architectures, but I'm not super familiar with this literature. There is no TLDR for this paper, and I must admit, on reading the abstract and introduction I wasn't entirely sure what this paper was doing at first. Error bars would be a welcome inclusion, particularly in Table 3 where you have 0.1% separating FNA and MNasnet-92. I would like to see a comparison to a random search, as there are several papers (https://arxiv.org/abs/1902.07638, https://arxiv.org/abs/1902.08142) indicating that this is a very strong baseline. The technique results in improvements in both performance and training time.
The authors formulate it as a transport cost learning in optimal transport framework with constraints giving by side information. - The empirical result is quite comprehensive and convincing in that it includes from illustrative examples to real-world datasets (RNAs) and includes many relevant baselines. 5) It seems that there is nothing in the code sharing folder? # Summary This paper proposes a new way to learn the optimal transport (OT) cost between two datasets that can utilize subset correspondence information.
That said, there is quite a bit of room for improvement in terms of the writing of the paper. For example, In Section 2.1: - Why is k introduced?
In this paper, the authors proposed two methods of Nesterov Iterative Fast Gradient Sign Method (NI-FGSM) and Scale-Invariant attack Method (SIM) to improve the transferability of adversarial examples. 4. Is there an efficient way of calculating the gradient for scale-invariant attacks like translation-invariant attacks in Dong et al. (2019)? Without this, the authors cannot claim its effectiveness since only experiments on NIPS2017 is not enough. Overall, this paper is well-written.
The logic is simple and clear and the paper is well-written. The authors propose a simple but effective strategy that aims to alleviate not only overfitting, but also feature degradation (oversmoothing) in deep graph convolutional networks (GCNs). There is at least a nice interpretation of choosing 0.5 for the dropout proportion in regular dropout (maximum regularization).
This paper proposes a way to compress past hidden states for modeling long sequences. Attention is used to query the compressed representation. Overall, I found the work interesting and experiments are thorough and strong. It is always great to see a new benchmark released to the community. I am happy with the efforts made by the authors and I am raising my score to 8 (accept). A variety of compression techniques and training strategies have been investigated in the paper and verified using tasks from multiple domains including language modeling, speech synthesis and reinforcement learning. The key novelty of this model is to preserve long range memory in a compressed form, instead of discarding them as previous models have done. I think this is really necessary and should be reported. How exactly the compression is carried out on various network architectures is not clear after reading the paper. Achieving SOTA is one thing, which could be attributed to large resource pools and maybe larger parameter sizes of models. ## Original review This paper presents a new variation of the Transformer model, named Compressive Transformer. The choices of compression functions are intuitive and natural. What is the difference between sequence, memory, and compressed memory?
3. In a datacenter setting, they compare the algorithm with all-reduce, which is a centralized communication method. The authors also show CHOCO-SGD with momentum is effectiveness in practical. Overall, I think the technical contribution of this paper is unclear and the evaluation is not convincing. Extensive empirical results are presented in this paper and the two use cases highlight some potential usage of the algorithm. This paper studies the convergence of CHOCO-SGD for nonconvex objectives and shows its linear speedup while the original paper of CHOCO-SGD only provides analysis for convex objectives. In Proc. Advances in Neural Information Processing Systems (NIPS), 2017.
Summary: This paper is about developing VAEs in non-Euclidean spaces. Is it not differentiable at K=0? Was its variance learned? This kind of information is in my opinion crucial for assessing a construction to the latent space of VAE model, as it can have a lot of influence on the kind of information the model will try to store in its latent space. Why 6 and 12 dimensions here? Does this property remain in curved spaces?
This paper studies the problem of training binary neural networks. My biggest concern is that ResNet is itself a very wasteful architecture in terms of compute and parameter count. - The authors did not visually show the maps of real-valued and binary activations. The steps for building binary network takes several components: traditional strategy to binary/optimize a model (like data augmentation,  binary initialization using 2-stage optimization, etc), real-to-binary attention matching that tries to match the output of real values and binarized model, and data-driven channel rescaling to better approximate real convolutions.
This paper attacks the problem of pruning neural networks to obtain sparser models for deployment. This paper gives rise to a fully-automated procedure for identifying and preserving the filters in layers that are essential to the network's performance. In general, this paper is very well written and organized. *CONF* 2019. Summary: In this paper, the author propose a provable pruning method, and also provide a bound for the final pruning error. The results of pruned network should be improved, rather than getting worse, since some redundant filters/params are removed from original network. The authors use a measure of the sensitivity of the network outputs to the channels in a particular layer (eqn 1). It would also be nice to relate the work to this best paper this year.
The motivation of this paper is "most methods still decouple the lower-level skill acquisition process and the training of a higher level that controls the skills in a new task." The paper proposes a method to learn higher-level skill selection and lower-level skill improvement jointly. This behaviour is not described anywhere. In addition to the parameters, they do not fix the time length. Section 4: the advantage function is not defined. Some works are even cited in this paper, for example, option-critic, feudal network, etc. What I like in this paper: 1. The paper, in general, is well-written so that I can understand it well. - The URL of the website with code and videos does not have any code.
I think this can be improved in a camera-ready version or in submission to a later conference, should overall acceptance not be met. The one shortcoming of the paper is that it takes a simple idea and makes it somewhat difficult to follow through cumbersome notation and over-mathmaticization. That said, I feel the lack of clarity in the writing is actually the main drawback. Furthermore, it is not exactly equivariant due to the fact that you are defining input on a 2D square grid, but that is a minor detail in the context of this work.
Although its theoretical analysis with respect to the performance of anomaly detection is limited, experiments show that the proposed method is effective and superior to the existing anomaly detection methods. Since the proposed method is using RSB as it's core part, and claims to be a non-linear extension of it, it would be crucial to have a comparison with RSB, at least on those experimental setups, where high-level features are used (Tiny Imagenet with ResNET features, Reuters-21578, and 20 Newsgroups).
</update> The paper shows that the MSE of a deep network trained to match fixed random network is a conservative estimate of uncertainty in expectation over many such network pairs. - What is the x-axis for Figure 3 for the baselines? One could imagine that for e.g. simple priors and with sufficiently dense sampling of the domain of the function this can happen in practice.
I think it would be a great addition to *CONF*. Figure 4 is a bit confusing, and it would be better if the authors can include the label for the x-axis. * It seems like the differential physics loss requires a differential solver (in this case, for Burger/Navier-Stokes). The paper presents an interesting mix of neural networks and traditional PDE solvers for system control, and I vote for acceptance. Questions and suggestions for improvements: * What form of L_o^* and alpha was used in all the experiments?
I expect that this paper will encourage future work to explore more problems in this area. The proposed approaches are pretty elegant, and in a sense seem fundamental. * "intrinsic value function of agent i, I_{-i|i}^\\pi is \\beta > 0 is a weighting" -- I think part of this sentence was accidentally deleted. To the best of my knowledge, the broad idea of applying information theory to multi-agent exploration, in addition to the specific instantiation described in the paper, is novel.
I have a ton of questions about this method, but they are good questions. It's possible that this happens, but there is no evaluation that discusses this, and from all of the examples I'm led to believe that this is basically also just learning a few program templates, the same ones learned by previous methods. I feel like something must be missing here, or a simple LSTM decoder is more magical than I thought. Are you really not doing anything special to handle those? Can you add a table in an appendix showing the complete list of operators used? Later in the paper the specifics of those claims are made more clear, and while they are justified, they are very narrow claims. I found myself immediately looking for the numbers/results when you introduce the experiment. -- what is the early stopping criterion in Alg 1? Please understand them, however, in terms of my overall score and what I said above. I think you should elaborate on how the attention over the encoded text interacts with the attention over previously generated tokens.
Similarly authors give a variational form of the wasserstein natural gradient . It's important to be able to estimate natural gradient in a practical way, and there have been a few papers looking at this problem but mostly for the case with a Fisher-Rao metric. The motivation of the natural gradient is well-motivated. Natural Wasserstein Gradient similar to the so called natural fisher gradients preconditions the gradient using a matrix that uses the local curvature of the manifold of the parametric distribution.
I like that the authors performed this ablation given that the expectation over surrounding contexts is computed approximately via samples under a language model. This formulation is intuitive and more efficient compared to blindly learning contextual information in the model. This may be problematic for longer inputs (a pargraph), where the overall prediction may not change a lot when you remove a single phrase (since the evidence is everywhere).
Even though in the worst-case complexity is not optimal, the authors argue that for matrices that are commonly used in machine learning architectures (e.g. circulant matrix in a convolution layer) the characterization is optimal. (ii) can perform better than fixed permutation matrices (though parameter count also increased by 10%),
- p9 phenomenon -> phenomena; the the videos -> the videos; these observation -> these observations; of next -> of the next; in real world -> in the real world This paper introduces a new synthetic video understanding dataset, borrowing many ideas from the visual question answering dataset CLEVR. The compositional action classification task is harder and shows that incorporating LSTMs for temporal reasoning leads to non-trivial performance improvements over frame averaging. It is a well-argued, thoughtful dataset contribution that sets up a reasonable video understanding dataset. It is mostly well-written (except for section 4 which would benefit from extensive proofreading) and does a good job at covering relevant work. I like the fact that each task comes both with both static and moving camera. Finally, the localization task is challenging, especially when camera motion is introduced, with much space for improvement left for future work. In 2018 ACM Multimedia Conference on Multimedia Conference, pages 239–247.
It is not obvious to me how the proximal gradient was derived to (3)-(5). To address this, the authors train on RNAStralign and test on ArchiveII. The method consists of a Deep Score Network and a Post-Process Network (PPN). On the specific task of pseudoknot prediction, the method also performs well (F1 is >0.23 over the baseline).
Importantly, the method is grounded on solid theoretical footing for extracting minimal relevant information (rate-distortion theory / information bottleneck method). These methods produce scores that highlight regions that are in a vague sense "important." Minor Comments a) Is there a particular reason for this choice of colormap? ----- Given L_1=0 really implies that no information of the corresponding region is used for the certain beta, but is this true for the original model (beta=0)?
The task or a set of tasks? The claim is that the agent is first able to learn a near-optimal policy for a small # of problems and then is able to solve a large # of tasks by such a learned policy. In particular, the visualization in 4b showing options learned in Amidar does not show much improvement from what was observed before in Harb, 2018. Experiments are conducted on the four rooms environment and Atari 2600 games and demonstrate that the proposed method leads to faster learning on new tasks. Overall: An interesting objective function, Learn not only option set but also the number of options needed and incrementally learn new options. This paper proposes a new option discovery method for multi-task RL to reuse the option learned in previous tasks for better generalization. During the offline training, they add one option at a time and move onto the next option when the current loss fails to improve over the previous loss, which enables automatically learning the number of options without manually specifying it.
It should be "Cai et al" - Table 2: unclear: "accuracy without content" The paper's incorrect claims (weakness 1) are highly concerning and strongly suggest rejecting the paper. 2.3. Page 6 mentions twice the "ratio between APR and PR", is this is this used/evaluated in the results? 1) The propose to sample nodes nodes based on "regional" uncertainty rather than node uncertainty 2) They use an variant of pagerank to determine nodes that are central, and hence most likely to affect subsequent classification in graph convolution classifiers. Minor: The paper contains many minor writing issues, e.g. - missing spaces, e.g. "distribution,and" (page 2) 2. Clarity: I found the paper rather difficult to understand and follow: Some specifics: 2.1. 1.3. "We outperform all existing methods in the Cora dataset, and get very similar results to the best accuracy obtained by Chang et al methods:" - Table 1: incomplete sentence: "∗∗ scores for smaller budget, since it was the"
A few ideas: * Randomly sample a (possibly large batch) and learn to weight it (closely related to the straight through estimator) * Would be nice to understand which samples are chosen and why. To sum up, I don't think the proposed method is RL-based, it would be more appropriate to define it as a MAB problem, and this paper should solve this problem before publishing. * I found the discussion and figures presented in 4.2 to be quite nice and informative. This function needs be updated in settings where the underlying dataset changes. * Would be nice to show the sizes of datasets and how many samples end up being used for different values of lambda. I've given a weak accept, conditioned on being provided more evidence regarding 1) comparisons to simple differentiable alternatives, 2) sample efficiency of the RL method, and 3) basic analysis of the weighting function. Besides, the state transition in RL relies on decision making at each time step, while it has not reflected in your paper and code, namely, the state-transition independents on the decision making. * It is a nice result that the l1 penalty actually works well in reducing the number of samples chosen by the
It is also noticed that the existing metrics for selectivity do not adequately discriminate highly selective units in CNN. So it is not only possible, but rather likely that the learned "object detectors" are to some degree driven by the statistics of the data, not the labels - e.g., there could be a highly selective "bird" unit which nevertheless has high false positive rate for any of the more specific bird species categories in the imageNet nomenclature. I do not see a simplistic dichotomy, where one could or should determine which of the two interpretations is "right" or "wrong". According to that study, almost 60% 0f all fc8 units are "object detectors", with very high conherence between humans and selectivity metrics. We selected 233 ..." : Which criteria is actually used to choose the candidate units for the analysis? This work investigates the collection of methods that have been proposed to find units in neural networks that are selective for certain object classes. It is a laudable effort that someone took on that job. The paper empirically studies the category selectivity of individual cells in hidden units of CNNs. It is a sort of "meta-study" and comparison of different metrics proposed to identify cells with a preference for a specific target category. For example, I find it quite remarkable that some unit has 8% recall at perfect precision. - is an indeed important problem for *CONF* community: Personally, I feel the "existence" of selective units in RNN could be interesting, but the "non-existence" in the case of CNN is not that surprising for some readers, as it seems much likely (at least to me): The final layer of CNN would be surely selective across classes, but it may be not the case for the hidden layers
This paper proposed a new diffusion operation for the graph neural network. --- A sampling of typos --- Overall, the major criticisms of this paper: - The proposed algorithm is not clear. - The paper needs a lot more polish and proof reading to make this paper presentable.
The paper argues that isomorphic graphs are akin to duplicate images in computer vision and should be removed from a dataset. While (a) is very interesting, and an important contribution, (b) and (c) are contradictory. Moreover, being able to capture the equivalence relation can be important for various graph learning tasks, e.g., to facilitate that two topologically equivalent graphs are be classified similarly. - The results and recommendations presented in the paper are intuitive and somewhat trivial
[****] Distributed Gaussian Processes (ICML-15) 6) Reproducibility The data is from published sources (toy, ebirds, precipitation, digits) and the code for the baseline methods and for the LAIM method itself is available. There are also a few technical ambiguities that need to be clarified. c) Intro: "with some special structures" -> fix d) Background: "q(f)~N(mu,V)" -> imprecise notation, rather "q(f)=N(mu,V)" -- I think I have elaborated this in points
In this paper, the authors propose the Homotopy Training Algorithm (HTA) for neural network optimization problems. L can be seen as a regularization parameter that is gradually decreased as we optimize the new optimization function. 2) After equation (7), should G():= \\nabla H instead of F?
However, I have several concerns: Major: 1. It seems that the whole process assumes that there is difference for the parameters in the environment of GGD with adv/benign samples, and the goal is to search for the major components of it and use a classifier to detect. This paper proposes an approach to adversarial detection.
Based on the well-known universal approximation property of FNNs, the paper shows that their RNN-based filter can approximate arbitrarily well the optimal filter. The paper is well-written and easy to follow. It considers a general state space model and uses feedforward neural nets (FNN) to learn the filtering and forecast distributions. To me it seems utilizing sufficient statistics? Overall the paper seems to be a straightforward application of universal approximation theorem of deep neural network.
You can see this by observing that assuming that when {x_k}=E_K(H(I)) holds, we can choose all other pixels to be exactly the value returned by H(I). This paper proposes a method for multi-instance object classification and reconstruction that does not require any location-based supervision. It employs two submodels, where the first generates a heatmap of intereting region and the second model is a task-specific model that works on image-patches, for example a classifier or an autoencoder.
It seems that this is only needed for Theorem 8 to hold.
Furthermore, important details are left out in the appendices, which make it difficult to read the main body of the paper in a self-contained fashion. 7 - What does "robust" adversarial attack mean?
In summary, it is good that a theoretical bound can be derived from the paper, but this paper's quality may need more enhancement particularly on its writing and experimental parts. This should be presented earlier since not every reader will be completely familiar with learning theory. The main hypothesis is that the degradation in performance in adversarially robust networks is due to many samples being concentrated around the decision boundary, which makes the network less confident about its decisions. 4. Finally, this paper seems to be written in a hurry. I an inclined to increase my rating and would suggest to weak accept this paper. This seems like a very minor comment, but this graphs are not very complicated, so they should be easy to understand; yet it takes several minutes to take in what is happening in the graph.
I would like to see an empirical analysis of that as well. Instead, the effect should be that tasks are in (greater) violation of the task i.i.d. assumption.
Discussion would be helpful. The paper introduces a new concept-based interpretability method that lies in the family of self-interpretable models (i.e. it's not a post-hoc method). Is it for efficiency reason? * For the model architecture, why did the authors choose to use the straight-through estimator and not other methods (e.g. concrete layers, ...) For (A), as the first and second part of the model introduce discrete choices, they use a RL with Monte-Carlo approximation of gradients. The system is evaluated under two measure: 1) classification accuracy and 2) concept accuracy. Self-interpretability is achieved by a two-stage model: First, a concept-extractor finds the related pieces of consecutive words (excerpts) in a given text that are related to a concept among a set of given concepts (if any), then the model makes its predictions solely based on the presence or absence of concepts (binary). Thanks again for a well-organized and easy-to-follow paper.
For this generalization error, the authors give both bounds for a fixed generator and a uniform bound for a class of generators. c) Section 3 and 4 have bunch of theorems and collieries without much explanation. I suggest authors to change multiple hyper-parameters and train more networks to improve the evaluation. It also is not clear how they get the bound that they attribute to Bartlett, et al from the bound in that paper. d) I don't completely understand the notation in Corollary 3.3. In my opinion, the mathematical writing is not up to the standard for publication in *CONF*. Some of the things that can be improved: a) The discussion on the different definitions of generalizations is not really helpful in the current format.
My Take: This paper's only point of novelty over a vanilla VAE-GAN implementation is the inclusion of the KL(E(G(Z)) || p) term in the generator loss, which is very similar to the idea behind VEEGAN. Generally, this paper was well written. Why don't you do this? Please examine your paper for formatting mistakes.
Secondly, the generator is trained on a supervised image translation tasks: the original image and the style, extracted from the target image, are fed to the generator, and the output is a translated image. You may want to replace "e_i" with "s_i" to avoid confusion. [1] Jaejun Yoo, Youngjung Uh, Sanghyuk Chun, Byeongkyu Kang, Jung-Woo Ha. Photorealistic Style Transfer via Wavelet Transforms. It is also difficult to find its definition. My overall rating is borderline.
In any case it is not clear why this should necessarily be a good inductive bias for all images, although it is plausible that it helps in some cases. [2]A Regularized Framework for Sparse and Structured Neural Attention . The authors then compare their TVMax approach with softmax and Sparsemax attention for image captioning and show improvements on the MSCOCO and Flickr datasets. I wonder whether there is a better task for evaluating the visual attention. Therefore, My decision leans to a weak accept. The other issue with their approach is that it doesn't seem to scale well - if I understand correctly their algorithm takes O(n^2logn) for sequence length n. I am not convinced of the motivation for sparse attention unless it is for long sequences, since otherwise the regular softmax should be able to assign 0's to the un-needed items. André F. T. Martins, Ramón Fernandez Astudillo
The method (dubbed SMiRL) is evaluated in visual and proprioceptive high-dimensional "entropic" benchmarks (that progress without the agent doing anything in order to prevent trivial solutions such as standing and never moving), and compared against two surprise-maximizing intrinsic motivation methods (ICM and RND) as well as to a reward-maximizing oracle. This paper takes a pragmatic approach to this by training a density model on the full set of visited states which are reset at the start of each of a series of training episodes. 5. The agent trying to reach stable states sounds like exploration is discouraged.
The approach is similar to methods that use multi-stream networks (a stream for each domain), but using the filer decomposition scheme, the authors avoid the issue of excessive increase in the number of parameters typical in fully multi-stream architectures. This paper introduces a way to decompose features for better domain adaptation via learning domain-invariant representations. "Domain-Specific Batch Normalization for Unsupervised Domain Adaptation." In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. Make it clear that these points are here to help, and not necessarily part of your decision assessment. A toy example presented is convincing and shows the correction basis learned in a simple synthetic case.
Also in this section, the authors mentioned Tucker decomposition for the tensor regression. In 2.3, there is a lack of definition for  \\Lambda_1 and \\Lambda_2. Therefore the novelty for this aspect seems a bit weak for me. Maybe some further investigation of the game demon_attack is needed to understand why using scattering in this game in particular gives such a huge performance boost.
It would be nice if the authors and discuss this in the revision To decouple the dependency between the head size and the embedding size is not a novel point. I re-read this paper multiple times and the only concluding finding I have is that this paper proposes an explicit way of setting the projection dimension regardless of the number of heads. - A simple approach that proves strong in several NLP tasks.
The experiments conducted in that paper seems to be similar to the ones that are done in this paper. Three different datasets (i.e. image, gene expression, health-care) are chosen to evaluate the proposed model's effectiveness, while different regularizers (i.e. image prior, graph prior, and sparsity prior) are explored for the respective task. It is not clear which model is used in Figure 2. Some of these should serve as baselines. This would imply that (human-understandable) information needs first to be transferred from a model to humans. I am concerned that only a limited set of expert-invented human priors can be used in this approach. Further, feature attribution methods aim to develop a richer notion of the contribution of a pixel to the output. Strengths. 1. Incorporating human knowledge into the model has a growing interest in ML / CV communities. 3. The paper provides well-documented supplemental materials that contain details of the experimental setting and additional supporting figures. Attribution priors as you formalize it in section 2 (which seems like the core contribution of the paper) was introduced in 2017 https://arxiv.org/abs/1703.03717 where they use a mask on a saliency map to regularize the representation learned. Also, in Figure 5 showing that integrated gradient cannot highlight black pixels. More impressively, the model does outperform all other controls with a good margin in the anti-cancer drug prediction experiment, which is a nice demonstration of that domain knowledge could be incorporated in a neural network training to achieve better performance. So with that the paper positions itself not as a survey but as a method paper but lacks evidence that the method expected gradients performs better. Unless end-users cannot understand the model's behavior, how can we expect humans can provide knowledge to model? as measured by R^2 (Figure 2 Left). The paper should have a single focus.
The paper's contributions can be summarized as follows: 1) A data representation that converts the 3D atom locations to a 3D voxel density map, so that they can be encoded by a standard 3D convolutional network. Prior work on this task has used 1D (SMILES) and 2D (Graph) representations. Without such scores in the crystal generation domain, it is not easy to judge how good a generated crystal is. Weaknesses ------------------------ 1. Limited methodological novelty: The methods used in the paper, i.e. the data representation (see detailed comments), the encoder network, the decoder network and the segmentation network are all existing methods without any (or with only minor) modifications. 7. PointConv: Deep Convolutional Networks on 3D Point Clouds 5. Grammar Variational Autoencoder 6. 3D U-Net: Learning Dense VolumetricSegmentation from Sparse Annotation An encoder-decoder architecture is used to create a representation of a molecule and to reconstruct the molecule from its representation. Because atoms that differ in atomic number by 1 or 2 will have different valencies and hence exhibit different properties? 3. Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs
This paper addresses a limitation of BatchNorm: vulnerability to adversarial perturbations. *The proposed method involves a hyper-parameter \\rho, but it may result in problematic issues.
The paper proposes an approach for learning graph convolutional networks for inferring labels on the nodes of a partially labeled graph  when only limited amount of labeled nodes are available. 1. As the self-training is going on, are there different computational costs or are they about the same? 3. Will such self-training be useful for general NN self-training procedures It tracks three limitations of [1] and propose three  use a threshold-based rule to insert new pseudo-labels and dynamic change the pseudo-label set. 2. The gap of the experiment results between the proposed method and the baseline methods are quite small. 3. Only GCN instantiation are provided, it is suggested to evaluate the effectiveness on the other GNN variants, such as GraphSage, GAT and MoNet. The main idea here consists in relying on self training to get a better coverage of labeled nodes enabling learning with less deep models, this translates to a simple and intuitive algorithm.
"Algorithms for CVaR Optimization in MDPs". I went through this section, the main results, and the proofs in the appendix. Second, the robust actor critic algorithm is based on a multi-time scale minimax gradient approach, which is also quite standard in this field, and besides asymptotic convergence it is unclear how efficient this algorithm is.
For example, on page 3, in "The non-informative prior is a Gaussian with arbitrary mean (\\mu_1) and infinite variance (\\sigma_1)", I guess \\sigma means the standard deviation? Such regularization is somewhat similar to sparsity regularization on neurons, which forces the information to concentrate on a small portion of the neurons.
Unfortunately I'm not an expert in this area and I don't feel confident in having a very strong opinion about this paper, willing to fight for its acceptance. The work is based on a hypothesis that a causal process can be modeled by "independent" modules and sparse interactions. The idea behind this architecture is that it would allow the different modules to specialize in different mechanisms and that would allow compositionality.
The authors found that in a setting with low budget for hyperparameter tuning, tuning only Adam optimizer's learning rate is likely to be a very good choice; it doesn't guarantee the best possible performance, but it is evidently the easiest to find well-performing hyperparameter configurations. This paper introduces a simple measure of tunability that allows to compare optimizers under varying resource constraints. * minor: in figure 8 in the appendix, the results after 100 iterations is, as far as I understand, over a single replication, so is not particularly reliable (and will always be 100% of a single optimizer) Comparisons which, while mentioned, should perhaps have been discussed and compared more in detail in this work. as the main contribution. However, I do not think the metric they introduce is good enough to be recommended in future work, when comparing tunability of optimizers (or other algorithms with hyperparameters). This could significantly increase the tunability of SGDM.
[Overview] In this paper, the authors proposed a shuffle strategy for convolution layers in convolutional neural networks (CNNs). The idea is borrowed from the biological domain, and then transformed to a spatial shuffling layer which can shuffle the feature response at each convolutional layer.
This paper extends the unpooled mention pair model of annotation (MPA) (Paun et al., 2018b) with the hierarchical priors (e.g., mean and variance) on the ability of the annotators. I suggest explaining community profiles more. The proposed method was evaluated on Phrase Detectives 2 corpus, which was annotated by players in a game with a purpose setting for coreference resolution. Strengths: This seems like a simple, strong and sensible approach when annotations per annotator are sparse. I am wondering of the connection between community and sparsity. * Authors claimed that "We let the number of communities grow with the data, a flexibility that we achieve using a Dirichlet process mixture," but this is not clear in the modeling in section 2.1.
The method overall doesn't seem to be able to match first order gradient methods, and it is not clear whether this is because of using the RMSProp/Adam preconditioner as a curvature matrix. The ideas are interesting. However, I have a number of concerns/questions about the work, that I list below. I can not support acceptance for current version. 3. The experimental section only reports "log-loss", which is not enough to deep learning applications. a) What is (\\epsilon^{-2}, \\epsilon^{-3})?
There are a lot of typos in the paper. ------------- This paper proposes an attack method to improve the transferability of targeted adversarial examples. Even though the experiments show effectiveness partially on VGGNets, but the overall improvements are not sufficient for me to claim the general effectiveness of the method unless the paper could provide additional results on broader range of architectures and  threat models.
Given a set of expert demonstrations, this work provides a policy-dependent reward shaping objective that can utilize demonstration information and preserves policy optimality, policy improvement, It is generally studied in The description of DQfD and DDPGfD in the related work is not accurate. They actually propose exactly the same framework as a special case in the appendix of that paper. https://ieeexplore.ieee.org/document/8794074 is another method built on DDPG that has both a critic and actor loss like yours and would make a useful comparison. and the convergence of policy iteration at the same time, under the assumption that expert policy is optimal and stochastic. The proof of Theorem 2 is similar to the proof in Proposition 1, [1], though in a different context. The authors conducted sufficient experiments to demonstrate the effectiveness of the proposed method, compared with the state-of-the-art in RLfD. I don't think there's enough space in the abstract to go into that level of detail. They claim that using demonstration data in a supervised manner "cannot generalize supervision signal over those states unseen in the demonstrations," but most of these approaches are using neural networks and definitely are generalizing those signals to other states. The authors use a regularized reward function that minimizes the divergence between the policy of the expert and the one followed by the agent. the explicit computation of expert policy is avoided. This paper presents a method for doing RL from demonstrations in continuous control tasks.
What about beta1 and beta2 for Adam? 4. How sensitive is performance to the values of these hyperparameters? Overall I think this work requires quite a bit of work before it is ready for publication, and would benefit from a much more thorough empirical evaluation of the algorithm. 2. Is the learning rate tuned?
It would be better to provide more explanations on the graphical model for meta-graph and the meta-graph architecture in the context. To do so, each graph is treated as a link prediction "task". More specifically, they generate an effective parameter initialization for a local link prediction model for any unseen graph by leveraging higher-order gradients and introducing graph signature function into graph neural network framework. The paper is conceptually solid, however, it is hard to claim novelty in individual ideas in the paper.
The paper is really well written and enjoyable, clear in its description and in the objectives it aims to achieve. Moreover, I think that using braces instead of parentheses would be more correct in these cycles. Other comments to the proposed manuscript are: 1. In Definition 1 the authors declare that the goal is to satisfy f(T,M)=f(T'M) and g(T,M)=g(T'M), and then in the following paragraphs they change it to f(T,M)≈f(T'M) and g(T,M)≈g(T'M) with no justification. The paper also presents a good experimental campaign that shows good performances. The paper targets a very important problem in practice. On page 8, "When the termination crite gets stricter", crite should be corrected in criterion. To improve the readability a bit further, I would suggest trying to move equation 1 after or close to its reference, or at least to describe before it what KL is. The first sentence on page 5 seems to be incomplete as it is written.
The reason I say this is so that the reader should not (wrongly) interpret that this is the first work that finds "favorable" properties of wider networks (the paper does not make this claim, but it is easy for a reader to interpret it). I have a few comments. Overall the paper is written well and the ideas and results are communicated crisply.
Or could position i in query and position i in key be in different clusters? 8. What is the motivation of using half of the heads for local attention and the other half for routing attention (cf. The paper is also very well written and easy to follow and understand. Is there any reason that you abandoned this design and used Eq. (2)? (Additionally, the authors seem to suggest that Qi⊤Kj=Qj⊤Ki in the subsequent analysis, which should not be the case, unless W_Q = W_K.) Also, just curious, how did you regularize WR to be orthonormal while training? However, the cluster attention seems to group the words together, and there is no cross-cluster attention (i.e., the graph is broken into smaller components). This paper proposes content-based sparse attention to reduce the time/memory complexity of attention layers in Transformer networks. the intro paragraph of Section 5)? One negative of the paper is section 4.1. Or do you change the softmax normalization such that it is over C_i? In particular, in addition to points raised by reviewer 2 there are concerns with regard to lack of ablation studies, and major clarity issues.] Are we then, in language modeling tasks, performing attentions among words only around these "anchors"? I think the paper can be improved by including more elements, such as ablative experiments and runtime benchmarking. Pros: + The math notations are generally clear (e.g., dimensionality) and the paper is well-organized.
Interestingly and counter intuitively , it is not a monotonically decreasing function. It would be beneficial to clarify when it is happening: a) For each individual of the population during step (1), b) before performing CMA, c) after CMA. While the paper does a great job at presenting the problem and its applications and propose a framework that generated a loss that can transfer to other datasets without any tuning required. It is unclear that the genetic optimization is superior to simply choosing random loss functions.
These results suggests that some of the complexity in RL design can be ignored. This paper presents a framework for evaluating offline reinforcement learning (RL) algorithms. Though BRAC summarizes offline RL methods in a neat way, it would be more technically sound if a general theoretical analysis/insights of offline RL algorithms can be offered in the paper, e.g. showing the reason that vp is outperforming pr through convergence analysis in the tabular case. I appreciate the authors for their careful empirical study. And I think the authors did a good job addressing a difficult problem. Clearly the authors of those previous works thought they were needed. I commend the authors for performing a valuable test and comparison of existing offline RL methodology. Finally, the paper presents lots of results, but I did not see any mention of the statistical significance of these results. Does the BRAC framework reproduce the results for previous papers? Results from a  thorough series of experiments are presented which suggest that certain details of recently proposed RL methods are not necessary for achieving strong performance. The authors provide extensive results; but it wasn't clear whether these were "apples-to-apples" comparisons with the previous results in the papers that proposed the "unnecessary" technical complexities. Overall, the paper is well written and easy to follow. I am leaning to accept the paper because (1) the experimental design is rigorous and the results provide several insights into how to design a behavior regularized algorithm for offline RL. Minor comment: Error bars should be added to the all the bar plots. For example, I didn't see the authors say that they reproduced the results of previous works, only that they tested previous methods in certain tests. Specifically, the paper does a thorough ablation study on BEAR, BCQ, and KL-control within the BRAC framework. **UPDATE** After reading the rebuttal, I think my concerns are addressed and thus I updated my rating. The paper empirically investigates the effectiveness of each regularization scheme as well as each divergence function and conclude that vp is slightly more effective than pr while all divergence functions have similar performances.
This paper proposes a multi-task dynamical system for sequence generation. - The main motivation of this paper is to treat each sequence as a task in the training set (customization of the individual data sequence). This paper proposes to add a latent variable to a dynamical, thereby encoding the notion of "task", eg, in Mocap, the latent variable could encode the walking style in an unsupervised manner.
One issue with comparing this method to most other OoD detection works is that it considers OoD detection on *batches* of (all OoD data) or (all in-distribution data). In evaluation mode, likelihoods for each OoD sample are evaluated independently, which results in a similar observation to prior work showing that CIFAR10 likelihoods are inaccurate for SVHN. The batch size used for train/evaluation is rather large (64, this detail is hidden in the Appendix and I would have appreciated the number put in the main experiments section). What does this mean? Does this mean their BPP is good? In some ways, this makes things more well-defined (hard to compare distributions when one of them is just a single sample from an arbitrary distribution). Nits: - "...such as learning a mixture of Gaussians", I believe this toy example was on univariate gaussians, not mixtures.
To model functions s and t In this paper, a GraphNVP framework for molecular graph generation is proposed. It is not possible to train model with variable number of nodes. This paper presents a new reversible flow-based graph generative model wherein the whole graph i.e., representative attributes such as node features and adjacency tensor is modeled using seperate streams of invertible flow model.
Summary: this work uses tensor methods to improve graph convolution for dynamic graph, where the nodes are fixed and the edges are changing. It is well-written in general, but the definitions are dense and hard to follow. Slice-wise matrix multiplication is also common in practice. I am interested in how this will influence the runtime and memory cost. Datasets are collected from practical problems and of moderately large scale.
A measure of global accuracy is proposed to reflect the global accuracy of the embedding. What seems right to me is to compute global score (i.e. how much global information has been preserved) by comparing to some statistics in the (high-dim) x space, not to another method. Major merits of this paper are: 1. The proposed method seems effective.
This paper proposes a flatness measure that is invariant to layer-wise reparametrizations in ReLU networks. The authors also claim that measuring generalization using test error is flawed, but do not provide details about their method of measuring generalization. This paper describes a connection between flatness of minima and generalization in deep neural networks. This seems to be a missing step in relating flatness/feature robustness of a layer to the generalization of the whole network. There are many relevant work in this area that connect feature or weight robustness to generalization look at [1,2,3,4] for some examples. While this is interesting, it is not clear to me that this guarantees generalization for deep neural networks. **************************** After author rebuttals: Author have added discussion of related work which was missing in the original submission (thanks!). This is derived through a straightforward observation that perturbations in feature space can be recast as perturbations of the model in parameter space.
I feel this is an important detail to include. The key to the improvements is in the iterative prediction of the causal graph (for F) and in having attention over the causal graph (in \\pi_G). This seems to be a bit of an overreach. I imagine this is soft-attenetion but it needs to be clarified with equations and explanations. Only until Section 3.2 did I realize that N is the number of both "cause" set and "effect" set. It's possible that many empirical problems could be solved to a large degree by advances in machine learning without having to resort to explicit causal modeling.
5. In Table 2, 3, and 4, it is not clear on why GAT and GraphMix (GAT) are missing. Instead of trying to incorporate an augmented dataset into the graph, this paper uses a seperate fully-connected network (FCN) that shares weights with a graph neural net (GNN). For the MLP, the manifold mixup loss is used for training.
This work addresses the important problem of generation bias and a lack of diversity in generative models, which is often called model collapse. While this work is focusing on black box methods for evaluating and palliating mode dropping (aka collapse), it's a bit disappointing that these results are at least also evaluating on white-box type methods in settings where mode dropping is clearer, e.g. PACGAN on stacked MNIST or even normal CelebA. With the proposed methods, the authors showed that most STOA methods have a wide gap between the top p faces of the most popular face identities and randomly sampled faces. In addition, some explanations in this work are very hard to parse, e.g., the first paragraph of the methods section. Finally, the authors demonstrated that there exist a high-density mode, but not whether some modes might be missing. The writing and presentation are good. How can this method be used to find missing modes if the generator isn't generating them without the real data?
2. The authors presented a thorough analysis on the proposed KA strategy and compared it with KL strategy in terms of the precision and recall for the student models. b) similarly, in Figure 5, it is shown that KA has generally higher entropy than KD. (Murphy, 2012) Machine Learning: a Probabilistic Perspective.
However, the term "interpretability" is very vague and it is not properly defined in this paper. I find the paper not easy to follow, with a non-negligible amount of typos in the notations and results. A more principled or in depth analysis of this phenomenon is needed to make a stronger case. the paper is not well written, and 2. - In Eq. 1, b_{t-1} and x_t are not of the same dimension, so the cannot be multiplied by the same matrix U (this is why the matrices V_x and V_b are introduced later on). In this paper, a new unit based on the outer product called TPRU is proposed for recurrent neural networks.
Is it meant to be P_1(X)? - It is not clear from the paper whether the  []_+ op back-propagates gradient or not, which will make a big difference here. 2. It is unclear how costly the method is in terms of resources and training time. Page 3, line 8: Each \\alpha corresponds (to) a \\lambda
In addition, a discrete latent variable model is used in the model to encourage the model to produce a diverse set of alternative predictions. There is not a huge algorithm novelty for the methods proposed in this paper, but they can well address the domain issues and improve the performance. - Table 3, lists the average number of unique reactions classes.
The idea of the paper is good and Algorithm 1 sets out to learn the exploration policy when the expert policies do not agree.
Such a baseline is not clear in the paper, and the comparison with (Tu et al., 2019) is not provided in the paper. 1) The benefits of BO? 3) It might be useful to show the convergence of BO in terms of objective value versus iterations/queries. It was shown in (https://arxiv.org/pdf/1907.11684.pdf, Table 1) that BO usually leads to larger \\ell_1 and \\ell_2 distortion. 2018. This paper applies Bayesian optimisation (BO), a sample efficient global optimisation technique, to the problem of finding adversarial perturbation.
This paper investigates the impact of using a reduced precision (i.e., quantization) in different deep reinforcement learning (DRL) algorithms. In a sense it is neat to see that eventual errors do not compound, but that's it. With respect to the results being known, quantization is known to succeed in supervised learning tasks. - Is it really necessary to explain Fp16 quantization as it is done now, with even a picture of two bytes? It is repetitive, spending too much time with basic concepts, and it still ignores small details that matter (e.g., calling it Atari Arcade Learning).
I expected it to be exactly reconstructing s_t (given that the others are trying to predict s_t+1)? Specifically: 1) It is unclear what this paper is claiming to improve over prior work: is the goal to a) learn a good forward model, or b) show that emergent entities allow better downstream tasks. I would remove this figure fully. In those cases, it'd be hard to access how the model may generalize to real-world data, where object appearances and texture can be complex. However, I was shocked that the authors seem to be unaware of the abundant related work in this area (see below).
As pointed by the paper, Yamada et al., 2017 have a very similar objective and it is not very clear from the paper what is the additional contribution that this paper makes. This table, RELIC, can be used in various tasks like entity typing, entity linking and question answering.
Is o_l(.) an intermediate step in f(.)? This makes the effectiveness of the proposed losses a bit questionable. * (Sec4) "Gradmask proves to be too powerful a regularizer for this task, and never produces a model with good generalization performance." - This approach is not very compelling (e.g., comments about limited novelty and lack of concrete examples to boost intuition). (approach) Actdiff: 1) The Actdiff loss requires a mask that highlights areas of the input image which have signal and not distractor regions. I think the problem considered in this paper is interesting and important. The idea of regularizing using saliency maps has been explored and even applied to medical data like the MSD used here in Gradmask (one of the strong baselines this paper compares to). I assume it is a CNN based autoencoder of some sort. (evaluation - Multi-Site dataset) A final task tries to construct another synthetic dataset out of real X-ray images collected at two different places. My major concern on this study is the experiments.
The paper presents an unsupervised approach for learning landmarks in images or videos with single objects by separating the representation of the image into foreground and background and factorizing the representation of the foreground into pose and appearance. 3. what is the thin-plate-spline warped image? Do you have an explanation for that? how do you know it is foreground and only colorizing this part? - Why are there more than 8 points in Fig. 2 for "Ours8" (and more than 12 for "Ours12")?
However, I believe that this argument is based on the assumption that representations learned for a single task are indeed highly similar. I am also curious as to why only one of these scenarios was experimented with in sections 6 and 7. The objects in subsets A and B may have the same category.
I suggest that this paper is weak accepted. Their technical innovation is to combine a marginal error term that does not depend on x (which ensures coverage) with a local variability error term that does depend on x (to allow for greater variability in areas where the model is more uncertain and there is less data). Can you please provide a discussion of how this would affect the reported results? Could you please check this reference and let us know if it substantial is different from Influence functions that you develop? Maybe mention this in the appendix They do a great job of communicating this concept. https://arxiv.org/abs/1705.08292 The authors provide an interesting study on uncertainty estimation for deep learning for regression problems. - Also on p.8, can you please clarify how you selected the threshold for the evaluation of "discriminative power"? This is an intuitive approach that the authors explain well. However, I have concerns that prevent me from recommending an accept at this time: 1) Similar recursive formulations for HOIFs have appeared in the literature, so the claims in Section 3.3 should be toned down.
Table 2 suggests that a single model, even trained with 40B sentence pairs, does not outperform a single model trained with 20M sentence pairs as in "He et al., 2019", while being significantly more expensive to train. It is impossible to reproduce the results of the experiments conducted in this paper in future validation. Overall, the experimental setup is impressive, but the improvements in terms of BLEU are relatively small, and the technical contributions seem quite thin to me for a ML conference. In Section 4.3, I'm curious about why only 6 layers are used in the encoder and decoder? The key idea of their method is to dynamically assign training instances to different model components and update different components according to the assigned instances. If that is the case, this is expected to see a drop in performance, BT is usually a very effective, but not so much when the monolingual data is noisy or out of domain.
This paper shows that UMixUp and DAT are equivalent when the number of samples tends to infinity. This paper introduces directional adversarial training (DAT) and UMixUP, which are extension methods of MixUp. DAT and UMixUp use the same method of MixUp for generating samples but use different label mixing ratios where DAT retains the sample's original label. Reviewers will be instructed to apply a higher standard to papers in excess of 8 pages. Thirdly, the experimental results show that the performance gain by UMixUp is relatively small in comparison to that of the original MixUp.
I imagine the generator could rely too much on the attention map as a result - how this is alleviated/prevented should be explained. - Why post hoc and RAM are evaluated on different datasets from each other in qualitative results? - User study will be helpful. This appears to be the opposite of the desired behavior, so the objective needs to be reformulated.
The most important theorem which is claimed as the theoretical contribution of this paper (i.e. Theorem 6) did not even appear in the main contents but only in the appendix. "... to provide value in predicting patients' diagnosis." is better written as "... With regards to the experiments, I worry that the model is not compared against simple baselines, such as a PCA.
The authors propose to learn a Transformer in embedded spaces defined via m hash functions, with application to (fixed length) sequence-to-sequence classification for NLP. It seems that the technical part of Superbloom, including the hashing and the inference, is the same as those in (Serra & Karatzoglou, 2017). For a given labelled pair (x,y), the model outputs a matrix P∈Rm×d, whose i-th row is trained using the i-th hash hi(y). The size of the vocabulary could be largely reduced through hashing, which makes a larger embedding dimension and more complex internal transformation eligible and thus better performance. Since the method is applicable to any problem involving natural language data (and more generally categorical values, such as knowledge base completion), I would have expected experiments on tasks with a well-defined state-of-the-art. * the task is to predict masked links in sequences of links with the surrounding text filtered out. b) How were hash functions inverted and what was the cost of doing so?
[Original reviews] This paper proposed to modeling image as the combination of a GAN with a Deep Decoder, to remove the representation error of a GAN when used as a prior in inverse problems. Although the method is clear and straightforward, in the experiments, the influence of the new model component seems marginal. However, I would still appreciate if the authors can provide an overall model figure in the model section to help understanding. Still, it would be good to think about some more experiments (and include at least one of them in the paper): 1. You compare to IGAN and show that you achieve similar performance. Intuitively, the manner of the proposed linear combination model is rough and less reasonable.
- Abstract: "it is also quantitatively similar or better in accuracy" -> shouldn't it be "and" instead of "or"? I find that the proposed method appears to be theoretically sound and is interesting in revealing differences to other information theoretic methods especially in the early layers. In essence, what should be said is 1) value encompasses the importance of a pixel, 2) saturation presents the max-min of the distribution and 3) hue shows the position in the network. I did not consider it in this review since it was published a few weeks ago on Arxiv, but it could be interesting to discuss it nevertheless. The conclusion and discussion are short and could be filled a little more (some captions could be shortened in order to give more space). The method is interesting as it does not require multiple backward passes such as other gradient-based method and thus prove to be more time-efficient.
While I am not sure about the area of peer prediction, in the area of learning with noisy labels (in a general sense), there were often 10 to 15 papers from every NeurIPS, ICML, *CONF* and CVPR in recent years. This paper is well written. A very related work to this paper: L_{DMI}: A Novel Information-theoretic Loss Function for Training Deep Nets Robust to Label Noise, where no restrictions have been made on the class-dependent transition matrix and the proposed method does not need to estimate the transition matrix. Moreover, this paper explores the theoretical properties of peer loss when p=0.5. The paper is not well-presented.
Specifically, the authors propose a method that dynamically generates K answers given a paragraph  in order to generate diverse questions and, secondly, pre-training the question generator on answers in a sentence generation task. 3) How many synthetic QA pairs are used for Table 3? 4) What is the objective of training the span selection model? AAAI 2018. - Tang et al. Learning to Collaborate for Question Answering and Asking. Regarding Section 2.1 1) Did you attempt to predict 'number of answer candidates' by regression or classification? 2) For Figure 5(a), do you have results with BERT without any data augmentation as well? How does the number of parameters compare to previous state of the art?
(1) it is unclear whether it was pre-trained similarly to the proposed methods, and I think that the fact this works is not that interesting. Up to section 3.3.1 (and - really - until I read the appendix...), the writing sort of led me to assume that (1) the "(pre-condition, action sequence) -> post-condition" split was a fairly standard manner of compose a hypothesis, and that (2) the templates were mostly symbolic. However, I do not feel that all of my concerns have been addressed and thus will keep my score as it is. arXiv preprint arXiv:1611.01843. -- Update after rebuttal: Thank you very much for your response. So, it seems that formulating the problem using MDP is not reasonable to begin with. Ideally, I would like to see some comparisons between this type of hypothesis and other decompositions used in previous literature, since it seems like the method exploits this particular structure quite heavily and I don't quite understand how it generalises to other tasks. D., Erez, T., Battaglia, P., & de Freitas, N. More broadly, it might be easier to compare using bar plots showing final performance, rather than training curves 5. I'm confused by how the pre-training is done. The authors present a framework for testing a set of structured hypotheses about environment dynamics by learning an exploratory policy using Reinforcement Learning and a evaluator through supervised learning.
As the paper points out, the problem with the Fisher score for the recent deep generative model architectures is that Fisher score operates in the parameter space and the deep models have a very large number of parameters. My first concern about this work is its novelty. Pros: This paper is well-written overall and the method is clearly presented. This separate powerful decoder has nothing to do with PixelCNN, which is the major reason that I vote reject.
It is better to use real data statistics to show the prevalence and concrete examples of such unsmoothness. In other words, you can simply use a decoder-side CGT, and mask the temporal self-attention as in the Transformers.
(they have experiments on outlier detection) Figure 1(a) and (b) in reference to the text are incorrect. I believe reporting results on at least two datasets is necessary to demonstrate the generalizability of the method. Positives ------------ 1.I liked the intuition behind the proposed method and I felt its worth exploring. Overall, the method is promising, but I have the following concerns: * Using the reconstruction error as an anomaly score has been explored many years ago (check replicator neural networks), the novelty here is to enforce that on the latent space in the context of a variational auto-encoder. I guess this could be answered by more experimental results on richer data sets (even synthetic is fine).
Now I understand it and think it is a useful metric. For confidence evaluation, they compared the prediction performance on the original image, masked image (only salient regions) and inverted masked image (only non-salient regions). Therefore, it is also unclear what to make of the numbers in e.g. Table 2. The experiments given in the paper, it looks like confidence and correctness are positively correlated.
It would be good to define this. (Real valued labels are allowed but are not considered in this work). Whether that's what you're doing or not, it should be clarified. This paper proposes a novel method that is an interesting take on imitation learning, but it is hard to judge how relevant this method is, as the paper has several inconsistencies and weaknesses that need to be resolved before it is accepted.
- Could you please further explain how you compute PCA using batch data, how you update online and how you employ that in convolution weights together with BN? Figure 1: It seems to me Figure 1 is obvious. The proposed method and initial results are promising. In the experimental analyses, the proposed method outperforms some of the previous work in terms of the compression ratio and accuracy for training ResNet-34 and MobileNetV2.
Summary: This paper investigates the choice of noise distributions for smoothing an arbitrary classifier for defending against adversarial attacks. About the main results: there seems to be a discrepancy between the results reported for Cohen et al. and the original paper for both CIFAR-10 and ImageNet L2 certification. But a fundamental trade-off means that *any* method that attains good accuracy must sacrifice robustness and vice versa; this requires a "for all" statement, i.e. a lower bound. For \\ell_\\infty perturbations, the paper suggests another family of distributions combining the \\ell_2 and \\ell_\\infty norm (Eq. 9), and argues that it outperforms the natural choice of \\ell_\\infty norm-based distributions (Eq. 10). Writing comment: Change some of the Theorems to Propositions. #3 (sketchy justification): The paper justifies a smoothing distribution that concentrates more mass around the center as follows: "This phenomenon makes it problematic to use standard Gaussian distribution for adversarial certification, because one would expect that the smoothing distribution should concentrate around the center (the original image) in order to make the smoothed classifier close to the original classifier (and hence accurate)." Typo after equation 4: ||f||_{L_p} Addressing 1-3 effectively will improve my score.
The fairness component relies on a  definition of fairness based on causal inference, relying on the idea that a sensitive attribute should not causally affect model predictions. - It is unclear what is new and what is related work in page 3. In terms of suggestions, I think the experimental section needs to be extended and that the various modelling choices need to be explored and/or be further justified. The authors propose a novel joint optimisation framework that attempts to optimally trade-off between accuracy and fairness objectives, since in its general formal counterfactual fairness is at odds with classical accuracy objective. * the justification for using ATO in the internal layers of the network is a bit insufficient Certainly the study of fairness problems did not start in 2016. Figure fonts are very small and hard to see.
I like the high-level idea of this work and agree that there is not much work on using prediction explanations to help improve model performance.
If the original space is a structured space like Euclidean space, then effectively this paper's method coincides with regular distance preserving method in dimension reduction, and Johnson-Lindenstrauss theories. ### Suggestions to improve the paper The authors discuss the a novel technique, called Random Distance Prediction, to learn rich features from domains where massive data are hard to produce; in particular, they focus on the two tasks of anomaly detection and clustering.
(c) The setup for the last experiment is not clear. The authors propose a framework for sensor placement called Two-step Uncertainty Network (TUN) based on the idea of information gain maximization. should be MI(y,x_k|v_k, Obs)? - In Fig. 1a, the "red arrows" for indicating TUM look like brown? Figure 2 appears on page 3 and is only referenced on page 4. The authors seem to have adopted a different paradigm in this paper: Large training datasets are needed for the prior training of both neural nets (in the order of thousands as reported in the experiments). Similarly, with 3 observations, all 10 instances/imagined spectrums can exhibit the first spike (without observations on it).
By taking advantage of the structured composition of the latent space into per-layer contributions in the StyleGAN approach, experiments are performed to show that different levels of semantics are captured at different layers: layout being localized in lower layers, object categories in middle layers, followed by other scene attribute, and lastly the color scheme of the image in the highest layers. - Fig 4 caption: typo "while lindoor" -> "while indoor" 5) This is not a really weakness, but perhaps an ablation that may help. And what happens when there is a tie? Both of them seem unrealistic units for training a GAN. Overall, I am inclined to update my rating to lean towards acceptance. The paper has grammatical errors  (sentences are not well written), typos (ex; "manipulabe" on page-8 which should be "manipulatable") and is not polished. Do you discover any changes weakening your claim? Moreover, Layout variation is just view-point variation. Or are only four scene semantics chosen to begin with? How generalizable is this approach to other kinds of GANs other than PGGAN and BigGAN (or rather, why is this approach relatable to StyleGAN, PGGAN and BigGAN alone)? A set of qualitative experiments demonstrate manipulation along several axes. Here, I would like to encourage the authors to use a consistent terminology -- The four semantic abstractions have been referred to as "Variation Factors" (page 3), "Candidate concepts" (page 6), "Visual concepts"(page 12), "Semantics" (page 8) interchangeably throughout the literature, which is confusing. --------------------------- This paper investigates the aspects encoded by the latent variables input to different layers in StyleGAN (Karras et.
However, I like the method and could be accepted as an *CONF* paper. Experiments are conducted on MNIST and Fashon-MNIST datasets, which are used as OOD and in-distribution, and vice versa. Thus, I am not sure whether the performance of the proposed algorithm is dramatically better. Moreover, I think the authors should evaluate their methods on more realistic cases. 3. Instead of generated OOD samples, could the authors report the performance with explicit OOD samples similar to [Hendrycks' 19]? On the other hand, note that softmax classifiers produce a high confidence if the input vector and the weight vector of a certain class are in the same direction (of course feature/weight norm also matters, but let's skip it for simplicity).
Detailed Comments: A primary weakness of this approach is that it seems like there is one network that learns the options and is shared across all task (that would be the prior) and then there is a task-specific network for all options (posterior), wouldn't this be very difficult to scale if we want to learn reusable options over the lifetime of an agent? In IJCAI, [3] Andreas, J., Klein, D., & Levine, S. Mann, and Shie Mannor. "Adaptive skills adaptive partitions (ASAP)." Advances in Neural Information Processing Systems. (2015). Approximate value iteration with temporally extended actions. -Leads to coordination b/w master policies, * What does delta(z_t - z_{t-1}) mean in section 3.1? I would recommend evaluation in a variety of high-dimensional domains such as other instances in Mujoco, and visual domains. It was not defined anywhere. ICML [4] Tessler, Chen, et al. "A deep hierarchical approach to lifelong learning in minecraft." Thirty-First AAAI Conference on Artificial Intelligence. Distral is relatively closer in performance to both MSOL and MSOL frozen. The results in moving bandits alone are very convincing.
In order to effectively learn R and S embeddings, the authors propose two possible ways to do so: LSTM (Fig 2) and 1-layer Transformer (Fig 3). For this reason, I feel the authors should have continued showing results for the other baselines from the first experiment. My main concern regarding this paper is two-fold: limited novelty and insignificant performance gain. This aligns with some recent findings that BERT is undertrained (Liu et al. 2019) https://arxiv.org/abs/1907.11692 Other comments: Typo on page one: "[] To strengthen the generality of …." I understand the authors are just trying to make a point that BERT does worse than their model in this case and that this is not good for transfer, but still I find this to be artificially constructed.
(1) *Overlap in pruned sub-networks*: In the middle of Sec. 4, Fig 3-5 examine the similarity of pruning masks between methods. Second, the observations are only presented for LeNet and MNIST and it is non-trivial whether they extend to large scale models. weights in 6(a) are a spaghetti tangle and the FC weights in 7(a) are constantly increasing in magnitude. *Rating* There are interesting bits of data in this paper, but the overall story is somewhat muddled and some inferences seem to be insufficiently supported by data (1-2 below). Is the ordering of training samples fixed in addition to network initialization? In particular, the authors tested several different pruning techniques by varying evaluation criteria (L_1, L_2, L_-\\infty and random) and pruning structures (structured, unstructured and hybrid).
More minor comment: - I guess the definition of Etrain  (Eq.(17)) requires an expectation with respect to the training data. I think it is a solid work and vote for acceptance. - Assumptions of the activation function f should be provided; is it just assumed to be differentiable?, ReLU is included? They analyze the performance of a simple regression model trained on the random features and revealed several interesting and important observations.
The main idea of this paper is to solve multi-agent reinforcement learning problem in dominance solvable games. This is not really discussed in the paper; the conclusion talks about directions for future work, for example expanding the number of RL algorithms where convergence can be proven, or producing complexity bounds for convergence. The fact that standard MARL learning rules (e.g. independent Q learning) converge in games with iterated dominance solutions is a very well-known result in Learning in Games (see [1], [2]). The paper is quite well-written and understandable. How can this be applied when the space of policies becomes too large to be enumerated (and thus determining whether a policy is strictly dominated becomes impossible)? The paper states that one of solution concepts of dominance-solvable games is iterated dominance solution, which is different from Nash Equilibrium and may be more suitable under certain scenarios. Even so, the Markov game considered is fairly simplistic. 2) This paper only has *convergence* results, but does not have *convergence rate* results. 2. The notations are inconsistent and unnecessarily complicated.
**Minor comments** In  references section : (Kingma & Dhariwal, 2018) is not in a proper format (nips 2018) The paper proposes an approach for image generation that relies on an autoregressive model for the image pixels.
In addition, the contribution is incremental and not well-motivated. This paper is motivated by the unstable performance of Transformer in reinforcement learning, and tried several variants of Transformer to see whether some of them can stabilize the Transformer.
As far as I can see, it is very similar to the former SENet especially in Figure (3) and Equation (2). - The method obtained improvements over various networks (SuffleNet v2, MobileNet v2, ResNet 18) on ImageNet. Methods - Consider adding parameter counts in experiment tables Is the computation flops calculated in the right way? The use of dynamic convolutions is by no means a novel idea and has been studied in multiple previous works in vision (mixture of experts, soft conditional computation, pay less attention with dynamic convolutions, ...) which the authors fail to cite/compare against. Concerns - The main concern of the reviewer is that the model shares the core contribution to the existing method; squeeze-and-excitation network (SEnet, Hu et.al.).
Many of these prior works include a temperature parameter for trading off risk-seeking vs risk-aversion (e.g., \\beta in Eq 11 of [Mihatsch 2002]), which is arguably a more transparent (to the user) and easier to analyze (for the RL researcher) than the order statistics used in this paper. The paper is written clearly and the approach is straightforward. This paper presents a modification to policy gradient methods that are computed from advantage function estimates. Minor comments * "that humans own" -> "that humans' own"
Weaknesses: 2: In the most general case, it is not obvious why it is easier to define and learn a set of models that only use noise to make predictions (which is the required first step for their proposed solution) as opposed to learning a model that only uses signal (which is the goal of the problem). I would expect to see that Bagnets alone do worse than vanilla Resnets on Unbiased and IN-A. ### Update after Author's response
For example, in the second half of Sec.2 introducing two kinds of learning with rejection models, it should be included in a "related work" part. - Similarly, what happens if the attacker and the rejection function rely on different norms to compute the attack and the rejection score, respectively? ------------------------------------------ Thank you for the rebuttal. In the last equation of page 2, there is a rejection function, so minimizing this loss is a "separation-based approach". The paper does not show any connection between "learning with rejection" and "adversarial learning". The authors state that they use a 30-step of the PGD algorithm to find z^*. I will rate it a clear rejection.
The question of how to encode external knowledge in neural networks is a crucial one, and the limitations of end-to-end learning with supervised data is well-made. I even found a wrong reference (Section 3). And this paper contributes in a novel way to incorporate the constraints with both soft and hard training strategies. I don't get why 3 is embedded by itself in the diagram, and then combined with the remainder using the MLP. (I realise the dataset already exists and was presented elsewhere, but this might be worth a footnote).
This paper proposes to use the variational auto-encoder (VAE) to sample the network architectures. ============ previous comments Neural architecture search can be formulated as learning a distribution of promising architectures (the sampling policy). Also, it claims (2) VAENAS-G helps to search for large models, which  I do not see experimental supports. * For ImageNet experiments, the authors are using a ShuffleNet-like search space which has fundamentally different building blocks than other architecture search baselines (commonly built on top of inverted bottleneck layers).
In summary, I'm willing to be convinced that this is an interesting and scientifically novel result. The authors view this approach as a generalization of Go-Explore, since it does not rely on having a reset mechanism. 2. In appendix D, the authors discussed what the parameter \\delta_t controls, however, it is unclear how \\delta_t should be chosen in implementation. If the authors want to escape the shadow of this kind of technique which cheats by some framings of RL, more appropriate demonstration environments must be selected. So one major question is whether Go-Explore is a scientifically appropriate benchmark to compare with for this setting. This paper proposes an approach for diverse self-imitation for hard exploration problems. Could a simpler design be ruled out? All the primary experiments appear to be for deterministic environments.
1. The problem that this paper addresses seems to be new and interesting. The paper tried to provide both theoretical and experimental reasoning for this framework. For example, the MDP example is just an off-policy policy evaluation problem, and it is very well known that in this case you need to consider the behavior policy, for example with importance sampling. Authors have not cited any paper in this literature, and did not situate their work with respect to this literature. 2. What are the partially observable parts of the environments in Figure 1 (a) & (b)? They show that models typically learned in this context can be problematic when used for planning. Finally, I found that limited experiments supported the points made in the paper. *Summary* This paper considers the effect of partial models in RL, authors claim that these models can be causally wrong and hence result in a wrong policy (sub optimal set of actions). That said, I think the paper as written could be substantially improved with a little extra effort. I vote to (weak) reject the paper due to the major issues with section 2.
- It is better to compare it with a larger dataset. Overall the task descriptions should be in a separate section where the setup is described in a lot of detail and motivated properly. Thus, It is interesting to see that continual learning is used in sequential data. In that sense, it would be much crucial to show more meaningful ablation studies and analysis for proposed model. The contributions of the paper are 3 fold - new benchmarks for CL with sequential data for RNN processing, new architecture introduced for more effective processing and a thorough empirical evaluation. However, there is a few of thing about them. Then, I decide to give a lower score that even the authors suggest that the main contribution is a definition of problem setting. Its a benchmark after all.
What is the intuition of using a and b? 2) In addition to attack success rate and query complexity, it might be useful to compare different attacks in terms of ℓp distortion, where p≠∞. A small novelty appears in a way to handle a bounded search space. " Isn't it the contribution of (Ilyas et al., 2018b)?
If it is for demonstrating the benefits of global gradient for gradient memory, I think it is more proper to also include the results of DGC without factor masking? Although they theoretically prove a new version of DGC, it's just a minor modification and no significant performance improvement as shown from their empirical results. NITS to improve the paper (not related to the rating): 1. The last contribution bullet forgets to mention that it is about comparing to DGC. However, that specific case isn't analyzed and it isn't clear how incorporating that projection would affect the accuracy, since it would essentially be countering the effect of error feedback. Overall, I appreciate the authors for their theoretical contribution for DGC and well written paper.
- In Theorems 1 and 2, what is the bound on the steplength in order to obtain the convergence result for τ=0? Are multiple trials run? - Is ϵ used to determine the subset or is it based on a predetermined subset size? - What is Δ on page 5? What is the effect of CRAIG on the expected risk? - Figure 4: isn't 2000s \\approx 30min really slow for MNIST? 3. Similarly 80% accuracy on CIFAR10 is sufficiently low for Resnet-56 to be alarming. "On the ineffectiveness of variance reduced optimization for deep learning." arXiv preprint arXiv:1812.04529 (2018). Has CRAIG been evaluated in settings with millions of datapoints? Is there any deterioration in generalization performance? Based on the experiments provided in the paper, it does appear to yield a significant speedup in training time.
This paper proposes to train a GAN and an EBM jointly, and bridge them using a Stein discrepancy. In the paper the stein critic is shared between the two stein divergence which means that the authors are rather considering : S(λ1Pr+λ2PG,PE)
A loss minimization won't make equalities in (3) and (5) hold exactly, which the analysis do not account for. Furthermore, the paper proposes TransComplEx -- an adaption of ideas from ComplEx/HolE  to TransE -- to mitigate issues that can not be overcome by a simply chosing a different loss. The authors claim that their contributions consist of two parts: 1) proving that the proper selection of loss functions is vital in KGE; Regarding the experimental evaluation: The paper compares the results of TransComplEx and the different loss functions to results that have previously been published in this field (directly, without retraining). There seems to be merit in distinguishing the loss when studying relation encoding but I think the paper's analysis lacks proper rigor as-is. Paper writing: * The manuscript should be improved with a thorough revision of the style and grammar. Therefore, the experiments might be unfair to RotatE. Suggestions/Questions: 1. It would be great if hyperparameters listed in the "Experimental Setup" section could be presented in a table for better readability.
In this paper, authors propose a way to speed up the computation of GNN. In conclusion, I think this is a good paper. The idea is clear and easy to follow. Moreover, for sequential aggregation, it can find a HAG that is at least (1-1/e)-approximation of the globally optimal HAGs (Theorem 3). 2. What kind of graphs can the proposed model be applied to?
In light of that work, there is very limited novelty in this paper. Overall, I'm just not convinced this paper is novel enough to merit publication.
I learned a lot by reading it. Another thing that demotivated me is that I couldn't find the discussion about the subtleties in using curriculum learning and PPO for the theorem-proving task in the paper. It would be nice if there was a clear explanation of the role of curriculum in the learning algorithm. and I think accepting papers that do this work is a good policy. * p8: a a well ==> a well
There are a plenty of works on visual explanation methods, such as guided-backprop[1], excitation-backprop[2], integrated gradient[3], Grad-CAM[4], real-time saliency[5] and so on. In NeurIPS #Strength The method is easy to implement and using the idea of interpretation for detecting adversarial examples seems interesting.
This works presents a method for inferring the optimal bit allocation for quantization of weights and activations in CNNs. The formulation is sound and the experiments are complete. It means that some weights in some layers can be quantized with higher or lower bits per weight. Based on this conclusion, the authors claim that their search for the best bit allocation strategy is with a less complexity.
In this case, can influence function be used? To do so, the authors make two methodological contributions: 1) working through the calculus for the pre-training setting and deriving a corresponding efficient algorithm, and 2) adding L2 regularization to approximate the effect of fine-tuning for a limited number of gradient steps. Is the influence equation well defined (or the Taylor approximation justified) if H is not positive definite? 3. Page 7, last paragraph, "we replace all inverse Hessians in (11) with identity matrice"=>why? frog examples being used for both pretraining and finetuning? How to use the proposed method to identify source samples that cause negative transfer as discussed in the introduction? 2) In what situations might we want to examine the influence of pretraining data, and can we design experiments that show those situations? Also, I am not quite sure about the practical value of calculating influence scores. This extends influence functions beyond the standard supervised setting that they have been primarily considered in. For presentation, I think it is not correct to use 'pretrain' or 'finetune' before a noun.
(3) compute sub-levelset persistent homology and (4) study the resulting barcode (for 0/1-dim features) (i.e., the mentioned "canonical form" invariants). An algorithm is presented for the computation of barcodes, and some small-scale experiments are conducted. The paper is also unclear in many parts. From what I understood, the idea is to effectively
This work provides  theoretical analysis for the NAS using weight sharing in two aspects: 1) The authors give non-asymptotic stationary-point convergence guarantees (based on stochastic block mirror descent (SBMD) from Dang and Lan (2015)) for the empirical risk minimization (ERM) objective associated with weight-sharing. What is the advantage of ASCA comparing to SBMD? For example, what is the beta parameter when training a NAS problem? Also, comparing to first order DARTS, search cost is the same and this is hard to justify the better convergence rate for EDARTS. Why we need such alternative?
Claim is that this has not been successfully done in a RL setting before, so a new problem is proposed (multi-agent pac-man) and results are presented on this problem. 1. The exposition of the method needs to be improved to assume less background knowledge of the heuristic PGM and  structure2vec methods, investing some text introducing them.
This paper conducts experiments on graph classification task and finds GFN gives a reasonable performance, whereas GLN's performance is weaker. This paper presents a dissection analysis of graph neural networks by decomposing GNNs into two parts: a graph filtering function and a set function. The experiments are designed nicely: 1) it compares with various baselines on a variety of popular benchmarks; 2) ablation studies single out the importance of different graph features, such as degree, and multi-hop averages; 3) verifying whether the good performance GFN comes from easier optimization. This demonstrates that the current GNN models may be unnecessarily complicated and overkill on graph classification.
[Reviewer's response:] I disagree with authors on this because GEM, its faster version (A-GEM (Chaudhry et al. 2018)), and all other methods explored in the recent study which I mentioned in my review (Ref#2) use the single epoch protocol and are perfect match to be compared with this method but there is no memory-based baseline except for VCL with coreset and FRCL (only for MNIST variations) which makes it difficult to measure this method's capabilities (performance, memory size, and computational time) against methods which only require one epoch to be trained. They select most memorable samples depends on eigenvalue. Proceedings of the 35th International Conference on Machine Learning, in PMLR 80:4548-4557 If so, have they considered a "no-task" or an "overlapping" task boundary in their experiment?
" This is not very well articulated, "a lot" is vague and a little familiar, "significantly" could be used here. 6. In figure 1 the shown CGI Map is for which class? This paper presents a strategy for visualizing activation in networks that corresponds to features in the input layer. randomizing the weights of a model to prove that the input's resulting saliency map is different from a trained model' saliency map. For the top horizontal part of the digit, it plays a role in determining both 3 and 5. Assume that for one such pixel the value of h_5_i is greater thatn h_3_i (looking at the figure it is not unreasonable to expect that).
Croitoru et al. also relies on video to extract the object features, and this requirement is not as explicit in this work. How does the method perform in images where multiple objects are in the view? However, the current type of algorithm is dependent on the assumption that the background follows relatively consistent textures, this may not necessarily be true in practice, and hence the application could be quite limited.
or alternatively modify the claim (to what it actually shows) and highlight the significance of the connection between matching subnetworks and stability in this highly sparse subnetwork regime. ——— Although finding a connection between two seemingly distinct phenomena is novel and interesting, I would recommend a weak reject for the following two reasons: 1) The scope of the experiment is limited to a quite specific setting, (Also same for Resnet-50 and Inception-v3)
The proposed method consists of two ideas: (1) spectral regularization (i.e., Dirichlet energy) with a re-parameterizing basis and (2) multiresolution of spectral loss (i.e., zoomout loss). The proposed algorithm is a simple shallow and fully linear network. If it refers to the parametrization of X by \\Phi P C Q^T \\Psi^T, then it is just a special case of deep matrix factorization since both \\Phi and \\Psi are fixed, and P and Q are optimized to be approximately orthonormal. --------------------------------------------------- Thank you for the detailed rebuttal. This paper proposes a new method for geometric matrix completion based on functional maps.
I guess what the authors want to say is something like "taking g(x)=∑l=1,2∑m=1MlglmYlm(x), (g11,...,g1M1)∼Unif(SM1−1(1/2)), and (g21,...,g2M2)∼Unif(SM2−1(1/2))". I would replace with \\delta to stress out it is a functional and not regular derivative. Appendix F: there are typos in the r.h.s. in the first line. This is why I think I can potentially raise my score to a weak rejection. This paper is technical and some readers will be interested of simply knowing the hypothesis made and type of results obtained. Ideally, you could add error bars to the data, accounting for the dispersion inherent to a single-realization case. For publication in a machine learning conference, I think more effort should be devoted to speaking to the machine learning audience.
- What is the motivation for using Graph kernel for similarity? If not, why is this a novel approach? Authors use GNN and multiple RNN's, what was the model capacity used and how it impacted the performance? This paper proposes a framework to model the evolution of dynamic graphs for the task of predicting the topology of next graph given a sequence of graphs. For instance, on Page 2, L is used to  describe edge attributes but then it is replaced by E in Page 3. Why is the same window size good for all graphs? w is used for window-size of sequence used as input and also as neighbor node. I believe this can be done for simple graphs like circles, paths, and ladders. - Why Set2Set was used for ReadOut function?
The proposed initialization is aimed at helping to maintain longer-term memory and instability during training such as  exploding gradients (due to linearity). Second, the autoencoder-based init scheme (Pasa&Sperduti, 2014) is not new while the only technical contribution of this paper is a minor change of this scheme so that it works for the LMN. Equation 1 and 2 suggest that there is a vector m^t per timestep (as oppose to having 1 for the entire sequence). (section 3.2) The proposed initialization outperforms the baselines on the MNIST dataset. And then they use the weight to initialize the Lieanr Memory Networks(LMN). The writing is clear and easy to follow. 2. Although the copy task was used in ((Arjovsky et al., 2015), I believe the original task was proposed in the following paper and hence this citation should properly be the correct one to cite here, 3. TIMNIT is a relatively small speech recognition dataset.
The environment in the paper is small (compared to e.g., House3D for EQA) and has a limited variety. (2) The designed attention modules is lack of generalizability. (3) The results in Table 2 are convincing.
It seems that it is not used in Algorithm 1. This paper proposes an unsupervised hierarchical approach for learning graph representations. It looks like the main point is  that this architecture is trying to emulate iterative coarsened residual optimization of the Wasserstein metric between a graph and its representation. - In the qualitative study in Section 4.4, while the authors discuss coarse nodes, they are just an input from the user and results are arbitrary. This paper proposes a method to summarize a given graph based on the algebraic multigrid and optimal transport, which can be further used for the downstream ML tasks such as graph classification.
In light of this, some justification and explanation shall be provided for using this criterion for optimality. This paper proposed "F pooling" for Frequency Pooling, which is a pooling operation satisfying shift equivalence and anti-aliasing properties. The method is tested on Resnet/Desnet on CIFAR-100 and subsets of ImageNet, showing better performance than the original models. Also, from the three Tables in the experimental part, the improvement of F-pooling over AA-pooling (developed by the main reference of this work) does not seem to be significant or consistent. It is good to me that the authors discuss one limitation on the imaginary part of output and I would like to hear more on other potential limitations for this method. This will help to make this paper more self-contained. Experiments could be conducted on more benchmark datasets with more CNN architectures to convincingly show the effectiveness of the proposed F-pooling.
For the pre-trained model, they will not only use its weights but also use it to generate a spatial attention map and help the model focuses on objects of images. I keep my original scores. I would modify it so instead of discarding mini-imagenet classes that are overlapping with Places I would discard the problematic Places classes. 7) The writing of this paper is very poor: a lot of typos and grammar errors, inconsistency between narratives, abuse of notations, wrong equation reference, even missing punctuations. I think the suggested task is important and more realistic than the usual FSL benchmarks. Some experiments show that the pre-trained model can improve few-shot classification accuracy.
- In OOD detection tasks, Hydra underperforms Prior Networks on 5 of 8 datasets (note that PN (2.60) is better than Hydra (3.11) in the case of MNIST (test)). It is unclear that the marginal improvements demonstrated justify the increased cost and how this approach would scale to larger ensembles. Overview: This work introduces a new method for ensemble distillation. - The proposed scheme provides the same advantages of the ensemble in terms of uncertainty estimation and predictive performance, but it is computationally efficient compared to the ensemble. This means that in those scenarios one does not actually have access to a pre-trained ensemble. The choice of baselines is reasonable. Writing: The paper is well-written, illustrations are good. Although its goal is different from this paper, just applying such multi-head architectures seems to be incremental.
Such an analysis of P_l^k as a function of the tasks (and for several layers) would be interesting to see, for example for EMNIST-47(10 tasks). Experiments show improved results over OWM (the method that this paper builds on) and EWC. 4. It is not clear why the proposed method can solve the issue that OWM faces with (bad accuracy when tasks are not quite related). 6. The authors should mention that the method is pretrained on ImageNet in section 4.3. The method is considering the 'task continual learning' scenario (also known as task-aware) which means that the task label is given at inference time. This paper introduces Principal Components Projection, a method that computes the principal components of input vectors, using them to train on a transformed input space and to project gradient updates.
Compression of Fully-Connected Layer in Neural Network by Kronecker Product (Zhou, Wu) Secondly, I'm not convinced we will use this method to build network in real world applications. This paper proposes a new way to create compact neural net, named Atomic Compression Networks (ACN). (2) Throughout the experiments, for the same hyperparameter (e.g. Table 4 in A.2) do you run Algorithm 1 more than once and select the best sample architecture?
This work introduces GQ-Net, a novel technique that trains quantization friendly networks that facilitate for 4 bit weights and activations. It is a well-written paper. For example, the alternative optimization of W and \\theta is similar to alternative re-training in network pruning, although a unified loss/optimization framework is applicable in this case. I think the paper will benefit from a more in-depth discussion and analysis on this regularization issue. I addresses the existing issues in the common paradigm, where a floating-point network is trained first, followed by a second-phase training step for the quantized version. The authors argue that this has the effect of "guiding" the optimization procedure in finding networks that can be quantized without loss of performance. Overall, I am on the fence about this work and tend to reject. Comments: I consider this a well-written paper with great clarity and good empirical performance.
However, I doubt if this is enough for a full conference paper. The paper is well written and it is technically correct. This paper only proposes some minor improvements based on the original CPC method and use a deeper network to get better performance. This observation should be of interest in the broader community, and points to the need for more diverse metrics for unsupervised representations. - The CPC is utilized to enhance spatially predictable representations which benefits a lot data-efficient image recognition. - The paper can be treated as an uptaded version of the original CPC paper. All results are very impressive and is in-line with current trends of using a linear classifier on top of a deep feature extractor (e.g., Nalisnick et al., "Hybrid Models with Deep and Invertible Features"). - The capacity of network architecture is crucial for self-supervised learning. [Cons] - In Sec. 4.1, four axes are identified to upgrade CPC v1 to CPC v2.
Additionally, the Music Transformer model is also conditioned on a combination of both "style" and "melody" embeddings to try and generate music "similar" to the conditioning melody but in the style of the performance embedding. ## Questions 1. In section 4.2, how do you use the Y? Why use this feature compared to existing techniques for measuring similarity between symbolic music pieces? Where does the IMQ kernel come from? Multiple encoder structure has been widely investigated in machine translation. Is it real valued? The authors mention (Yang and Lerch, 2018) but use a totally different set of attributes compared to that paper. 4. There should be more background and description in Section 4. This connection is not motivated adequately and after reading (Jitkrittum et. 5. In section 5.2, a conditioning sample, a generated sequence and an unconditional sample are used to compute the similarity measure. What is the size of the feature vector? What does the p() and q() mean ? However it is not clear if this dataset will be publicly released or is only for internal experiments. A lot of work has been published on this topic, most recently in the context of Query-by-Humming [1]. Firstly, I think the algorithmic novelty in the paper is fairly limited. The music is represented as a variant of the MIDI format. The following two papers are about conditional unsupervised image-to-image translation, which build a cycle-consistency loss during the feedback and might help improve the performances. Overall, I think the paper presents an interesting application and parts of it are well written, however I have concerns with the technical presentation in parts of the paper and some of the methodology. The authors also mention an internal dataset of music audio and transcriptions, which can be a major contribution to the music information retrieval (MIR) community.
Is the 8-bit training only applicable for a part of the model? Clarity: The paper is clearly written with some visualizations for readers to understand the 8-bit training.
This is more-or-less expected thanks to the superior performance of implicit updates in general. While potentially offering a faster convergence with respect to epochs, the nonlinear updates have two major drawbacks: 1) While there are preliminary theoretical results (fixed points of the method are critical points), it remains unclear whether the computed update is still a descent direction on the original energy.
Summary of the Paper: This paper describes a method for training Bayesian neural networks in the context of stream data. The main issue for me to understand it is how to get these codevectors. The notation x_0 and x_1 for the test point and the NN weights is confusing. It explores a different way of modeling distributions with DNN. 2. I think the paper might need a bit more explanation about codevector, since it's not a very well-acknowledged concept in this field. For example, in Table 2, BNN (shown as MU) is significantly slower than DU/DBNN and DNN.
The proposed method concatenate the first a few layers of the student network with the last a few layers of the teacher network, and claims the gradient directly flows from teacher to student, instead of through a KL or L2 similarity loss between teacher and student logits. It outperforms previous methods on various datasets. The method is adapted for different tasks, classification and bounding box regression are presented in the experiments. Overall the method proposed in this paper is simple but effective, and adequate experimental results are given to show its performance improvements. 5. Page 5: "training strategy is more accelerate than" – odd phrase It is unclear to me why proposed method is better than AT, FT or FitNets.
Why E\\hat{H} = \\hat{H} guarantees the consistency of \\hat{E} = Diag(\\hat{H})? - The model defined in Fig. 1 seems the influence E should have a sparse diagonal vector. Specifically, they fit the model Y=(XE+N)F, where X are the predictors, E is a binary matrix indicating the true causes, N is a noise term, and F is a mixing term.
However, the method for comparison is not properly set. To me, if the work could be changed to compare against works which are not so tightly constrained, not for the purposes of holding it to the same standard but to understand it's relative standing, or to better justify the very strict constraints which somehow, despite out-of-distribution detection being a popular upcoming topic, apparently only has one other paper that matches it. concatenation on the proposed method as well? - Summary: This paper proposes an out-of-distribution detection (OOD) method under constraints that 1) no OOD is available for validation and 2) model parameters should be unchanged. Though the idea is interesting, I am skeptical about the effectiveness of the proposed method. There is also  theoretical guarantees showing exhaustiveness of the proposed methods in detecting all possible out-of distribution examples. I remark that this paper still requires a lot of revision; comparison in the main paper is somewhat unfair and all new results are in the appendix. [R1] Stutz et al. Disentangling Adversarial Robustness and Generalization. 2. Also, I wonder the main body of the proposed method itself is really effective or some minor tweak they made is essential. ** post rebuttal start ** However, according to the original paper, simple FGSM is used for validation, so I am not sure such a huge difference can actually happen. The motivation of the proposed approach is clear, and the method seems novel. I do not necessarily see something wrong with the paper, but I'm not convinced of the significance (or sufficient efficiency) of the approach. This paper proposes a new framework for out-of-distribution detection, based on global average pooling and spatial pattern of the feature maps to accurately identify out-of-distribution samples.
Good efforts to explain the network problems (latency, congestion) and how they are tackled by delayed updates and temporally sparse updates. In the proposed algorithm, there is no dampening nor apparent limit of the maximum value of t; such a difference with prior art should entail a serious (theoretical) analysis.
The motivation of this paper is interesting. The generative models to obtain disentanglement representation could be investigated in the frame-work of this paper. I suggest rewording this. This paper performs empirical study on the influence of overparameterization to generalization performance of noisy-or networks and sparse coding, and points out overparameterization is indeed beneficial. However, I still think the "information gain" of this paper is somewhat thin. I find the paper has some drawbacks. The writing of the paper is clear, and I could follow the contents easily. - All datasets investigated in this paper are rather small. I think the analysis can be more in-depth to make this paper more interesting. This is an interesting and useful observation, particularly since it at first sight appears to be in disagreement with some earlier work (the authors suggest explanations for the differing observations). - Summarizing the above arguments, the insight obtained in this paper is a bit weak. In the numerical experiments, the effect of over-parameterization is investigated from several aspects.
All in all, I think using a standard gaussian prior is not a good idea, and that fact renders the explanations provided in this paper obsolete in my opinion. - Equation (4) is missing a factor of (1/2). So that is the message that the paper is trying to convey here? In A.2.1 you prove that there exists a VAE whose ELBO grows infinitely (exceeding the local maxima of (7)). The paper considers several experiments to illustrate this issue. 4) I felt that section 5 was significantly weaker than the rest of the paper. b. I think there is one paper that the paper should discuss: Two problems with variational expectation maximisation for time-series models by Turner and Sahani.
I imagine that more data in the training set (if it existed) could help to reduce the gap in performance the paper is concerned with. Summary: This paper provides a thorough analysis of why vision-language navigation (VLN) models fail when transferred to unseen environments. First (and perhaps least important) is that 6.3 is missing some implementation details. etc. This should be clarified. I anticipate this paper to significantly influence future work in this area. a complete investigation (which may be out of scope for the rebuttal period) may require evaluating performance of one of these systems. This paper has some pretty exhaustive treatment diagnosing the source of the agent's 'environment bias' (which, as I discuss below, I believe is more accurately referred to as 'overfitting') in Sec. 4. corpus (e.g. all generated sentences vs. The second contribution is to use semantic information, compact statistics derived from (1) detected objects and (2) semantic segmentation, to replace the RGB image and provide input to the system in a way that maintains state-of-the-art performance but shrinks the performance gap between the seen and unseen data.
I can not understand in anysense that I know. What is l(.) here ??? This part is unclear to me in this paper. I was not able to assess the importance of the theoretical contributions of the work as my research is not in this area, so my comments are limited to the other aspects.
They find that (i) the auto-encoder representation does not capture the semantic information learned by the supervised representations and (ii) representations learned by the model depend on the label taxonomy,  how the targets are represented (1-hot vs. This is an interesting study. This work needs to be better situated within the context of previous work in this field.
Can the authors give a detailed discussion why is the expression of f(x) = g(x) + s(x) in equation 9 the right one to be minimized in practice (e.g., in the context of materials and drug discovery)? Isn't G_1 a GP? Why is it able to accept x_i and D as inputs? experimental uncertainties? Fig. 1 shows that the noise peaks with a relatively high frequency at a single error magnitude value. Since no convergence guarantee is given, a more extensive empirical analysis with real datasets needs to be provided to better understand the performance and behavior of the proposed BO algorithms.
The key approach of the proposed method is to apply a classification function (equation (3)) obtained by solving a GSSL problem to graph convolutional networks. In addition, the authors adopt a parallel system and weighted combination of max and average pool. Both undirected and directed graphs are used in experiments. The relevant previous work in the area seems to be cited, and the paper appropriately embedded in the previous work The motivation is clear, and the technical details are easy to follow. However, in practical, it is impossible to compute the infinite terms.
This paper presents a technique for model based RL/planning with latent dynamics models, which learns the latent model only using reward prediction. This paper claims that one only needs a reward prediction model to learn a good latent representation for model-based reinforcement learning. The proposed model uses an encoder to learn embedding the state to the latent state, a forward dynamics function to learn dynamical system in latent state space, and a reward function to estimate the reward given a latent state and an action. Why might this be the case? The justification for Table 1 vs. Specifically, I see the following issues: (1) the experimental environments seem artificial, and hand tailored for this method,
5. (6), what is n(k-1, e)? and Algorithm 1 are not for Deep HRL as said in Abstract and Introduction. To put it in a different way, it is unclear to the readers why we want to solve this special class of hMDPs and what does hMDPs have to do with the general issues in hierarchical RL.
2018. This paper investigates the aleatoric uncertainty and epistemic uncertainty in machine learning. - (p.9) There is a typo in the name of Jøsang in the references. 5. (p.4) The ELBO loss (6) is unclearly defined, and not connected to the direct context. This term was manually added as additional regularization to "prefer the evidence to shrink to zero for a sample if it cannot be correctly classified" in (Sensoy et al., 2018), and a different regularization was used to encourage distributional uncertainty in [3]. The discussion of concepts and problem definitions look fragmented and incoherent. What is the originality of the L-p norm here? Multisensor data fusion: A review of the state-of-the-art.
I like that the author(s) stick to 10 clusters for MNIST, but for comparison I would have liked to see a KNN generated accuracy alongside their equation 19 based accuracy. Since the equality symbol is used, it is unclear where is approximation. Circling back to the experiments, the author(s) use reported values from DEC and VaDE. The main difference is the authors use some hyperparameters to control the optimization of the whole model and make some more proper hypothesis.
They use the resulting embedding to learn a reward function and ignore the extrinsic reward. *Review*: I think the paper provides a compelling motivation, and is well written. I'm especially concerned because I don't feel your competitors are not relevant/representative of the current state of reward shaping. Rao and Ballard is one, but there is a rich literature following from this work into the free energy formulation (Friston) and active learning.
The presentation in this paper does remove the assumption of a fixed cardinality, but since this seems to be a mild assumption, it is not clear what is gained by this (beyond mathematical elegance). Deep sets) can approximate uniformly real-valued functions that are uniformly continuous with respect to the Hausdorff (resp. Notations should showcase the result that theoretically, only two hidden layers (with appropriate definitions) are needed. Summary: UATs are important and interesting, however, they do exist for the architectures that are targeted in this paper. I thus maintain my recommendation of weak reject PointNet (Qi et al, 2017) and Deep sets (Zaheer et al, 2017) have allowed to use deep architectures that deal with point clouds as inputs, taking into account the invariance in the ordering of points. 3. The paper lacks an experimental section. It might find a better audience at a venue that is more specialized in this type of work (e.g. applied mathematics or more theory-focused machine learning venues). The additional illustration improves the accessibility of the paper. - It is important in order to know the representational power and fundamental limitations of basic algorithmic building blocks. This paper brings a valuable theoretical contribution to the existing state of the art of their approximation abilities. === Post rebuttal update === They further provide examples of functions that can't be mutually approximated by PointNets and DeepSets.
Consider the histogram for object "dog" in Figure 2. To verify this hypotheses, the authors have created a dataset through a crowd-sourcing service which represents "numerical common sense". As one example, why ask about "large" and "small" values rather than something with more precise semantics (like the 10th and 90th percentile, for example)? In fact, if the correlation coefficients for this case is comparable to the case with concatenated features, it would mean that the word embedding for the object is not helping at all!
In the end, the paper is essentially arguing that it's better to use different learning rates (for the inner loop) during meta-training and meta-testing. When this is mentioned again in the introductory section, it is followed by a statement indicating that meta-learning an initialization is one solution. If so, why should that be the case?
Overall, this is a strong paper and I recommend it for publication. My major comment is that the paper does not indicate anywhere that the research code is released, only that it's based on SEED RL. In follow-up work, I'd like to see a similar paper for various "discrete RL" tasks (a subset of Atari, VizDoom, DMLab, MiniGrid, BabyAI, ProcGen, and perhaps even Obstacle Tower, Minecraft, StarCraft (I or II) or the recent NetHack environment) with similar factors of configurations.
This paper shows a relationship between the project rule weights of a Hopfield network (HN) and the interaction weights in a corresponding restricted Boltzmann machine (RBM). I really enjoyed reading the paper, I learned something new, and I think others will too! I do not see the purpose of (7) and (8), and they are only referred to in the Appendix (the review content in the Appendix is informative by itself though). It is an important advance in our understanding of Hopfield nets and RBMs. Summary The experiments show advantages of BN initialisation, pointing to new directions of improving RBM training.
A large portion of the method consists of a search method over the space of possible sparse networks, combining it with growing the network to get a NAS-like method. If it is only one, it does not seem reasonable that all the probabilities growing or pruning channels and layers are the same.
Summary: This paper presents a generative model based on stochastic differential equations (SDEs), which generalizes two other score-based generative models score matching with Langevin dynamics (SMLD) and denoising diffusion probabilistic modeling (DDPM).
The authors propose a generative model that is a combination (product) of a VAE and an EBM, where the goal of the EBM is to reduce the probability of out-of-manifold samples, which are typically generated by VAEs. I also enjoyed the proposed change in the paper -- and it seems to elegantly solve several problem in EBM training. Some comments and questions: Does the separate twos-stage training enable the model to reach the optimal point that can be reached in joint training, or is it an approximation?
Thanks to the authors for their hard work and the nice paper. Finally, the technical contribution of the paper is also quite limited. Originality, Significance: This paper establishes reference points for modern LTR research. Sec 3.2 - Hyperparameters for neural networks - learning rate and batch size are usually crucial for neural networks, but are not tuned for any of of the baselines (as far as I could tell). Comparing to traditional gradient boosted tree-based LTR models, is it really worth putting efforts into studying neural LTR models? I both enjoyed this paper and think it's a strong contribution to the ranking literature. Then, it presents a few tweaks related to feature transformation and data augmentation to improve the performance of neural models. Having an *CONF* paper published on this issue will help spreading the fact, which is significant on its own. It first conducts a set of experiments to show that GBDT outperforms some neural rankers. Summary In this paper, the authors study the problem of neural LTR models.
Therefore, they can adversarially train the perturbations and model to obtain a robust model and robust word embeddings. Summary: In this paper, the authors aim to build a robust model against word substitution attacks.
For example, in the experiments shown in this paper, they  compare performance of deep equilibrium linear models with linear models and deep neural networks.
This is hinted at in the main text, but I think it is central enough to the interpretation of the experiment that it should be moved there. Here's where I see a possible failure with the technique in this paper. Is this a realistic assumption that p(o|a) is known? My questions regarding this point are: Do you agree that this could be a problem in richer environments than those presented in the paper? I feel like flipping the words to "we can therefore relabel only a single..." better communicates that. The OCC algorithm suggests that a necessary condition is that the message graph is acyclic.
This, coupled with the fact that their readouts leverage retinotopy, it is surprising that the authors never discuss the spatial segregation of the "held-out" neurons (say H) from the neurons in the training set (say T). Strong points: Empirical modelling of neural responses has a long tradition, and the results in this paper are state-of-the-art. This is nice work overall. In particular, they propose a novel readout mechanism that is parameter efficient and drives the core to learn better and generalizable features of the visual inputs. Is this oversight or intentional?
The benchmark is based on extensive measurements on real hardware. The set of analyzed hardware is limited While I was able to find official reproductions of specific FBNet models on github, I'm not sure whether there's an official open-source implementation of the search space itself. Quality The authors make a convincing case that is is not sufficient to consider theoretic hardware metrics like FLOPs for ranking different architectures since the rank correlation with respect to FLOPS and practical hardware metrics such as latency can be quite low. Notes on Rating: I've given the paper a borderline score (5) in my initial review, due to the open questions mentioned in the "cons" section above. In my view, the submission's main contribution is a promise to publicly release inference time and power usage measurements and code for 5-6 different hardware devices on two existing NAS benchmark tasks: NASBench-201 and FBNet. The submission also provides some analyses on this data. Recommendation In summary, I think the proposed HW-NAS-Bench will prove useful for HW-NAS development.
The paper presents a linear time and space attention mechanism based on random features to approximate the softmax. (It would be even better if they could compare to it in a future version.) The logic in the introduction is a bit contradictive to me: Some are able to achieve better asymptotic complexity (citations). The experiments support the claims of improved accuracy via choice of kernel and gating, and preservation of speedups inherited from the linear attention formulation. The results are strong. Unlike Linear Attention, the proposed RFA outperforms the original multi-head attention baseline on both LM and MT tasks. On the other hand, eq 7 should be the same as eq 5. In Proc. of ICML, 2020. Edit: I have updated my rating based on author response. The approach is centered around a linear approximation of softmax attention, and is extended with a gating mechanism similar to a GRU.
4)It may be better to state some discussions for the lower bound on the generalization error. Second, there is a factor 2 in front of it. To give an example, consider a task where an overparametrized complex network generalizes well in practice, it seems unlikely to me that a (very) sparse or pruned network would "perform similarly". Does it also relate with distillation complexity? 3)What are necessary/sufficient theoretical conditions for the effectiveness of distillation strategy (from the generalization error bounds)?
The crux of the approach is in equation (2) and in particular in ρ(gp→q∈[0,2π). This allows a kernel to be written as a linear combination of 20 kernels for KNeigh and KSelf resulting in 24 only unknowns for one layer. Many of these works compute some form of a point cloud normal (thus a tangent plane) and choose a direction orthogonal to it (hence fix a gauge). (2020). Continuous Geodesic Convolutions for Learning on 3D Shapes. I would be interested in a execution time breakdown for the whole method, showing the bottlenecks. My reason for not giving a higher score remains the limited experiments (which is likely not something to be addressed in two weeks), but even so I think the work is quite worthy of being accepted. However, lack of thorough evaluations, the missing links to the literature and the rather inaccessible presentation of the material should definitely be improved. The figures complement the text well and are helpful for understanding. The paper is unreadable without the appendix and somehow it would be better to make it self-contained and move the experiments in the appendix. It bridges the more theoretical equivariant convolutions with graph neural networks for mesh processing, which are more commonly used in practice.
This paper is a significant contribution to the field. The paper also spells out what are likely to be the most used cases of U(1) and SU(2) and their quotients by discrete groups. Though it is not complicated, I would include this. It is explained in the paper and more so in the appendix that it is necessary over R, but it could be a bit clearer and earlier in the paper. This work extends previous results for particular symmetries and outlines a method for obtaining these parameterizations for any compact group symmetry. Up until now this has done group by group.
For example, (a) is it reasonable to use a GP with a smooth kernel as an interpolant of the inputs? Minka, T. P. (2001). Expectation propagation for approximate Bayesian inference. But in Section 4.7, they mention that their approach requires to evaluate Gaussian Process at a set of points which is similar to what was done in Li and Marlin(2016). The rest of my review is some requests for clarity and writing suggestions. UAI (pp. 362-369) Matthews, A G de G, et al. (2018).
The paper establishes that this is strictly more general the linear MDP assumption, where the above-discussed closure holds for backups of all functions (and not just linear Q functions). It seems that an analysis of LSVI-UCB with general function classes has recent done in [1] (?) Minor concern: In theorem 1, you state the regret is O(Hd3T) while in the abstract it's O(d3T). It must be noted that Jin et al had already noted & observed that such an assumption is enough, and that their proofs accommodate this.
Weaknesses: There is a lack of baselines to compare against, and the paper has not really stress-tested the algorithm to ensure it is in fact robust. --Summary: They proposed a robust method for the adversarial attack on VAE using a hierarchical version of β-TCVAE and conduct analysis on the relationship between disentanglement and robustness to support their choice of approach. --Recommendation In sum, the paper is well organized and consists of extensive theoretical proofs and experiments. I vote for a more neutral score for now.
A natural comparison against methods that do not utilize the safety constraint features is to include a very large negative reward for failure and see if the algorithms can avoid failure via this signal instead of the separate safety signal. Besides, mathematically, many of your variables are not defined, not even in the appendix, e.g., in equation (2) B^ is not defined; α which seems a key tuning parameter in Theorem 1 is not defined, etc. I believe that this paper introduces an important contribution to the RL community that is concerned with safety. Is this type of rejection sampling guaranteed to always stop? The authors formally show that it is possible to upper bound the expected probability of failure during every policy update iteration (Thm1), which is a non-trivial result.
[1] "Eyeriss: A spatial architecture for energy-efficient dataflow for convolutional neural networks", ISCA 2016 Results show improvement in performance but it is not clear to me why. How does the work compare to the methods described in [3,4]? [3] and [4] also evaluate on a very small number of workloads, but I believe they probably got a freepass since they were the earliest works in their domain.
I did not understand where this is appearing in the math and I cannot check whether the intuition conveyed by the figure is correct or not. And magically this changes in (6), and a clip non-linearity is introduced ? Overall, this is a reasonably nice piece of work. Strength: (1) This paper proposes a layer-wise optimization method for ANN-SNN conversion. Also (5) seems wrong in itself, the authors are trying to approximate a rectified linear network but it suggest that the activity will be equivalent to a linear network (at least when v(T) is small) ? As one might expect, lower thresholds, and longer simulation times, both of which lead to potentially higher spike counts and thus lower discretization errors, lead to smaller conversion errors. Nice performance was obtained in all cases: better than using a normal ReLU, or other comparison activation functions, in the "target" ANN. (3) I'm not sure if I missed anything.
(8)  to the paper's formulation in (12). From my perspective, this is a much needed and love-to-see work for the line of neural generative modeling.
The way it utilizes a small amount of OOD data is novel (eq.3). The methods, including unsupervised and semi-supervised methods that use a few labeled outlier data, are evaluated using four datasets. Cons: Their method is a pretty-straightforward combination of two established methods, contrastive self-supervised representation learning and the Mahalanobis distance as a metric of distance from a point to a distribution. Comments: It's interesting to see the availability of only 1~5 samples per class for OOD data can result in some noticeable gains. This assumption is not valid in general cases. Is single cluster assumed for both in-distribution and OOD data in (3)?
This paper compares the reproducing kernel Hilbert spaces (RKHSes) generated by a deep neural tangent kernel (NTK), a Laplacian kernel, and an exponential power kernel. A notable contribution in the proof is the application of analytic combinatorics to obtain the asymptotic rate O(n^{-3/2}) of the Maclaurin coefficients of the NTK which is intractable due to its recursive definition. In Theorem 2, I am very curious about the seemingly contrary results: $\\mathcal{H}{K{\\text {exp }}^{\\gamma_1, \\sigma_1}} \\left(\\mathbb{S}^{d-1}\\right) \\subseteq \\mathcal{H}{K{\\text {exp }}^{\\gamma_2, \\sigma_2}}\\left(\\mathbb{S}^{d-1}\\right),and\\mathcal{H}{K{\\mathrm{exp}}^{\\gamma_2, \\sigma_2}}\\left(\\mathbb{R}^{d}\\right) \\subseteq \\mathcal{H}{K{\\mathrm{exp}}^{\\gamma_1, \\sigma_1}}\\left(\\mathbb{R}^{d}\\right).$
This paper studies how to improve the worst-case subgroup error in overparameterized models using two simple post-hoc processing techniques: (1) learning a new linear classification layer of a network, or (2) learning new per-group threshold on the logits. Strengths: The paper is very well-written and easy to follow. This topic is interesting. The paper is in general written well, and demonstrates the problem convincingly. There are case (normalization) issues in the references: "ml", "t-sne" (not exhaustive, a through check is recommended).
My understanding is that since JBDA and JDBA-TR do not reply on a fixed OOD dataset, EDM trained on auxiliary OOD dataset may be well generalized to these attacks' OOD data. A larger number of queries are used in the previous attacks. Specifically, it appears that a robust defense requires the hashing function to consistently select the same model in the ensemble in spite of small changes in the input. I wonder how the defense performs with other choices of attacker's data e.g., EMNIST which is a bit more similar to MNIST.
This paper proposes a VAE based hierarchical model for video prediction. It lies in a categorical structure space which is easier to predict. Then the authors translate the predicted semantic map to a real video sequence in a frame-by-frame manner.
The improvements of the collective robust certificate over the existing ones is sufficiently high in terms of certified ratios. The paper is well-written and easy to follow. Robust Collective Classification against Structural Attacks. Pros: This is the first effort that considers collective robustness certificate. The paper shows strong theory and experiments to illustrate the efficacy of the proposed collective certificate. I think this is a valid method to assess robustness of classifier satisfying locality like GCN.
A paper like this with carefully constructed constructed and a clear conclusion is also a valuable addition to this debate. While this does shed some light on the correlation of local entropy and local energy in promoting flatness, I'm not sure if one experiment on CIFAR10/Resnet18 is sufficient to justify correlations in deeper architectures that have been trained on larger datasets. (I tried hard to find where Figure 1 is explicitly mentioned but I simply couldn't. The authors also do not present any reasons to expect that generalization is related to flatness that are grounded in theory. I am however concerned about the incremental value of this manuscript in view of the long line of work that it builds upon. I believe this will lend more insight in why wide minima generalize better for deep networks.
Contributions i) Proposal of a novel confidence regularized loss for image classification and a novel algorithm that dynamically sieves out corrupted samples basing on their loss. As such, I am raising my score to a 6, and would like to recommend accepting this paper. But if the model capacity is sufficiently large, I think it can both overfit CORES2, and overfit those noise samples. One major complaint I have for the paper is the lack of novelty of the paper. In addition, I guess fx∗[y]=1 is still problematic in the theoretical analysis since CORES2=\\inf given the ideal classifier. The authors misuse the terms "sample" and "example".
There is a submitted paper (to this *CONF*) that includes continuous relaxation of discrete network structure optimization for network growing (not pruning). Is the proposed method applicable to networks for other tasks such as detection and segmentation? As a result, it is possible to get a highly sparse network out of an existing pre-trained dense network.
The paper under review introduces a number of geometric measures (isoperimetric, isocapacitory ratios that relate to Brownian motion or heat diffusion probabilities) that are applied to study neural network decision boundaries locally. Is it on a graph?
Also, I can see a benefit in improving the simulators or the source domain to reflect the target domain, I don't think that taking the source domain as-is is the way to go, because this is also a waste of data from the target domain. This result that safegaurds -> safeguards (2)Further comment on this assumption. However, I believe this paper is borderline and I lean towards reject for a few reasons. And this assumption seems to become lemmaB2 (or look very similar to it), this is quite confusing. DARC utilizes an adversarial-like reward that distinguishes between source and target domains.
It is introduced very late in the paper and it is not clear where the proposed loss helps. Dataset semantics are less important for unsupervised pretraining:  They transfer from a variety of tasks, faces, objects, etc using supervised and unsupervised pretraining. Negatives: The major insight into the differences is limited:  mainly that we pay a price when the low-level information is lost by the supervised pretrained model.
The connection to the NTK seems a bit weak and superficial — Based on eq (3), the authors propose the energy functional in eq(4) for learning the meta-parameter and this is where the RKHS comes in. Overall, this is a solid contribution that should be of interest to the community. This is of merit since it is known that MAML type approaches are far too sensitive to the outlier tasks. I'm maintain my recommendation to accept this paper. They demonstrate it using just two attacks: a black- and a white-box one, which I don't consider extensive enough. They offer some empirical evidence that this is indeed the case. Cerviño, J. A. Bazerque, M. Calvo-Fullana and A.
finite               (1)                  (2) infinite           (3)                  (4) However, I do think this paper is a meaningful contribution, that puts together a few ideas that were lying around and shows that you can use them to make progress in calibration in NNs. Update: the authors have greatly improved the figures and tables, and expanded the captions, removing my major concern about clarity. Table 3: what is the number of examples in NNGP-LL last column? Page 3, top: "under gradient flow to minimize a loss, the output distribution remains a GP". Assessment: The paper is very clear and is an interesting read. Appendix: lots of good material there, some of which could be moved to the main paper (and some material in the main paper should be moved to the appendix, in particular some rows in table 1 and Summary: The submission studies Gaussian process models with the infinite-width neural network kernels.
This becomes very laborious. One such example is that the variable o is used to represent occupancy as well as the agent location in space. Neither is emission model (should be measurement model). The proposed model is therefore a nice unification of neural networks, dynamics and multi-view geometry. Strengths The work builds on a fundamentally new and interesting line of generative variational approaches to SLAM A transition model describing the evolution of the dynamics of the agent is also learnt. A graphical model with attention mechanism and ray casting is used to model how the world and the agent state renders the RGBD sensor data.
The presentation of the method (which spans roughly two pages and a half) is lengthy and not very clear. 1), but also θ(t) (e.g., line 2 of procedure Forward, algorithm 1). The authors introduce Contextual Transformation Networks (CTNs), a replay-based method for continual learning based on a dual-memory design and a controller that modulates the output of a shared based network to task-specific features. Pros of paper The strongest part of this paper for me is the experiments section. ########After rebuttal######### I appreciate the author's effort in addressing my concerns. Why is hl obtained from h~l−1? The temperature hyperparameter τ is undefined in eq. This information is used to pick the correct task embeddings and the correct task-specific final classifier ("head").
Summary The paper proposes a novel approach for third-person visual imitation learning from observations, ie for imitating a different agent in a potentially different environment purely from visual demonstrations. Without any regularization, I'm surprised DisentanGAIL learns anything at all. Originality As mentioned in the paper, this paper is closely related to Stadie et al. (2017). It motivates well the distinction between domain information and goal-completion, and highlights why previous methods like domain confusion loss can fail. The notion of "prior data" is used in the paper, but I cannot find a clear description of it anywhere. Overall, based on the arguments above, I would recommend a reject for this paper. Post-Rebuttal Comments I thank the authors for their detailed feedback. The text says that the DCL substitutes the mutual information constraints, so the only difference I see would be learning a distribution over latent representations rather than a deterministic feature extractor. However, I have a few concerns about this approach, which I will list as follows. Nevertheless, I've increased my score to a 6. The paper is also well written and easy to understand. If I understand Figure 3 correctly, the orange line is without any regularization (lower bound) and the green is learning without domain differences (upper bound). Clarity and Correctness The paper has a few somewhat painful clarity issues that make it difficult to understand.
Summary In this work, the authors present a method for learning audiovisual (AV) representations from videos using a Transformer-based model architecture. (3) Unfair comparison in Table 2(b). Not a negative point in itself, but related to how this article is written: content-aware negative sampling is not new, see e.g. FaceNet (Schroff et al. 2015), On Mutual Information in Contrastive Learning for Visual Representations (Wu et al. 2020). This paper studies modeling and training choices when designing a single model based on ConvNets and transformers for audio-visual representation learning. This typical trend is due to the memory requirements for training a multi-modal transformer end-to-end. It would be more rigorous to also have an experiment where one reduces the (parameters) size of the model without sharing from 155M to ~34M (or 31M, and decompose W=UΣV for those weights too), and compare this to the all/part parameter shared models.
Do you have an answer for this? I would have also liked to see more ablations. The constrastive losses introduced in the paper are interesting. Given that the main contribution of the paper is empirical (none of the ideas are new), better and more comprehensive experimental results would have strengthened this work. I am not sure I missed it, but I do not have an objective view on the computational overhead (especially on having to sample the right-hand side of the non-similar keys).
While I do agree that training a graphical neural network to be able to produce a quality policy for a number of control tasks from the opening item environment is difficult the author of the paper might be missing at least one of the key points from the previous work in that you can learn a stronger modularization of policy. The paper is well written, and methods and analysis approach used are clear. In other places, the paper contrasts transformers with GNN-based methods ("substantially outperforms GNN-based methods"), as if transformers were not GNNs. To avoid confusing readers, it would help to explain that GNNs are a broad class that includes both transformers and SMP, which differ in their message passing schedules, etc. Overall an interesting approach that is expected to improve performance in MTRL and needs further exploring. Confidence intervals or standard deviation? This limitation probably deserves to be highlighted more prominently. Questions Why were no results provided for the Walker-Hopper or Walker-Hopper-Humanoid combinations tested by Huang et al? ----- Post Discussion ---- I have updated my rating for the paper after the authors have provided additional discussion and experiments to address my concerns. This term has not been defined anywhere in the paper and without this definition, it's difficult to understand the contribution this paper is making.
Questions: How is SAC(theta) computed? Is it a policy with its own parameters? I understand that P(s0|θ)=∑τ∈ΩP(τ|θ) where Ω are the subset of trajectories that terminate in state s0. Overall I think the paper has the potential to be a good paper but could still be substantially improved and I'm leaning towards rejection. In equation (3), is \\tau' independent of \\tau_-T:-1, so the right-hand term (in red) can be moved outside the blue expectation? The idea makes sens and is well explained. Is this related to the GAIL baseline? What is encoded and decoded by VAE? For this reason, I am unable to recommend acceptance at this stage, due to major clarity issues. The gradient estimator involves simulating a possible past from a demonstration state (using a learned inverse policy and inverse transition function) and then simulating forward from the possible past (using the policy and a simulator) The gradient is then the difference between features counts from the backward and forward simulations.
How is the memory used in the read model? The authors show the efficiency of Temporal Shift Module (TSM) (Lin et al., 2019) in the encoder of memory models. The Kanerva machine: A generative distributed memory. Specifically, this paper proposed a novel memory allocation scheme,  replacing the stochastic memory writing process in prior works KM[1]  and  DKM[2] with a set of deterministic operations. The baseline model in the ablation study is too weak. Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory. It is better to draw Z in the generative model picture;
Rating Aiming at acquiring an efficient model in a data-driven manner is indeed important for video models. This paper proposes a novel framework called VA-RED2 to reduce spatial and temporal features to be computed for video understanding, which can reduce FLOPs when inferencing the video but remains the performance. We know that Gflops is not a good indicator for speed comparison. For the action localization task, J-HMDB-21 dataset is used. What is the contribution and motivation of using it here in searching video models? Directional Temporal Modeling for Action Recognition, ECCV2020
Summary Of Contributions: This paper proposes to automate the design of auxiliary network and its allocation under decoupled neural network scheme, a design that speeds up network training and potentially boost model accuracy. I wonder why SEDONA performs better than backprogation (sometimes much better as in Tiny ImageNet)? W3: Complicated optimization tricks seem necessary to get the bilevel optimization to work (Section 3.3: "In bilevel optimization, meta variables (α, β) depend on the learning trajectory of layer and auxiliary weights (θ, φ) (i.e. a sequence of values of (θ, φ) during inner optimization). i assume this is the wall-clock time to achieve convergence, but I couldn't find a definition of convergence or stopping criterion, or how speedup is measured. Yet the authors set K=4 in Table 3 and got a contrary result. In the spirit of recent trends in greedy layer-wise and indirect training, SEDONA allows gradient information to flow either from the next layer as in backpropagation or from an auxiliary head, trying to make a prediction using the current layer's output.
Summary: This work tries to find a compromise of model-based and model-free methods, using a teacher and student network . The word trajectory can be used in many different contexts, I don't think it was made clear anywhere in the paper what is the defining features of the "trajectory-ness" that the authors want to emphasize. Overall, I have a mixed feeling about this paper and I currently stand between scores 5 and 6. I suggest to add relevant citations in Sec.1. Since a positive rating is already given, I would keep it unchanged. Is there any particular reason for using classification loss in all examples especially for a typically regression problem? The proposed model is interesting and may lead to a series of follow-up studies that leverage the strengths of both model-free and model-based methods using knowledge distillation techniques. Which task do model-free methods achieve substantially better performance? The proposed method was tested and compared to other model-free methods.
For a simple class of networks and for TFNs, the authors prove D-spanning. Pros: Achieving rotation equivariance is important to point cloud network as it is the key to improve the expressiveness of point cloud features. The universal approximation property for equivariant architectures under shape-preserving transformations is discussed. Minors: There are some typos in the inset figure on page 1: "Equivarint" -> "Equivariant". Another difference between the described networks and practical TFN is that in the described networks, all relevant parameters are in the pooling layer, which sums a large number of terms (looking at the proof of lemma 2, exponential in D), while in practical TFNs, the parameters are in the filters.
Paper strengths I think the ideas proposed in this paper are interesting and I would not be aware of any architecture that would use a similar arrangement of tensorization and attention in the mid-layer part to allow for a lightweight 3D convolution architecture. The paper shows competitive results on Something-Something as well as on Kinetics-400 To achieve that, the authors propose to divide feature channels into several sub-dimensions (called channel tensorization) and then perform group convolutions at each sub-dimension sequentially to improve channel interactions. The Paper is well written and easy to follow. The paper also provides detailed ablation studies on the approach. Typos: Page7:  In our experiments, to ensure GFLOPs is comparable with other methods. 200–210, 2020. Heng Wang, Du Tran, Lorenzo Torresani, Matt Feiszli, Video Modeling With Correlation Networks, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020
Another related concern is that, in cortex, despite of a smaller number, I neurons are often responsible for controlling the dynamics/computation due to the dense connectivity from I to E neurons. Pros: This is a nice and new insight. *page 4, "Unlike a column constrained network, a layer in a DANN is not restricted in its potential function space. Other that this comment I learn and enjoy from reading this paper. To make this useful, it would helpful to make the comparison more specific and clear. Pros:1.To my knowledge, this is the first E/I network that could achieve comparable performance with the standard ANN model on MNIST task (although at the same time, I have to say that not too many papers have studied and reported this issue).
classification error." This sentence is probably the most important summary of this work, but it's so long and dense that it's very difficult to parse. A similar question is also, for certain data there is a larger gap between the proposed method and ELR (in appendix). I feel that there can be room to be improved in this paper. Its effects are thus hard to interpret although it is instrumental to obtain a concave functions for the proofs. However, the detail of this phenomenon is not verified in a more detailed manner. However, it is better to provide any clue that we can extend this result to more general settings.
Given its graph structure and its continuous time formulation (employing the adjoint method for differentiation/backpropagation), this method allows the usage of samples placed arbitrarily in space and time. A discussion on this aspect would be useful. This is good to see and makes sense. This is maybe what was done for the PDE-net, but the paper is not clear here. This would be important to understand how hard the tasks being performed are. Thus, assuming that the authors can clarify this part and show that the proposed method yields benefits, I think this could be an interesting paper for *CONF*.
It is not clear that the authors pick RegNet and tune it highly and compared with EfficientNets. Why is this a problem? Weakness: -- There is a lack of accuracy comparison with other removing batch normalization works. The proposed SPP seems to be a good tool for analyzing a model. How did the authors compute gamma in eq.(3) in a training phase? Comments) The major problem of this paper is none of the advantages of NF with SWS are highlighted over BN, so it is hard to find any reasons for replacing BN with NF-SWS.
I regard this work as a new application of LTH to binary neural networks. In general, the paper is well written and the theoretical and experimental works support the authors' claim. This paper, at least the main text, is not self-contained. Pros: The authors try to express in a way that every step of logical connections in this paper can be clearly understood by readers.
What is the difference of using backprop through gradients of the loss vs stochastic search gradients (log likelihood trick) gradients for different dimensions of the optimization variable? It is benchmarked in a variety of fields (1) energy-based learning, (2) robotic control, and (3) portfolio management. Pros Paper is clear and grounded in existing literature and context At the current state it is hard for me to understand how their approach for differentiation of an embedded optimization problem is principled and why it should be better than other approaches. For non-global optimizers (such as gradient descent) starting in such a way that we do not end up in the wrong local optimum is crucial. The results are interesting but require a more compelling presentation and in depth analysis. The argmin is therefore a set-valued map and not differentiable in the classical sense (even when the optimum is unique almost everywhere in the parameter space it is possible that the optimal value is discontinuous in the parameter). For a locally strictly convex optimization problem of the form x^star = argmin_x f(x, theta) So backpropagation of one gradient step with a high variance gradient estimate compared to the true derivative which has rank n curvature information should be inefficient in theory for truly high-dimensional optimization problems.
Because the problem with large init is the bad gradient direction (as hypothesized in paper), then scaling the learning rate would not help. I think it just needs a few more passes, with an eye to making sure things are accessible/understandable/flow. I googled it quickly and it seems that coherence means something specific in linear algebra and signal processing: (https://en.wikipedia.org/wiki/Mutual_coherence_(linear_algebra), https://en.wikipedia.org/wiki/Coherence_(signal_processing)) It shows that the initial scale of a 2-layers MLP, with sinusoid or ReLU activation, can control the memorization behavior of the network, from very little overfitting to complete memorization. The conclusion should stand on its own and summarize results, not reference them in a way that requires me to have read the whole paper to understand. It then proposes an alignment measure which correlates with generalization for different initial scale. How does it fit with the argument about homogeneity?
This pipeline is trained end to end using YOGI optimizer for regular gradient updates and 'proximal gradient descent' for T which does soft thresholding with a lower bound of 0 (accomplishing both sparsity and positivity part). In this paper, the authors proposed a method to learn efficient representations of discrete tokens. iii) This is a minor point, but AUC results in MovieLens besides MSE can reflect the ranking quality in recommendations. This two-step approach reduced the overall number of parameters. ANy explanation as to why this happens? For language tasks and word embeddings, anchoring method has been shown to be effective in several tasks already (e.g. [1] http://papers.nips.cc/paper/8152-the-global-anchor-method-for-quantifying-linguistic-shifts-and-domain-adaptation). This design admits multiple ways of initializing the anchors A. al. 2016)  and Post-Sparse-Hash (Guo et.al. This may or may not suffice (for the purpose of adding domain knowledge), but on paper, there is a chance that some finer structures of the domain knowledge may get lost.
-Proposition 4 states for pre-conditioners (ii) and (iii) the bias is monotone for α in some range depending upon the covariates population covariance. Experiments are also conducted on neural networks in a student and teacher setup. Overall, the paper provides a comprehensive study of the impact of preconditioning/second-order methods/natural gradient on generalization by giving a precise analysis in tractable regression settings, which illustrate conditions under which preconditioning is or is not useful for better generalization. The authors then go on to state that, in short, this is due to (see Appendix A) NGD moving parameters further from initialisation, and thus, no longer well described by a linear model i.e. NTK. Meanwhile for non-parametric regression, source and capacity assumptions are leveraged to achieve finite sample guarantees.
Empirical results show that, an induced compressor obtained from a class of biased compressors (e.g., top K gradients) has better performance than a biased compressor from that class with the same communication cost. Queries and Suggestions Why do both C1(g) and C2(e) need to be communicated if C is unbiased? The flexibility of the proposed approach which makes it amenable to the extensions  in Section 4 is not illustrated in the experiments which are limited to a direct comparison of the proposed approach with EF. For eg. Are all combinations of biased and unbiased compressors acceptable?
The paper builds on the Neural ODE framework by using delay differential equations (DDEs) instead of ordinary differential equations (ODEs). As it stands, it only indicates that the initial state of a NDDE is specified by a function over an interval, rather than a single vector, which is all that is being used. There are some weak points in this work. (3)    A novel learning algorithm that implements the forward for h and the backward pass for h,lambda (the augmented variable) and dL/dw (L is the loss) by a piece-wise ODE solver, dealing with the different delayed states. In this way the network can take into account a former hidden layer.
When some of the Xis are correlated (e.g. consider a vision task), there could be quite a gap between I(Z; X) and the independent assumption version. I don't know of any prior work that takes this approach. I'm more confident this is a good paper now. Key idea is to instantiate the compression term of the information bottleneck framework with learned term that sets irrelevant feature dimensions to 0. Weak Points: I found the reinforcement learning experiments not convincing since only a fixed region of the input is modified by noise (ie. I think this should be one of the baseline. The approach is demonstrated in experiments in (1) robust exploration setting for RL, (2) adversarial attacks on ImageNet, and (3) an experiment showing that their approach is able to maintain performance on ImageNet with reduced dimensionality. If that's similar to DB, what would be the benefit of DB? Authors have addressed my concerns and clarified some of the confusing points that I had.
The proposed method is novel and effective. This paper has clearly explained the two types of parameters, i.e., critical parameters and non-critical parameters. The idea of this paper is novelty and meaningful. I think this paper is interesting and makes sense. Besides, this paper exploits multiple methods for comparison and considers various noise settings to verify the effectiveness of the proposed method. The paper is very well-written. This paper aims to reduce the side effect of noisy labels before early stopping, thus CE is an importance baseline in this paper.
In a nutshell, the framework learns a "dataset-to-neural-network-architecture" transformation using a database of datasets and architectures. The dataset encoding part is just borrowed and there is no improvement to adapt NAS tasks. In my view, I think MetaD2A pays more emphasis on meta-learning in NAS field. 2019. The authors address neural architecture search (NAS) scenarios. Overall Review: This paper proposes a new scene of fast adaption of NAS, which may be a good direction of NAS & meta-learning. Their motivation is interesting to me and they clarify their difference compared with traditional metaNAS in Figure 1. Similar graph decoder is proposed in previous NAS works [1] and performance predictor are proposed more times. The paper is well written and structured
Weaknesses: The evaluation is missing an important baseline model, which are (A)NP models that have self-attention in the encoder for processing the contexts (c.f. model figure in ANP paper (Kim et al., 2019b)). I believe that this is a relevant paper for the conference. Previous solution look limited and the proposed method seems natural and a more effective method of aggregating this information. These models assume that there is a task-specific global latent variable and task-independent latent variable. Summary of the Paper: This paper describes Bayesian context aggregation for neural processes. However, this paper and many neural process papers are written in the context of "Formulating scalable probabilistic regression models with reliable uncertainty estimates."
I think the significance of this paper hinges on (1) how large this bias is for reasonably complex tasks, and (2) if this type of bias might occur in other RL objectives, besides empowerment. It is useful to the extent it aids performance in those settings. Additional experiments are needed. In addition to experiments justifying the extra term, it would also be useful for the authors to include more motivation and intuition about why and when it is important. In general, the paper is hard to follow. Minor comments "methods for measuring it" -- This makes it sound like Arimoto + Blahut proposed methods for measuring empowerment. Is the GMM approach in S4 just a special case of the model learning approach in S3, where the model is taken to be a GMM? Illuminating a previously neglected algorithm is worthwhile and I want to reward that. Cons: The experiments are a) done only in toy domains and b) even there demonstrate only a 5-10% improvement in empowerment. They introduce two ways of estimating the missing term: one appropriate for discrete state spaces, and another appropriate for continuous state spaces. However, the difficulty in reading the mathematical notations and expressions severely handicaps the reader's ability to carefully understand these contributions.
Comment (1) hints at a larger (but vague) point that the paper is trying to characterize a stochastic optimization procedure with a solution of a deterministic gradient flow ODE. This paper is clearly written and well edited. In my opinion, this paper fails to deliver that, which is why I recommend rejection. As it currently stands, this paper is borderlin on the acceptance threshold for me.
(A potential answer may be that there's no training before pruning is finished, but why is this important?) To address this concern, the methods (SNIP, GraSP, SynFlow) are performed during training and showed that they perform inferior to LTR in Fig. 6. (1), suggesting possible issues that need to be overcome to improve accuracy, and proposes a set of experiments and comparisons that should be part of any new technique that claims to discover a good sparse mask at initialization.
Take Owens and Efros (2018) for example. Such baselines would make it easier to understand how well the system is doing and which parts of it are the most useful and important. 2) or spectrogram (fig. 1) for audio? It is evaluated on a subset of the YFCC100m that is annotated by human raters as to whether the clips have on-screen, off-screen, or both types of sounds, with the predictions of a previously described model  (Jansen et al, 2020) helping to reduce the number with only off-screen sounds. For example, In equation (6) please explain the notation "P(?)" in the following sentence: "minimum loss over all settings P(R) of the labels" This paper proposed an unsupervised method for open-domain, audio-visual separation system.
In the first stage modeling, the authors proposed a new phoneme-level acoustic condition modeling in addition to the speaker and utterance-level approaches. Having listened to the examples they gave, I do find that there are speakers for which it is clearly not as good, but this is not reflected in the evaluator's results. The novel piece that enables this is the conditioning of layernorm in the model on the speaker embedding. Please clarify this issue. The overall structure of acoustic condition modeling in Figure 2 (a) is not so clear. The tactic for speaker modelling is that the speaker conditions only the scale and bias terms in the decoder. 4.2 Method Analysis: What does it mean to remove conditional layer normalization? MSE? How is it determined that acoustic conditions such as loudness or room conditions are actually captured by the utterance- and phoneme-level acoustic condition modelling? However notice that, if I'm not mistaken, these acoustic embeddings are used zero-shot; it is only the speaker embedding that is the input to fine-tuning, and this only via the normalization parameters. Overall, the model architecture is interesting and results seem to show its validity. In this paper, the authors present AdaSpeech, a TTS system that can adapt to a custom voice with a high quality output and a low number of additional parameters. For higher reproducibility, authors need to describe it in more detail. In page 3, random chosen  -->  randomly chosen
Clients with higher computation capability can train larger models while clients with less computation capability train smaller models, and all these model architectures belong to the same model class. If that is the case, I would like to see an explicit ablation study that distinguishes between the two. In the conclusion, the authors state that their method achieves better results with fewer number of communication rounds.
This paper proposes and interesting and novel way to handle weak labels from human demonstrators. The paper is written very well, in fact most papers contain a lot of spelling mistakes but this paper was a joy to read in this regard :) The concepts are also explained clearly. The results show that the models using the weak labeling out-performed models with no labeling. (semi)supervised learning [see Locatello et al. and papers citing this work) This paper presents a technique that uses latent variables to model the uncertainty over a group of class labels that could describe the task (e.g., slow, soft, left-of-object). By doing so, it is possible to have only partial labels (weak labels). The paper does a good job of comparing the methodology with 3 different off-the-shelf models for implementing the inference networks (GS, AAE, and VAE), as well as comparing each with and without the weak labels (baseline). The paper needs to present real robot results and cover related work in more detail. Experimental section fails to investigate and establish these claims. Overall, though, this paper does present a novel solution to the problem of user-provided labels.
In contrast to (Phong et al. (2018)), the proposed method works for CNNs as well. In particular,  this paper tries to form a system of linear equations to find a training data point when the gradient of the deep learning model with respect to that data point is available.
Summary: This paper propose a population-based AutoRL framework for hyperparameter optimization of off-policy RL algorithms. The automation of reinforcement learning is beneficial to the research community, especially for researchers who are not familiar with RL but in need of it. To show that the neural architecture adaptation is a crucial part of the framework (which is a major difference between the proposed method and PBT), the authors might have to move to a complex domain of environments to demonstrate that. To achieve this goal, they integrate three technologies, i.e., evolutionary RL for hyperparameter search, evolvable neural network for policy network design, and shared experience replay for improving data usage. Strengths: The idea is simple and intuitively makes sense.
This paper studies the mean-field limit of the policy gradient method (with entropy regularized) and proves that any stationary point under this setting is a global minimizer. The paper only shows convergence, but fails to give more detailed properties like convergence rate, etc. The paper is well-written. The technical contents seem sound and a comprehensive literature review is provided. Will it convergence to a limiting cycle or diverge?
I appreciate this work for its motivation and the algorithm is simple-to-implement and not computationally expensive, which points to an interesting direction for future study. Another problem with \\eps-greedy is that it explores forever. It'd make it easier if "(100%)" is added to the y-axis of Median/Mean plots. Overall, the paper provides a simple yet effective exploration technique for RL methods. At a more substantive level, it is not clear how exhaustive the list of desired properties of an exploration algorithm is.
Also, the author argues that audio labels is special, but in the paper, other type of high-dimensional representation of labels that uses external information are not explored, such as word2vec. Then, they performed regression using the spectrogram as a label. In particular, it proposes to introduce high dimensional and high entropy label representations for group truth, to improve image classification performance from two practical matters --- Robustness and data efficiency, while achieving comparable accuracy to text labels as the standard representation. Strength: The idea of giving speech signal as a proxy for categorical label is interesting. They used spectrogram of the pronunciations (TTS-based generated speech) of class labels as a high-dimensional representation. For this reason, I recommend rejection.
This paper considers a setting (as I understand) where the test task is out-of-distribution of P(T). I do like the use of ensemble and also adversarial examples, and intuitively they can improve the test-time adaptation. If no, and you use running stats, then a simple baseline would be to use test time statistics, so I would add this comparison to your experiments. Further, it has always been the case in MAML, that one can store a checkpoint θ0 trained from some tasks, and  when a new task (maybe entirely different) comes, we start from θ0 to adapt. Considerations I think the paper is well written and motivated. I recommend acceptance, but I want to first to hear the author's response to my doubts. What is the computational overhead in order to gain the additional accuracy?
I could see this paper be re-written almost as a proper tutorial paper in this topic of research. The idea is quite interesting to encode the objectives as task codes and then to write a smooth approximation to the predictor function as a weighted sum of indicators and the try training a net to learn this smoothening. This is specially so when SGD is not really required by the subsequent developments in the paper. There are many places unclear, in particular, the "task distinctiveness". Can the authors point to this assumption anywhere in that paper? However, this seems unnecessary and limiting. This is where the reader looks first. This paper provides impressive sample complexity analysis, with both informal and formal versions. For example, Lemma 4 and Theorem 8 are the main support of the paper, and should be in the main part of the paper.
It is unclear how it is implemented in the network model, and how this information can get to the grid cells. Clearly, the proposed model is related to many of the previous models, but to go one step further and say that it unifies these previous models, that would seem to be a over-claim in my view. A key quantity in generating "a sense of direction" is the quantity s_G in Eq. (9). Can the authors elaborate on what point is being made in Figure 3.H? The writing also needs to be tightened in several places. This paper shows how SR representation theory can be used in a model of grid cells to plan and navigate towards a target. Strengths: The proposed method is efficient and doesn't need a decomposition for future state occupancy and can be done directly by re-weighing of eigenvector (by eigenvalues) of the transition matrix. In summary, the method only works on deterministic gridworlds where certain boundary conditions hold or the space is small enough to double its size so it still fits in memory. Is there a way to falsify the hypothesis/model? The current paper could use some organizational improvements, and the experiments could be more comprehensive and tuned to demonstrate sharper points. This feels quite restrictive and potential wasteful in terms of computation. It would be helpful to see a concrete description or simulation of a neural network implementing action-directed SR. Overall, the work should be of interest to any *CONF* attendees who engage in research surrounding grid cells. However, it feels that several key statements in the paper need to be clarified, and some statements need to be toned down.
Ultimately, I don't think this is only a minor mark against the work, and one that can be overlooked given that such cases are at least clearly stated as limitations of the approach. Be more clear about why you chose this and if it is optimal somehow or not I feel like i is not scoped here It's hard to parse but it looks equal to the expression in 10 at first glance – it's the appendix so please explain further. This is a paper that focusses on the timely and important problem of uncertainty quantification for the predictions of deep neural network classifiers. I'm recommending acceptance since the idea seems useful and well-argued both conceptually and experimentally. Another concern is the fact that getting well calibrated Clopper-Pearson intervals with good statistical guarantees takes a non-trivial number of samples and it appears this would scale with the number of classes. Is this overhead considered in figure 2a? Weak points + Clarifications: I am confused about the application of this method to safe planning. I think this is a OK trade-off to make when in safety-critical scenarios, but then the authors give "fast inference" as one of their primary applications, it seems like a bit more discussion of this may be warranted.
As a result, it is unclear to me why ESM performs worse than ESMN in Tab. 1 for DR-Ego-S but comparable for all other tasks in the table, or why ESM and not ESMN is used for some of the experiments. While I like the proposed approach, I also see multiple significant weaknesses: I found the experimental evaluation nearly impossible to understand. The paper proposes an ego-centric representation that stores depth values and features at each pixel in a panorama. The formulation of the proposed approach builds on a Kalman Filter setting and encodes memory in a spherical structure.
This paper presents a local search approach along with an interesting theoretical analysis of their approach.
The Fourier neural operator is by construction (like all neural operators) a map between function spaces, and invariance to discretization follows immediately from the nature of a Fourier transform (just project onto the usual basis). This seems to be quite constraining, could you comment on this? I have to admit that my understanding of this paper is rather limited and I have lots of conceptual questions about the implementation. Strengths and weaknesses: Much of the theoretical legwork for this paper, namely, neural operators, was already carried out in previous papers (Li et al.). 2020. This work attacks the important problem of learning PDEs with neural networks. Experiments demonstrate that the Fourier neural operator significantly outperforms other neural operators and other deep learning methods on Burgers' equation, Darcy Flow, and Navier Stokes, and that that it is also significantly faster than traditional PDE solvers. In addition, a concise detailed description of the network architecture is missing. As one of your motivations behind this work is to learn the operator, it could have been interesting to test your approach using different sample points as in the training data.
"Ensemble methods are a simple approach to improve a model's calibration and robustness." Who found this? Summary: The work studies how a better calibration of individual members of an ensemble affects the calibration of an ensemble. In the paper, ECE is measured in percentages. This even further limits the contribution of this manuscript.
In your experiments, how important is the accuracy of the dynamics model? So is it one or two-dimensional? The proposed use of a hypernetwork is plausible and novel to my knowledge. Impact & Recommendation Despite that there seem to be a lot of hacks that make this method in the specific settings, I think the general idea behind it is sound. What if the object is re-oriented? Why does a "1-dimensional code" lies in a 2d space? It's become a standard for system-identification-style works and it's justified in my opinion since your method isn't inherently useful in simulation where the user has access to all the information and can arbitrarily reset/reposition the model. Questions: In eq. 1, should omega be a parameter of H(.) instead of F(.)?
of heads, etc), and the length of predicted trajectories (H). The results in Figure 3 show a small performance difference between IS (proposed approach) and baselines due to the large variance. (4) Add citations to the related work on ToM and its application in MAS. For training, MADDPG is used as a backbone MARL and implement ITGM and AM on top of it. For PP and CN domain explanation (Section 5.1), it is unclear what each agent observes.
This paper considers the problem of per-instance model adaptation for neural data compression, and proposes a new method for end-to-end finetuning the model that is quantization-aware, by introducing an additional term that measures the compression cost of model update to the typical rate-distortion loss. A more realistic decoder would be conditioned on information in previously encoded frames, changing its behavior. -log p(δ) based on the density p(δ). For example, Netflix is optimizing their classical video codecs at a "shot" level. Clarity (8/10) The paper is well written and clear. Even JPEG (1992) allows us to fine-tune the Huffman table for an individual image ("optimized JPEG"). Compressed model updates are also used in parallelized implementations of SGD (e.g., Alistarh et al., 2017). These asymmetrical coding times are often acceptable, as the authors note, since encoding-decoding is often a one-to-many relation.
(e.g., detection of person category having a more diverse appearances can be more affected by the number of instances used in training.) It provides a comprehensive review on related papers on object detection especially one-shot detection and their limitations. The authors should conduct the same experiments under a different number of shots. In addition, why did increasing the number of categories reduce the detection accuracy of known objects? -> either The paper suggests that a major factor for increasing few-shot performance in the few-shot object detection task is the number of categories in the base training set used to pre-train the few-shot model on a large set of data before it is adapted to novel categories using only a few (or even
It's unclear to me due to the expectation in (4) and (5). In my understanding, CϵE is a class of sets of trajectories. (p.2, Introduction) In general, the solutions to the IRL problem are not always best-fitting in the previous approaches because a highly nonlinear inverse problem with the limited information is very likely to get trapped in a secondary maximum in the recovery. Clarity The readability of the submission is poor and needs to be improved. The algorithm is evaluated on a 10x10 gridworld and compared with MaxEnt-IRL and DeepMaxEnt-IRL. (p.3, Regular Structure of Reward Functions) ϕi(s,a)i=1 I have never seen such a thing done before and it is interesting and possibly a route to robustness, but I would have liked more explanation and discussion. (p.1, Abstract) a global viewpoint
The authors adopt an existing augmentation algorithm and apply on the nodes of each training graph, and use the perturbed graphs for training. Just because augmentation hurts the performance of MLP on images but improves on graphs doesn't mean data distribution is the primary determinant of the efficacy of augmentation. 2020. Data Augmentation for Graph Classification. (2020). Data Augmentation for Graph Neural Networks. DeeperGCN+FLAG is currently ranked 2nd on the OGB leaderboard for graph property prediction. The method is general and may be applied to any GNN for a very small improvement. ogbg-molpcba: +2: DeeperGCN+VN+FLAG, +2: GIN+virtual node+FLAG, +1: GCN+VN+FLAG, +1: GIN+FLAG, +2: GCN+FLAGc. For instance, the impact of biased perturbation is statistically insignificant in table 2, and those limited numbers are not sufficient to make such a deduction. ---- Pros The authors evaluate their method on the Open Graph Benchmark (OGB), which is a standard benchmark that facilitates comparison with other methods. To be clear, this is not a weakness of this paper.
The paper presents a method for improving the accuracy when training CNNs from scratch on a small dataset. Then one adds more layers, freezes the previously trained and train on bigger patches and so on.
During training, cross-entropy loss are used for both pathways, and an "imitation" loss is used to encourage the CoarseNet pathway to mimic the FineNet The outreach to backward masking oversold a computational analogy as a neural computational model while providing a vague explanation of the background and results of the experiments. (Related work) Although the authors argued that existing models are conceptually different, it doesn't mean that architecturally similar models [3, Hou et al. ], SOTA in adversarial defense [4, 5], and most importantly other brain-inspired models, targeting robustness [6, 7] or not [8, Tang et al. ], shouldn't be compared against to properly prove the value of this work. In tables 1-2, are the reported results the output of FineNet? The exact images used to produce each of the results are not clearly explained. what is the neuroscience evidence of relative shallowness of M-pathway? The choice of the number of feedback steps is ad hoc. 2019.
—Summary: The authors propose a generalized neighborhood message aggregation function for GNNs. The proposed choice of generalized aggregation functions is SoftMax and PowerMean, which generalizes Max and Mean functions and interpolates them. Is it possible to compare to DGCNN/DeepGCNs on S3DIS? #####Cons##### (1) Although the provided experiments are comprehensive, some key experiments are missed. The Paper is well written and is easy to follow. Also, this paper proposes an interesting perspective to study this problem. B. The effectiveness of the whole model has been shown strongly. The experimental results on OGB is impressive and can demonstrate the effectiveness of the proposed approaches. However, in my opinion, the paper is missing the theoretical justification of its proposals and I have concerns about the results (details below).
The general idea is starting from a prior work (Video Textures) and extending this work with a learning framework. clarity: The pipeline of the proposed method is clearly presented in the method part. The analysis of the quantitative and qualitative results is convincing and logical. (i) a new pipeline for modeling and calculating probabilities of transitioning between frames of the same videos. (3) Outperform the competing algorithms on a set of evaluations The scalability of this method is limited. (2) It is not true that existing methods fail to generate more than a short sequence of frames, e.g., (Lee et al. 2019) in theory can generate videos with arbitrary lengths. Overall, this work is well organized and easy to follow. In the introduction part, the authors present the basis of their work (Video Textures) and present a comprehensive comparison with previous works. And the proposed method demonstrated promising performance. (ii) Extending the model to a conditional situation and performing the task of audio conditioned video synthesis. (8) What are the results if the classic methods also use the interpolation network? The motivation is clear and ideas are simple and useful. Second, this method seems to be example-specific, which needs retraining if fed a new video sequence. Moreover, the video interpolation is directly borrowed from previous work without further improvements, where I think is still challenging and worth to explore. To guarantee the smoothness of the transition between different segments, an existing interpolation method is used to connect these video segments in a sequential order. (6) For unconditional video synthesis, the musical instrument playing videos mostly contain small motions. Cons: originality: This work is more like a simple extension of the previous work (Video Textures) with limited novelty.
Can we say that the suspicious model is truly the watermarked model? Unlike prior methods, the method provides a resistance bound for attacks. [1] to the watermark embedding and extraction process, it is possible to ensure that the watermark is robust to watermark removal when the network parameters are modified by less than a certain calculated value. The authors have created a well written paper for a new watermarking method that addresses an important challenge in security intellectual property rights for deep learning models. The proposed method is based randomized smoothing techniques together with optimizing the model on a dedicated trigger set. The method reduces accuracy of the trained model. Then, for the l2-constrained adversary, what is certified for the model trained with Alg. 2?
Summary: The paper proposes an algorithm to search for hardware designs and neural architectures jointly. Co-designing neural network architecture and hardware architecture is not new. Cons: The technical contribution of this paper is limited. It is a little unclear why the papers by Jiang and Yang and the papers above are dismissed? When Neural Architecture Search Meets Hardware Implementation: from Hardware Awareness to Co-Design https://ieeexplore.ieee.org/abstract/document/8839421 The main difference between this paper and previous hardware-aware NAS papers is that this paper has an additional hardware search space beside the neural network architecture search space. The system is able to find the best solution under latency and chip-area constraints.
This term is not clearly explained in the paper. The pros and cons of this paper can be summarized as follows. However, there is nothing in the formulation of this concept which requires that this is an importance and could in fact be any form of weighting. Overall, I think the novelty of this work is limited and the experimental results are not very convincing. Summary: This paper proposes a new evaluation framework for imbalanced data. The paper lacks a demonstration that your approach actually does give a more appropriate ordering of the machine learning approaches. I'm inclined to rejection of this paper.
However, the theoretical work in MINE is also very weak and only focuses on estimation consistency and not convergence rates (i.e. the statistical bias and variance of the estimator). Contributions i) Proposal of a novel regularized MINE objective for solving the drifting phenomenon. Summary The paper introduces a generalized version of the mutual information neural estimation (MINE), termed regularized MINE (ReMINE). Isn't this a good thing? In Section 3.1 the notation is technically incorrect. The experiments are somewhat supportive of including the regularization, especially when the MI is higher which is a known issue with some MI estimators. For example, does it exist in the density ratio estimator in logistic regression or in JS dual lower bound? For example, there is little to no discussion of why the synthetic dataset proposed is a good choice for studying the underlying properties of MINE.
First, in Table 3 some results (CycleGAN for MRI-CT and DA for PET-CT) of competing methods are worse than simply training on the CT images (PURE-CT in Table 2). Also, predicting age is a regression task, and not a discrimination task. The selection of hyper-parameters, experimental setups, and split of data into train/test using different approaches requires more explanation: a) It is not clear how the lambda values were selected.
This is certainly nice to see, but it makes a direct comparison to prior work (that is DP) difficult, and a little unfair. This paper addresses the problem of an unbalanced dataset and tries to equalize the accuracy for different classes (labels). DPSGD (Abadi et al. (2016)) uses the Gaussian mechanism and calculates privacy cost using differential privacy definition. Through experiments they show that their algorithm does indeed result in an improvement in fairness, according to a variety of fairness metrics. Is this a typo or can you clarify why you are adding noise in this way?
Training GCNs for large graphs is important for real-world applications. This paper addresses the problem of training GNNs in a distributed environment (e.g., with multiple machines communicated through a network). Did the authors reduce the training set, cut the graph to a smaller one (but keep the training set), sample multi-hop neighbors for each node in the training set, or do something else? It is not clear how this method work for deep GNNs. In table 2, for GS, why is the acc of distributed method better than that of a single machine?
The submission proposes a meta-learning algorithm attuned to the hierarchical structure of a dataset of tasks. (8) before the main algorithm (Algorithm 1) is introduced, and Algorithm 2 only refers to a generic "similarity metric" (as in the original work, [1]). The paper compared the results of TreeMAML with MAML and the Baseline on SinusRegression Task and Linear Regression Task. Strengths The authors investigate an important and under-considered problem in meta-learning: how to leverage structure within a task distribution. This paper proposed a learning algorithm of meta-learning: TreeMAML, to share information across tasks in meta-learning models.
The method is a three-stage process: (1) searching - this phase involves training full BERT with some coefficient parameters to learn the mask, (2) drawing - use the mask to "draw a ticket" or select the sub-network to train, (3) training. They demonstrate that the technique works for BERT-Base and BERT-Large for GLUE and SQUAD tasks. Pros The paper is well written and the presentation of the contribution is simple and well-motivated. So, perhaps this reduction in pre-training steps might not be applicable for larger pre-training datasets. The distance metric is still Hadamard like in EarlyBird? The graph indicates that for MNLI and QNLI 60% seems like a better choice. In order to reduce computation, the authors propose pruning the number of attention heads and neurons in the fully connected layers. Experiments show that performance isn't that much worse when EarlyBERT is used for fine-tuning and for pre-training. As a result, this paper has a great potential, and its results seem very promising. The work is well-thought through and authors do a good job of explaining their approach and other existing works using lottery tickets. Misc Nitpicks The phrase "structured sparsity' is used in multiple places, but never defined.
And the ensemble achieves the new state-of-the-art results in a few-shot setting, comparing to previous regular and ensemble approaches. The authors of [3] also used intermediate layers for better classification results. The presentation of state of the art results is incomplete. The results in mini-ImageNet and tiered-ImageNet are impressive. The find in Figure 2(a) is very interesting.
In particular: The paper shows for certain artificial target functions with low-dimensional structures, the neurons start out from a random-feature behavior and then a few are selectively activated, distinct from the rest of the neurons which are "suppressed". In Fig. 8 they look related, but it's difficult to tell how much. While some interesting observations can be made, I consider the presented results and gained knowledge as limited in scope and hence slightly tend to suggest to reject. (Shall quenching neurons have coefficients that converge to zero? This is a pure empirical paper and the phenomenon has no justification (even heuristic mathematical justification).
(2019). Phyre: A new benchmark for physical reasoning. [2] CausalWorld: A Robotic Manipulation Benchmark for Causal Structure and Transfer Learning, https://arxiv.org/abs/2010.04296 This paper is a review of model-based approaches of integrating causal inference to reinforcement learning (RL) in different environments (application areas). Post Rebuttal I would like to thank the authors for the detailed rebuttal. Specifically, it compares monolithic models with models with explicit structure: GNNs and modular models. I am therefore not sure whether *CONF* is the right venue for this paper. The authors provide software to analyse how three types of models ("monolithic", i.e. latent space models without a graph-like structure of the latent space, graph neural networks (GNN) and "modular", i.e. the C-SWM model (Kipf et al., 2020)) perform in two artificial "environments" devised by the authors (physics and chemistry) based on a number of metrics, some of them also proposed by the authors.
This paper proposes a method to detect adversarial examples. 2019. Summary: this paper is about adversarial detection based on counter-attack. "Adversarial examples are not easily detected: Bypassing ten detection methods." Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security.
Is this a contradiction to the main motivation of using a smoothed label for augmented data? [Cons] -- The problem of adjusting labels for augmented data is indeed of interest for the community. The label assignment is calculated by the distance between the clean data and the augmented data, and updated by performing a label smoothing based on the calibration performance over a hold-out-validation data set. For example RandAugment, and CTAugment.
Training with a large OOD dataset like [Hendrycks et al.] is not common, and the observation in this paper is limited to this setting. In fact, this was a question in my mind when I read Hendrycks et al last year. Conceptually, the approach in Hendrycks et al also seems more brittle and there are distinctions between these two methods (e.g. see Vernekar et al 2019, "Analysis of Confident-Classifiers for Out-of-distribution Detection"). I am inclined to agree with R1 on the quality of comparisons. My take is that at a high level the contribution of this paper is above the bar of *CONF*, but the experiments aren't controlled enough so I vote for a weak reject. While it is a smaller set in this paper, Hendrycks et al say "experiments in this paper often used around 1% of the images in the 80 Million Tiny Images dataset since we only briefly fine-tuned the models.". In short, I recommend authors to rewrite abstract/intro as suggested by R3, to properly emphasize their contribution. I look forward to hearing back from the authors and I'm open to changing my score. In NeurIPS, 2018. [Dhamija et al.] Reducing network agnostophobia. I believe that this is a direction worth exploring; however, I do feel that the authors could have provided some more insights into the following decisions: What are the desired characteristics of the OOD dataset used to augment the training set?
I would have expected to see the following analysis: A)    Auxiliary states vs. history-dependent (non-Markovian) neuralODE B)    Auxiliary states vs. additional parameters of neuralODE This is due to the following reasons: A) In prior work, a similar approach has been employed in various prior works to model hidden confounders, e.g. [Nodelman, U., Shelton, C. R., & Koller, D. (2012). Expectation-Maximization and Complex Duration Distributions for Continuous-Time Bayesian Networks.
This paper studies the variance of stochastic gradient in SGD conditioned on the initialization point. For a deep linear model, the result shows that the variance of gradient is a polynomial in 1/b with no constant term. In addition to that, the authors conduct a lot of experiments involving non-linear networks and real-world datasets, that show the inverse dependence of the variance of gradient and batch size throughout the training. My own conclusion is that deriving general results on generalization from MNIST is a perilous exercice, if not plain wrong. The authors try to open up to the problem of generalisation but fail to a proper theoretical link with their own work, while their experimental results are obtained only on MNIST and therefor subject to caution (and in fact contradict previous work).
In addition, a masked label prediction strategy is proposed to reduce the negative influence of the label leakage problem. Cons: The insight/motivation of this method is not very significant. Pros: This paper proposed a novel framework to more effectively and explicitly utilize the label information by GNN in semi-supervised scenario, and the experiments illustrate its effectiveness in general benchmark datasets. Minor comments: Abstract: we adopt a Graph Transformer jointly [using] label embedding? The authors proposed a unified message passing model to make a graph neural network to be able to incorporate both label propagation and feature propagation. Section 4.3: instead of itself feature → instead of it's features The paper is very well written and is easy to understand. The writing of this paper is poor. To me the residual connection is helpful when stacking many layers (Li et al., 2019; Chen et al., 2020), while in this paper the number of layers is relatively low. However, no ablation studies are provided to demonstrate the impact of these two independent components.
Although the authors claimed that CNV-Net is the first tool to use a CNN to detect CNVs, this is not true. Compared to the experiments conducted in the previous works, the experiments of the proposed work seem limited, unrealistic, and biased in favor of the proposed method.
The idea is to form local graph for each node using PPR-Nibble, a local clustering method proposed before, and then use transformer on top of the local graph as encoder for node classification and link prediction. What is the time complexity of this method? The other weakness of this paper is their experimental results are insufficient to verify the proposed method outperforms the sampling-base method. In this works => In this work The reason for this should be given. This method might be even slower than GCN itself. This contradicts to both [1] and [2]. Without this study, it is hard to tell what is the novelty of this paper and whether the local clustering is useful.
For disentanglement specifically you can also use existing benchmarks and datasets from Locatello et al. (2018). Minor: Definition of generative maps fG(i):Z−>M[...]iA (Section 3.1): I believe A was not defined before, is that just the number of generators? Is this an optimization problem? Along this direction, the tangent and normal of a are with respect U.
Autoregressive critic of FSAC is the same as that in Metz et al. (2017) (also stated in the paper I believe). The word action is frequently used instead of action dimension and sub-action. Exploring and understanding factored action spaces is important, and the paper presents a reasonable step in this direction, and will therefore provide a foundation for further work. Questions What is the impact of the action ordering for the autoregressive factorization? (b) PPO and SCA adaptations for IF + AF; and Also, the paper does not set a clear agenda for what would be interesting to see in the results; Is scalability to large action spaces being investigated (in which case, comparison with the non-factored baselines of PPO and SAC should be included)? It is stated that there is no inter-correlation between action components for the MuJoCo benefits. Hybrid Reward Architecture for Reinforcement Learning The number of discrete sub-actions("m") for the policy is treated as a hyper-parameter.
To me, this modification on differential privacy is very big, but it is not well discussed in the paper. And this shows that it might be very easy to design deterministic algorithms under this new privacy notion. This is what happens in the paper, and without a good justification for that, I don't see why such a loss of privacy is okay. In particular the privacy guarantees are clearly stated, and their difference to pure DP highlighted. The paper proposes taking a coordinate-wise median among the reported local sign-vectors and gives its theoretical guarantees.
A recent paper (Lakshminarayanan and Singh, NeurIPS 2020) provided a new perspective on Neural Tangent Kernels for Gated Neural Networks, by decomposing the network into independent paths. Specially,  this paper shows that architectural choices such as convolutional layers with pooling, skip connections, make deep learning a composite kernel learning method, where the kernel is a (architecture dependent) composition of base kernels. Is it correct to interpret the result as follows? As we allow the width go to infinity this relationship tends to one of equality (up to a constant multiple). This interestingly indicates that  standard deep networks have in-built structural properties that may explain their success before training them. Then, the output of the neural network can be viewed as a weighted sum of active paths, equivalently the dot product of the neural path feature vector and a neural path value vector. It also presents experimental result on MNIST and CIFAR for four proposes regimes of (Definition 5.1) that models are robust to combinatorial variations in layers and inputs.
Compared to mixup and cutmix, the improvement reported in Table 2 is marginal. In this work, authors provide an analysis of mutual information for MSDA and the develop a new variant of mixup. Aside from that mixup is hard to say "adversarial training" (what is the threat model in this scenario?), I feel that this result is irrelevant to FMix motivation.
Pros: MLP fed with node features and spectral coordinates of a given node is competitive with a GCN and more efficient than GCN.
To my understanding, this work addresses specifically the model proposed for TensorFlow quantum, and this should probably be made more explicit, as it's somehow different from current literature, where quantum neural network architectures are the sole computational node, and no classical computation is performed classically (besides the optimization of the parameters of the variational circuit). Using a technique best on Taylor polynomial approximations, the paper finds that a large class of smooth functions can be approximated using O(log(1/\\epsilon)^(n/d)) quantum gates, qubits,  and classical width.
In permutation decoding, one aims to decode a permutation of the received codeword in the hope that it will lead to successful decoding as compared to applying the decoding algorithm on the received codeword. Is there not any other, more advanced, methods for selecting at least a subset of permutations? Only BCH codes were used for evaluation. However, except for some intuitive reasons it is not clear that the approach would have practical merit. I mention this because the performance degradation, for all ablations, looks quite large and pernicious, but it is difficult to assess their impact without a proper comparison. For example, Fig. 3 (a) contains the BP lower bound and ML bound. page 2: "a self-attention model (introduced in Section 2)" should be "a self-attention model (described in Section 2)". Still, there is no doubt it actually works, and the performance is significantly outperformed. ######## Post rebuttal ############## Thank you for your response. We usually consider the top 1 performance only for this kind of application which generally requires a very low level of error rates. If not, perhaps please comment on the selection of permutations done in approaches like BPL, and how that selection criterion won't be applicable here. Unfortunately, it seems that the experiments were run on a very limited set of codes. Decision, and key reasons Accept, after discussing and further elaborating some of the previous concerns. Although you clearly explain this in the following sentence, I would rephrase that sentence. How is the same node embedding v being used for all i in wi=ui+v? Thanks to the possibility of freely generating training samples on these schemes, it is possible to achieve very satisfactory training for permutation embedding and classification. [Main Strengths] This paper's main strength is that the background section is well-drafted, the problem statement is clear, and each algorithm block's motive is adequately referenced.
To name a few, (1) As the authors write themselves, the approximation in eq (13) is crude. Can HDGE be used in isolation for generative modeling tasks? The second reason for my rejection of the paper is the paper requires an effort to make it self-contained, especially for the experimental section. This yields a simple objective to optimize. Formatting error in figure 4 in appendix
Summary In this paper, the authors propose a novel approach for quantifying the statistical significance of binary masks predicted by a subclass of deep neural network (DNN) models for image segmentation problems. Other, related aspects are (i) which type of supervision the models require for pre-training and (ii) which type of output layers are required in order for the null hypothesis to be relevant. Given the change in architecture reported in the supplementary material, I could guess that in this case only tumor/no tumor labels were provided, but this is neither stated nor, as far as I could see, shown in the code provided. I would recommend having the submission proof-read for English style and grammar issues.
I think in any case such details need to be included in the paper, to be clearer that the transferability quantified is in the scope of a particular instantiation of a specific algorithm. The conclusions of this submission are unclear and questionable. It is also not explained how the environments are chosen. The only novelty is about using which states as adversarially perturbed input. Review Summary: The idea of analyzing perturbations' transferability is interesting, but it is hard to say that the approaches are satisfactory. Besides, all experiments are done only on DDQN, hence the claims are hardly validated. The results show "a single perturbation from a random state of a completely different MDP" is not normally distributed.
This is called complementary label learning. The research agenda of the paper looks reasonable, even if it can be seen as a very specific instance of partial label learning (where one just considers the complement of the complementary label and tries to learn from it). Though conditions (10)/(20) are insightful for determining robustness, for a reader who is encountering them for the first time, it may help to intuitively explain the conditions. The improvement in performance over GA/PC/Fwd is impressive in table1. Comments: The paper addresses an important problem but it is written in a hurry which makes it hard to assess its contribution. The goal is to predict a correct label for a given sample when only given complementary labels.
Strength : I believe the paper is well written and easy to follow. This paper proposes an approach that adaptively decides when to update the simulation policy, based on the difference between it and the current learned policy. However, I think this is ok since the paper is application-focused. Motivation of the paper: This paper studies an interesting question that is rarely studied in practice.
Informally, this means that the magnitude of the dot-product between the learned pattern detectors and their detected patterns is correlated with the distribution of the patterns in the data. This paper didn't prove PSI holds for SGD except in a toy example (two training points). It seems very unlikely that this has not been observed before (at least empirically). In this manuscript the authors derive theoretical analysis for the generalization guarantees of a naïve CNN (3-layers) where the task is a simplified binary classification task, under the assumption that the images contain orthogonal patches (a naïve assumption). We formally define this as the "Pattern Statistics Inductive Bias" condition (PSI) and provide empirical evidence that PSI holds across a large number of instances.
Pros: The choice of learning rates in MARL is an interesting and important issue. Specifically, the learning rates are updated to directions maximally affecting the Q-function, and the algorithm dynamically balances the learning rates between actor and critic. The improvement in AdaMa is incremental. However, the proposed method is not convincing in terms of the lack of larger-scale experiments or theoretical results. The authors should evaluate the performance of AdaMa in more practical models in addition to these four toy examples.
This development is also motivated by two practical desiderata of federated learning: (a) a good trade-off between communication load (per iteration) and no. This paper proposes distributed SVGD, which maintains N particles both on the server and on the client. The paper is in general well-written and easy to follow. PAPER SUMMARY This paper introduces a new approach to probabilistic federated learning, which builds on the previous PVI work of (Bui, 2018). I do see some analysis in the appendix, but I think some results are better to be present in the main text.
I only list them as evidence to disprove the conclusion's assertion that "this paper is the first study showing that effective opponent modelling can be achieved without access to opponent observations (at execution time)", as that is definitely untrue. 1) an A2C implementation that observes last_reward and last_timestep to see if NOM (or LIOM (Act,Rew)) improves, or Issues and Suggestions Experiments section. The description of the three games left me with quite a few questions (what exactly is observed by the players? I'm still in favour of accepting the paper. I found it easy to read. During training, a VAE is trained to encode the agent's observed trajectory to a latent space, and then decode it back to the full trajectory (including opponent observations and actions). Possibly! I know Speaker-Listener is a standard game, but I'd be curious to see results with either Initial random placement? I'm trying to get some idea of the magnitudes of the rewards, which are based on Euclidean distance. The problem is significant and the approach is a natural fit. However, of the 3 environments described in this work, 2 are purely cooperative (Speaker-Listener, Double Speaker-Listener) and the third is a mixed setting involving cooperation and greedy behavior. Is the Speaker assigned a color?
One can construct a neural network architecture that is identical to an adapter network during testing time. In this work this is restricted to tasks which share the same state and action space. Although the idea of FLAP is simple, the strong experimental results have demonstrated that by predicting weights rather than optimizing, FLAP is a fast and effective meta-RL algorithm for adaptation to OOD tasks compared to previous approaches that did not focus on this area. In the current manuscript, it is clearer that the "adapter network" predicting the "final linear layer" of the network is a unique component in this paper. I couldn't find any discussion about this observation or empirical study for clarifying why the proposed method is good for generalization. In Paragraph 2, Section 2: For ϕk and πl, k and l are the number of trajectories, which are inappropriate to denote ϕ and π, considering replacing it with the denotation of the trajectories. For example, it would appear that the adapter network should not work on sparse rewards tasks (where the transition function is unchanged between tasks) or other situations where most experience tuples do not provide information regarding the specific task.
The authors talk in the introduction about "recently proposed robustness curves" and cite a paper from 2020 for them, but it seems like those curves were already in use before that. The author argues that robustness for a specific epsilon may not be enough and suggests robustness curves as an alternative. The author introduced a better criterion for this important question. is also quite interesting and really drives the point that the authors want to make. is great and provides a great explanation of the problem that the authors identify. For example, the results the authors give in their Table 1. While I agree that you are going to get more information if you compute a full robustness curve than if you sample it at a bunch of points, I'm not convinced that it is worth the effort. It will be very helpful for the researchers to the advantages of this curve over point-wise measures. This would be a much cheaper solution (and is essentially what reporting experimental results for a few chosen eps achieves).
And the authors explain the relatedness of the representation function and topics in a document. It proves that the proposed procedure can recover a representation of documents that reveals their underlying topic posterior information in case of linear models. In topic modeling, this assumption is usually justified in that the resulting topics turn out to be interpretable. The training task is try to predict where two half of a document are from the same document. Write that the Bayesian theorem is applied in the last equality and that the label y=0 makes the document parts independent. The main strength of this paper is suggesting a sound and straightforward learning algorithm to construct document representation. Word2vec is not developed for the purpose of document classification, online VB does not have classification performance as a strong point and bare BOW is surely not suitable as a realistic baseline. The model allows to recover the topic structure of a corpus that is generated from a generative topic model. In the beginning you say your approach is to use landmarks and the Direct variant is rather suddenly introduced in a later part without discussing the differences and implications in much detail.
For example (Kim et al. 2020)? Issues: Section 3.2: "To be a useful feature for Rpost, latent vectors should be arranged in a similar way to p(y), which possesses information about how the labeled dataset is skewed." - p(y) is a distribution of labels right? The proposed model that combines an AAE that generates the output distribution, and an adversarial model that enforces the distribution of the predicted output to resemble the true distribution of the output. Some of my concerns are addressed. ########################################################################## Questions during rebuttal period: Please address and clarify the cons above. I do not understand this. These two claims seem contradictory to me. I think a rating of 6 is fair for this version of the paper and I thank the authors for their efforts in updating the work and addressing my concerns directly and efficiently. In practice, it's more likely that values within certain ranges were over (or under) sampled, leading to mismatch between the empirical target distribution and the true target distribution. First, the input x was mapped to its latent space through encoder R_enc. The most important concern being eased was the type of bias was too constrained at first and now there are experiments with a more unconstrained version of bias that is more convincing.
ii) Graph Neural Networks with Generated Parameters for Relation Extraction, In ACL'19 The authors propose a method for simultaneously learning the graph structure (or a graph generative model) and the parameters of a GNN for node classification. Overall, the paper is well written and easy to follow. The basic idea of self-training is to add high-confident predictions to the training set to increase supervision. [Soundness] It is unclear why datasets from domains discussed in the introduction section were not considered in the experiments. In this case, creating the kNN graph is a discrete operation and it is not clear to me how to differentiate through such an operation. This is a topic of recent interest and highly relevant to the *CONF* community.
The paper proposed (1) to use a graph neural net to predict the performance of network architectures, (2) to query new architecture proposals to try next from the predictor, and (3) to iteratively refine the predictor using the collected dataset using gradient descent. This should nicely demonstrate where your main technical point is. -Second,  this method can work well for small models and small search spaces, but can be hardly applied to larger models.
The paper provides experimental evidence that the proposed method outperforms other subset selection baselines, such as Learning to Select (LTS) and random selection (RS). For the Set Classification/Prediction task, I would suggest clarifying that for this task a set typically contains the features of a single example, so D=x. I'm assuming that the blue vertical vector is supposed to represent Dc. Is that correct? Some examples: The context for the mathematical expression in (4) is very unclear.
Summary The paper studies a certain notion of spectral sparsification of directed graphs. Authors propose a novel method to approximate a given directed graph with a´nother one (the sparsifier) which has fewer edges. Cons: It is not clear what ML task the paper is trying to solve or improve upon, and what improvement is achieved. This paper considers the problem of sparsifying directed graphs, a timely task of importance in many applications.
This paper proposes a training method for classification, with the goal of training with less data. The auxiliary classifier is designed to encourage the early layers to learn more meaningful features, and Section 3 supports this relation. This submission proposes a training strategy that leverages background/noise data to learn robust representations. This is not true. What about NCE and all the follow up work? Table 8 includes reduced-training-set experiments on CIFAR, however 3/5 of the training set is still way too big, and the remaining 2/5 are not utilized as unlabeled in-domain data. Minor points: -- Figure 3 is not a fair comparison. A critical point, that is missing from this paper, is how would this data augmentation work by itself without the auxiliary classifier.
Also, as a very minor comment, I believe that, strictly speaking, the gradient (with respect to Δ) of the loss in these equations should be computed at ϕω0(ti−1) because otherwise the right-hand side of these equations would be dependent on Δ(ti). I think the idea is interesting. However, it is hard to find a theoretical and experimental basis for high-quality solutions. [-] Minor commentsThe image quality in Figure 1 is poor, so it is difficult to identify text even if it is enlarged.
The paper uses a contrastive representation learning paradigm to learn a feature encoder and a similarity measurement. This will make readers feel like the idea of Equation 5 and Equation 6 is original in this paper. This paper considers the problem of semi-supervised learning, where the unlabeled data may include out-of-class samples. The paper is well-written and the claims are clearly clarified. If a sample belongs to an unknown class it is not clear why this would help SSL. Quality: This paper is well written and well organized. The threshold hyper-parameter is the key to filtering out-class samples. Again, this is not a compelling argument. In ECCV, 2020. https://arxiv.org/pdf/2008.11203.pdf Significance: Given that some parts of this paper are highly similar to [a], the significance of this paper is downplayed. The loss function that integrates out-of-class samples is counter intuitive and seems to be chosen based on improved empirical evidence.
The main strength of this paper is to extend the work of Cai et al. (2019) beyond the Linear MDP setting to one with a kernelized transition matrix.
The authors identify the consensus distance as the key factor that affects the generalization performance of decentralized training. There are a couple of issues that need to be addressed. The conducted experiments are extensive and the delivered message is pretty clear -- Critical consensus distance exists in the initial training phase and ensures good optimization and generalization, while a non-negligible consensus distance at middle phases can improve generalization over centralized training. (especially in this case a warm-up scheme was used). In particular, standard implementations of all_reduce only require that each node communicate 2 copies of the parameters per iteration. Although there is a connection between rates and generalization, one is not equivalent to the other. Additional references mentioned: Gupta, Serrano, DeCoste, "Stochastic weight averaging in parallel: Large-batch training that generalizes well," *CONF* 2020 and arxiv:2001.02312 Is it possible that in the centralized setting, ResNet-20 is overfitting, and the error from decentralized SGD has a regularizing effect, leading to better generalization? Is there a cite for Lemma 4?,  there seems to be studied in the literature before. In general, the paper is well written and there are several interesting observations and discoveries involved regarding the generalization performance of decentralized learning.
The Unsupervised Learning of Transformation Equivariant 2D Representations by Autoencoding Variational Transformations is used for 3D shape descriptor learning, which the authors claimed as "self-supervised" learning. The views are sampled in a regular spacing and not randomly. The formulation is intuitive, the manuscript is well written and easy to follow. While my main complaint is that the idea of this work is very simple and even can be called as common sense, and I have encountered this idea in many other papers, though in different fields, such as human pose estimation and 6d object pose estimation. The authors need to prove the properties for Transformation Equivariant directly for 3D objects. Maybe it would be more adequate to change it to 3D rotations everywhere or demonstrate at least one additional type of transformation. The current presentation of the paper is based on the 2D project image representation for 3D objects. Areas for improvement: -Firstly, the representation of the transformation that the author used in the paper is not well specified. If the authors wish to use Transformation Equivariant  in [1][2] above, the authors might want to consider adding additional 2D to the 3D reconstruction process, and  then consider the order of doing transformation and doing reconstruction etc.)
More specifically: (1) The proposed model is a fairly straightforward application of self-attention to text, which has been similarly used (albeit with BiLSTMs) in Zhong et al 2020. The manual describes the roles and the behaviors of the entities in the environment. I read several recent papers in the natural language grounding field but still puzzled about the term (for example, the semantic meaning of "entity" in  [2] is different from this paper). Why is G-ID baseline performing so poorly on validation and test data? The game is described in Figure 1 and section 5.1: there are three entities to each game (messenger, enemy, goal), and each entity can be stationary, chasing, or fleeing movement. This is the main focus of the model — to learn a mapping between entities and their descriptions.
The effectiveness of the proposed metric is mainly verified in two NAS benchmarks (NAS-Bench-101 and NAS-Bench-201), whose correlation to the actual accuracy is relatively significant (Fig 3). One possible way to make this work stronger and meet the acceptance criteria is to provide some empirical (or even better, theoretical) analysis of the influence of Σ on the flexibility and invariance of a network. For example, NASWOT deteriorates in performance on Imagenet which has more diverse images. β is a hyper parameter. If I understand correctly, the architecture is searched on CIFAR-10, and then evaluated on all three datasets.
(1), personalized model is a convex combination of two models. In Section 2.1, for any agent i, and for a mixing weight αi, hloc,i∗ is defined as (I suppressed the hat notation over hloc,i∗ and calligraphic font due to some compilation error here). That is what I meant by a "single global model with good performance (i.e. trained on the full dataset)". There, the goal is to solve two minimization problems w∗=argminw∈Rd1n∑i=1nfi(w),vi∗=argminv∈Rdfi(αiv+(1−αi)w∗), In this paper, the authors propose a variant of FedAvg that not only produce the global training, but also a mixture of the local model and the global model, which is called personalized model. Finally, numerical experiments and comparison with other methods in the literature are provided to support the theoretical results.
Which ideas are used from related work and what is new to this work? Summary: This paper presents a method to train a neural network to predict the time-dependent costs, and start and goal states needed to run time-dependent shortest-path planning in a dynamic 2-D environment. EVALUATION The evaluation seems one of the weak points of this work. The authors study this architecture in the context of imitation learning from a small number of expert demonstrations. While planning, in general, is an important problem and differentiable planners are an important research topic, the motivation of this work is not clear. Overall, I think this is a very solid work, and I recommend acceptance. How does this approach compare to the recent work of [2]?
(3) adds each edge in a greedy way, which may result in a suboptimal graph. The proposed method now only considers the edge importance while other comparing methods consider the importance of edges, nodes, and features. This type of "causal" explanation is considerably more feasible for and better fits graph networks thanks to their sparse and modularized structure. What is an interpretation of a z representation of a node? Summary: The paper introduces a novel method called Causal screening which takes a graph and the prediction made by a GNN, and returns an explanatory subgraph. 4 in practical applications. I can imagine that the value can be quite small, and probably some threshold is needed. I guess that it is interesting to study individual impact of edges on the clusters. I also agree that causal attributions of edges of edges are more reliable than information from gradients, often used to explain models. All in all, if the paper is improved on clarity during the revision period, I would lean towards acceptance. The difference in faithfulness (accuracy) compared to prior works on explaining graph predictions is clear and significant.
Some comments: The paper gives a good discussion of existing works and where the paper lies in the line; it would be better if the authors can briefly discuss meta-RL which is close to the problem being studied in this paper However it is hard to understand what does Assumption 1 imply -- Is it a strong or weak assumption? A lot of effort is spent on setting up Theorem 1 in a completely detached way, and then it's actual relevance to the problem at hand is summarized in a hand-wavy corollary. This will make it easy to follow the multiple terminologies of tasks, entities, resources, introduced in Sec 3. Lets say t = 2 and resulting action is [0.2, 0.8] Strengths: Using RL to solve sequential resource allocation problems is interesting and well-motivated, it can promote the impact of RL approaches when deployed This is however already clearly pointed out in the paper and placed as future work, so this is somewhat fine to me. Explain the solution and how it exploits the structure of the problem. An reinforcement learning algorithm to learn a permutation invariant policy is derived. In this case it seems the set is the output of policy network. I dont understand this. By the defintion do you mean: pi(sigma(a), sigma(x)) = pi(a,x). Also it seems that the symbol pi switches semantics a few times - first, it denotes a deterministic policy, then a stochastic policy, and finally a policy network.
Thanks for author(s) for their paper. Similar to Direct Feedback Alignment (DFA), the aim of this work is to introduce a viable alternative to back-propagation (BP) that works in parallel while achieving similar performance. Despite the fact that KP does not make any assumptions about the structure and inductive biases of the network, DKP is proposed only for CNNs and image base classifications. Figure 2: Value of λ is missing.
The authors then propose a relaxed definition of disentanglement and show that it can be realized by means of a shift operator in latent space. This paper studies the notion of disentanglement in a group representation theoretic setting. This analysis culminates in a general impossibility theorem for this type of disentanglement. In addition, the model doesn't appear to be very flexible as it requires that the transformation is known in advance. The key weakness is that their new formulation of disentanglement is that it is definitional does not give a plan of how this should be done.
The authors present conditions that need to be satisfied by the encoder and decoder parameters, and show empirically that the regularization terms that they propose ensure that the resulting autoencoder has an isometric decoder. "As-usual " => As usual p. Maybe I am missing something, but would it be impossible to generate, say, a 50 dimensional manifold in 100 dimensions? Table 1 should be Figure 1. How can we practically make use of the isometry property in applications other than data visualization? However, there's no discussion about the "diffeomorphism" in the following sections. Or "AE's are designed to reconstruct..." or "An AE reconstructs..." Through a series of experiments and visualization, the IAE exhibits better manifold structure. Distances between points on a data manifold are not usually measured through L2 distances in a latent dimension, and it is not clear why one should require that L2 distances in the high dimensional space are the same as distances in the latent space. This comparison would be useful to have to compare the usefulness of the embeddings. The order of Figure 3 and Figure 2 is messed up.
The mathematical motivation of this paper is missing and this causes the impression of untrustedness on the model design. Please compare it with a few Trojan attack methods in recent years. To impede backdoor attacks, many models are marked as outliers and discarded, clipped, and noised, generally speaking, which could lead to performance degradation. The work being proposed in this manuscript is simple and straightforward to implement. This paper suggests a new solution to protect FL models from backdoor attacks. The topic of simultaneously defending against the backdoor and the inference attacks is significant. In particular, the adversary wants the final model to make an incorrect prediction for certain inputs. In FL, clients locally train model updates using private data and provide these to a central aggregator. The experiments have multiple aspects presented and show promising results in various metrics. The cosine distance calculation between W_i and W_j is conducted of every pair of the models. Especially, only one paper from 1986 is mentioned and nothing especially has been proposed in this work. Some study is encouraged to discover such choice. minor: please attach your main context pdf in the submission and submit the appendix in the supplementary material The paper proposes a backdoor-resilient federated learning method to defend the backdoor attack of poisoning the models.
(i) interpreting that the mathematical formulation of SDEs is directly comparable to the ML formulation of GANs, I still like the paper, that could be accepted in my opinion, but I think it oversells some contributions that are unfortunately not exploited (the brownian interval thing in particular, or am I wrong ?) You are mentioning X and H as the (strong) solutions to your SDEs (1) and (2).
It seems like the authors combine existing ideas (hierarchical and neural NMF, NCPD) into a new method. It is not clear why the definition in Equation (9) is chosen. It would therefore be of value to answer 1) how the experiments would scale to higher dimensions (for instance for images of the forest time laps) and 2) how the suggested approach would work on a multi-modal database. It also proposes a training method that leverages forward and backward propagation. Here, the true structure of chromatic interaction is hidden and we cannot observe it. It also does a good job of connecting to applications. In what sense is (Wi)p1,p2 approximating it? It looks like it should based on the derivation in the appendix. So the technical contribution of this paper is summarized to the development of neural NCPD, but it is a direct extension of Gao et al. (2019). Is it the expression in the Frobenius norm in the paragraph titled "Hierarchical NMF (HNMF)" above? (eds) Independent Component Analysis and Signal Separation. In particular, in the discussion on approximation in Section 2.1, it is not clear if this idea is used in the implementation, which might make it difficult to replicate the results.
I would be happy to increase my score (and confidence) in this case. In this case, Theorem 3 states that any function f1(x) can be extended to be equivariant via fj(x)=f1(g⋅x), where g is a permutation such that g(j)=1. I recommend a significant revision of the paper to make it more readable. Proving a result of this generality is technically very challenging. Although I am not a professional mathematician, I know that there are many pitfalls when proving results like the one in this paper. I think some examples and explanation should be provided. If this is all required for universality proof this would be a great simplification over previous proofs. Understanding their approximation power is crucial. Nevertheless I still think the paper makes a nice contribution, so I will keep my rating. This also relates to the question I asked above about the condition in Theorem 11. What can be said about the equivariant tensor models and graph neural networks using the universality result in this paper? Weak points: The paper is written badly and is very hard to follow. Since FNNs are known to be universal this implies universality of CNNs. I think the general CNN formulation and the Conversion theorem are of merit but i think the paper should undergo a rather serious revision before ready for publication.
I also find it a bit uncomfortable penalizing the authors for not running experiments on ImageNet, and I think the variety in architectures that the authors tried, compensates for this. Summary: This paper presents a novel weight decay regularization, stable weight decay by using the bias correction to the decoupled weight decay in adaptive gradient descent optimizer. Moreover, a couple of statements can be arrived at by directly observing existing algorithms, which are not that technical. ============= Update avec rebutal and discussion with AC and reviewers. Additionally, I am a little confused about the statement that the effect of weight decay can be interpreted as flattening the loss landscape of θ by a factor of (1−ηλ) per iteration and increase the learning rate by a factor of (1−ηλ)−2 per iteration. In particular, there is no theoretical justification that this is the case. When applied to Adam, the authors derive AdamS, supposed to work better than the previous AdamW, which already improved how weight decay and Adam interact. In fact only CIFAR-10 is evaluated with multiple learning rates. Without knowing what "stable" meant, I had a hard time taking the introduction seriously, because I didn't know what "unstable" meant exactly, and that the decoupled weight decay method was "unstable". Experimental results based on benchmark dataset show that the proposed scheme outperform the popular and advanced optimizers in generalization. There is no need to give Definition 1 formally for Stable Weight Decay as that doesn't sound like a definition. The Pytorch documentation calls 1-beta_3 dampening and its default value is zero. In the draft, the authors can directly say constant or time-varying weight decay. Weaknesses: My main complaint is that this paper is poorly written. However, one major issue in my mind is that conclusions are only supported by the empirical results, which though look promising. Why is replacing <\\theta_{t-1}> by <\\theta> justified? Comments and questions: I think the concept of weight decay rate and total weight decay should be explained better, and earlier in the paper. A minor point, in Eq 3, how did the authors arrive at −2t−1 in the superscript of weight decay rate, not −2t+1? After reading the rebuttal and considering carefully, I think the authors' response addressed some of issues in my mind so I raised the score. I increased my score to a 6 because I think the paper in its current form is enough to get accepted, but there are still improvements that could be done to make it much stronger.
This paper provide a method for high-order structure prediction problem. It is important to distinguish between the settings for which the proposed method and the existing work are designed for. For instance, given that authors A, B and C have a paper together, task of inferring authors A, B, C having another paper with a fourth author D is an example of higher-order relationship. For strengths, first, the kernel estimator based method does not require learning process and shows good efficiency in the prediction tasks.
The close correspondence shown between the accuracy in classification tasks and the entanglement entropy of the models (Figure 3) is interesting, and hints at the possibility of a compelling link between theoretical quantum many-body physics and practical considerations in ML. However, there are several things that are not clear.
I think this is standard for such papers. However, from the description and examples in this paper, I have a little doubt for this improvement: For creating the aligned corpus, the authors say that they chose only short expressions, namely 1-6 words. The second sentence is confusing to me, and I am a native English speaker. That being said, I strongly agree with the authors that neural machine translation of African low-resourced language is important.
A mixture of unimodal distributions (such as a GMM) is multi-modal. Cons: The description of the proposed mechanism is inconsistent with existing literature and is very unclear and confusing in parts. This paper proposes a monotonic attention to improve the latency of decoding. The effectiveness of the proposed method was validated by 1) artificially created long utterances, 2) Librispeech (segmented and concatenated utterances), and 3) machine translation. Detailed comments: In the introduction, "The GMM attention is a pure location-aware algorithm in which the model selects attention windows cumulatively without considering source contents.": This is a little bit hard to understand. Why is this necessary? It seems to impair the training of some heads, at least for SAGMM-tr according to paragraph 4 of Sec. 4.2
E.g. from 75.3 (SwAV) to 75.5 (proposed method) on linear classification on ResNet using features learned in unsupervised way; 82.6 (SwAV) to 82.8 (proposed method) in transfer learning on VOC object chanllenge. And the contribution of this paper is applying CutMix in the context of contrastive learning, which is yet another augmentation among a huge variety of possibilities. - both k-means clustering and knn neighbors are computed, and then for a given anchor image x, and images x' that fall within the same cluster and are a knn neighbor (and additionally closer to the cluster center than From appendix C, is it clear there is a big difference in accuracy from 200 to 800 or more epochs. Recommendation My initial recommendation is leaning towards reject. Weaknesss: The proposed improvements show rather limited improvement over state-of-the-art. "Contrastive learning targets at learning an encoder that is able to map positive pairs to similar representations while push away those negative samples in the embedding space." does not sound right, especially usage of word "those", rephrase. A large number of recently proposed unsupervised representation learning approaches was included in the comparison. Improved regularization of convolutional neural networks with cutout, 2017.[MixUp] Mixup: Beyond empirical risk minimization, Zhang et al., 2017.[Attentive CutMix]  Attentive CutMix: An Enhanced Data AugmentationApproach for Deep Learning Based ImageClassification, Walawalkar et al., 2020.[FixRes] Fixing the train-test resolution discrepancy, Touvron et al., NeurIPS 2019. Pros The paper proposes a simple, yet effective, data augmentation method that seems to help learning stronger representations for some tasks. This is an overstatement. It sounds, like there's a serious problem with previous contrastive representation learning approaches and the proposed methods solves them. I missed a more theoretical and extensive explanation about this point, which is basically the core idea of the proposed approach.
The main hesitation with this paper is the novelty of the proposed method. This paper proposes a joint learning framework for GNN classification model and graph topology, which leverages variational EM as a learning framework. A minor concern is about the motivation of this paper. Summary: The authors present a method for tackling the problem of over-smoothing in graph convolutional networks. The paper is well-organised and written in a logical way. This includes empirical comparisons to a wide array of existing competing methods. From the paper and the appendix, this point seems not discussed in detail. Can your method be extended to this case?
It is argued that by replacing a dense layer with a truncated butterfly network and a dense layer, the number of parameters is reduced from kn to kℓ+O(nlog⁡ℓ). And in the experiments, it seems that all the n are powers of 2 (except Tech). I think that low matrix approximation experimentation (Sec 7) can be more thorough. Why are only three datasets (in Table 3) used?
Summary The authors propose LIME: a pretraining strategy for learning inductive biases for mathematical reasoning. Case: Bag(o) (These beans are from this bag) And it is surprising that pretraining on these simple tasks can work.
Cons of paper I am not convinced that the minibatching that the authors suggest (both for SI as an approximation to the AF and for EWC in the last paragraph of Section 5) is correct ("Batch-EF"). In International Conference on Artificial Intelligence and Statistics, AISTATS 2020 Since I could not see other utility in this paper, I recommend rejection. Should we try and approximate the Fisher matrix in more ways in CL? So their ω(MAS) is different from yours. Unifying these regularisation methods is great, and not obvious (particularly in the case of SI). Also, I want to emphasize that association is not causation. Therefore, I argue that it is more meaningful to investigate which condition/assumption makes a certain algorithm optimal, rather than framing all algorithms into one unified framework. The paper is well-organized and easy to follow. The paper is written well, with good detail and very good experiments. However, I could not find any description of why the applicability is restricted and to what extent it is applicable. If your empirical analysis and conclusion that it is the bias that explains SI's performance still holds with SG (without Adam), then the argument is straightforward. Although I disagree with some of these, I agree with others: Some claims are overstated in the paper. ** POST DISCUSSION UPDATE ** [1] Le Roux, N., Manzagol, P. The only similarity that I find between the Absolute Fisher and the original Fisher is that they can be computed with the gradient. 4 is not discussed later in the text, or in other words, if ω~(SI) is similar to ω(EWC), what about ω(SI)? I think the best regularization method varies depending on the specific model architecture and task design. Review summary I really like the majority of this paper. Also, the overall logic of this paper is too weak. Given that the relationship between AF and F has now been addressed, I will increase my score.
The result is improved on multiple unsupervised machine translation, and this paper claims that more diversity is brought to the synthetic data, so a better translation model can be trained. I suggest that the author should use (y_s, x_t) data to train based on the (ott et al., 2018) model, and report the effect comparison (In my experiments, the second stage model implemented with fairseq trained only on (y_s, x_t) surpass both agents trained with XLM due to more efficient implementation in fairseq). Typo: p.3 5.2.In Appendix -> 5.2. Recommendation: Overall, this is a good paper and I would recommend acceptance. What does this "x-y" mean? These are more practical conditions for unsupervised MT in true low resource languages. This paper describes a method to enhance unsupervised machine translation through data augmentation. This simple idea is explored extremely thoroughly. The paper reads more like a journal paper that has undergone several stages of review than a conference paper. It would be greatly strengthened by a full-data experiment for even just one or two of the language pairs. The proposed method is quite simple yet effective, but it is also a kind of data enhancement. Also clarify the Bleu scripts, tokenization and other post-processing used for evaluation.
The effective learning rate is not easy to control. Or is it a setting that is not supported by the assumptions in Thm. 2? The AdamG* considered in the paper does not use element-wise learning rate.
This paper begins with the empirical observation that adversarially trained models often exhibit a large different in clean (and robust) accuracies across different classes. It also offers a theoretical study under a Gaussian mixture setting that respects Eq. (1). Perhaps there is a cleaner way of formulating there results or highlighting the key components of the analysis that resolves this. As the authors mentioned in Section 6.2, this may be due to particular algorithms and data distribution. Assuming A^2 >> q(K), the terms simplify to: Rnat(f,−1)=P[N(0,1)≤A(1−K)] Rnat(f,+1)=P[N(0,1)≤A(1−K)]
This paper studies online test for qualitative treatment tests. In the introduction, the difference of ATE (which is widely used in AB test in tech companies) and QTE is discussed only in words. This is a clear rejection. This  circumvents the absence of any tractable analytical form for the limiting distribution of this new test statistic. Do you recommend applying the test for low dimensional data (number of features is 5 for Yahoo)? The author's addressed my concerns and I guess the ones of the other reviewers too.
I think it would be best to pitch the paper this way. Besides the presentation, I don't quite understand how PABI can be used as a practical measure for other applications. However, it's not clear if efficient approximations for PABI will be feasible in all cases. It seems like the point is for applying PABI to partial labels. This should be appropriate since PABI and the Bayesian setting assume that the model is well specified. This would be much easier to read in a table. Weaknesses While the generality of the proposed PABI framework is great and improves over existing work, I think this paper could be scoped more carefully and the scope could be clarified better. "The training samples [are] generated i.i.d.": It is the case for most PAC-Bayes analysis, but I wonder to which extent this assumption holds for the NLP problems studied as experiments. I might suggest adding a requirements.txt or similar. Computing PABI may be challenging in some cases.
In this paper, the authors proposed Search Data Structure Learning (SDSL), which they claim to be a generalization of the standard Search Data Structure. (i) novel contributions, (ii) key algorithmic and technical details S. (2011). Learning to search efficiently in high dimensions.
SUMMARY The paper presents a method to decompose scenes into its constituent objects. - when a relatively simple variation of a model like here is proposed I would want to see an effort to analyse the contribution beyond how it affects the numbers The supervision comes from the object reconstruction loss and the self-supervised loss of classification and regression of anchors in the RPN module. [Paper strength] The paper is well motivated, and the proposed approach seems to be reasonable. This is done with a generative framework that generates both bounding boxes and segmentation masks for each object. does it tell us some fallacy or failure of the original model and if so, does it fix it? However, in this Faster-RCNN-based framework, the objects are selected in one step, how to select the K-1 objects in all proposals? In this paper, the authors introduce a region-based approach for unsupervised scene decomposition. There is no result on real images. Another missing baseline is MONet(UNet).
Summary of the paper This paper proposed the new time scaling analysis for the cross-entropy loss with temperature in the deep neural networks. Finally, the manuscript is poorly written and needs to be largely reworked to be considered for publication. For example, I wonder what the optimal beta is for state-of-the-art BERT-based models. I like the topic, but I think the draft still has room for improvement to become a great paper. I don't see how the theory in Section 2 is crucial for the understanding of the impact of β. Comments and Questions Q) In Sec 2.2 to 2.4, what types of models and datasets are used in the numerical experiments ? Hence, I think it can be move to the appendix, and some from the appendix can be moved to the main paper.
For example, a Gaussian process is a stochastic process, but doesn't have anything to do with the processes considered in this work. Can the authors comment on this? What are the 'expected number of samples' that are used? p.2: 'the model is robust to' this is not clear and never discussed in the paper.
The paper is clearly written, and presents an approach to efficiently utilize long range convolutions through a nonuniform FFT in for coulomb particle configurations. In terms of experimental results, I think a couple of points would deserved to be answered (see below). The method is demonstrated to be effective by a N-body problem. What could be the significance of this finding for a practical application is not discussed, therefore not made clear. In the proposed algorithm, a sampling in a regular grid is required. Here is my (very late) review.
Summary: In this paper, a learning method that accelerates the training of DNN is proposed. In terms of criticisms,  there is very limited scholarship of related ideas that have been used both for linear models and for DNNs, in particular (a) various factor-based models that already exist,  (b) preconditioning of linear systems,  (c) neural nets trained on some other sort of residuals But the training hardware is not explained. Pros: Simple and straightforward proposal, easy to understand, and seems to lead to improved accuracy/reduced loss early in training. I think they are not converged, because the training and testing curve is perfectly smoothing without any fluctuations. So, unlike e.g. AdaGrad or Adam,  the algorithm is not really adaptive in the sense that the learning rate is kept constant throughout training. All training comparisons are measured only as a function of wall-time. The proposed method is more similar to feature extraction instead of a training method. al, "A new preconditioner that exploits low-rank approximations to factorization error". At least for MNIST I'd expect decent performance to be obtainable from the factor features alone. The paper describes a training scheme based on decomposing input features into two parts which have different training dynamics: a low rank "factor feature" computed using PCA on the raw features, and a high rank "residual".
I like the intended focus of this paper which is to perform self-supervised training of small data for downstream tasks with applications for zero and few-shot learning. However I find it a bit dense in terms of explanations and might need more illustrative figures. The paper provides a very in-depth survey of recent work on pretraining research and a clear scoping of the problem to be addressed in this work against the other work.
It seems like learned sketching has not been used for Hessian sketching and regression before. Can the proof be adapted for a case when A is rank deficient? From the reviewer's point of view, the meaningful analysis for learned IHS should certainly be how the converge relates to  the statistics of the training data, to show the benefit of the learned sketch theoretically (i.e. to show how much better the learned sketch SA compare to the unlearned ones in terms of Z_1 and Z_2). It would be helpful if you clarified this. References: Simin Liu, Tianrui Liu, Ali Vakilian, Yulin Wan, and David P. However, it seems like R won't be invertible unless A is of full rank. Should it be "short-and-fat" rather than "wide-and-fat"? ADVANTAGES: Learned sketching is a fairly new and interesting idea.
Significance of This Work: The direction of this work is significant and worth being paid attention to. Collecting data from MIMIC-III is a reasonable choice for creating a multi-modal multi-task dataset. The discussion and future work is not quite related to the paper, for example, it was mentioned about isng images, but images is not one of the modalities in the proposed benchmark.
Thus, I think the regularization proposed in this paper is known. To improve the practical performance of meta-learning algorithms, this paper proposes two regularization terms that are motivated by two common assumptions in some recent theoretical work on meta-learning, namely Regularizing the singular value is similar to the spectral normalization proposed in [1]. Here are the main concerns of this paper: The proposed method in this paper is based on the meta-learning theory as stated in Section 2. Is this means the proposed regularizes would become trivial while applied on top of a more complicated model, e.g., LEO[1]? The meta-learning loss in Eq. 4 is a bit different from the popular meta-learning objective. Therefore, there is no way we can enforce/ensure these assumptions. ########################################################################## Reasons for score: Overall, I vote for reject. To ensure the assumptions of the theories, the authors propose a novel regularizer, which improves the generalization ability of the model. The Frobenius norm regularization is similar to the commonly used weight decay. Could the authors make this notion clear? Weakness: I am skeptical of the novelty of the second regularize in Eq.(4). Ref: [1] Andrei A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu, Simon Osindero, Raia Hadsell: Meta-Learning with Latent Embedding Optimization.
In this paper, the authors proposed two graph pooling methods, i.e., Neural Pooling Method 1 and 2. So it is clear how well the method can generalize to large-scale graph classification problems. For example, in section 3.2, there is only one long sentence in a paragraph. compared to existing graph pooling methods, the authors think their methods are able to capture information from all nodes, collect second-order statistics, and leverage the ability of neural networks to learn relationships among node representations, making them more powerful. Strengths: The proposed method is simple and motivated by several limitations of current graph pooling methods such as average and summation, DIFFPOOL, SORTPOOL, TOPKPOOL, SAGPOOL, and EIGENPOOL. Have you tried your graph pooling approaches on other underlying GNN models?
Summary: This paper observes that in meta-RL (and evolutionary biology), sometimes it is advantageous to learn behaviors that adapt to the particular task, while other times not adapting to the task, and instead relying on a task-agnostic "hard-coded" behavior is sufficient. Overall, this paper was an interesting read. Yet in the paper it seems to be defined as executing a policy that moves farther away from the start. The main question of the paper -- when does it make more sense to learn vs. This paper provides an analysis of RNN-based meta learning approaches. learning. Then they train an RL^2 agent and verify that it behaves as expected in these regimes. And it was not clear that this was one of the main takeaways of the paper, as these concepts do not appear anywhere else in the paper. In the finite horizon case, the meta-learner will necessarily learn a strategy optimal for the given horizon because that's exactly what it's optimized for. Strong points. This paper tackles a novel question which is fundamental to the field of metalearning. This section also convincingly shows that existing meta-RL agents roughly learn the Bayes-optimal policy in this case.
where m(⋅;θ) is a model and θ is its parameter. In the proof of Theorem 1, the authors only considered a specific α, and overlooked the existence of other α that are equally optimal, which led to the wrong claim that θ^ converges to θ∗. There is some improvement in performance, but not much difference. ∂LC(θ,α)∂ω=−E∑i=1KU(i|x,θ∗)(∂(mi(x;θ)+αi(x))∂ω−∑k=1Kexp⁡(mk(x;θ)+αk(x))∑jexp⁡(mj(x;θ)+αj(x))∂(mk(x;θ)+αk(x))∂ω) =−E∑i=1K(U(i|x,θ∗)−exp⁡(mi(x;θ)+αi(x))∑jexp⁡(mj(x;θ)+αj(x)))∂(mi(x;θ)+αi(x))∂ω Thus, any θ,α that satisfy U(i|x,θ∗)=exp⁡(mi(x;θ)+αi(x))∑jexp⁡(mj(x;θ)+αj(x)) are optimal.
5.2) and the experiments (Sec. For (2) to hold, you'd need (y(0), y(1) independent t |z,x) to hold. In particular, the observation that one might estimate a decoder up to a different affine transformation in the treated and control arms seems like a useful insight. All of this is to say that clearly stating assumptions, and the cases they eliminate, is essential for any identification argument.
This paper proposes a hybrid-regressive machine translation (HRT) approach—combining autoregressive (AT) and non-autoregressive (NAT) translation paradigms: it first uses an AT model to generate a "gappy" sketch (every other token in a sentence), and then applies a NAT model to fill in the gaps with a single pass. Can the authors comment on the training cost of HRT in comparison to AT in terms of, e.g., number of epochs, wall-clock time? From Figure 2, what I see is that Chunk performs slightly better than Random. The idea of combining AT and NAT is interesting, and the paper is very clearly written. Overall, this IR issue is under-studied in the literature, which deserves more attention.
Is there a reason for that ? And why are the results inconsistent with those reported in the original paper ? What is the difference ? I am not sufficiently close to the field to know whether this is a novel argument or accepted fact. The paper proposes a method of choosing variables for branching in branch and bound approaches to MIP solving. Counting the number of feasible solutions for a MILP is I believe an NP-hard problem.
Strength: The proposed method is simple and easy to implement. The paper proposes a knowledge distillation method for face recognition, which inherits the teacher's classifier as the student's classifier and then optimizes the student model with advanced loss functions. It considers the situation of single teacher model and multiple teacher models. Current experiments lack the comparison to the state-of-the-art methods, i.e. ArcFace and CosFace. It is good to know what specific architecture is favored under the authors' proposed framework. So more analysis and detailed discussions on the pros and cons of ProxylessKD and L2KD are needed. why the experiments make the setting of templates using teacher model to extract feature, while the query using student model to extract feature? In ablation, how would the number of teachers influence the student performance?
(Note that currently it only shows up to e=0.4.) In addition, I think it would be better to put all other assumptions (if any) on the noise model in the Theorem. This paper formulates a framework for reinforcement learning and behavior cloning from weak supervisions (i.e., noisy rewards or imperfect expert demonstration). The proposed idea is simple and general, and can be applied to both RL and IL In RL, the issue is often not that the reward is noisy in a fixed state, but that it is sparse within the state space, such that the return under a random policy is noisy.
Five different models are evaluated on three (partially novel) benchmarks, providing a unifying perspective on the relative performance of these models. It is good to combine both in one paper. But the empirical evaluation is not convincing. Overall, this paper is interesting in setting up a benchmark for unsupervised object representations which is a very important problem in computer vision, reinforcement learning, etc. In particular: the dataset associated with the benchmark are mostly based on existing works - they might be appropriate for evaluating this task, but the level of contribution is a bit limited; Given the cons and specifically on not a clear actionable suggestion on how to improve models and no analysis beyond synthetic datasets I am leaning towards a rating of below acceptance threshold. Potentially, this can be useful for the community and can help to create a common ground for evaluation. [1] SPACE: Unsupervised Object-Oriented Scene Representation via Spatial Attention and Decomposition, *CONF* 2020 The paper presents an empirical evaluation of a number of recent models for unsupervised object-based video modelling.
The paper proposed a novel personalized federated learning method using a mixture of global and local models. In step 3, the training of the local mixture-of-experts method doesn't need to upload data and gradients to the server-side. In (8) all weights are learned. Step 1 & 2 are FedAvg and local supervised learning that are existing methods. The third step which fine-tunes in the local and global models using a gate network is essentially fusing the global and local models. Strengths The authors target an important problem in Federated Learning: how to personalize the model to mitigate the nonIIDness.
And it (2) requires agents have access to the global states. eta and kappa might be described elsewhere, but it would be helpful to reference where. In particular, it seems that the loss functions do not drive mu's represented by NNs to the fixed point solution of Eq (3); psi shows up in Eq (3) but does not play a role in the following development of the method. A comparison with a randomized graph and ablation with different reset time (n) intervals would be interesting. However, it is some concerns regarding methods that lead to my overall negative rating. Following that definition, this proposition wouldn't be true, so it seems like it needs more explanation, or more careful wording. Is it exact? What are the complete set of parameters? It is a little bit unclear what assumptions are required for all the theoretical and experimental claims of this paper. The authors use experiments on CityFlow, MPE, and MAgent to demonstrate that their method can outperform the SoTA methods and is scalable. The empirical results is impressive. The experiments shown cover many important baselines that are shown to be good baselines in respective environments. The cited PRL article (Levine 2018) seems to retain this standard use of optimal: it uses a distribution over trajectories with an equation similar to here (a softmax over accumulated trajectory rewards), and makes use of the property that trajectories corresponding to an optimal policy have maximum probability in that distribution. In the experiments, it would be interesting to check if intention only helps the nearby agents. Overall (weak accept) The paper has a clear introduction and motivation of the proposed algorithm.
Also, it seems that the "per-channel" quantization method is utilized in this work, but the formulation in (2) seems to be for "per-layer" optimization. The paper introduces a series of techniques to quantize neural networks, and how to combine them: Layer by layer quantization where weights can change as needed (rather than to the nearest quantization error). "and [is] much less prone to over-fitting" 2/ The analysis requires specifying the rank of W and in particular the relationship between M and N. (typically compration RATIO is like 12:1, and compression rate is like 2X, 3X...) Cons: The framework is relatively complex and consists of multiple steps. I think the approach in the paper is pretty interesting, and specially the integer linear programming solution. Same for "min-max" in Fig. 1 and Table 1. The labels are not descriptive (light pipeline, advanced pipeline, relaxed advanced pipeline) and hard to find in the text. With so many "proposed components", the missing of thorough ablation study is a big problem. "MAC operations." -> acronym not previously introduced (unless mistaken) "thus enjoy[ing] some of the flexibility"? There is no clear explanation of how AdaQuant increases the generality of the quantized model, and the discussion about the sample size (B) is hard to understand (why there's infinite solution when B << N? For instance, the baseline accuracy for ResNet50 is 77.2% and MobileNetV2 is 73%, while the paper uses 76.1% and 71.8%. "where V is a continuous variable V" -> redundant "we investigate [a] mixture" "results with high degradation" -> in high degradation This paper proposed a set of methods for post-training quantization of dnns. good performance. clear presentation. easy to read and follow Cf. "Sec.3 Trans-Precision Inference in FP8".
Do Fig.2(a) to (c) correspond to the same (optimal) actions? Q-learning can be applied in the RL setting, but not the method proposed in this paper. This overall disjointedness then makes the conceptual innovation of this work more mysterious to understand, which is a concern. The fact that samples in a limited pool of IID samples concentrate around the region with high probability density is not evidence that this is a poor estimate for the expected value, but rather that the expected value is not representative of a uniform distribution across  the space.
This paper reexamines the original (MM) and the non-saturating (NS) GAN objective. For this reason, a new objective (NS-GAN) was proposed which modifies the generator's objective to alleviate this gradient vanishing issue. Though because this is a common mistake in the literature, I'd be fine with the addition of a note that explains this caveat before presenting the theoretical argument (without insisting on a fundamental solution to this issue). Xing. On unifying deep generative models. The key observation is that the difference between the gradient of the generator objective of MM-GAN and NS-GAN is that MM-GAN has a factor of D_p(G(z,\\theta)), whereas NS-GAN has a factor of 1-D_p(G(z,\\theta)), where D_p(G(z,\\theta)) is the output of the discriminator on a sample generated from z. They are unreadable unless zoomed in very far on a screen. CoRR, abs/1706.00550, 2017. URL http://arxiv.org/abs/1706.00550 [2] Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, and Eric P. I would have appreciated experiments on a larger dataset like CIFAR or high-res CelebA. In Figure 7, I find "best" and "worst" picks by qualitative methods to be somewhat unconvincing. Pre-trained models from prior GAN papers could be used to obtain these scores. There is no information gained by seeing loss curves. I found this to be an interesting work that provided a non-trivial insight, backed it up with clear and easy-to-follow theory and demonstrated their observations held on some medium-scale experiments. Strong areas: I am a very big fan of work that questions standard assumptions that are taken almost as fact within our community.
This is in contrast to RIDE is clearly not designed for that, RIDE-SimCLR is, so while it is nice to prove that RIDE-SimCLR does have this property it could be made a tiny bit more brief. in these tasks) in their own approach. I find this formulation interesting and useful. It provides a variety of visual analyses that are typical of this area of research and present the contrasts between this work and prior efforts.
For example, it is close to impossible for a reader to follow this paper without having read (Arjovsky et al 2019) and (Liu et al. 2018). I regret to say that despite the fact that the subject area of the paper is exciting, I am adjusting my score to 4 post rebuttal. In particular, there is a huge performance gap in Fig 1.b. for θy∈(0,0.15) that needs to be addressed. However, the real world is not so black and white and hence this poses a severe limitation. Please make that explicit and also provide some intuition for why this regularization penalty with a scalar "w" makes sense for your problem set up. Further, the paper proposes an approach inspired by recent developments in the fairness literature for domain generalization. Each of these partitions, referred to as 'environments', represent a different training distribution, and the goal is to train a model that performs equally well across all of them.
"Moreover, the top-1 model on T(0) does not necessarily perform the best on T(1) , conforming to the results in (Wang et al., 2020).", what results are you talking about specifically? And I guess it should be "confirming". "suggesting their insufficiency to cover hard examples that may be encountered in the real world", maybe replace "insufficiency" and "cover" with "inability" and "handle". Consider moving the superscript 4 after the period to make it clear that it is a footnote and not exponentiation. The paper therefore proposes a measure based on the discrepancy of a group of segmentation models to identify more valuable images to annotate and add to the training data in a iterative fashion. I would have prefered legends in each figure, as opposed to having to scroll up and down to find the relevant information. It would be good if the authors could describe how this specific problem has been addressed before in image analysis and particularly image segmentation. If the methods tend to disagree on a limit number of typical cases, then these cases will be added to the training set and it is not so surprising that improvements in the target model is seen. I noticed in the Appendix, the authors also compared their method with entropy-based active learning – a vanilla baseline needing no competing model.
Author comments on step (ii) During testing, this ensemble is frozen and used to generate feature samples from unseen observations. This will allow the authors the piece apart which part of their contribution is useful and which isn't.
APT (representation) can be understood as pre-training a state representation. In section 4.3, it is awkward that I find APT and APT (representation) similar across different curves in Figure 4, so I'm not convinced the policy initialization is useful. Question: Conceptually eq. (5) looks quite noisy (dependent on batch samples a lot), and like some form of contrastive learning objective still (maybe entropy maximization is equivalent to making representation contrastive?). Unsupervised representation learning has obtained impressive results in supervised scenarios, and adapting these methods to RL is an important research direction. The results are promising, and I would suggest to include this setting, together with a deeper analysis, in the main paper.
For example, if j is in between i and head(i), then j must be in the smallest constituent that contains both w_i and w_head(i). In addition to comparing to prior work, it would help to characterize the performance of the StructFormer to include baselines that are trained on the same dataset as that used by the authors, so that we can disentangle the impact of some of the choices made here. The parse in turn determines a soft attention mask for a Transformer encoder module. (d) How was the gap value of 0.1 selected? The paper is a bit sloppy in writing. STRENGTHS The observation that dependencies can be recovered from syntactic heights given constituents is insightful and motivates a natural joint parsing algorithm (Algorithm 1). There are three types of concerns I have about the paper in its current form: The description of the method is dense and difficult to understand, and has at least a few notational issues (details below). I would recommend a careful and comprehensive rewrite of this section. p. 5: "a unsupervised" --> "an unsupervised" How are the attention masks defined in equation (10) used? The BuildTree function call in line 8 does not match the function signature in line 1.
To address the issue of optimizing high-dimensional sampling hyper-parameter in data sampling and release the requirement of prior knowledge from current methods, the authors introduce a searching-based method named AutoSampling. For example, it may be meaningful to check the alignment of data weights and classification scores. It is formulated with a population based training strategy. It has been a recent trend to make almost all key factors of deep networks learnable, such as differentiable data augmentation. Disadvantages: l    In Table 1, the number of workers does have an influence on performance, and this influence is positively correlated in my opinion, however, we can see a performance degradation for DenseNet121. while the exploration step estimates the sampling distribution according to the sampled data in exploitation step and rectifies it to sample all data possibly. From this description I believe this paper has done it before: "CASED: Curriculum Adaptive Sampling for Extreme Data Imbalance". It is not clear to me what the intuition of P(x) is. This should be randomized at least for CIFAR. The authors have conducted sufficient experiments to verify the superior of their method, especially for the effectiveness and generalizability. It seems that very small margins are observed in comparison with random exploration.
What is the effect of location for SN in a CNN (equivalent analysis for CN is presented in Tab4)? CA is also a unit that is inserted in the ResNet block so that it's interesting to have an experimental comparison as well. - The authors explains SelfNorm recalibrate feature style while  CrossNorm performs style augmentation. It is difficult to agree that SN and CN, which are argued to control style and content for the benefit of the recognition task at hand, are really working as speculated. I find it a bit dangerous to let such a convenient and simplifying view of the matters be published and guide researchers in the field to adopt the same kind of viewpoint. It should thus also be possible to present it in a more concise form. CN is a twin invention that randomly swaps the mean and variance statistics of features of two channels. They may serve as inspirations but without extensive experiments it is hard to related concepts like style to the manipulation of network parameters. Detailed comments are summarized as follows: Pros: - The paper contributes a solution by forming a unity of opposites in using style for model robustness. The method is very simple and I think that is a major strength. Questions/Recommendations It is probably beyond the scope of the review period but a demonstration of the technique on some non image data would be amazing making the theoretical argument in Section 4.1 that the method can work on other domains much more powerful.
This paper is concerned with 3D molecule learning. While it is true that most current techniques rely mostly on 2D (for small molecules) or 1D (for large molecules) representations, it is not for lack of trying to incorporate 3D information, but because In fact, these methods are often SOTA in their fields. By creating a standardized set of prediction tasks and associated data sets, the authors have presented a resource that may help the community to compare 3D atomistic methods quickly and fairly. There seems to be a fair amount of papers tackling the non-binary problem (Montanucci et al. [4], Cao et al. [5], Rodrigues et al. [6] to name a few). Finally, in Section 4, the paper could benefit from stating very explicitly what is novel and what is not novel in the three proposed 3D architectures. They show that a lot of existing tasks can do well when 3D structure is considered. My overall recommendation is a weak accept. The framing of the paper ignores decades of work in chemoinformatics, in particular (but not limited to) around kernel methods. Are 3D models better than this? In Advances in Neural Information Processing Systems (pp. This is obviously essential to the paper and I would feel more comfortable accepting a version of the paper that includes this information (possibly with URLs withdrawn if there is a concern about maintaining the review process blind).
The key idea is to compare  sparse and dense networks that have the same number of (non-zero) weights. While this is a good start, I am not sure that this is really a fair comparison, though.
While it is generally a great idea to guide the selection of radar regions to be sampled at a higher rate the paper is very application-focused and lacks novelty in its method. Use of Faster R-CNN (slow) Summary: In the paper, the author(s) propose 1) a method to dynamically adjust the sampling rate on radar data using 2D object detections (algo1) and previous image and radar data (algo2); 2) an end-to-end transformer-based 2D object detection model using both radar and image data. There is no discussion or reasoning in these choices. Assume a car moves 30 mph, in 0.2s it can move 2.68m, which is about 3/4 length of a car. I would recommend a complete restructuring of the paper to clearly expose the goals and contributions of the authors, rather than just list a set of unmotivated design choices.
For example, a "concept" in the paper is actually an "event", not a "concept". It is unclear why demonstration data is important for this method, and why it is not general for any human action. The authors may need to look upon those for a better variety of baselines and also evaluation metrics. Introducing a two-level hierarchy into concept learning is also not new. The introduction explaining demonstrations in a robotics scenario does not feel related to the content of the paper. Quantitative results are not convincing. How do you define the level of concepts and how did you balance the levels in video and language? The cons include (In my opinion, the main weakness is the experiments): Some design of model (e.g., Traversing across the concept hierarchy, Observation, and Instruction Regeneration, etc) are not fully estimated in this section: are they really useful? 8 layers and 8 heads just for the Encoder seem like a very big model for such a relatively simple text. As the network is unsupervised, the starting time and ending time of each concept is quite crucial and the problem was tackled by training using a soft-DTW loss. The lower-level concepts and upper-level concepts in both visual and language are a little vague without clear definitions. This paper addresses a relatively new topic to learn the hierarchical concepts in videos and commentary in an unsupervised manner.
define T (global number of edge updates) and H (number of local updates in between edge communication); where and when quantization is applied and why it helps in reducing communication complexity in the main text. The authors claim that this is the first work to consider decentralization, local updates, asynchrony, and quantization in conjunction. (5) In the theoretical part, I did not see in which measure does this new algorithm excel the existing ones. What is the benefit of using the quantization method in Davies et al. (2020)? Update The authors' response addresses some concerns, and I would like to keep the initial scores. For (14) and (19), use rλ2≤r2λ22 to get rid of the first order term. Significance and clarity Contributions are significant and novel, to the best of my knowledge. Whether is it possible to update one node based on the results from multiple connected nodes (i.e., one node is activated)? Experiments in the distributed setting are carried out for image classification and speech recognition, showing that the algorithm is generally able to achieve performance comparable to a model trained in the centralized setting at increased execution time, but faster than state-of-the-art distributed SGD methods. Is the coefficient $\\frac{n - 2}{n}# in Eq (18) missing? Recommendation: Weak reject. As of the current version, the proofs need to be improved. This condition is very difficult to satisfy in applications. Therefore, there is still synchronization in Alg. 1. The H2 term in Theorem 4.1 and 4.2 may not be good enough. Arguments for acceleration is not convincing. (4) The claim in the abstract that the new algorithm can converge to local minima is not supported, since the theorems only imply gradient convergence. Contributions: This paper analyzes the convergence of decentralized SGD with asynchronous updates, quantization and local updates, which is novel and challenging. Theorem 4.2 requires T∼O(∗). Does it work if T is greater? The 1st equation in Section E has an extra '-'.
This being said, the application of LSH in this context is (seemingly) new, and the two basic similarity measures are interesting. iii) You mentioned that you are using CPU or computation.
In Eqs. (7) and (8), notations of the loss and reward should be defined. Reasons for score While I really want to emphasize that the problem is very interesting and that I like the premise of L2E, I think the paper, in its current form, is missing the target. that positive returns are guaranteed against opponent without a clear style (whatever that precisely means). Summary The paper suggests a novel framework (coined L2E) to learn a policy that is optimized to adapt quickly (and exploit) a wide range of unknown opponents. Hence, it is unclear how much more effective and diverse opponents that OSG can generate compared to state-of-the-art opponent generation-based algorithms (e.g., population-based RL (Jaderberg et al., Science-19)). Who is the opponent in Figure 4? It seems that we need the exact opponent and base policy at all times in L2E. An important claim of the paper is that explicit opponent modeling requires large sample complexity (Section 1).
Summarization of the contribution: This paper presents a novel ADversarial Meta-Learner (ADML), the claimed first work that tackles adversarial samples in meta-learning. Finally I have a concern with the evaluation protocol: the algorithm suggests that adversarial examples are generated by drawing a fresh batch of data. Recommendation and reason: Weak Reject. Page 1: it is better to rephrase the sentence about MAML to give a clearer description of it. Method is agnostic to the model and the form of adversarial attack Additional comments: The language of the paper needs to be polished and refined.
In experiments they show that this outperforms the offline metaRL method PEARL, and combining multi-task offline RL with AWR in a naive way. For now I give a score of 5, but I'm open to increase this and look forward to the author's response! However, in this paper, this is not the case. This is one of the key differences, IMO, between meta-RL and offline meta-RL and given that this paper's main contribution is introducing offline meta-RL, I feel it really should be very clear about this point. In the MuJoCo tasks considered in the experiments this might not be such a problem due to (a) dense rewards and (b) "good" offline data. I saw you added a motivation for this in Sec 3, which makes me a little bit more convinced. Therefore, I understood we're simply changing it to just a weight matrix of the same dimension. PEARL samples a fixed set of tasks at the beginning of training while ProMP and MAML samples a set of tasks at every iteration. In the definition of 'task' described in the paper this is fine since task=MDP. The approach is evaluated on offline versions of 4 continuous control problems. I would have liked to see performance on MetaWorld benchmark. Concepts are well explained and hypotheses clearly stated. Overall, I find the ideas proposed quite interesting. If so, why wasn't it used in the past? In Related work Kirsch 2020b,a seems to be the same paper cited twice
Concerns: Technical sophistication: -As I understand, the goal is to be able to quantify the effect of various sources of non determinism on performance. For example, a WideResNet-28x10 can give approximately 95% test accuracy for CIFAR-10 and has a much larger capacity than the ResNet-14. The authors make the surprising discovery that each source of nondeterminism results in an equal amount of variability and model diversity. This is because it is hard to be convinced that the process of attribution can be established entirely based on statistical measures. It is therefore necessary to analyze all possible combinations of source variations for the conclusions made to hold true. Furthermore, the authors claim that these sources of uncertainty are all dependent on network weights, with even small changes in network weights drastically affecting the network's performance. If the single linear layer problem is convex, it is expected that a single bit initialization perturbation still leads to the global minimum.
The evaluation shows that it can reach the performance of a vanilla transformer in most of the examined tasks while having fewer memory requirements in general. [1] https://arxiv.org/abs/1901.10430 This paper introduces the Attention Free Transformer (AFT), an alternative to multi-head attention (MHA) operation in Transformer. (2) One major limitation that stands out from the experiments, despite their size, is that there is no head-to-head or controlled comparison with a previously established efficient transformer such as the ones mentioned above. This is done by element-wise multiplication of a query representation with a compressed kv-memory.
Therefore, I can not consider this as a contribution and think that this part is misleading for a reader. The paper investigates the over-parameterization of attention heads in Transformer's multi-head attention. It is better to have a deeper analysis and explanation. Here are a few detailed comments: -- In practice, it seems the proposed approach didn't speed up the training, even though it gives an improvement in terms of FLOPS. For example, keeping the same quality it reduces the number of parameters from 6.110^6 to 5.410^6, which is not going to make a large difference. Namely, while the original definition of attention layers does not have biases in linear projections for q/k/v in attention, the authors claim that implementations contain the bias terms, and spend some time showing how to model the biases in key and query layers properly. The authors also propose a Tensor Decomposition based method to easily convert MHA to its collaborative version without retraining. This is still an open question so might not be appropriate to say transformers suffers over-parameterization. ======================== Paper Summary: This paper proposes a new form of multi-head attention. Strengths a nice analysis of PCA components showing that individual heads are not low-rank, but their concatenation is. This attention can be applied either instead of the standard attention during training, or as a drop-in replacement for an already trained model. If you look a deeper look into Transformers, in case of BERT, the attention block only takes around 25% of total parameters. Figure 2 is somewhat confusing.
Following the prior work, this paper proposes an exploration method unifying the step-based and trajectory-based exploration. For on-policy methods (A2C, PPO), the proposed method has large performance gain on Mujoco tasks. Is the proposed method sensitive to these hyper-parameter choices? For the off-policy case, there is insufficient explanation for why they use single sigma and the connection point of the proposed method and eq (5). Clarity: This paper is generally written clearly. This paper presents a method to combine step-based exploration with trajectory-based exploration (in the form of action-space noise and parameters-space noise) in continuous MDPs, which is scalable to deep RL methods. Would the authors consider this alternative? Originality: As far as I know, the proposed technique is novel in the literature of undirected exploration.
In relation to the above, it may be good to have a comparison experiment with denoising auto-encoder and VAE. This is a pure question, is it possible to know the dimensions of the manifold through this technique? In this research, Authors propose to add noise to the data sampled from low-dimensional manifolds in a pseudo manner, but in actual measurement, noise has been included in data naturally without adding it in a pseudo manner. Then full dimensional manifold is recovered and subsequently deconvolution is applied (equation 7).
Strengths of this work: The key idea of this work is to decouple the search of network topology and the search of operators. It is not very clear. Another approach is to replace all operators with one single operator e.g. convolution.
The authors also derive a max-ent version of this and show that this can improve performance on some Atari games (though this is not that convincing). Moreover, if the TD error is a bound (which I think isn't with neural networks as I discuss in the next point) on the empirical EVB, can't I just drastically overestimate Q-values and get a larger empirical EVB value to be super high and prioritize on those examples? Should we not be sampling experiences, and simply sorting the experiences by priority and training our agent on experiences in descending order of priority? When defining EVB, PIV, EIV in Eq. (3)- Eq. (5), "s_k" is used.
eq.(2),(3): what is O(n) here? Pros: The proposed algorithm is clever and appears to do well compared to existing approaches in experiments. This is a finite βdet result, with a claim only holding in the limit. This occurs often in the paper and in the appendix. anything else?) The mathematical justification of the statements seems to be correct for me and ok to follow. Why the inconsistency? End of Page 3: how is \\mathcal{G} related to trace invariants formally? Section 2.2: this is not clear. The algorithms function by considering cutting an edge in the graph representation of the trace invariant, yielding a matrix whose leading eigenvector provides a (up to a rotation) estimate of the signal vector v. Recommendation: At the current stage I vote for rejection.
In ICML'19. For a situation where the sensitive attributes are missing, there are several works, including This seems to be a prerequisite for the disentangle algorithm to perform well. This paper introduces the problem of enforcing group-based fairness for "invisible demographics," which they define to be demographic categories that are not present in the training dataset. #Minor comments and questions In the experiments, for colored-MNIST, a comparable portion for each quadrant is retained for the context dataset, have you tried different retained portions and how does that affect clustering quality? The authors should clarify this in a later version. I don't think this is a significant result. The weak points of this paper are as follows: The experimental results have a high variance. We can all agree that this sounds unfair, and we would like to rectify this." without any proof or mathematical argument. Furthermore, these groups are not hugely imbalanced in the context set to begin with.
(2)What is the difference between the searched architectures by using BN, CCBN and SaBN? In this paper, the authors propose Sandwich Affine strategy to separate the affine layer in BN into one shared sandwich affine layer, cascaded by several parallel independent affine layers. It seems to me that the paper organization is poor. The results in this paper are encouraging, but I believe the paper needs to explain more clearly why SaBN is expected to work (given that it preserves the hypothesis class as well as the minimum of the training objective). (3)  "The categorical index i of SaBN during searching is obtained by applying a multinomial sampling".
It is certainly a good idea to work out an approach in its full generality, but some of the components taking up space in the presented derivation are immediately cut in the experiments section (like the DKL(π || p(at∣a<t) term), so you might as well present a simplified version of the result that focuses on the method actually used. Starting with accumulated rewards makes it confusing, as one could be made to believe that the agents never successfully learn to perform the task and avoid poisons. "Period costs" should really be called "Episodic returns", as this is really more standard. However, this paper is promising and I look forward to seeing it mature. Criticisms: My main problem with the paper is that the authors do not show that the joint model does anything. They compare their model against baselines such as A2C with convolutional networks as feature extractors , A2C with the World Model (Ha et al) as a feature extractor (also based on convolutional networks) and a random policy. References [1] Ortega, P. A., Wang, J. It is hard to say whether OPC mimics humans' knowledge acquisition without any sort of evidence. This is not demonstrated convincingly and is a huge missed opportunity.
The proposed conditional networks is practical. Additional Feedback: Figure 2 caption: "(e) Fully Cond. The paper demonstrates the experiments on two tasks (i.e. semantic segmentation, image classification), but the proposed conditional network is different and does not have a unified architecture. Recommendation: I enjoyed reading this submission and think that the idea of "conditional networks" constitutes a novel and relevant contribution to improve OOD generalisation.
