For inference only, other works has more to offer but this is a promising technique for learning. In overall, this paper is an accept since it shows good performance on standard problems and invent some nice tricks to implement NN in hardware, for *both* training and inference.
The work is extremely creative and packed with interesting experiments. They provide rich analysis of the emergent languages the agents produce under different experimental conditions.
The authors provide a method for learning from demonstrations where several modalities of the same task are given. Why not adding (non Bayesian) context (not label) to the task will not work as well? For me, this is not the pain point in this tasks. I know how hard is to make robotic tasks work... 2) I'm not sure, and I haven't seen evidence in the paper (or other references) that SNN is the only (optimal?) method for this context. But I think some more work is needed in this work: comparing to the right current state of the art, and show that in principal (by demonstrating on other simpler simulations domains) that this method is better than other methods. Indeed, SNN is a good choice for adding (Bayesian) context to a task.
Summary: The paper presents a modification of the Winograd convolution algorithm that enables a reduction of multiplications in a forward pass of 10.8x almost without loss of accuracy. Review: The paper shows good results using the proposed method and the description is easy to follow. This paper proposes a method to build a CNN in the Winograd domain, where weight pruning and ReLU can be applied in this domain to improve sparsity and reduce the number of multiplication. This modification combines the reduction of multiplications achieved by the Winograd convolution algorithm with weight pruning in the following way: - weights are pruned after the Winograd transformation, to prevent the transformation from filling in zeros, thus preserving weight sparsity A general limitation of the proposed method is the network architecture inconsistency with the ordinary CNNs. Due to the location change of ReLUs, it is unclear how to transform a pretrained ordinary CNNs to the new architectures accurately. I only have a couple of questions/comments: 1) I'm not familiar with the term m-specific ("Matrices B, G and A are m-specific.") and didn't find anything that seemed related in a very quick google search. The resulting Winograd-ReLU CNN shows strong performance in three scenarios (CIFAR10 with VGG, CIFAR100 with ConvPool-CNN-C, and ImageNEt with ResNet-18). 2) Although small filters are the norm, you could add a note, describing up to what filter sizes this method is applicable.
This paper studies problems that can be solved using a dynamic programming approach and proposes a neural network architecture called Divide and Conquer Networks (DCN) to solve such problems. Using an architecture to learn how to split the input, find solutions, then merge these is novel. - improvements over previous solutions
Since it is not known in advance what might be a good set of transformations, it is not clear what is the behaviour of the model when the large portion of transformations are not encoding the latent representation of clusters. Thanks to the reviewer for clarifying this. Given that in many applications such parent-class supervised information is not available, the authors of this paper propose domain specific pseudo parent-class labels (for example transformed images of digits) to adapt ACOL for unsupervised learning. For instance, in the case of MNIST, rotations with different degrees are applied.
Using an architecture to learn how to split the input, find solutions, then merge these is novel. Hence my current more neutral review rating. In particular I would like to see a clear comparison in terms of latent traversals on dSprites between beta-VAE and DIP-VAE models presented in Table 3. 2. Regarding the correlational plots (the bottom row of Table 3 and 4), I don't think I can see any clear patterns (especially on CelebA).
This needs to be analyzed very thoroughly because some experiments seem to imply that Flip and NoFlip are giving same performance (Fig 2(b)). In Section 4 they provide quite varied empirical analysis: they confirm their theoretical results on four architectures; they show its use it to regularise on language models; they apply it on large minibatch settings where high variance is a main problem; and on evolution strategies. The paper introduces a simple idea, flipout, to perturb the weights quasi-independently within a minibatch: a base perturbation (shared by all sample in a minibatch) is multiplied by a random rank-one sign matrix (different for every sample). The gain in wall clock could be a factor, but would need to be measured on the figures more clearly.
This paper investigates numerically and theoretically the reasons behind the empirical success of binarized neural networks. It further explains why binarization is able to preserve the model performance by analyzing the weight-activation dot product with "Dot Product Proportionality Property." It also proposes "Generalized Binarization Transformation" for the first layer of a neural network. This paper presents three observations to understand binary network in Courbariaux, Hubara et al. (2016). This paper tries to analyze the effectiveness of binary nets from a perspective originated from the angular perturbation that binarization process brings to the original weight vector. The first observation is interesting, is explained clearly and convincingly, and is novel to the best of my knowledge. There is also a strong correlation between (binarized weights)*activations and (binarized weights)*(binarized activations). In general, I think the paper is written clearly and in detail. a. My mistake. Perhaps it should be clarified in the text that u are the weights.
Algorithm 1. is called "minimization for detection and generating out of distribution (samples)", but this is only gradient descent, right? The authors propose to train a generator network in combination with the classifier and an adversarial discriminator. This paper proposes a new method of detecting in vs. The problem setting is new and objective (1) is interesting and reasonable. This paper is clearly written, proposes a simple model and seems to outperform current methods. The problem of interest is timely and important, and the provided solution seems reasonable and is well evaluated. Moreover, [1] did not seem to generate any out of distribution samples. Given the title also contains "detecting", I feel authors should write explicitly how the detection is done in the main body. In response to authors' comprehensive reply and feedback.
This paper proposes an approach to generating the first section of Wikipedia articles (and potentially entire articles). The paper presents strong quantitative results and qualitative examples. In general, the paper is well-written and the main ideas are clear. In some of the examples the system output seems to be significantly shorter than the reference, so it would be helpful to quantify this, as well how much the quality degrades when the model is forced to generate outputs of a given minimum length. Authors claim that the proposed model can generate "fluent, coherent" output, however, no evaluation has been conducted to justify this claim. With a fixed reference/target Wikipedia article, if different models generate variable sizes of output, ROUGE evaluation could easily pose a bias on a longer output as it essentially counts overlaps between the system output and the reference. ---- After reading the authors' response and the updated submission, I am satisfied that my concerns above have been adequately addressed in the new version of the paper. ---- After reading the authors' response and the updated submission, I am satisfied that my concerns above have been adequately addressed in the new version of the paper.
The paper devises a sparse kernel for RNNs which is urgently needed because current GPU deep learning libraries (e.g., CuDNN) cannot exploit sparsity when it is presented and because a number of works have proposed to sparsify/prune RNNs so as to be able to run on devices with limited compute power (e.g., smartphones). ---- After reading the authors' response and the updated submission, I am satisfied that my concerns above have been adequately addressed in the new version of the paper.
Originality The paper proposes a path consistency learning method with a new combination of entropy regularization and relative entropy. Clarity The paper is well-written and clear. - Some ablation studies (e.g., on entropy regularization and relative entropy) and sensitivity analysis on parameters (e.g. \\alpha and update frequency on \\phi) would be helpful.
- There are parts of the papers which are confusing or not well-written. The most interesting part is a joint training for both compression and image classification. The most interesting part is a joint training for both compression and image classification. The most interesting part is a joint training for both compression and image classification. - Joint training of compression + other tasks.
Strong points: * To my knowledge, the proposed defense strategy is novel (even if the idea of transformation has been introduced at https://arxiv.org/abs/1612.01401). The main takeaways of the paper are to incorporate transformations that are non-differentiable and randomised. Designing an attack in case of a non differentiable transformation is obviously not trivial since back-propagation can not be used. * The proposed approach really helps in a black-box scenario (Figure 4). Four adversarial attacks strategies are considered to attack a Resnet50 model for classification of Imagenet images. Designing an attack in case of a non differentiable transformation is obviously not trivial since back-propagation can not be used. Overall, the works investigates an interesting idea, but lacks maturity to be accepted.
This paper proposes an idea to do faster RNN inference via skip RNN state updates. The task of reducing computation by skipping RNN inputs is interesting, and the proposed method is novel, interesting, and clearly explained.
This paper proposes an idea to do faster RNN inference via skip RNN state updates. This paper shows that residual networks can be viewed as doing a sort of iterative inference, where each layer is trained to use its "nonlinear part" to push its values in the negative direction of the loss gradient.
"Determinantal point processes for machine learning." Foundations and Trends® in Machine Learning 5.2–3 (2012): 123-286. "Determinantal point processes for machine learning." Foundations and Trends® in Machine Learning 5.2–3 (2012): 123-286. The paper is revised and I saw NMS baseline is added. I think that it will only be a problem for extremely large numbers. The rebuttal is convincing and I decided to increase my rating, because adding the proposed counting module achieve 5% increase in counting accuracy. 3. Could the authors provide more insights on why the structured attention (etc) did not significantly improve the result?
SUMMARY The paper considers the problem of using cycle GANs to decipher text encrypted with historical ciphers. But it seems that this is not used in the experiment and that the authors consider that the introduction of the embedding is a substitution for this.
It is not clear to me whether the output prediction on those skimmed tokens is made of the full hidden state (updated + copied) or a first few dimensions of the hidden state. The examples (Table 3 and Figure 6) show that the skimming process is appropriately performed (skimmed unimportant words while fully read relevant words etc.) It would be good to use REINFORCE to do a fair comparison with (Yu et al., 2017 ) to see the benefit of using small RNN.
In the following, the authors explore the landscape of RNNs satisfying the necessary conditions. A novel linearized version of the LSTM outperforms traditional LSTM on this long-term dependency task, and raises questions about whether RNNs and LSTMs truly need the nonlinear structure. Linear Surrogate RNNs is an important concept that is useful to understand RNN variants today, and potentially other future novel architectures.
The paper is rigorous and ideas are clearly stated. 9. In the experiments the reduced dimension used is equal to 1 for two of the experiments and 2 for one of them. 8. The authors mention that "we can clearly see from Fig. 3a that DAGMM is able to well separate ..." - it is not clear to me, it does look better than the other ones, but not clear.
This is complemented by the SCAN model, which is a beta-VAE trained to reconstruct symbols (y; k-hot encoded concepts like {red, suitcase}) with a slightly modified objective. This is, however, not the case in this paper (at least not in the current manuscript) due to its over-simplified experiments. It seems that the only difference between the unstructured (entangled) and the structured (disentangled) visual VAE is the color space of the input (RGB vs HSV). Prelimary Evaluation --- This clear and well written paper describes an interesting and novel way of learning a model of hierarchical concepts.
These strategies are evaluated in a particular semi-supervised transfer learning setting:  the models are first trained on some source categories with few labeled data and large unlabeled samples (this setting is derived by subselecting multiple times a large dataset), then they are used on a final target task with again few labeled data and large unlabeled samples but beloning to a different set of categories. The studied problem is interesting, and the paper is well-written. The studied problem is interesting, and the paper is well-written.
The paper presents an extensive framework for complex-valued neural networks. The writing is clear, concise and easy to follow. It is unclear how the phase information in the input waveform is transformed into the phase of the complex activations in the network (because I think it is implied that this is what happens). Comments: - The related work section is comprehensive but a bit unstructured, with each new paragraph seemingly describing a completely different type of work. Some more insight into how phase information is used, what it represents and how it is propagated through the network would help to make sense of this. Maybe some subsection titles would help make it feel a bit more cohesive. With this in mind, it is of course completely fine that the results are not better than for real-valued networks.
Pros: - The nice thing about this method is that average pooling is in some sense a special case of this method, so we can see a clear connection. Other comments: - Given that this method's flexibility, I could imagine this generate a new class of pooling methods based on lossy transforms. Other comments: - Given that this method's flexibility, I could imagine this generate a new class of pooling methods based on lossy transforms.
Comments: I really appreciate the author(s) by providing experiments using real models on the ImageNet dataset. The algorithm seems to be easily used in practice. In the actual performance, the paper presents both practical efficiency and better generalization error in different deep neural networks for image classification tasks, and the authors also show differences according to different settings, e.g., Batch Size, Regularization. Why should people use Neumann optimizer but not Adam, which is already very well-known? Algorithm 2 is more heuristic approach, with a couple of parameters to tune it.
The paper presents a new approach to generate adversarial attacks to a neural network, and subsequently present a method to defend a neural network from those attacks. They compare this optimization method with two baselines in MNIST and CIFAR, and provide an analysis of the decision boundaries by their adversarial examples, the baselines and non-altered examples. As a summary, the authors presented a method that successfully attacks other existing defense methods, and present a method that can successfully defend this attack. The provided analysis is insightful, though the authors mostly fail to explain how this analysis could provide further work with means to create new defenses or attacks. - The analysis of section 4.1 is interesting, it was insightful and to the best of my knowledge novel. - I think the authors should make a claim on whether their proposed attack works only for defenses that are agnostic to the attack (such as PGD or region based), or for defenses that know this is a likely attack (see the following comment as well).
The paper takes an interesting approach to solve the existing problems of GAN training, using Coulomb potential for addressing the learning problem. They claim that under the condition that global optima are achieved for discriminator and generator in each iteration, the Coulomb GAN converges to the global solution. The model collapsing is not just because loss function in training GAN. Overall, I think this is a good paper that provides a novel way of looking at and solving problems in GANs. I just had a couple of points in the paper that I would like some clarification on : * In section 2.2.1 : The notion of the generated a_i not disappearing is something I did not follow. Overall, it presents an interesting approach to overcome the mode collapse problem with GANs.
This is a fairly strong paper. The proposed models make sense and the writing is for the most part clear, though there are a few places where ambiguity arises: - The variable "Evidence" in equation (4) is never defined. The appendix seems to suggest that the authors are simply performing multilabel classification based on a predefined set of classes of errors, is this correct? However the application to program repair is novel (as far as I know). Clarity: The paper is clearly written. For example, the Cai et al. paper from *CONF* 2017 is not considered --- References Cai, J., Shin, R., & Song, D.
It could lead to new insight on automating design of neural networks for given problems. Instead of merely defining an architecture as a Directed Acyclic Graph (DAG), with nodes corresponding to feature maps and edges to primitive operations, the approach in this paper introduces a hierarchy of architectures of this form. popular models could be an interesting addition to the paper. In addition, the authors present results that appear to be on par with the state-of-the-art with architecture search on CIFAR-10 and ImageNet benchmark datasets. The method proposed for an hierarchical representation for optimizing over neural network designs is well thought and sound. This is a gross overstatement. > Our evolution algorithm is similar but more generic than the binary tournament selection (K = 2) used in a recent large-scale evolutionary method (Real et al., 2017).
Comments: - The paper is well-written and relevant literature is cited and discussed. There is a big literature on learning from demonstrations that the authors could compare with, or explain why their work is different. The paper is clear, very well written, and well-motivated. Exploration is still a challenging problem for RL. However experimentally the paper performs better than the previous approach. While the experiments show that DOMNET improves over Shi et al, that could be explained as not having to train on raw pixels or not enough episodes. Their proposed algorithm DAgger fixes this (the mistakes by the policy are linear in the horizon length) by using an iterative procedure where the learnt policy from the previous iteration is executed and expert demonstrations on the visited states are recorded, the new data thus generated is added to the previous data and a new policy retrained.
Two key ideas in the paper include the use of Gaussian noise for the aggregation mechanism in PATE instead of Laplace noise and selective answering strategy by teacher ensemble. It is demonstrated that sampling from a Gaussian distribution (instead from a Laplacian distribution) facilitates the aggregation of teacher votes in tasks with large number of output classes. The novelty of this work is a refined aggregation process, which is improved in three ways: a) Gaussian instead of Laplace noise is used to achieve differential privacy. The paper proposes novel techniques for private learning with PATE framework. This is done by leveraging the synergy between privacy and utility, to make better use of the privacy budget spent when transferring knowledge from teachers to the student. The extension of an approach for learning with privacy to make it scalable is of merit. This is for sure an important topic. I am not familiar with privacy learning but it is interesting to see that more concentrated distribution (Gaussian) and clever aggregators provide better utility-privacy tradeoff. on the positive side: Having scalable models is important, especially models that can be applied to data with privacy concerns. I think this is a nice modular framework form private learning, with significant refinements relative to previous work that make the algorithm more practical. The paper is well written, and the idea of the model is clear. It would be helpful to add a comparison. These works also involve a "student" being trained using sensitive data with queries being answered in a differentially private manner. on the negative side: In the introduction, the authors introduce the problem by the importance of privacy issues in medical and health care data.
The experimental results are convincing enough to show that it outperforms other active learning algorithms. On the whole this is interesting work and the results are very nice.
The ideas are presented often out of order and are repeated in cycles, with some critical details that are needed to understand the method revealed only in the later cycles. The ideas are presented often out of order and are repeated in cycles, with some critical details that are needed to understand the method revealed only in the later cycles.
In this paper, the expressive power of neural networks characterized by tensor train (TT) decomposition, a chain-type tensor decomposition, is investigated. The result of this paper is interesting and also important from a viewpoint on analysis for the tensor train decomposition. 1. The authors compare the complexity of TT representation with CP representation (and HT representation). In addition, I would like to see the performance of RNNs and MLPs with the same number of units/rank in order to validate the analogy between these networks. However, CP representation does not have universality (i.e., some tensors cannot be expressed by CP representation with finite rank, see [1]), this comparison may not make sense. Though I enjoyed reading this paper, I have several concerns.
"without learning a model (Mongillo et al., 2014).": Seems like an odd choice for a citation for model-free RL. (And, in other places.) "An important property of E-values is that it decreases over repetition" -> "An important property of E-values is that they decrease over repetition". Detailed comments: "Where γ is" -> ", <newline> where γ is". Notes: - The plots are horrible in a print. On the theoretical side, can a bound be proven for this approach, even in the tabular case?
The work is fairly novel in its approach, combining a learned reward estimator with a contextual bandit algorithm for exploration/exploitation. 2) is the remainder of that paragraph a description of a "standard learning to search step"? page 5 "and MTR" -> "and DR" -- Inconsistent language. For instance, x is sometimes referred to as the "input example", "context" and "features". Given that much of the paper is devoted to 1-dev, it's a bit disappointing that this issue is not analyzed in more detail, and furthermore the results are mostly hidden in the appendix.
I now think the paper does just enough to warrant acceptance, although I remain a bit concerned that since the benefits are only achievable with customized hardware, the relevance/applicability of the work is somewhat limited. - Alg 2: Should it be Δ or Δk+1? *l2 -> L_2 or l_2 in section 3.1 last paragraph. *Delta -> \\Delta in last paragraph of section 2.2 - Section 3: What about compression results for CIFAR and SVNH? It would be interesting to know an analogy, for instance, saying that this adaptive compression in memory would be equivalent to quantizing all weights with n bits.
It would be interesting to see what are values of \\gamma(\\phi) and L(\\phi) for some distributions (e.g. Gaussian, uniform in hypercube, etc.) to give more intuitions. A major strength of the result is that it can work for general continuous distributions and does not really rely on the input distribution being Gaussian; the main weakness is that some of the distribution dependent quantities are not very intuitive, and the alignment requirement might be very high.
This paper introduces a method for learning new tasks, without interfering previous tasks, using conceptors. In Section 2 the authors review conceptors. The main advantage of using conceptors is their trait of boolean logics: i.e., their ability to be added and multiplied naturally. The main advantage of using conceptors is their trait of boolean logics: i.e., their ability to be added and multiplied naturally.
This paper designs a new IPM(Integral Probability Metric) that uses the gradient properties of the test function.
This paper designs a new IPM(Integral Probability Metric) that uses the gradient properties of the test function. In this paper, the authors treat the descriptive text as answers, is this motivation still true if the question generation is conditioned on answers, not descriptive text? The paper is well written and easy to follow. 3: In section 4.2, the authors claim this is the theoretical explanation of the generalization capability of the proposed model (also appear in topic effect analysis). I think the proposed work is mostly related to: 1) "Towards Natural Question-Guided Search" by Kotov and Zhai (2010), and 2) "K2Q: Generating Natural Language Questions from Keywords with User Refinements" by Zheng et al. (2011), and other recent factoid question generation papers where questions are generated from a given fact (e.g. "Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus" by Serban et al. (2016)). Overall, a misconception about topic vs. I would also suggest, for your next experiments, that you try to generate questions leading to answers with list of values. Hence I suggest you revise your qt set. I would also suggest, for your next experiments, that you try to generate questions leading to answers with list of values. Hence I suggest you revise your qt set.
According to the authors, this paper extends(?) previous results on a NN with a single layer with a single unit. Summary: The paper considers the problem of a single hidden layer neural network, with 2 RELU units (this is what I got from the paper Given this architecture, the authors focus on characterizing the objective landscape of such a problem. In the abstract the authors state that it has to do with a two-layer RELU network with two hidden units (per layer? Comments: 1. The paper mainly focuses on a specific problem instance, where the weight vectors are unit-normed and orthogonal to each other. It doesn't seem to be relevant to the results of this paper (because the NN architecture proposed in this paper is rather small). Another issue is the fact that, on my humble opinion, the main text looks like a long proof.
The approach in this paper is to study a standard MNN with one hidden layer. 2) Lack of algorithmic results: While the volume of suboptimal DLM being small is an interesting result, it doesn't provide substantial algorithmic insight. The paper is well written and well presented, and the limitations of the approach, as well as its advantages over previous work, are clearly explained. This is a theory paper.
Summary: This paper studies the geometry of linear and neural networks and provides conditions under which the local minima of the loss are global minima for these non-convex problems. Authors claim their result extends the results for matrix completion from Ge et al. (2016) . This is false claim as (10) is not the matrix completion problem with missing entries, and the results in Ge et al. (2016) do not assume any non-degeneracy conditions on W. This seems to be a limitation of the methodology: unless I'm missing something, this situation cannot be addressed using locally open maps. Authors claim their result extends the results for matrix completion from Ge et al. (2016) . This is false claim as (10) is not the matrix completion problem with missing entries, and the results in Ge et al. (2016) do not assume any non-degeneracy conditions on W.
Pros: - Nice model which seems to perform well. There are two benefits of using the tree2tree model: i) use the grammar of the language, and ii) use the structure of the tree for locating relevant sub-trees Does it work in a context-free, bottom-up fashion?
As pointed out by the authors themselves for b=1 Swish is equivalent to SiL proposed in Elfwing et. 3. For leaky ReLU, use larger alpha will lead better result, eg, alpha = 0.3 or 0.5. Comments: 1. The search function set and method is not novel. Overall, I think this paper is not meeting *CONF* novelty standard.
This paper presents a study of reinforcement learning methods applied to Erdos-Selfridge-Spencer games, a particular type of two-agent, zero-sum game. The paper presents Erdos-Selfridge-Spencer games as environments for investigating deep reinforcement learning algorithms. Is that what is meant by the sentence on page 6 "We conjecture that reinforcement learning is learning to focus most on moves that matter for winning"? And how is this done. For instance, if there are a large number of elements in l, and or phi(A_{l+1}) is very close to 0.5 (or phi(A_l) is very close to 0.5) then this doesn't give the attacker the opportunity to fine tune the policy to select very good partitions. This feels a little under-justified. And how is this done. Various points: - The explanation of the Erdos-Selfridge-Spencer attacker-defender game is clear. A linear baseline also allows for easy interpretation of what is learned (is it the exact formula of phi(S)?), and can be parametrized to work with varying values of K. - The comparison of supervised learning vs RL performance is interesting. It seems the game is easy from a reinforcement learning standpoint, and this is not necessarily a bad thing, but then the experimental study should be more rigorous in term of convergences, error bars, and baselines. What is meant by this? • As the authors state, this paper is an empirical evaluation, and the theorems presented are derived from earlier work.
Imagine a slight twist on the game: There is a sword (with a lock on it), a key, a slime and the door (and maybe some spikes). Both the premises assumed and the conclusions drawn are quite reasonable given the experimental paradigm and domain in which they are conducted. The paper is clearly written, and the experiments follow a clean and coherent narrative. Overall: I really enjoyed reading this paper and think the question is super important. Given recent advances in RL and ML that eschew all manner of structured representations, I believe this is a well-timed reminder that being able to transfer know-how from human behaviour to artificially-intelligent ones. Considering a simple video game, where an agent receives a reward when she completes a game board, this paper starts by stating that: - Firstly, the humans perform better than an RL agent to complete the game board. If I have no doubts about these results, I have a concern about the method. In that case, how is it different from So it cannot be concluded that the change of performances is due to human priors. Here without semantic priors I would hypothesize that human performance would fall quite far (whereas with semantics people would be able to figure it out quite well). Here without semantic priors I would hypothesize that human performance would fall quite far (whereas with semantics people would be able to figure it out quite well). Issue 0: The experiments seem underpowered / not that well analyzed. The authors interpret the fact that performance falls so much between conditions b and c to mean that human priors about "objects are special" are very important.
In this paper the author propose a CNN based solution for somatic mutation calling at ultra low allele frequencies. Summary: In this paper the authors offer a new algorithm to detect cancer mutations from sequencing cell free DNA (cfDNA). Albeit the above caveats, we iterate the paper offers a nice construction for an important problem. Pros: The paper tackles what seems to be both an important and challenging problem. Can they show a context they learned and make sense of it? It appears that the proposed method (Kittyhawk) has a steep decrease in PPV and enrichment for low tumor fraction which are presumably the parameter of greatest interest. The "pipeline" is never well defined, only implicitly in p.7 top, and then it is hard to relate the various figures/tables to bottom line results (having the labels wrong does not help that). The idea is that in the sample being sequenced there would also be circulating tumor DNA (ctDNA) so such mutations could be captured in the sequencing reads. Moreover, the authors themselves suggest how to proceed along this line of research with further improvements. It is not clear what is the source of the other cancer control case. Many terms are not defined or defined after being introduced (e.g. CIGAR, MF, BQMQ). If the entire point is to classify mutations versus errors it would make sense to combine their read based calls from multiple reads per mutations (if more than a single read for that mutation is available) - but the authors do not discuss/try that. How does this relate to the original papers they cite to motivate this direction (Alexandrov 2013)? Moreover, the authors themselves suggest how to proceed along this line of research with further improvements.
The paper presents a combination of evolutionary computation (EC) and variational EM for models with binary latent variables represented via a particle-based approximation. evolutionary EM algorithms, even though they exist for the models in question. Detailed comments: 1. When revising the paper for next submission, please make the title more specific.
2. say the test function, which originally should be in an RKHS, will be approximated using random feature approximations. I still recommend rejection for the paper, and as I said in the first review, the paper is not mature enough. Also the paper is not clearly written, and I would suggest better not to copy-past paragraphs in the abstract and intro.
The paper describes an empirical evaluation of some of the most common metrics to evaluate GANs (inception score, mode score, kernel MMD, Wasserstein distance and LOO accuracy). In the paper, the authors discuss several GAN evaluation metrics. Section 4 summarizes the results, which concluded that the Kernel MMD and 1-NN classifier in the feature space are so far recommended metrics to be used. I think this paper tackles an interesting and important problem, what metrics are preferred for evaluating GANs. In particular, the authors showed that Inception Score, which is one of the most popular metric, is actually not preferred for several reasons. Appendix G in https://arxiv.org/pdf/1706.04987.pdf) Do you think it would be useful to compare other generative models (e.g. VAEs) using these evaluation metrics? Cons -It is not clear why GANs are the only generative model considered -Unprecedented visual quality as compared to other generative models has brought the GAN to prominence and yet this is not really a big factor in this paper. - The authors implicitly contradict the argument of Theis et al against monolithic evaluation metrics for generative models, but this is not strongly supported. The authors point out that different architectures yield similar results for their analysis, however it is not clear how the biases of the learned representations affect the results. The use of learned representations needs more rigorous justification -The evaluations rely on using a pre-trained imagenet model as a representation. Although this work and its results are very useful for practitioners, it lacks in two aspects. Thanks for an interesting paper. Thanks for an interesting paper.
The authors propose a method for graph classification by combining graph kernels and CNNs. In a first step patches are extracted via community detection algorithms. * The weights refer to the RKHS and filters are not easily interpretable. Frequent subgraph mining is extensively used in various methods for classification of graph-structured data, for example: * Tsuda, K., Entire regularization paths for graph data, ICML 2007. - It is mentioned that the parameter h is fixed to 5 in the WL kernel. In contrast, parameters (number of epochs and the learning rate) are tuned in the proposed method.
There is a (non-negative) importance weight associated with each state and a collection of states has weight that is simply the product of the weights. According to that, the experiments they demonstrated in this article are not well designed so that the conclusion they made in this article is not robust enough. Negatives: - The math is fudged around quite a bit with approximations that are not always justified The proposed architecture could identify the 'key' states through assigning higher weights for important states, and applied reservoir sampling to control write and read on memory.
According to that, the experiments they demonstrated in this article are not well designed so that the conclusion they made in this article is not robust enough. DReLU shifts ReLU from (0, 0) to (-\\sigma, -\\sigma). Using DReLU to improve the state-of-art neural network in an uncontrolled setting is important. 3) Batch normalization is popular, especially for the convolutional neural networks. Although DReLU's expectation is smaller than expectation of ReLU, but it doesn't explain why DReLU is better than very leaky ReLU, ELU etc. I personally have tried ELU/LReLU/RReLU on Inception V3 with Batch Norm, and all are better than ReLU. 3. In all experiments, ELU/LReLU are worse than ReLU, which is suspicious. Although the BN paper suggests using BN before non-linearity many articles have been using BN after non-linearity which then gives normalized activations (https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md) and also better overall performance.
The method presented in this paper seems to be novel but lacks clarity unfortunately. The defended idea is to use the context to fit a mixture of Gaussian with a NN and to assume that the noise could be additively split into two terms. I agree that in practice this effect can be mitigated at that the strategy can be correct in the contextual case (but then I'd like to the dependancies on x to be clear) * As an example using O(1000) and O(1M) in the figure one. * For eqn (1) it would be better to refer to and "optimistic strategy" rather to UCB because the name is already taken by an algorithm which is not this one. The idea is interesting but maybe not pushed far enough in the paper: *At fixed context x, assuming that the error is a function of the average reward u and of the number of displays r of the context could be a constant could be a little bit more supported (this is a variance explanation that could be tested statistically, or the shape of this 2D function f(u,r) could be plot to exhibit its regularity). It is clearly not sufficient to me, as it does not gives insights about why such proposal is done. 2. In Section 4.2.1, CTR is modeled as a Gaussian mixture, which doesn't look quite right, as CTR is between (0,1). The only positioning argument that is given in that section is the final sentence "In this paper we model measurement noise using a Gaussian model and combine it with a MDN". Other remarks: - Equation (1) does not fit with mixtures considered in 4.2.1.
The paper proves the separation by constructing a very specific function that cannot be approximated by 2-layer networks. In fact, these last two papers go further and show that this has implications for learnability not just for representation as the current paper shows. In a sense, this is complementary to the separation result in Safran and Shamir (2017), mentioned by the authors, where the function is arguably "natural", but the distribution is not.
The paper proposes to make the inner layers in a neural network be block diagonal, mainly as an alternative to pruning. Why was this mentioned? And it doesn't seem to be comparable. (4) there is some vague connection to random matrices, with some limited experiments that are consistent with this observation but far from establish it, and without any theoretical analysis (Martingale or Markov chain theory)
What I like about Neural-Programmer Interpreters and Neural Programmer [1] is that they are tested on less toyish tasks (a computer vision and a question answering task respectively), and I believe the presented method would be more convincing for a more realistic downstream task where hints are noisy (as mentioned on page For instance, when providing input-output examples as well as the auxiliary loss in Eq6, what exactly is left to learn?
What I like about Neural-Programmer Interpreters and Neural Programmer [1] is that they are tested on less toyish tasks (a computer vision and a question answering task respectively), and I believe the presented method would be more convincing for a more realistic downstream task where hints are noisy (as mentioned on page On the positive side, it is nice to read a paper that focuses on understanding what an agent is learning. This, however, is not addressed in the paper. In particular, I did not see the value of situating their model in a grounded environment. Additionally, I was unconvinced that simpler models could not be used to examine the phenomena that they analyzed. I found the analogy persuasive in theory, but I was not convinced that the current manuscript really demonstrates its value. 5. The section on layerwise attention claims to give a "computational level" explanation, but this is a misleading term to use — it is not a computational level explanation in the sense introduced by David Marr which is the standard use of this term in cognitive science. I also found it hard to understand why colors were hard to learn given the bias towards colors shown earlier in the paper. 3 A situated language learning agent Also, I don't see what we should learn from Figure 5 (besides the fact that in the controlled condition shapes are easier than categories). "naturalistic" analyses in the word learning section did not convince me.
However, when RL is applied to navigation problems it is tempting to evaluate the agent on unseen maps in order to assess weather the agent has learned a generic mapping & planning policy. By the way to me results presented in figure 5 are not enough to claim that the agent trained on random map is implementing a purely reactive wall-following strategy. This paper is a critique of deep reinforcement learning methods for learning to navigate in 3D environments, and seems to focus intensively on one specific paper (Mirowski et al, 2016, "Learning to Navigate in Complex Environments") and one of the architectures (NavA3C+D1D2L) from that paper. By the way to me results presented in figure 5 are not enough to claim that the agent trained on random map is implementing a purely reactive wall-following strategy.
Based on experiments using CIFAR10, the authors show that adversarial training is effective in protecting against "shared" adversarial perturbation, in particular against universal perturbation. There is also no analysis of what happens for adversarial examples for the detector. The paper shows that adversarial training increases the destruction rate of adversarial examples so that it still has some value though it would be good to see if other adversarial resistance techniques show the same effect. - The visualizations of universal perturbations as they change during AT are nice.
This paper discusses using neural networks for super-resolution. The authors relate the training of a single filter (or neuron) to equation (7), but they define D, that is not used in all of Section 2.1. The authors relate the training of a single filter (or neuron) to equation (7), but they define D, that is not used in all of Section 2.1.
FractalNets amd DiracNets (https://arxiv.org/pdf/1706.00388.pdf) have demonstrated that it is possible to train deep networks without skip connections and achieve high performance. Just because a network performs averaging of different paths and individual paths perform worse than sets of paths doesn't imply that ensembling as a mechanism is in fact the cause of the performance of the entire architecture. You claim that FractalNet shows no ensemble behavior. While this is not explicitly mentioned in the FractalNet paper, it clearly would not break the design principle of FractalNet which is to train a path of multiple layers by ensembling it with a path of fewer layers.
Just because a network performs averaging of different paths and individual paths perform worse than sets of paths doesn't imply that ensembling as a mechanism is in fact the cause of the performance of the entire architecture. And crudely speaking, you can think of a class weight to be the expectation of its sample weights and you will end up in a similar setup. In Line 3 of the paragraph below Equation 5, "classe" should be "class".
The authors observe that the proposed recurrent identity network (RIN) is relatively robust to hyperparameter choices. - It seems from Figure 4 (a) that the average estimation error is higher for RIN than IRNN and LSTM and only decrease toward zero at the very end.
The paper presents a number of interesting results: 1) Larger networks are typically more learnable than smaller ones (typically we think of larger networks as being MORE complicated than smaller networks -- this result suggests that in an important sense, large networks are simpler). These results nicely complement the work which studies the "sharpness/curvature" of the local minima found by neural networks, which argue that the minima which generalize better are those with lower curvature. It is clear that VC dimension and radamacher complexity alone are not enough to explain the generalization performance of neural networks, and that neural networks with high capacity by these definitions are likely "simple" by other definitions (as we have seen in this paper). A small network (N1 = 16 neurons) with low test accuracy results in a low learnability, while a large network (N1 = 1024 neurons) gets a higher test accuracy and higher learnability. How different would that be in terms of simply learning random labels on real data directly. -As suggested in the final sentence of the discussion, it would be nice if conclusions drawn from the learnability experiments done in this paper were applied to the design new networks which better generalize Summary: This paper presents very nice experiments comparing the complexity of various different neural networks using the notion of "learnability"
- Previous compression work uses a lot of tricks to compress convolutional weights. I think this is a key experiment that should be run as this result would be much easier to compare with the other methods.
This is, i beleive, the field of "statistics" or "probability" for correlated variables. This true for a field theory, as well for continous theories of, say, mechanics, fracture, etc...
Cons: * Not a clear paper Mostly it is hard to estimate what is the contribution of the model and how the results differ from baseline models. Based on its incremental nature and weak experiments, I'm on the margin with regards to its acceptance. For example, the new energy function in equation (4) larges achieves similar goal as the original energy (1) proposed by Zhao et. Quality and significance: This is quite a technical paper, written in a very compressed form and is a bit hard to follow.
The paper does a good job of setting up and comparing empirical performance of various regularizers (penalties on weights and penalties on hidden unit representations) and compares results against a baseline. DNNs are rather pipes that transform information from one domain to another, where representations are learned as an intermediate model as the information is being transformed. All that is derived is that it may be a good idea to penalise large variations in the representation -- within-class variations, in particular.
Also a bit confusing is the notation "conv2", "conv3", etc. Another broader question I have is in the distinction between lower and upper layers (those referred to as "feature extracting" and "classification" in this paper). Heuristics for distributing connections among windows/groups and a measure called "scatter" are introduced to construct the connectivity masks, and evaluated experimentally on CIFAR-10 and -100, MNIST and Morse code symbols. So it seems that expanding the investigation to include all layers, or at least more layers, would be good:  It might be that more of the "classification" function is pushed down to lower layers, as the upper layers are reduced in size. While it seems clear in general that many of the connections are not needed and can be made sparse (Figures 1 and 2), I found many parts of this paper fairly confusing, both in how it achieves its objectives, as well as much of the notation and method descriptions.
The authors present a solid overview of unsupervised metrics for NLG, and perform a correlation analysis between these metrics and human evaluation scores on two task-oriented dialog generation datasets using three LSTM-based models. 1) This paper conducts an empirical study of different unsupervised metrics' correlations in task-oriented dialogue generation. iii) About the scatter plot Figure 3, the authors should include more points with a bad metric score (similar to Figure 1 in Liu 2016). iii) About the scatter plot Figure 3, the authors should include more points with a bad metric score (similar to Figure 1 in Liu 2016).
What is the size of the database?
The clustered representations are the visual concepts. Also the second experiment, which shows the spatial clustering for the "car wheel" VC, is unclear, how is the name "car wheel" assigned to the VC? That would make sense, given that then the dimensions of the vector f_p is a scalar (activation value) per image for that image, in layer k, around pixel p. Also the second experiment, which shows the spatial clustering for the "car wheel" VC, is unclear, how is the name "car wheel" assigned to the VC? For example, the introduction is written rather "arrogant" (not completely the right word, sorry for that), with a sentence, like "we have only limited insights into why CNNs are effective" seems overkill for the main research body.
- I am confused by the references in the caption of Table 3 - surely the Waibel reference is meant to be for TDNNs (and should appear earlier in the paper), while p-norm came later (Povey used it first for ASR, I think) and is related to Maxout - What is a "sequence-level variant of CTC"? In the last paragraph of section 3.2, why is there a huge difference in real-time factors between the clean and other set? - what is the relationship of the presented ASG criterion to MMI? not sure if it would help, but it might The paper describes some interesting work but for a combination of reasons I think it's more like a workshop-track paper. - What is a "sequence-level variant of CTC"?
The idea is introduced clearly and rather straightforward. (2) the results on MNIST and CIFAR 10 are not good enough for practical deployment. 1. After equation (5), I don't understand how the gradient of L(tilde_W) w.r.t. B(i) is computed.
In particular: a) Data augmentation is a very domain specific process and limits of augmentation are often not clear. Delving deeper into this could make the paper a lot stronger.
Previous approaches for question answering with module networks can (at best) make a hard choice among a small number of structures. Will this work in larger domains? MODELING Figure 2 is great. It would be nice to have a little bit of discussion about the motivation for these particular modeling implementations---some are basically the same as in Hu et al. (2017), but obviously the type system here is richer and it might be helpful to highlight some of the extra things it can do. Johnson)? Can you provide experimental evidence of this?
The paper is thorough and well-explained. The presentation is very clear, the design of the architecture is beautiful, and I was especially impressed with the related work discussion that went back to identify other game search and RL work that attempts to learn parts of the search algorithm. This seems risky, and I suspect that UCB and more statistically principled approaches would be more robust in this regard? I'm sure I'm misinterpreting some detail here, but how is this a fair comparison? I know that many of them can be solved by A* search with a decent heuristic. + is R_1 similar to R^1 In overall, it is a nice idea to use DNN to represent all update operators in MCTS. I suspect that the O(N^2) complexity is very prohibitive and will not allow this to scale up? I suspect that generating the training data and learning the model takes an enormous amount of CPU time, while 25 MCTS rollouts can probably be done in a second or two. Is it the reason why in experiments M is always small and increasing it does not make a huge improvement?. The proposed method allows each component of MCTS to be rich and learnable, and allows the joint training of the evaluation network, backup network, and simulation policy in optimizing the MCTS network.
If that is not the case, This seems risky, and I suspect that UCB and more statistically principled approaches would be more robust in this regard?
The structured deep-in factorization machines allow higher-level interactions in embedding learning which allows the authors to learn embeddings for heterogeneous set of features. ---------- OVERALL JUDGMENT The paper is not clear and thus I am not sure what I can learn from it. This proposed scheme is evaluated on two datasets -- movies and education in a retrieval setting. Finally, the most striking flaw of this paper is the lack of references to previous works on word embeddings and feature representation, I would suggest the author check and compare themselves with previous work on this topic. This paper provides a clean way of learning embeddings for structured features that can be discrete -- indicating presence / absence of a certain quality. ---------- DETAILED COMMENTS When the authors refer to word2vec is not clear if they are referring to skipgram or cbow algorithm, please make it clear. The novelty of the proposed approach seems limited in light of the related paper that is concurrently under review at *CONF*2018, on which this paper heavily relies. Comments: The paper is well written and addresses an important problem of learning word embeddings when there is inherent structure in the feature space.
This paper proposes a fast way to learn convolutional features that later can be used with any classifier. The acceleration of the training comes from a reduced number of training epocs and a specific schedule decay of the learning rate. This paper proposes a fast way to learn convolutional features that later can be used with any classifier. Two proposals in the paper are: (1) Using a learning rate decay scheme that is fixed relative to the number of epochs used in training, and And for (2), it is a relatively standard approach in utilizing CNN features.
This writeup describes an application of recurrent autoencoder to analysis of multidimensional time series. The paper describes how existing methods are applied to a specific data set. As a result, it is quite difficult to judge the merits and novelty of the paper. The paper doesn't frame the work in prior research at all and the six papers it cites are only referred to in the context of describing the architecture. In short, the paper in its current form does not provide sufficient details for the reviewer to judge its merits and contributions.
Technically speaking, the proposed self-supervised scheme with two conv nets is very interesting. The inability to choose the optimal number of atoms is a major drawback of the method, and the experimental section could be improved. Cons: - it would be a bit unconvincing that identifying 'hard selection' is better suited for neural nets, rather than many existing exact methods (without using neural networks). The model is experimented on two small datasets of few thousand of molecules, and compared to a state-of-the-art DeepTox, and also to some basic baselines (RF/SVM/logreg). The key problem of the method is its seeming inabability to find the correct number of atoms to use. Overall the method is interesting and has a clear impact for molecular prediction, however the paper has limited appeal to the broader audience.
This work proposes a multi task learning framework for the modeling of clinical data in neurodegenerative diseases. 2. On-line settings to train parameters ( guaranteed convergence in a single pass of the data) However, in this experiment, the features are handcrafted before they are fed into the models. ( As proposed model is a deep model, the lack of comparison with deep methods is dubious) What is the interest of predicting baseline (or 6 months at best) cognitive scores (relatively low-cost and part of any routine clinical assessment) from brain imaging data (high-cost and not routine)? For this reason the Gaussian assumption for the cost function used in the method is still not appropriate for the proposed application. Conclusion: Though with a quite novel idea on solving multi-task censored regression problem, the experiments conducted on synthetic data and real data are not convincing enough to ensure the contribution of the Subspace Network. If this is due to space limitation in the main text, they may want to provide a complete proof in the appendix. - The computation time for the linear model shown in Table 3 is quite surprising (~20 minutes for linear regression of 5k observations).
The authors tackle the problem of estimating risk in a survival analysis setting with competing risks. ( As proposed model is a deep model, the lack of comparison with deep methods is dubious) Related works: - For your consideration: is multi-task survival analysis effectively a competing risks model, except that these models also estimate risk after the first competing event (i.e. in a competing risks model the rates for other events simply go to 0 or near-zero)? - The authors introduce F(t, D | x) as cumulative incidence function (CDF) at the beginning of section 2, however, afterwards they use R^m(t, x), which they define as risk of the subject experiencing event m before t. - The competitive gain of the authors method in comparison with other competing methods is minor.
Related works: - For your consideration: is multi-task survival analysis effectively a competing risks model, except that these models also estimate risk after the first competing event (i.e. in a competing risks model the rates for other events simply go to 0 or near-zero)? For example, just say "We distill a parent model to a child model with a subset of the labels." Related works: - For your consideration: is multi-task survival analysis effectively a competing risks model, except that these models also estimate risk after the first competing event (i.e. in a competing risks model the rates for other events simply go to 0 or near-zero)?
The fact that these different inverse maps arise under these conditions is interesting --- and Figure 5 is quite convincing in showing how each expert generalizes. Overall, it is nice to see the different inverse maps arise naturally in this setting. Another direction I think would be interesting, is how few examples are needed in the canonical distribution? Another direction I think would be interesting, is how few examples are needed in the canonical distribution?
Most seriously though, Part (3) only considers critical points (i.e., derivative equal to zero), not local minima occurring at non-differentiable locations. Clarity: - The main claims/results in the paper are not stated very clearly, and the authors are not clear about what the contributions of the paper are or why they are useful. They conjecture, and then attempt to argue for a simple network, that, over these regions, the loss function exhibits nice properties:  all local minima are global minima, all other local optima are saddle points, and the function is neither convex nor concave on these regions.
The authors use an energy function based approach. The distribution output from a given node is defined in terms of a learned conditional probability function, and the output distributions of its input nodes. The novelty in the paper is implementing such a regression in a layered network. However, this experiment uses 3BE outside of its intended use case --- which is for a single input distribution --- so it's not entirely clear how well the very simple proposed model is doing.
The paper tries to build an interpretable and accurate classifier via stacking a supervised VAE (SVAE) and a differentiable decision tree (DTT). However, in this case, the latent space is being used as input to the tree. I personally think some of the dimensions of the latent variables of the vanilla VAEs can also be interpreted via interpolation in each dimension.
latent variable used to simplify the calculation of the entropy H(Y|C) is confusing and needs revision, but otherwise the paper is interesting. I(C;Y) = H(Y) - H(Y|C). I(C;Y) = H(Y) - H(Y|C).
This, however, is not the case. I appreciate the importance of noise modeling, but not sure if the presented algorithm is a right way to do it. However, we strongly recommend keeping the paper at 8 pages, plus 1 page for the references and as many pages as needed in an appendix section (all in a single pdf).
The proof states that Y -> T -> X forms a Markov chain, but this implies that T is a function of
This work proposed an interesting graph generator using a variational autoencoder. Strengths: - Generating graphs is an interesting problem, and the proposed approach seems like an easy-to-implement, mostly reasonable way of approaching the problem. Strengths: - Generating graphs is an interesting problem, and the proposed approach seems like an easy-to-implement, mostly reasonable way of approaching the problem. The main challenges of generating graphs as opposed to text or images are said to be the following: (a) Graphs are discrete structures, and incrementally constructing them would lead to non-differentiability (I don't agree with this; see below) Strengths: - Generating graphs is an interesting problem, and the proposed approach seems like an easy-to-implement, mostly reasonable way of approaching the problem. Based on this motivation, the paper decides to generate a graph in "one shot", directly  outputting node and edge existence probabilities, and node attribute vectors. I see this as equivalent to choosing an order in which to linearize the order of nodes and edges in the graph. - many crucial elements  in graph generation are not dealt with: a) the adjacency matrix and the label tensors are not independent of each other, the notion of a graph is in itself a way to represent the 'relational links' between the various components I would have at least liked to see a comparison to a method that generated SMILES format in an autoregressive manner (similar to previous work on chemical graph generation), and would ideally have liked to see an attempt at solving the alignment problem within an autoregressive formulation (e.g., by greedily constructing the alignment as the graph was generated). - some of the main issues with graph generation are acknowledged (e.g. the problem of invariance to node permutation) and a solution is proposed (the binary assignment  matrix) - notions for measuring the quality of the output graphs are of interest: here the authors propose some ways to use domain knowledge to check simple properties of molecular graphs - The exposition is clear (although a bit more detail on MPM matching would be appreciated) To handle this, the paper proposes to use a simple graph  matching algorithm (Max Pooling Matching) to align nodes and edges. A graph is represented by a soft adjacency matrix A (entries are probability of existence of an edge), an edge attribute tensor E (entries are probability of each edge being one of d_e discrete types), and a node attribute matrix F, which has a node vector for each  potential node. A downside to the algorithm is that it has complexity O(k^4) for graphs with k nodes, but the authors argue that this is not a problem when generating small graphs. The search space of small graph generation is usually very small, is there any other traditional methods can work on this problem?
Unfortunately, I do not understand main points made in this paper and am thus not able to give an accurate evaluation of the technical content of this paper. My comments / feedback: The paper is well written and the problem addressed by the paper is an important one. 1.3 In point (ii) under the maximum likelihood section, I don't understand it at all and I think both sentences are wrong. (1) *cannot* really be the true distribution, because the true distribution is unknown and therefore cannot be used to construct estimators. For example, 1.1 The q(.|.) distribution in Eq. 1. The idea is a good one and is great incremental research building on the top of previous ideas. To sum up, I can not recommend the paper to acceptance, because (a) an important baseline is missing (b) there are serious writing issues. Same applies to the dirac distribution q(y|x), the true conditional distribution of outputs given inputs is multimodal even for machine translation. 1.2 I understand that the ML objective is different from what the users really care about (e.g., blue score), but this does not seem a "discrepancy" to me. It is mentioned that r is a "reward" function, but I don't know what it means and the authors should perhaps explain further. 2. For the RL approach, I think it is very unclear as a formulation of an estimator. (b) Experimental Results 2. The performance of the proposed method is not significantly better than other models in MT task.
It would be much valuable to see ablation studies to show the effectiveness of such criterion: for example, simple cases one can think of is to model It is definitely surprising that a simple method like this ends up working this well.
In general, I think the problem studied in this paper is very interesting, and the topic of counterfactual learning, especially policy optimization with the use of offline and off-policy log data, is important. So I find it a bit misleading to suggest that the learned policy are not being improved when the logging policy is more deterministic. The contribution of this paper is of two-fold: 1) the authors extend the results from Cortes's paper to derive a new surrogate objective function, and 2) they show how this objective can be approximated by f-GAN techniques.
The improved upper bound given in Theorem 1 appeared in SampTA 2017 - Mathematics of deep learning ``Notes on the number of linear regions of deep neural networks'' by Montufar. The improved upper bound for maxout networks follows a similar intuition but appears to be novel. However, the new bounds proposed (Theorem 1, Theorem 6), seem like small improvements over the previously proposed bounds, with no other novel interpretations or insights into deep architectures. However, the new bounds proposed (Theorem 1, Theorem 6), seem like small improvements over the previously proposed bounds, with no other novel interpretations or insights into deep architectures. Finally, for small networks, they formulate finding linear regions as solving a linear program, and use this method to compute the number of linear regions on small networks during training on MNIST
The critical insight is that the hidden states in the LAM are not coupled allowing considerable flexibility between consecutive conditional distributions. Comparing with the Masked Autoregressive Flows (Papamakarios et al., 2017) paper, it seems that the true difference is using the linear autoregressive transformation (LAM) and recurrent autoregressive transformation (RAM), already present in the Inverse Autoregressive Flow (Kingma et al., 2016) paper they cite, instead of the masked feedforward architecture used Papamakarios et al. (2017). The critical insight is that the hidden states in the LAM are not coupled allowing considerable flexibility between consecutive conditional distributions.
Once we train and achieve a network with best performance under this constraint, we take the sign of each weight (and leave them intact), and use the remaining n-1 bits of each weight in order to add some new connections to the network. Are there studies where the capacity of such networks is investigated, when all the weights are trained concurrently.
This randomization does not account for the many experiments that were required to find this range. While I believe that raising this issue is important and that the method proposed is a step in the right direction, I have a number of concerns which I will list below.
That is, transforming the original model constructed from indicator functions (hence difficult to optimize by gradient based method) to a smooth differentiable function by diffusing the landscape. This paper proposes a soft relaxation of the box lattice (BL) model of Vilnis et al. 2018 and applies it to several graph prediction tasks. The observation is that when two boxes are disjoint in the model but have overlap in the ground truth, no gradient can flow to the model to correct the problem (which is happens in case of sparse-data. meet and join definitions seems to refer to a set product, while the p(a) equation has a standard product (or does it?). An illustrating figure would still be nice to include, also for the convolutions of eq 2. This paper presents a novel, theoretically well-justified idea with excellent results, and is likely going to be a high-impact paper. Similarly in Flickr and MovieLens the method performs well. This paper presents a novel, theoretically well-justified idea with excellent results, and is likely going to be a high-impact paper.
The conjecture is interesting and it is still a open question for whether a pruned network can reach the same accuracy when trained from scratch. The authors show that there exist sparse subnetworks that can be trained from scratch with good generalization performance. The conjecture is interesting and it is still a open question for whether a pruned network can reach the same accuracy when trained from scratch. Given our lack of understanding of the optimization and generalization properties of neural networks, as well as how these two interact, then any insight into this process, like this paper suggests, could have a significant impact on both theory and practice. As a minor note, "generalization accuracy" as a term is not that common and might be a bit confusing, so it is better to write "test accuracy". After reading the rebuttal and the revised version, though the paper has been improved, my concerns are not fully addressed to safely accept it.
This result is surprising - the usual network pruning procedure assumed that a network is pretrained, and only then important connections are removed. This paper is well written and explains the main idea in a clear and effective manner. Please relate to it. Fundamentally, if you decouple weight pruning from initialization it also means that: - the first layer will be pruned out of connections to constant pixels (which is seen in the visualizations), this remains meaningful even after a reinitialization Because of that, I wouldn't call any particular weight/connection architecturally important and find it strange that such weights are found. Authors introduce  a criterion to be used for identifying important parts of the network (connection sensitivity), that does not depend on the magnitude of the weights for neurons: they start by introducing a set of binary weights (one per a weight from a neuron) that indicate whether the connection is on or off and can be removed. For this reason it might be worthwhile to plot the behaviour of the network as a function of "k". [4] Generalized Dropout. [5] Variational Dropout Sparsifies Deep Neural Networks. Furthermore, the authors should also refer to [5] as they originally did the same experiment and showed that they can obtain the same behaviour without any hyper parameters. - df/dc = df/d(cw) d(cw)/dc = df/d(cw) * w [2] A Simple Procedure for Pruning Back-Propagation Trained Neural Networks. [1] Skeletonization: A Technique for Trimming the Fat from a Network via Relevance Assessment. [3] Learning Sparse Neural Networks through L_0 Regularization.
In case when r < d, that is when the data distribution is supported on a low dimensional smooth manifold in the input space, things are quite different. Review summary: I would like to say that this paper was a breath of fresh air to me. In case when r < d, that is when the data distribution is supported on a low dimensional smooth manifold in the input space, things are quite different.
The idea is interesting, and the paper ideas are clear to follow. The idea is interesting, and the paper ideas are clear to follow. These include identifying a matching face in a set of faces (1,2 or N faces) for a given voice, or vice versa. In my opinion, this calls into question the hypothesis that what drives the improved performance is the fact that these models are trained to predict the covariates. Authors aim to reveal relevant dependencies between voice and image data (under a cross-modal matching framework) through common covariates (gender, ID, nationality).
I also find the claim of section 4.1 to be a bit mis-leading because it is claimed that weight decay applied with SGD and batch normalization only has benefits due to batch-norm dynamics, and not due to complexity control even though in Fig 2 and 4, there is a noticeable difference between training without weight decay, and training with weight decay only on last layer. This is more reasonable because bias terms have no effect on complexity and so it is reasonable to not apply weight decay on bias.
The paper presents a learning-based method for learning the latent context codes from demonstrations along with a GAIL model. The idea of using directed information for GAIL is novel and very interesting. However in the actual model, the authors make a sequence of variational approximations -- (a) reduction of eq2 to eq1 with a variation lower bound on posterior p(c|c,\\tau) and then replace the prior p(c) with q(c|c,\\tau) in eq 5. For example how many seeds have you used? * The paper is very well-written the goal and motivation of the paper is quite clear. This amounts to learning the option segments and the policies simultaneously.
The main advantage of the proposed method as illustrated in particular by the experimental results in the citation network domain is its ability to generalize well in the presence of a small  amount of training data, which the authors attribute to its efficient capturing of both short- and long-range interactions. The proposed method is novel and achieves good results on a set of experiments. This is a very good paper. However, that brings probably to one of the main issues with the papers - the authors are obviously very knowledgeable in graph convnets, graph signal processing, and optimisation. The core idea is to use the Lanczos algorithm to obtain a low-rank approximation of the graph Laplacian.
that can or that did discover? [Strengths]: This paper shows some promise when graph network-based controllers augmented with evolutionary algorithms. Paper is quite easy to follow. The results in this paper are impressive, and the paper seems free of technical errors. This makes the contribution of this paper in terms of the method hard to judge. - Sec 4.1:  would argue that computational cost is rarely a concern among evolutionary algorithms. What is the point that you are trying to make? Detailed comments: - in the abstract you say that "NGE is the first algorithm that can automatically discover complex robotic graph structures". speed up what? why is this a trade-off? The cost of evaluating the function is typically more pressing, and as a result it is important to have algorithms that can converge within a small number of iterations/generations. Therefore I would like to see experiments with the ES cost function, but with inclusion of the pruning step, and experiments with the AF-function but without the pruning step. But there are better baselines possible. Humanoid etc. maybe? => Baselines: The comparison provided in the paper is weak. How would the given graph network compare to this? what is the metric that you consider? The authors propose a scheme based on a graph representation of the robot structure, and a graph-neural-network as controllers. One such example would be to have a network for each body part and share parameters across each body part.
Quality and clarity: The paper presents a theoretical framework and method to determine the necessary number of bits in a deep learning networks. The authors use their derived formula for VRR to predict the minimum mantissa precision needed for accumulators for three well known networks: AlexNet, ResNet 32 and ResNet 18. For tightness analysis they present convergence results while perturbing the mantissa bits to less than those predicted by their formula, and show that it leads to more than 0.5% loss in the final test error of the network. Or put it another way, this is a hyperparameter that the authors can tune to match their chosen benchmarks. This is surprising to me, as quantization is usually modeled as _adding_ noise, leading to an _increase_ in variance (Mc Kinstry et al. 2018), so this is a nice counterexample to that intuition.
Authors propose to augment a conditional GAN model with an unsupervised branch for spanning target manifold and show better performance than the conditional GAN in natural scene generation and face generation. This manuscript proposes a robust version of conditional GAN (named RoC-GAN) that leverage the intrinsic structure in the output space. - The idea is simple and seems to be working. Strength: 1. The idea is simple and straightforward. General: In general, this is a well-written paper. %%%%%%%% After rebuttal %%%%%%%% I appreciate authors' efforts to address my comments and am satisfied with their response. I will change decision from rejection to acceptance.
- The ideas presented in the paper might be useful for other researchers that could build upon them, and attempt to extend and generalize the results to different network architectures. Then, {\\bf Theorem 1} provides an upper bound for the empirical Rademacher complexity of the class of 1-layer networks with hidden units of bounded \\textit{capacity} and \\textit{impact}. The authors also given lower bounds on the empirical Rademacher complexity for carefully chosen data points, showing that the bounds are tight. Note that at no point are the bounds in this paper "nonvacuous", ie they are always larger than one. This paper tackles the important question of why in the context of supervised learning, overparametrized neural networks in practice generalize better. An empirical comparison with existing generalization bounds is made and the presented bound is the only one that in practice decreases when the number of hidden units grows.
This quantity is interesting also because it's somewhat independent of the variance of the stochastic gradient across minibatches (it's the time variance, in a way), and further analysis might also show interesting results. Also it would have been interesting to see a recurrent architecture there, as I've heard much anecdotal evidence about the robustness of RNNs and LSTMs to asynchronous training.
This work is appropriate for *CONF*. This work is appropriate for *CONF*.
Although the method the authors suggest is a plausible way to explicitly model the relationship between syntactic pairs and to create a combined embedding for them, their presentation does not make this obvious and it takes effort to reach the conclusion above. The topic is fitting with *CONF*, and some attendees will find the results interesting. Thus, from the latter we will obtain a tool for finding embeddings of idioms (i.e. v_a+v_b+T(v_a, v_b,.)). Pros: - theoretical justification is given for their assumption that the higher-order interactions can be modeled by a tensor The authors point out that others have observed that this form of compositionality does not leverage any information on the syntax of the pair (a,b), and the propose using a tensor contraction to model an additional multiplicative interaction between a and b, so they propose finding the word whose embedding is closest to a + b + T*a*b, where T is a tensor, and T*a*b denotes the vector obtained by contracting a and b with T. The topic is fitting with *CONF*, and some attendees will find the results interesting.
2. The finding that there are center-surround or asymmetric (non-gabor) RFs in mouse V1 is not novel and not specific to this model (e.g. Antolik et al., 2016). Update after revisions: The authors performed extensive work to address my concerns.
I think that the dataset generation process is well-thought-out. Verdict: I thought this was generally an interesting paper that has some very nice benefits, but also has some weaknesses that could be resolved. - The general methodology of generating questions and ensuring that no question is too rare or too frequent and the test set is sufficiently different---these are important questions and I commend the authors for providing a strong methodology. The use of "blank inputs (referred to as "thinking steps")" in "Simple LSTM" and "Attentional LSTM" doesn't seem to be a standard approach. For example, the answer being a special "this is impossible" character for "factorise x^2 - 5" (if your training set does not use \\sqrt, of course). My main concerns are about the evaluation and comparison of standard neural models. This seems incomplete to me: there are tens of thousands (probably more) of exercises and problems available in workbooks for elementary, middle, and high school students. I am biased because I once did exactly the same thing as this paper, although at a much smaller scale; I am thus happy to see such a public dataset. I think the authors should move a portion of the big bar plot (too low resolution, btw) into the main text and discuss it thoroughly. The generation process of the dataset is well thought out. The main contribution is a synthetically generated dataset that includes a variety of types and difficulties of math problems; it is both larger and more varied than previous datasets of this type. The authors try to do this with composition, which is good, but I am not sure whether that captures the real important thing - the ability to generalize, say learning to factorise single-variable polynomials and test it on factorising polynomials with multiple variables? In fact, assuming that such methods outperform general-purpose models, we could investigate why and where this is the case (in fact the proposed dataset is very useful for this).
To approximate the gradient of the discriminator, they take samples of the generator parameters. its a probabilistic style optimisation for it, in the sense that you are defining a probability distribution (over qg(θg) and qd(θd)) and sampling from it, but its not really a "likelihood" in the formal sense. The authors should have their manuscript proof-read for grammar and vocabulary.
This paper is well written. At least this limitation should be pointed out in the paper. https://arxiv.org/abs/1810.01392 Pros: - Interesting observation of density modelling shortcoming - Lack of an extensive exploration of datasets Pros: - The finding that SVHN has larger likelihood than CIFAR according to networks is interesting. [Originality] I am not an expert in this specific field (analyzing generative models), but I believe this analysis is novel.
The paper shows that there is an alternating optimization-based algorithm for this problem that under standard assumptions provably converges exactly to the true dictionary and the true coefficients x (up to some negligible bias). I think the paper is relevant and proposes an interesting contribution. The paper deals with the problem of recovering an exact solution for both the dictionary and the activation coefficients. The paper is well written and the key elements are in the body. The authors suggest using Aurora 2015 as a possible initialization.
The "no bad local valleys" implies that for any point on the loss surface there exists a continuous path starting from it, on which the loss doesn't increase and gets arbitrarily smaller and close to zero. This paper presents a class of neural networks that does not have bad local valleys. The paper analyzes the loss landscape of a class of deep neural networks with skip connections added to the output layer. --In fact, in the 1st round read, I do not have a strong impression of "strict". 3)It may be better to mention explicitly that "it is possible to have bad local min" –perhaps in abstract and/or introduction. The good property of loss surface for networks with skip connections is impressive and the authors present interesting experimental results pointing out that
Since this emulation model is differentiable, they can easily train an algorithm to output a stroke to approximate the drawing via back propagation, and avoid using RL and costly compute such in earlier works such as [1]. Interpolations from raster-based generative models such as the original VAE tend to be blurry and not semantic. I think the value in this method is that it can be converted to a full generative model with latent variables (like a VAE, GAN, sketch-rnn) where you can feed in a random vector (gaussian or uniform), and get a sketch as an output, and do things like interpolate between two sketches. The main strength of this paper is the original thought that went into it. Most of it becomes clearer later in the paper - but I feel it would be good to put this into proper context here (or not mention it) I feel it would be important for this paper to add some quantitative measure of quality. Minor comments: - abstract: why is it like "dreaming" -> I do agree with the rest of that statement, but I don't see the connection to dreaming That being said, things are not all rosy, and I feel there are things that need to be done for this work to be ready for publication in a good venue like *CONF*. If not, and this work ends up getting rejected, please consider improving the work later on and submitting to the next venue.
This paper describes a framework - Tree Reconstruction Error (TRE) - for assessing compositionality of representations by comparing the learned outputs against those of the closest compositional approximation. Overall I think this is a solid paper, with an interesting and reasonable approach to quantifying compositionality, and a fairly compelling set of results. This in an interesting study and attacks a very fundamental question; tracking compositionality in representations could pave the way towards representations that facilitate transfer learning and better generalization. Overall I think this is a solid paper, with an interesting and reasonable approach to quantifying compositionality, and a fairly compelling set of results. The authors do not deal with trees in any of the examples, but rather with a set of primitives (apparent in the use of addition as a composition function which being commutative does not allow for word-order and the like deep syntactic properties). While the paper is very clear with respects to results, I found the presentation of the proposed measure overly confusing (and somewhat more exaggerated that what is really going on). Reviewer 2's comments also remind me that, from a perspective of learning composition-ready primitives, Fyshe et al. (2015) is a relevant reference here, as it similarly learns primitive (word) representations to be compatible with a chosen composition function.
In this paper, the authors proposed a new attack using deformation. This remark is important in that it changes my rating of the paper (being more indulgent with papers proposing new ideas, as otherwise the novelty is rather low compared to [Xiao and al.]). - The interpolation scheme (how is defined the intensity I(x,y) for a non-integer location (x,y) within the image I) is rather important (linear interpolation, etc.) and should be at least mentioned in the main paper, and at best studied (it might impact the gradient descent path and the results); - The results of Table 2 is interesting. - I think this is a good contribution, It is a kind of attack we should consider. - The interpolation scheme (how is defined the intensity I(x,y) for a non-integer location (x,y) within the image I) is rather important (linear interpolation, etc.) and should be at least mentioned in the main paper, and at best studied (it might impact the gradient descent path and the results); could there be a proof of this? More importantly, it is not clear at all, both in theory and algorithm, whether the advocated gradual deformation attack and defense can be unified inside a joint min-max/max-min learning formulation, as what PGD is rooted from. Minor: - The paper is a bit nationally convoluted for no good reason, the general idea is straightforward. On one side (see Eq.4), the deformation \\tau should be small enough in scale to make an accurate approximation. - for instance, what about generating adversarial examples for which the network would be fully (wrongly) confident? This could be useful in particular in the following perspective: - Mathematical side note: the "gradient" of a functional is not a uniquely-defined object in that it depends on the metric chosen in the tangent space. Pros: - The way of constructing deformation adversarial is interesting and novel
Clarity: The paper is clearly written in the sense that the motivation of research is clear, the derivation of the proposed method is easy to understand. The whole paper is written in a clean way and the method is effective. Significance: I think this kind of research makes the variational inference more useful, so this work is significant. The problem author focused on is unique and the solution is simple, experiments show that proposed method seems promising. I checked all the derivations, and they seem to be correct. So I do not know which is better and whether I should use this method or use the original STL with flexible posterior distribution to tighten the evidence lower bound. But I cannot tell the proposed method is really useful, so I gave this score. Overall, I think the idea is nice and the results are encouraging. Faced on this, I wonder which strategy is better to tighten the lower bound, should we use the STL with the mixture of Gaussians or use the proposed method?
This paper presents a simple multi-agent Deep RL task where a moving tracker tries to follow a moving target. This work aims to address the visual active tracking problem in which the tracker is automatically adjusted to follow the target. The paper proposes a novel reward function - "partial zero sum", which only encourages the tracker-target competition when they are close and penalizes whey they are too far. Experimental evaluation in both 2D and 3D environments is conducted. The tracker receives, from its own perspective, partially observed visual information o_t^{alpha} about the target (e.g., an image that may show the target) and the target receives both observations from its own perspective o_t^{beta} and a copy of the information from the tracker's perspective. Both agents are standard convnet + LSTM neural architectures trained using A3C and are evaluated in 2D and 3D environments. Citing Sun Tzu's "Art of War" (please use the correct citation format) is not convincing enough for adding the tracker's observations as inputs for the target agent. This is a very interesting problem and I see why their contribution could improve the system performance. The paper would have benefitted from a proper analysis of the trajectories taken by the adversarial target as opposed to the heuristic ones, and from comparison with non-RL state-of-the-art on tracking tasks.
This paper presents a mixed integer programming technique for verification of piecewise linear neural networks. Quality: The paper is very well written and organized.
This paper describes a novel method for solving inverse problems in imaging. Given this, I'm not entirely sure why the proposed approach is supposed to work. The core novelty of this paper is the portion that uses a neural network to calculate a projection onto a random Delaunay triangulation. This is theoretically motivated by classical work (Omohundro'89) and has the further advantage that the low-res reconstructions are interpretable. It'd be nice to see if you get any benefit here from their method relative to other approaches in the literature, or if this is just better than inversion using a U-Net.
The paper suggests a method for generating representations that are linked to goals in reinforcement learning. In this paper, the authors propose a new approach to representation learning in the context of reinforcement learning. The idea is novel (to the best of my knowledge), interesting and the experiments seem promising. The main idea is that two states should be distinguished *functionally* in terms of the actions that are needed to reach them, The first weakness of the approach is that it assumes that a learned goal-conditioned policy is already available, and that the representation extracted from it can only be useful for learning "downstream tasks" in a second step. A study of the effect of various optimization effort on these goal-conditioned policies might also be of interest. - most importantly, in Section 6.4, 6.5 and 6.6, much too few details are given. - Main missing details is about how the goal reaching policy is trained. But thinking further to the case where goals and states are different (or at least goals are only a subset of states), probably they would end-up with a different intuitive presentation of their framework. A positive side of the experimental study is that the 6 simulated environments are well-chosen, as they illustrate various aspects of what it means to learn an adequate representation. A side note is that the authors address in this Figure a problem pointed in Penedones et al (2018) about "The Leakage Propagation problem" and that their solution seems more convincing than in the original paper, maybe they should have a look. The two main flaws in the paper are the lack of details and missing important experimental comparisons. The first weakness of the approach is that it assumes that a learned goal-conditioned policy is already available, and that the representation extracted from it can only be useful for learning "downstream tasks" in a second step. A study of the effect of various optimization effort on these goal-conditioned policies might also be of interest. - most importantly, in Section 6.4, 6.5 and 6.6, much too few details are given. More precisely, it wishes to learn a representation so that two states are similar if the policies leading to them are similar.
The interpolation model composes two components -- given these conditions, it first regresses weights combining a set of precomputed deformation fields, and then a second model regresses dense volumetric deformation corrections -- these are helpful as some events are not easily modeled with a set of basis deformations. This is primarily an application paper on simulating liquids in controlled scenes using nets and appears novel in that narrow domain. The specific way deformations are composed -- using v_inv to backwards correct basis deformations, following up the mixing of those with a correction model -- is intuitive and is also something I see for the first time. This is an interesting idea to generate the required training data and build a generalizable model. The experimental results are sufficient for simulating liquids/smoke, except I would like to also see a comparison to using deformation field network only, without its predecessor. While this is a good applied paper with a large variety of experimental results, there is a significant lack of novelty from a machine learning perspective. Experimental results are sufficient. However, it is also necessarily to add more intuitions to the current approach. I found the paper hard to read at first, since the paper is heavy on terminology, only really understood what is going on when I went through the examples in the appendix, which are helpful and then on a second read the content was clear and appears technically correct. So, this is closer to a graphics approach and deep learning has been used before extensively in a similar manner for shape generation, shape transformation etc. This was done for Fig 6, but would be nice to also see it numerically in ablation in Fig. 4. The synthesized simulations are not physically accurate, but with certain visual realism. Right now the implicit surface deformation model is only tested on liquids examples, which limits the impact to that specialist domain -- it's a bit more of a SIGGRAPH type of paper than *CONF*. 3. In terms of practical applications, to the best of my knowledge there are sophisticated physics-based and graphics based approaches that perform very fast fluid simulations. So, the authors need to provide accuracy and computation cost/time comparisons with such methods to establish the benefits of using a deep learning based surrogate model. 2. But based on my understanding, this does not really explicitly incorporate the physical laws within the learning model and can't guarantee that the generated data would obey the physical laws and invariances. I think it would be helpful to add more ablation (deformation-only results for all cases) and experiments with different numbers of bases in the final version. If the AC decides to reject based on this fact I am ok with that as well.
The authors show how the PG theorem still applied for a input-aware critic and then they show that the best baseline one can use in conjecture with this critic is a input-dependent one. The meta-algorithm provided in Section 5 is well motivated and well described. 1312-1320). [POST-rebuttal] I've read the author's response and it clarified some of the concerns. From the formulae(eq. (4),(5)), it seems to be that the policy is unaware of the input variables.
The authors then address the problem of data drift in BMI and describe a number of domain adaptation algorithms from simple (CCA to more complex ADAN) to help ameliorate it. The individual variability in day-to-day brain signal is difficult to harness and this work offers an interesting approach to address this problem. Rigor: What are meaningful comparisons for all for the AE and DA portions? Please clarify. Page 8, How do the AE results and architecture fit into the EMG reconstruction "BMI" results?
Summary: Train a multilingual NMT system using the technique of Johnson et al (2017), but augment the standard cross-entropy loss with a distillation component based on individual (single-language-pair) teacher models. +++++++++++++++++++ I have updated my rating after reading author's responses The authors apply knowledge distillation for many-to-one multilingual neural machine translation, first training separate models for each language pair.
This paper proposes a variational approach to Bayesian posterior inference in phylogenetic trees. The paper would be stronger if it discussed these in more detail - how close can they come to approximating the models usually used in phylogenetic analyses? Reviewers may apply a higher reviewing standard to papers that substantially exceed this length." So I recommend trying to cut it down a bit during the revision phase.
In fact in the tandem game, LOLA will converge to sub-optimal scenarios with worse losses for both agents. Although I am not an expert on this topic, the paper seems interesting to me. However, since this example can be viewed as a fully cooperative game with joint loss L = 2xy, it does not support the broader statement that Nash is undesirable in all games. Minor Comment: First paragraph in Section 2.2, "It is highly undesirable to converge to Nash in this game" -> Nash equilibria This paper introduces a new algorithm for differential game, where the goal is to find a optimize several objective functions simultaneously in a game of n players. As Theorem 2 is the crux for all the theoretical advancement presented in the paper, clarifications on above correctness questions is very important for clear acceptance of this work.
Building off a study by Bartunov et al. that shows the deficiencies of some BP algorithms when scaled to difficult datasets, the authors evaluate a different algorithm, sign-symmetry, and conclude that there are indeed situations in which BP algorithms can scale. First, they show successful training of a ResNet-18 architecture on ImageNet using sign-symmetry, with their model performing nearly as well as one trained with backpropagation. In particular, they examine two methods for breaking the weight symmetry required in backpropagation: feedback alignment and sign-symmetry. The results are generally clear (though there is an incomplete experiment, I agree with the authors that it is unlikely for the preliminary results to change). I believe that there is enough detail for this work to be reproducible. Minor: refs are not homogeneous, first names citations are not consistent. - Figure 2: Would be nice if these colors (for backprop/FA/SS) matched the colors in Figure 1. Of course, one doesn't want to go down the road of declaring that "algorithm A is more plausible than algorithm B!", but the nuances should at least be seriously discussed if the algorithms are to be properly compared. A couple of remarks: I would be interested in understanding the robustness of the sign-symmetry algorithm w.r.t.
The paper presents a model for learning conditional distribution when arbitrary partitioning the input to observed and masked parts. The qualitative results presented in this work are interesting. The closest work to this of the Universal Marginalizer is compared to well, with more compelling examples in the appendix. Inference in this latent variable model is achieved through the use of an inference network which conditions on the set of "missing" (to the generative model) features. RMSE and accuracy of classification (from imputed data is compared). Experimental Results The model is evaluated against MICE and MissForest on UCI datasets. Novelty: Generative models have a long history of being used to impute missing data. Minor details: In equation (8) should x be x_b? The experimental results in this setting is not very encouraging, suggesting the proposed approach is effective only when the limitted mask patterns are known in advance. Clarity This is a poorly written paper. Please use a different notation when referring to the variational distributions (do not re-use "p").
The authors formulate the problem as a bilevel optimization problem: minimizing the validation loss over the hyperparameters, subject to the parameters being at the minimum of the training loss. The authors formulate the problem as a bilevel optimization problem: minimizing the validation loss over the hyperparameters, subject to the parameters being at the minimum of the training loss.
The authors propose a new weight re-parameterization technique called Equi-normalization (ENorm) inspired by the Sinkhorn-Knopp algorithm. The main difference with Path-SGD is that the network is explicitly balanced, while Path-SGD uses a regularizer to implicitly balance the network. Summary: This paper introduces equi-normalization (ENorm): a normalization technique that relies on the scaling invariance properties of the ReLU, similarly to Path-SGD. The experimental results show that ENorm performs better than baseline methods on CIFAR-10 and ImageNet datasets. The authors show that the proposed method preserve functionally equivalent property in respect of the output of the functions (Linear, Conv, and Max-Pool) and show also that ENorm converges to the global optimum through the optimization. (+) The theoretical analysis of the convergence of the proposed algorithm is well provided. (+) The computational overhead reduced by the proposed method compared with BN and GN looks good. Indeed, the authors note in their discussion that the criterion they optimize might be not optimal. (-)  The batch size shown in Table 2 and 3 may be intended to show the batch-independent property of the proposed method, but BN is also doing well in those tables.
VIP have been very successful in solving min-max style problems. After showing theoretical guarantees of these methods (linear convergence) the authors propose to combine them with existing techniques, and show in fact this leads to better results. First are simultaneous updates, and the other is alternated updates. VIP entails solving an optimization problem that is related to the first order condition of the optimization problem that we wish to solve. In this case two kinds of gradient updates can be derived. Two techniques that have been widely used to solve VIP problems are averaging and extragradient methods. But I understand that producing state-of-the-art inception scores is not the focus of the paper, therefore I would suggest that the authors release an implementation of the proposed new optimizers (ExtraAdam) for a popular DL framework (e.g. pytorch) such that practitioners working with GANs can quickly try them out in a "plug-and-play" fashion. Right now, only the advantages of extrapolation method and disadvantages of implicit method are mentioned which I find unfair for the implicit method.
This paper is about issues that arise when applying Information Bottleneck (IB) concepts to machine learning, more precisely in deterministic supervised learning such as classification (deterministic in the sense that the target function to estimate is deterministic: it associates each example to one true label only, and not to a distribution over labels). Such a deterministic relationship between outputs and inputs induces the problem that the the IB "information curve" (i.e. I(T;Y) as a function of I(X;T)) is piece-wise linear and, thus, no longer strictly concave, which is crucial for non-degenerate ("interesting") solutions. The authors argue that most real classification problems indeed show such a deterministic relation between the class labels and the inputs X, and they explore several issues that result from such pathologies. This work analyses the information bottleneck (IB) method applied to the supervised learning of a deterministic rule Y=f(X). SUMMARY: This paper is about potential problems of the information bottleneck principle in cases where the output variable Y is a deterministic function of the inputs X. For instance the T_alpha in equation (5) are not reachable anymore; the optimization space for the IB Lagrangian is different; etc. Thus, one has to be careful when defining the mutual information I(X,Y), which explains the problems with the IB information curve (which should asymptotically converge to I(X;Y) as I(X;T) gets large. I would rather argue that the opposite is the case, because I don't think that there are too many such problems with zero Bayes error rate. L0]); (2) there are many solutions to the optimization of the IB Lagrangian for any given compression/performance ratio (i.e. for any given beta in the IB Lagrangian method: I(Y,T)/I(X,T)) and some of them are provably trivial; Pros: - the paper is well written, mostly self-contained, and easy to read (for someone familiar with information theory); - A side remark about applying IB to neural networks: What about neural networks that are not a "linear" chain of layers (i.e. most networks now)? I feel it would be appropriate, either in the general literature section, either for discussing how to compute in practice the mutual informations (exact values vs. - As in practice T is constrained to belong to a particular space of functions (neural network layer with predefined architecture): how does this impact the study? Maybe rephrase some expressions that might be wrongly perceived?
The paper proposes training generative models that produce multi-agent trajectories using heuristic functions that label variables that would otherwise be latent in training data. In general, the paper is well written and the overall framework captures the essence of the problem that the authors are trying to solve. The model is trained to maximize the ELBO objective and log-likelihood over macro-intent labels.
The goal is to learn a discrete two-dimensional representation of the time series data in an interpretable manner. This paper deals with an interesting problem as learning an interpretable representation in time series data is important in areas such as health care and business. The authors conduct experiments on both static and time series data and validate that the method perform better than related methods in terms of clustering results as well as interpretability. This paper proposes a deep learning method for representation learning in time series data. However this aspect is not discussed in detail, while it would be beneficial to provide experiment about the sensitivity and accuracy with respect to the choice if this parameters. Some concerns/questions as below: 1) As the paper is based on SOM, some illustration of this method would be helpful for readers to understand the idea and learn the major contribution; It may be true that a 2D embedding provides a simple visualisation, however interpretability can be obtained also with much richer representations in a number of different ways (e.g. sparsity, parametric representations, …).
agree that the user study could be biased (and that "It would be a tremendous effort to find a completely fair experimental setting"), but, if this is the case, the argument that the method reaches human-level performance is brittle. p. 8: "nearly perfect" -> "nearly perfectly" Indeed, the method boils down to a variant of CNNs.
Novelty: (1) The error bound of value iteration with the Boltzmann softmax operator and convergence & convergence rate results in this setting seem novel. That paper proved a strong regret bound for Boltzmann-like exploration in the bandit case, which this paper actually does not for the RL case, so in some sense the homage is misplaced. 0) which of course means that it doesn't explore efficiently at all (see Singh 2000, Cesa-Bianchi 2017). Theorem 4 does not imply efficient exploration, since it requires very strong conditions on the alphas, and note that the same proof applies to vanilla Q-learning, which we know does not explore well. I presume the title of this paper is a homage to the recent 'Boltzmann Exploration Done Right' paper, however, though the paper is cited, it is not discussed at all. I liked this paper overall, though I feel that the way it is pitched to the reader is misguided.
(6)-(9). This paper proposes a seq2seq model which incorporates dependency parse information from the source side by embedding each word's subgraph (according to a predetermined dependency parse) using the Graph2Seq model of Song et al. (2018); the authors propose two variants for achieving an encoded source-side representation from the subgraph embeddings, involving bidirectional lstms. Regarding the approach in general, it would be nice to see how much it depends on the quality of the dependency parse. The results presented are also impressive: I don't think the IWSLT de-en results are in fact state of the art (e.g., Edunov et al. (NAACL 2018) and Deng et al. (NIPS 2018) outperform these numbers, though both papers use BPE, whereas I assume the current paper does not), but the results on the other two datasets appear to be. [significance] The experimental setting used in this paper is slightly out of the current main stream of NMT research. Comparing on the small datasets, the proposed method seems to significantly improve the performance over current best results of NPMT+LM. I like the synthesis of methods that the authors' present.
The experiments show that MarginAttack finds adversarial examples with small distortion (as good as the baselines or slightly better), and that the algorithm runs faster than the Carlini-Wagner (CW) baseline (but slower than other methods). The authors make a distinction between "fixed perturbation" attacks and "zero confidence" attacks. - In the introduction, the authors emphasize the distinction between fixed perturbation attacks and zero confidence attacks. So it is not clear that there is a large gap in difficulty. Thus all attacks make some kind of approximation, including this paper. - In the second paragraph of the introduction, the authors claim that fixed perturbation attacks and zero confidence attacks differ significantly. Moreover, it is not clear why PGD is only used for an l_inf comparison and not a l_2 comparison. Thus all attacks make some kind of approximation, including this paper. - The authors explicitly state that the step sizes for CW were tuned for best performance, but do not mention this for PGD. Additional comments: - In the introduction, the authors equate white-box attacks with access to gradient information.
Authors highlight the contribution of graph spectral regularizer to the interpretability of neural networks. Missing cites: [1] van den Oord et al, Neural Discrete Representation Learning. Pros: Interesting idea for bringing some benefits of graphical models into Neural Networks using a regularizer. Experiments verify that one can successfully improve the intrepretability of hidden representations. For more challenging cases, how to build the Laplacian graph reasonably? My main concern is that the power of Graph-based regularizer has been well-known in the ML community for a long time. When the layers contains thousands of neurons or more, how to add the regularizers efficiently? but how to address the more general problem?
Authors proposes new method against adversarial attacks. Paper is organized well and easy to follow. 3. the use of a multi-way encoding results in a weaker correlation in gradients between models I found (2) to be a surprising assumption, but it does seem to be supported by the experiments.
This paper considers parameterizing Dirichlet, Dirichlet-multinomial, and Beta distributions with the outputs of a neural network. I found this to be the most interesting portion of the paper and the most significant contribution. As the authors note, parameterizing an exponential family distribution with the outputs of a neural network is not a novel contribution (e.g. Rudolph et al. (2016) and David Belanger's PhD thesis (2017)) and though I have never personally seen the Dirichlet, Dirichlet-multinomial, and Beta distributions used, the conceptual leap required is small. Unfortunately, it is short on details and empirical results are referenced that do not appear in the paper (i.e. the second to last paragraph on page 5). Most of section 2 is dedicated to writing down, simplifying, and deriving gradient equations for these three distributions. - It is not clear what the authors are trying to show in section 4.1. Overall, I found the writing very clear, the main idea sound, and paper generally well executed, but I have serious concerns about the significance of the contributions that lead me to recommend rejection.
The authors propose to estimate and minimize the empirical Wasserstein distance between batches of samples of real and fake data, then calculate a (sub) gradient of it with respect to the generator's parameters and use it to train generative models. Comparisons with other variants of Wasserstein GAN is proposed on MNIST. In ICML (pp. 685-693). Using optimal transport computed on batches rather the on the whole dataset is already used in (among others) Typos: Eq (1) and (2): when taken over the set of all Lipschitz-1 functions, the max should be a sup The paper proposed to use the exact empirical Wasserstein distance to supervise the training of generative model. In ICML (pp. 685-693). Using optimal transport computed on batches rather the on the whole dataset is already used in (among others)
This paper present a study on efficient acoustic modeling using neural networks-based model. One of the biggest issues of this paper is that they use CTC as an acoustic model, while still many real speech recognition applications and major open source (Kaldi) use hybrid HMM/DNN(TDNN, LSTM, CNN, etc.) systems. 4. A more general comment on the work explored  in the paper. - The paper needs some discussions about TDNN, which is a major acoustic modeling (fast and accurate) in Kaldi This analysis is actually valuable, and this suggested change about the position of this TIMIT experiment can avoid some confusion of the main target of this paper.) This paper investigates a number of techniques and neural network architectures for embedded acoustic modeling. This analysis is actually valuable, and this suggested change about the position of this TIMIT experiment can avoid some confusion of the main target of this paper.) This paper investigates a number of techniques and neural network architectures for embedded acoustic modeling.
The contributions of this paper allow to use this model on real-word datasets by reducing the time and space complexity of the NTP model. The techniques are evaluated via empirical results on several benchmark datasets. [Summary] This paper scales NTPs by using approximate nearest neighbour search over facts and rules during unification. 3) Section 2 on the NTP framework is not very helpful for a reader that has not read the previous paper on NTP (in particular, the part on training and rule learning). It is a standard and well-known technique to restrict the search to a neighborhood, widely used in any applications of word embedding (e.g. in Khot et el's Markov Logic Networks for Natural Language Question Answering). In particular, it would be useful for the authors to focus on providing more insights on how the proposed techniques improve the results, and in what ways. - Utilizing text is an interesting direction for NTP in terms of integrating it with past work on KG completion. The argument that performance is given up for interpretability needs more discussion, and the effect of each addition to the system should be discussed as well. For a reader that has done so, the section feels redundant. [Comments] - For reproducibility: it is unclear whether evaluation in FB15k-237 is carried out on the KB+Text, KB, or Text portions of the dataset. 3) Section 2 on the NTP framework is not very helpful for a reader that has not read the previous paper on NTP (in particular, the part on training and rule learning).
This paper shows that a sentence selection / evidence scoring model for QA trained on SQuAD helps for QA datasets where such explicit per-evidence annotation is not available. 1) First of all, it is hard to say there is a contribution to the idea of sentence discriminator and sentence reader — people have used this framework for large-scale QA a lot.
========== Comments ======== The authors are exploring an important problem that is of great interest to the IIG community. So the network is not trained to predict 0 (or any initial values) for a newly encountered state. - similarly for (I, strategy) However, the games that are used for evaluation are very small, in fact I believe they have fewer states than the number of parameters in their network (the number of network parameters is not provided but I assume >1000). - train a new network vmodel_{t+1} on this "batch" with y=(v_I + vmodel_t(I)) and MSE loss
o This is to assess the size of the pattern space. • Were the pattern images pre-processed in any manner before being classified? I can see no contribution which is general enough to be interesting for the broader readership. - train a new network vmodel_{t+1} on this "batch" with y=(v_I + vmodel_t(I)) and MSE loss
The presentation of the new forget gate in "System 2" is clear in terms of being able to implement it, but it's not intuitive to me what this actually looks like.
This submission proposes a method for learning to follow instructions by splitting the policy into two stages: human instructions to robot-interpretable goals and goals to actions. This paper contains an important core insight---much of what's hard about instruction following is generic planning behavior that doesn't depend on the semantics of instructions, and pre-learning this behavior makes it possible to use natural language supervision more effectively. How are the instructions generated in this task? How are the instructions generated in this task? Such a modular approach has the advantage that the instruction-to-goal and goal-to-policy mappings can be trained separately and, in principle, allow for swapping in different modules.
This paper presents a thorough and systematic study of the effect of pre-training over various NLP tasks on the GLUE multi-task learning evaluation suite, including an examination of the effect of language model-based pre-training using ELMo. The work is focused on experiments, and draws several conclusions that are interesting, mostly around the amount of gain one can expect and the fact that the choice of the dataset is task-dependent. The authors cover a lot of ground in comparing a lot of the recent work, both qualitatively and quantitatively -- there are a lot of experiments. The paper seems to suggest that it consists of pre-training a model on the same task on which it is later evaluated. The main conclusion is that both single-task and LM-based pre-training helps in most situations, but the gain is often not large, and not consistent across all GLUE tasks. Training sentence representation in an unsupervised manner is hence crucial for real-world NLP applications. Minor details: Page 1: "can yield very strong performance on NLP tasks" is a very busy way to express the fact that Sentence Encoders work well in practice. I'm confused by what this means, and how this is different from just training on that task. The study and the experimental results will be useful and interesting to the community. I understand that the results of the current papers would hove to be re-run on all these tasks, but I'm afraid the current paper will have a limited impact if it does not use the most effective method at the date of publication... This paper represents an impressive amount of experimentation.
The submission proposes to increase the variety of generated samples from GANs by a) using an ensemble of discriminators, and b) tasking them with distinguishing not only fake from real samples, but also their fake samples from the fake samples given to the respective other discriminators. The paper proposes a multi-discriminator based extension to GAN training. Pros: + The proposed IntraFID is interesting but is missing two baselines (IntraFID for two batches of real data and IntraFID for two batches of a baseline GAN without the proposed technique) which would help calibrate and contextualize the newly introduced metric. - The paper does not have any direct/controlled comparisons with other methods that utilize multiple discriminators or batch based discrimination. Different schedules are demonstrated, but optimality of either is not guaranteed.
Specifially, these representative samples for each task are selected as support vectors of a SVM trained on it. The proposed method, SupportNet, is validated on a continual learning task of a classifier against two existing continual learning approaches, which it outperforms. To prove their usefulness, add two methods to Figure 3: (a)A method that uses support points without any regularizer. (3) In section 2.1 Deep Learning and SVM: In the line before Eq. 4. - The authors used 2000 support vectors for MNIST, Cifar-10, and Cifar-100. (-) Lack of related work on recent catastrophic forgetting
This approach assumes that the developer has knowledge of what are good/bad behavior for a specific task and that the behavior can be checked by hand-coded DFAs or PDAs. The shaping reward used for the four Atari games is -1000. Why was this? If these are really constraints on the action sequence, isn't this showing that the algorithm does not work for the problem you are trying to solve? The shaping reward used for the four Atari games is -1000.
This op is constructed by m convolution ops followed by an averaging op. The CIFAR-10 baseline numbers are not ideal, and since IEA is basically "plug and play" in existing architectures, starting from one of these settings instead (such as Wide ResNet https://arxiv.org/abs/1605.07146) and showing a boost would be a stronger indication that this method actually improves results. Crucially Maxout seems much too close to this work, and I would like to see an indepth comparison (since it appears to be use of mean() instead of max() is the primary difference). There are more recent followups that continued on the line of work first shown in Maxout, and there should be some greater comparison and literature review on these papers. Likewise for Tables 3-6. 3. Under this interpretation of the tables---again, correct me if I'm wrong---the proper comparison would be "IEA (ours)" versus "Ensemble of models using CNL", or  "(m=3, k=1)" versus "(m=1, k=3)" in my notation. With multiple combined paths (as in Dense ResNet) this equivalence seems stronger still. The choice of the mean here seems insufficient for creating the types of complexity in activation which are normally desirable for neural networks, so some description of why a simple mean is a good choice would be beneficial since many, many other functions are possible. The CIFAR-10 baseline numbers are not ideal, and since IEA is basically "plug and play" in existing architectures, starting from one of these settings instead (such as Wide ResNet https://arxiv.org/abs/1605.07146) and showing a boost would be a stronger indication that this method actually improves results.
This choice is ok for standard neural network layers, where effectively the choice is between a single catecorical aspect. The paper presents a way to compress the neural network architecture. In the specification of layers, the layer type is just appointed to an integer variable, even though in reality the layer type is a categorical variable. This paper deals with Architecture Compression, where the authors seem to learn a mapping from a discrete architecture space which includes various 1D convnets. The overall model achieves quite good result in compression. Second, it seems that minimizing L_c cannot guarantee that both error and the number of parameters are reduced. Overall, this was an interesting paper to read and worth of acceptance, provided that the proposed method delivers also in more competitive experimental settings.
Summary: Proposes a framework for performing adversarial attacks on an NMT system in which perturbations to a source sentence aim to preserve its meaning, on the theory that an existing reference translation will remain valid if this is done. Given source and target metrics for measuring similarity, an attack is deemed successful if the source difference is smaller than the relative decrease in target similarity to the reference. It is well structured, the problem studied is highly interesting and the proposed meaning-preserving criteria and human judgement will be useful to anyone interested in adversarial attacks for natural language. 3.2 For kNN, being semantically related doesn't imply that the relationship is synonymy, as would be required for meaning preservation. In 4.3 it seems obvious a priori that perturbations intended to be relatively meaning preserving would indeed preserve meaning better than unconstrained ones.
The proposed method instead constructs a target distribution which places probability mass not only on leaf category nodes but also on their neighbors in a known semantic hierarchy of labels, then penalizes the KL-divergence between a model's predicted distribution and this target distribution. SUMMARY The paper presents a method for classification which takes into account the semantic hierarchy of output labels, rather than treating them as independent categories. I suspect that the authors chose not to perform this comparison since unlike DeViSE and ConSE their method cannot predict category labels not seen during training; instead it is constrained to predicting a known supercategory when presented with an image of a novel leaf category. Based on this reason, I think the main contribution of this paper is the discussion on two novel learning settings, which related to the super-classes. However due to the omission of key references and incomplete comparison to prior work, the paper is not suitable for publication in its current form.
The authors proposed to use a separately trained GAN network to generate synthetic data for the student-teacher training. Strengths: - The paper sheds a light on an interesting aspect in model compression. Weaknesses: - The claim that reusing the same training data used for training the teacher model in model compression can lead to overfitting of student model is not very obvious and needs more experimental evidence in my opinion. I like the authors' explanation on why GAN is particularly good in a student-teacher setting. The compression ratio  depends on student-teacher training, which can take a relatively long time.
This paper presents an end to end rl approach for hierarchical text classification. The approach seems original, and a detailed experimental analysis is carried out on various datasets. - The experimental evaluation seems less convincing such as the results for HRSVM for RCV1 dataset are quite different in this paper, and that given HRSVM paper. - If it is the former, how does this compare to existing approaches for optimizing F1 metric. The paper proposes a label assignment policy for determining the appropropriate positioning of a document in a hierarchy. For instance, the dataset available under LSHTC3 is in the raw format, and it would be really competitive to evaluate this method against other such as Flat SVM, and HRSVM[4] on this dataset, and those from the challenge.
The paper proposes to use a regularization which preserves nearest-neighbor smoothness from layer to layer. This paper proposes the interesting addition of a graph-based regularisers, in NNs architectures, for improving their robustness to different perturbations or noise. The approach is based on controlling the extent to which examples from different classes are separated from one layer to the next, in deep neural networks. - the might exist a tradeoff between robustness, and performance (accuracy), that seem to be explaining the proposed results (see Fawzi - Machine Learning 2018, for example) Compared to the previous version, this paper made a good improvement in its experimental results, by adding two different robustness settings in section 4.1 and section 4.3, and also include DeepFool as a strong attack method for testing adversarial robustness. - are there experiments (e.g., on smaller datasets) that would show that the proposed method indeed regularizes and prevents overfitting as motivated in Section 3.4?
The paper looks into improving the neural response generation task by deemphasizing the common responses using modification of the loss function and presentation the common/universal responses during the training phase. Also there seems to be a discrepancy in figure 3 with the baseline output for first query having two "Where is your location?" outputs. - it would be interesting to know for the trivial questions if the performance was impacted by the deemphasizing (one that do result in universal replies) This paper presents a framework for understanding why seq2seq neural response generators prefer "universal"/generic replies. Also there seems to be a discrepancy in figure 3 with the baseline output for first query having two "Where is your location?" outputs.
However the paper in the current form does not fully adhere to the standards of conferences such as *CONF*. I particularly liked the experiment on semi-supervised learning with CIFAR-100. By replacing labeled examples with domain knowledge about the relationships among classes in CIFAR-100, the paper demonstrates a compelling use case for DL2. It is not clear that this affects the findings of the semi-supervised learning experiment significantly, although I would appreciate a clarification of the authors. In theorem 1. \\delta is a constant, right? Related Work ------------ There are a couple of points from related work that would be good to add to the paper.
With that said, their approach is well-motivated, and their experiments seem to show consistent small improvements in performance. I don't think the performance improvements are totally conclusive, but one of the most appealing properties of their proposal is that it shouldn't be much more computationally expensive than using a fixed minibatch size. In other words, their result does *not* show that their algorithm is close to outperforming a fixed choice of batch size (for that to hold, the comparator would need to be \\sum_t y(w(b^*,...,b^*),b^*)). The results show that the bandit approach allows to obtain a test error better (although not significantly better) than the test error corresponding to the best minibatch size among those considered by the bandit. In other words, their result does *not* show that their algorithm is close to outperforming a fixed choice of batch size (for that to hold, the comparator would need to be \\sum_t y(w(b^*,...,b^*),b^*)). But I practice I would expect that a graduated loss (e.g., signed percentage of change in validation loss), would be more informative.
Control variates are often estimated with an optimal scaling constant that depends on the covariance of the original function and its control variate. The paper is well written. (8)). As the paper currently reads, it feels as if it comes out of nowhere. Please see Sec. 3, "Policy Gradient Variance Decomposition" of the Mirage paper for further details. I recommend the authors look into adaptively estimating an optimal scale for the baseline using a rolling estimator of the covariance and variance to fix this issue.
Figure 3 shows the results on four different maps for which expert demonstrations are generated from a Finite-Machine Tree-search method (a competitive method in this environment). But this line of work could be a potentially promising direction. Although, the authors comment about the strong assumptions being made to aid the analysis. If that is the case, it might not be a fair comparison for the other policies, especially for the standard policies, which are trained under different initial states. However since that work was not published, it should not be held against this paper. The paper presents a strategy for solving sparse reward tasks with RL by sampling initial states from demonstrations. I believe this paper requires substantial improvements for publication and is not up to the *CONF* standards in its current form.
This is an emergency review, so apologies for the briefness. In a weighted voting game each agent is given a weight and the agents attempt to form teams. This approach is a fairly straightforward application of RL to coalition games, but could be of interest to researchers studying negotiation or multiagent reinforcement learning, and the authors demonstrate the success of RL compared to a normative standard. This is an emergency review, so apologies for the briefness. The paper concludes that deep RL is effective at learning agents for cooperative games in multiple ways: 1) Deep agents are better than a hand-designed agent. Given such a game, the __shapely value__ of an agent measures the importance of that agent.
This is not unreasonable and indeed common in mean-field analyses. * it would be beneficial to define the main objects, wide-network limits, in a more formal way (Section 2.3)
This paper tries to argue that pooling is unnecessary for deformation invariance, as title suggests, and proposes initialization based on smooth filters as an alternative. It shows different pooling strategies reach to similar levels of deformation stability after sufficient training. Pros: The paper considers a wide variety of pooling strategies and deformation techniques for evaluation. (iii) that this mechanism is data-dependent (sec Moreover, the reviewer felt that the authors could have built on those findings to ask (and hopefully answer) a few interesting questions, such as: -- Nowhere in the paper there is a discussion about critical Nyquist sampling and the need to reduce the bandwidth of a signal prior to downsampling it in order to avoid aliasing. However, CIFAR 10 is not a difficult dataset and the level of cosine sensitivity (shown as same with and without pooling) could very well be a steady state for the specific classification task.
Contrary to previous work, a single (conditioned) decoder is used for all instrument domains, which means a single model can be used to convert any source domain to any target domain. The empirical comparisons to UNIT are reasonably thorough, though I would have preferred more in-depth evaluation of the MoVE model as well. Specifically, the authors introduced an extra input (control) to encode the pitch class and octave information during encoding. There are some clearly visible differences. * Mor et al. (2018) do actually make use of an adversarial training criterion (referred to as a "domain confusion loss"), contrary to what is claimed in the introduction. * Some turns of phrase like "recently gained a flourishing interest", "there is still a wide gap in quality of results", "which implies a variety of underlying factors", ... Is this a typo? * The differences between UNIT (GAN; C-po) and UNIT (MMD; C-po) in Table 1 seem very small and I'm not convinced that they are significant. Summary ------- This paper describes a model for musical timbre transfer which builds on recent developments in domain- and style transfer. However, the more pressing issue is that evaluation is done either sample-wise within-domain (reconstruction), or distribution-wise across domains (transfer). * Mor et al. (2018) do actually make use of an adversarial training criterion (referred to as a "domain confusion loss"), contrary to what is claimed in the introduction.
[1] Multimodal Unsupervised Image-to-Image Translation (1) a smiling expression and Is the model easy to extend to novel styles for image translation? 2) As co-segmentation is proposed to "capture the regions of a common object existing in multiple input images", why does the co-segmentation network only capture the eye and mouth part in Figure 2 and 3, why does it capture the mouth of different shape and style in the third macro column in Figure 4 instead of eyes? 1) The paper says that "For example, in a person's facial image translation, if the exemplar image has two attributes, [3] Exemplar Guided Unsupervised Image-to-Image Translation Is it some manual manipulation for interactive transfer?
The generator is trained to generate samples in the low density areas of the data distribution. From the general explanation of the idea of the proposed algorithm in section 1 it is not possible to understand how it works - how do we model Q(c|x)? From the general explanation of the idea of the proposed algorithm in section 1 it is not possible to understand how it works
1) adam models keeps in memory x_t (the model parameter), g_t (the model gradient), m_t (momentum) \\hat v_t and v_{t-1} (the monotone and non monotone version of the second order moment estimation. This level of writing is not professional. I think there is a typo in Zhou et al. result: 1/2 should read p. First, the major argument of memory usage stems from 1) a miscalculation and 2) a misunderstanding of memory bottlenecks in deep learning.
This paper presents a laudable attempt to generalize the learning of active learning strategies to learn general strategies that apply across many different datasets that have variables of different, not pre-determined, types, and apply the learned active learning strategies to datasets that are different from what they have been learned with. - Experiments are still on toy datasets. I would have liked to see table 2 with more classifiers and with more competing AL methods. I recognize that this paper references why no such comparison currently exists, but I think this comparison would be extremely valuable to the paper.
This is a fundamental flaw in the experimental setup (in particular the choice of baselines) and thus a clear reason for rejection. The authors' proposed optimizer is just a one-layer neural net with 32 hidden units that gets as input basically all the terms that the hand-designed optimizers compute, and it has everything it needs to simply use weight decay and learning rate schedules
This paper proposed a general framework, DeepTwist, for model compression. This paper proposed a general framework, DeepTwist, for model compression. Since SGD is used for training, several minibatches are needed to achieve a relatively stable solution for projection using the proximal function, which is exactly the proposed framework in Fig. 1. PS: After discussion, I think the motivation of the method is not clear to understand why the proposed method works. Cons: - The idea is a simple extension of existing work. - In Table 4, it is hard to compare DeepTwist with the other methods because activation quantization is not used. Specifically, the proposed framework can be easily reformulated as a loss function plus a regularizer for proximal gradient. Using gradient descent (GD), there will be two steps: (1) finding a new solution using GD, and (2) project the new solution using proximal function.
The paper demonstrated the method on MNIST and CIFAR10, and evaluates it against a number of adversarial attacks. In summary the authors propose a  simple and intuitive method to improve the defense on adversarial attacks by combining random permutations and using a 2d DFT. But if more memorizing (as opposed to generalization) happens, the classifier is more easily fooled (the decision boundary is more complicated and exploitable). Also, the adversary may attack an ensemble of PPD models for different random permutations (i.e. expectation over random permutations). The experiments with regards to robustness to adversarial attacks I find convincing, however the overall performance is not very good (such as the accuracy on Cifar10). The permuted phase component does not admit weight sharing and invariances exploited by convolutional networks, which results in severely hindered clean accuracy -- only 96% on MNIST and 45% on CIFAR-10 for a single model. While the security of a model against adversarial attacks is important, a defense should not sacrifice clean accuracy to such an extent. This paper explores the idea of utilizing a secret random permutation in the Fourier phase domain to defense against adversarial examples. The authors should introduce an appropriate threat model and evaluate this defense against plausible attacks under that threat model.
More importantly, the performance boost is significant when DQN's parameters which are used to initialize the model for the new environment were trained using dropout and L2 regularization in the default flavour/mode. Summary: This paper focuses on a "generalization" in deep Q-network (DQN). Strengths: + This paper is interesting in the sense that it empirically shows that using regularization in training deep RL can be helpful when the goal is the generalization from one flavour of an environment to another one but very similar to the original. Specifically, they showed that when features (parameters of DQN) are trained in one environment (default flavour/mode) and then used as an initialization for the same model but for a slightly different environment ( i.e. still captures key concepts of the original environment ) can boost the performance of the model in the new flavour/environment. And I think this on its own is valuable.
The paper proposes a sampling-based method that aims at accelerating Batch Normalization (BN) during training of a neural network. Several sampling methods called NS, BS, and FS are proposed, and additionally, VDN is proposed to generate random virtual samples. Originality and Significance: I think the effort of trying to make BN less computationally heavy is respectable. (-) How to determine the sampling ratio for each normalization method is not provided, and it would be better if the authors can show some studies about sampling ratio versus the speed gain. Because random sampling is involved, this will result in less regular patterns of computation, this could likely make the implementation of BN to be less efficient. comments) - It is something strange why the authors used shallower ResNet on ImageNet and deeper ones on CIFAR datasets, maybe it was due to the training time, but the authors should clarify it.
This method provides a structured solution for reusing learned skills (with scTLTL formulas), and can also help when new skills need to be involved in original tasks. What is learned in the automata? This includes: situating this work more clearly against existing similar works which use logic in this way, clearly defining the novel contributions of this work as compared to those and others, overall making the methodology more clear and specific (including experimental methodology), and comparing/contrasting against (or at least discussing differences with) methods with similar motivations (e.g., HRL multi-task learning, meta-learning) to emphasize the need/importance of this work — I am aware that at least 1 HRL work is mentioned, but this work is not really contrasted against it to help situate it.
This paper proposes Deep Overlapping Community detection model (DOC), a graph convolutional network (GCN) based community detection algorithm for network data. In addition to the limited technical novelty, I have a few other concerns as well, including some on the experimental evaluation: - Real-valued node embeddings obtained from shallow/deep graph embedding methods can be used with *overlapping* versions of k-means. I have couple of minor issues to discuss: 1. For the sake of generality, I would recommend to use the general formula instead of particular 3-layer case in equation 3.
2565-2573). ACM. This paper describes a recurrent model (LSTM specifically, but generalizable) which can produce variable-wise hidden states that can be further used for two types of attentions: 1) variable importance for the importance of each variable (not accounting for time), and Furthermore, the authors develop a mixture attention mechanism and a summarization methods to quantify the temporal and variable importance in the data. - this will allow to assess the importance of the interpretability.
This is largely an experimental paper, proposing and evaluating various modifications of variational recurrent models towards obtaining sequence data representations that are effective in downstream tasks. - typo: "for use in a downstream tasks" - Figure 3, could it be that the use of hierarchical latent variables (H) accounts for the visual difference?
The task is the following one: - consider a set of pairs of binary values (-1 or +1); - return the k first values minus the k last ones. Note also that the probabilities in some theorems are not really probabilities of convergence/performance of the training algorithm per se (as one would expect in such PAC-looking bounds), but actually probabilities of the batch of examples to all satisfy some property (the diversity). Note also that the probabilities in some theorems are not really probabilities of convergence/performance of the training algorithm per se (as one would expect in such PAC-looking bounds), but actually probabilities of the batch of examples to all satisfy some property (the diversity).
I also have some doubts about the two claimed contributions of the paper (the authors actually list 3 contributions in the introduction, but for convenience I lump the 2 non-data ones together): (1) Dataset: The dataset was crowdsourced by giving workers an emotion label (e.g., afraid) and asking them to define a situation in which that emotion might occur and inviting them to have a conversation on that situation. (2) They show improvements on dialogue generation (in terms of empathy, but also relevance and fluency) using a multi-task objective, ensemble of encoders, and a more ad-hoc technique that consists of prepending inferred emotion labels to the input. The paper in particular is contributing its collected set of 25k empathetic dialogs, short semi-staged conversations around a particular seeded emotion and the results of various ways of incorporating this training set into a generative chatbot. (one for each emotion) or 64?
This paper is about CNN model compression and inference acceleration using quantization. This paper proposes to use n-ary representations for convolutional neural network model quantization. 3) Activation quantization in Section 4 is a standard way for quantization, but I am curious how to filter out the outliner, and how to set the clipping interval? ECCV 2018. Summary: This paper proposes a technique for quantizing the weights and activations of a CNN. 4. Similarly, what are the FLOPs in different settings of experiments? The main idea is to use 'nest' clustering for weight quantization, more specifically, it partitions the weight values by recurring partitioning the weights by arithmetic means and negative of that of that weight clustering. Minor comments and questions: - The wording is sometimes imprecise, making some arguments hard to follow.
This paper proposed a new method for image restoration based a task-discriminator in addition to the GAN network. It shows superior performance than the baseline methods without such task-discriminator on medical image restoration and image super-resolution. For medical image reconstruction and image super-resolution, the proposed method was not compared with any of the state-of-the-art methods, but only with the same method without a task-discriminator as a baseline. 3.  The authors should clarify the details on the Task network since it is non-trivial to model a task. For those tasks, there are many traditional methods and deep nets with different losses. Cycada: Cycle-consistent adversarial domain adaptation. 2. Actually, as the authors mentioned, GAN is not an appropriate model for image restoration when  accurate image completion is required. In this paper, the authors propose a novel method of Task-GAN of image coupling by coupling GAN and a task-specific network, which alleviates  to  avoid hallucination or mode collapse. Please see the following comments: 1. Adding an task-discriminator in a GAN network seems straightforward to improve the specific task.
*) The Riemannian gradient algorithm is not stated in this paper. Chen et al. Gradient Descent with Random Initialization: Fast Global Convergence for Nonconvex Phase Retrieval, 2018
This paper proposes a mixture of MAMLs (Finn et al., 2017) by exploiting the interpretation of MAML as a hierarchical Bayesian model (Grant et al. 2018). The proposed method is tested in a few-shot learning setup on miniImagenet, on a synthetic continual learning problem, and an evolutionary version of miniImagenet. They propose an EM algorithm for joint training of parameter initializations and assignment of tasks to initializations. - BMAML: https://arxiv.org/abs/1806.03836. This is also quite complex and expensive, compared to Versa, but provides good results. - Originality: The idea of putting a mixture model on the global parameters is not surprising. - Experiments on evolving tasks suggest the method is not able to capture task diversity. Comparative results are presented on miniImageNet (5-way, 1-shot). - Results on miniImagenet are not encouraging; the gains on MAML are small and similar methods that generalize MAML (Kim et al., 2018, Rusu et al., 2018) achieve significantly better performance. This is quite elaborate, and uses further approximations (ICM, instead of Gibbs sampling). - Clarity: The paper is not hard to understand. The first is artificial, and surely does not need an algorithm of this complexity. More discussions and explanations on this experiment are clearly required.
Pros: + The work provides a clear overview of previous work on approaches using multiple discriminators. Clarity: The work is a clear introduction/overview of this area of research. Training multiple discriminators (in this paper up to 24) significantly increases compute cost and effective model size. However, this idea (methods along this line) is not popular in GAN applications, like image-to-image translation. Although the presentation of the Hypervolume maximization method (Section 3.2) is not clear, the resulting loss function (Equation 10) is simple, and shares the same form with other previous methods.
There is no evidence that the method can scale to and work well on large-scale tasks, where improving the sample efficiency becomes truly crucial and challenging. It would be better to add comparative results on the CIFAR and Imagenet data for convenient comparisons with state-of-the-art.
It would be better to add comparative results on the CIFAR and Imagenet data for convenient comparisons with state-of-the-art. - Typo in Figure 4: "a shows" should be "(a) shows".
7) Experiments How would you estimate the range of suitable step sizes (for both a and w) for BNGD for a neural network? - Typo in Figure 4: "a shows" should be "(a) shows".
The authors test this in several gridworld environments as well as a sorting task and show that their method achieves superior performance and generalizes better to unseen states and task variations compared to several baseline methods. The method builds on imitation learning (behavioural cloning) to model the agent's behaviour and reinforcement learning to learn a probing policy to more broadly explore different target agent behaviours. Overall, I think the paper presents a really nice idea of how to improve modeling of agents. It may not be that it changes in the first time step (for obvious reasons), but it is essentially showing it many configurations of the expert. However, this task requires the learning to be interactive and thus the demonstrator needs to be present during the learning. and 2) how can this method work if you are not able to have access to a demonstrator long periods of time (or even at all)? However, in harder tasks, this will not be feasible. In reality, for sufficiently difficult tasks, a human would be the demonstration agent (as is done in most robotics tasks).
This paper describes an approach for training conditional future frame prediction models, where the conditioning is with respect to the current frame and additional inputs - specifically actions performed in a reinforcement learning (RL) setting. (2) From reading the intro/related work section, this work is clearly motivated in the direction of model-based RL, and the authors has already used this model for Frostbite. I recommend to reject this paper.
In this paper, the authors propose deep neural networks of infinite width. Moreover, the experiments conducted on finite width networks are not enough to justify the utility of this initialization scheme. Also, it would have been nice to see whether the Win-Win initialization is only useful for larger width networks compared to smaller width i.e. do other initialization schemes work better in this latter setting? Response to rebuttal: The authors have addressed my question about the weights being still in the same RKHS.
In summary, this paper does the following: - The initial problem is to analyze the trajectory of SGD in training ANNs in the space of  P of probability measures on Y \\times Y. The issue is that the paper abstracts the actual algorithm, model and data away and the only thing that remains are marginal distributions p(y) and conditional p(y'|y). b/ Meaning of this trajectory. Generally, I think the paper is on the borderline. It is an interesting observation that the trajectory of \\alpha-SMLC  is similar to that of SGD in these plots, but the authors have not made a sufficient effort to interpret this.
The authors propose to formulate the neural network architecture as a collection of multivariate categorical distributions. (3)). This is also empirically reflected in Table 1, which shows the proposed PDAS is similar to ENAS both in terms of efficiency and performance. (3)). This is also empirically reflected in Table 1, which shows the proposed PDAS is similar to ENAS both in terms of efficiency and performance.
The paper proposed a new framework for session-based recommendation system that can optimize for sparse and delayed signal like purchase. The paper aimed at improving the performance of recommendation systems via reinforcement learning. The author proposed an Imagination Reconstruction Network for the recommendation task, which implements an imagination-augmented policy via three components: (1)  the imagination core (IC) that predicts the next time steps conditioned on actions sampled from an imagination policy; Summary: The paper presents a session-based recommendation approach by focusing on user purchases instead of clicks. Strengths of the paper: (1) The research problem that the performance of recommendation systems needs to be improved is of great value to be investigated, as recommendation systems play crucial role in people's daily lives. Comments: The proposed architecture is an interesting inspiration from Neuroscience which fits into the sequential recommendation problem. (2) Experiments were conducted on a publicly available dataset. It would be better if the authors can draw the figure in other ways. In equations (2) and (3), what is theta_v? (4) The contributions of the paper in terms of theory are somewhat not significant. The motivations of integrating A3C (Asynchronous Advantage Actor-Critic) but not other techniques into the proposed model are not convinced to me as well. (3) Some details are missing, resulting in the fact that it is hard for other researchers to fully capture the mechanism of the proposed algorithm. It looks like a loss from a previous paper, but it's kind hard to track what it is exactly. (2) Figure 2 is not straightforward. (2) State-of-the-art reinforcement learning algorithms were not taken into account for baselines in the experiments. (3) Robustness to cold-start scenario was tested and evaluated in the experiments. Weaknesses of the paper: (1) The motivations of applying reinforcement learning techniques are not convinced to me. As the proposed method is built based on reinforcement learning, it would be better if the authors could include state-of-the-art reinforcement learning algorithms as their baselines. (3) the imagination-augmented executor (IAE) that aggregates the internal data resulting from imagination and external rewarding data to update its action policy. Questions: -How are cold-start situations encountered if items are one-hot encoded?
This paper proposes a new approach to enforcing disentanglement in VAEs using a term that penalizes the synergistic mutual information between the latent variables, encouraging representations where any given piece of information about a datapoint can be garnered from a single latent. The paper proposes a new objective function for learning disentangled representations in a variational framework, building on the beta-VAE work by Higgins et al, 2017. The concept of synergy has great potential in machine learning and is highly relevant. 4. There are insufficient details on the algorithm itself in terms of the approximations that are made to estimate the synergistic mutual information. Writing like this serves no purpose even when it justified, and it certainly is not here. The main concepts of synergy are not developed in this paper and the used penalization term is straight forward. The experiments you have do not make any inroads to answering these questions and there are no written arguments of note to address them.
The fact that SNAIL (TCML Mishra et al. (2017)) consistently outperforms this method puts a question mark on the significance of this work. The self-regularization allows the model to have a performance improvement, and it is considered one of the contribution of this work. - Related to the issues mentioned before, I may also complain that matching far away points might not be ideal. - fig.1, what are \\phi and \\psi. The self-regularization allows the model to have a performance improvement, and it is considered one of the contribution of this work. It would have been nice if authors used this added interpretability in some manner. - Related to the issues mentioned before, I may also complain that matching far away points might not be ideal. While understanding why a blackbox matching network is making a mistake and improving, is  harder.
Summary: This paper proposes a novel differentiable approximation to the curiosity reward by Pathak et al. that allows a learning agent to optimize a policy for greedy exploration directly by supervised learning, rather than RL. For DQN this is to be expected, but it shows that backprop through this function is more efficient than reinforce in getting to unseen state spaces. The goal of making a practical algorithm for real-world exploration tasks is exciting. Is there a citation that can back this? For example in this statement, robots aren't a requirement for evaluating intrinsic motivation.
This paper presents a topic model based on adversarial training. The model basically combines two steps: first to generate words (bag-of-words) for a topic, then second to generate the sequence of the words. This paper proposes a new framework for topic modeling, which consists of two main steps: generating bag of words for topics and then using RNN to decode a sequence text. Pros: The author draws lessons from the infoGAN and designed a creative object function with reconstruction loss and categorical loss. (3) Some of the experiment settings are not provided, for example, the number of topics, the value of \\alpha and \\lambda in the proposed model, the hyperparameters of LDA, which are crucial for the results. Perplexity (table 3) shows similar results for DBPedia and worse results (than WGAN-gp) for Gigaword. It is not so convincing to just use VAE+Wgan-gp as a baseline model. In conventional topic models, usually a topic is a distribution of words, so that top words can be selected by their weights. our method assumes that the documents are produced from a single topic ... My comments are as follows: 1. There are several issues of this paper on clarity: (1) The first major one for me is that the authors did not give any details on how to interpret the latent code (i.e. the topics here) with the top words. For the first task, classification is not the main purpose of topic models, and while text classification _is_ used in many topic modeling papers, it is almost always accompanied by other evaluation metrics such as held-out perplexity and topic coherence. (3) I did not see a major improvement of the proposed model over others, given that the only numerical result reported is classification accuracy and the state-of-the-art conventional topic models are not compared.
This paper aims to address the problem of lacking sufficient demonstrations in inverse reinforcement learning (IRL) problems. That said, the paper combines them in the most straightforward way, which does not incur any complications that call for technical solution that can be counted as a contribution to science. Imitation learning is only briefly mentioned in the related work (section-2), it would be helpful to elaborate on this. In the reported experiments, what is used and what is the impact on results, if any ?
That is, comparison of CPO and Lagrangian constraint based RL with Lyapunov based method proposed depends on a lot of factors (such as those just mentioned) that are not systematically explored by the paper.
This is achieved by using a generative adversarial network (GAN) to generate high-entropy samples that are then used by a nearest neighbor method to pick samples from a pool, that are closest to the generated samples. Given that your method is not working very well for CIFAR, I would like to see a more thorough investigation as to why that may be the case. Cons: (1) The idea of using GAN for active query synthesis isn't new. -The main contribution of this algorithm is computational complexity, but I am not very persuaded by the idea of using the GAN in order to produce a sublinear (faster) time algorithm for active learning, since training the GAN may sometimes take more time that the whole active learning process. Given that your method is not working very well for CIFAR, I would like to see a more thorough investigation as to why that may be the case.
Which brings me to point Cons: - RAML and SPG have not been established as important methods in practice. Furthermore, the MLE interpretation discussed is contained within the RAML paper, and the reductions to RAML and SPG are straightforward by design, and so do not really provide much new insight. Having access to these experimental results is important, since it would enable the reader to understand whether the benefits of the new approach are subsumed by regularisation or not. In particular, if this generalization can significantly outpeform existing methods it generalizes with non-degenerate settings, this would overcome the more incremental contribution of combining SPG and RAML. Wrt: 1), While RAML was a significant contribution at the time, it is now well established that RAML generally doesn't perform well at all in practice due to exposure bias (not conditioning on it's own previous predictions during training). Considering this, I feel that the importance of the paper largely rests on investigating and establishing the utility of the approach experimentally.
Here, the authors study a deterministic neural network, for which the mutual information estimation is difficult (I(X,L)) and error prone. This paper provides a method to do explicit IB functional estimation for deep neural networks inspired from the recent mutual information estimation method (MINE). By using the method, the authors 1) validate the IB theory of deep nets using weight decay, and 2) provides a layer-wise explicit IB functional training for DNN which is shown to have better prediction accuracy. To combat this they use the noise-regularized mutual information estimator (I(X; L+eps)). Both terms of the IB cost function are formalized as mutual informations, but since in neural nets, the latent "compression" is a deterministic function of the inputs, a severe technical problems arises: the joint distribution between p-dimensional inputs X and the q-dimensional latent compression L is degenerate in that  its support lies in a space of dimension p (and not p+q as it would be in the non-degenerate case). At the bottom of page 6 they rightfully say that mutual information is invariant to reparameterizations, but their noise regularized mutual information estimator is not (by their own reference (Saxe et al 2017). Just plugging in the Discriminator for the objective (equation (7)) is flawed. I believe the authors instead meant to say that the cited works deviate from the information bottleneck theory of learning suggested in (Shwartz-Ziv & Tishby 2017). They claim that Figure 5 (a) is more 'quantized' than (b) and "has reduced entropy". It seems that the paper is trying to convince two things to the readers: 1) The compression phase in DNN does exist 2) Layer-wise training helps to improve the accuracy.
This paper proposes a hybrid machine learning algorithm using Gradient Boosted Decision Trees (GBDT) and Deep Neural Networks (DNN). It seems heavily dependent on GBDT.
This paper discusses the problem of evaluating and diagnosing the representations learnt using a generative model. By extracting this kind of features, they effectively decrease the dimmension of  data. The author proposed an extended version of MNIS where they introduced thickening/thinning/swelling/fracture. This paper discusses the problem of evaluating and diagnosing the representations learnt using a generative model. By extracting this kind of features, they effectively decrease the dimmension of  data. The author proposed an extended version of MNIS where they introduced thickening/thinning/swelling/fracture. Since their method is manually designed for MNIST, the manuscript would benefit from a justification or discussion on the  common pitfalls and the correlation between MNIST generation and more complex natural image generation tasks. For example sharpness and attending to details is not typically a challenge in MNIST generation where in other datasets this is usually the first challenge to be addressed. I'm not convinced that ability of a model in disentangling thickness correlates to their ability in natural image generation. * Providing benchmark data for tasks such disentanglement is important but I am not sure generating data is sufficient contribution for a paper. Studying the properties of a generative model on such datasets is very challenging and the authors have not added a discussion around that. Their tools are a handy addition to the analytical surveys in several applications (e.g. how classification fails), but not convincingly for generation. However, when the entire image is subject to the generative model, it learns multiple properties from the image apart from shape too - such as texture and color. Therefore, statistically comparing the distribution of generated vs test data and binning the generated data is now possible.
This paper discusses the effect of L1 penalization for deep neural network. For network compression, it is common to add L1 Penalty to loss function. 3. It is also unclear how the trade-off in point (b) of the abstract is justified in the experiments. If so, it should be specified.
This paper proposes a multi-layer pruning technique based on the Hessian. Here, the corresponding Hessian matrix is approximated using the Fisher information to make the algorithm scalable to very deep networks. Summary: I do appreciate the fact that the proposed method does not require hyper-parameters and that it seems to yield higher compression rates than other pruning strategies that act on individual parameters. There is not much on that. - Compute time is not provided. Method: - It is not clear to me why the notion of binary parameters gamma is necessary.
Authors provide a convergence guarantee (without any convergence rate) by simply extending the convergence of gradient method. In particular, the method assumes the existence of a loss function for the main task that we are interested in, and a loss function for an auxiliary task that shares at least some of the parameters with the main loss function. Some examples are showed in the paper to support this argument, however it would be helpful if there is some theoritical gurantee on this. So a more general question would be: rather than define the similarity measure to measure the gradient similarity of the target and auxiliary loss, it would be more useful to try to learn or define whether the auxiliary task is good for the target task beforehand. Some examples are showed in the paper to support this argument, however it would be helpful if there is some theoritical gurantee on this. 2) In proposition 1, if the concerns in 1) are reasonable, the equation would be doubtful. In that sense, the method is no silver bullet. Here is the summary: Although the response addresses some of my concerns. Method should be experimented with some of those setups. Example of these methods are: [GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks, ICML 2018] and [Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics, CVPR 2018]. I think the paper needs to be experimented and compared with these established methods. Similar to my first points, these papers also use very realistic and interesting experiments which would fit better than the toy experiments in the paper. I think the paper needs to be experimented and compared with these established methods.
The trick that leads to computational tractability involves utilizing a latent variable and optimizing the f-divergence between joint distributions which is an upper bound to the (desired) f-divergence between the marginal distributions. The paper proposes a method for training generative models with general f-divergences between the model and empirical distribution (the VAE and GAN objectives are captured as specific instantiations). \\clarity & quality The paper is easy to follow and self-contained. So I cannot tell whether the proposed objective is really useful to learn the deep generative models. The statements of "KL (moment matching)" and "reverse KL (mode seeking)" are not consistent with what's stated in Sec 2.2 (the paragraph under Eq (3)). So I cannot tell whether the proposed objective is really useful to learn the deep generative models.
Which one do the models presented in Table 1 use? 6. Figure 2 visualizes proposed embedding space (2D) but it shows VAE and beta-VAE models and omits to show PSE.
A salient asset of the manuscript is that it avoids a pitfall of the original mixup algorithm: interpolating between inputs may result in underfitting (if inputs are far from each others: the interpolation may overlap with existing inputs). - I find the manifold mixup idea to be closely related to several lines of work for generalization abilities in machine learning (not just for deep neural networks). The authors theoretically prove that with the proposed training cost in Manifold Mixup, the representation for each class will lie on a subspace of dimension dim (h) –d +1 (h and d are the hidden dimension and number of classes, respectively). I would suggest that the authors fully compare with MixUp in the supervised learning tasks, namely using all the datasets (including ImageNet) and networks architectures used in MixUp for supervised learning.
This work considers the problem of learning a non-linear dynamical system in which the output equals the state. This work tackles a very challenging problem and the results are interesting. I agree that the paper has nice convergence results that could possibly be building steps towards the harder problem of unobserved hidden states however, there is more work that could be done for unstable systems and possible extension to ReLU and other activations to take it a notch higher. Should this assumption be included in the statement? The proof idea is to reduce this problem to the problem of learning a single non-linear neuron in the case that the covariance matrix of the data is well-conditioned. I suggest to write a summary of the steps required to prove the main result and how all of the technical ideas are combined together.
This paper proposed two new GAN structures for learning a generative modeling using the superposition of two structured components. Pros: the authors develop a novel GAN-based approach to denoising, demixing, and in the process train generators for the various components (not just inference). It seems like a noveel approach to demixing which is exciting. In general, they don't compare to any other methods. The other demixing setting of adding 1's and 2's has a similar problem. In general, they don't compare to any other methods. The other demixing setting of adding 1's and 2's has a similar problem. The authors need to provide (R)MSE  results that show how well the method can reconstruct mixture components on average over the dataset.
This paper studies the problem of making predictions with a model trained using dropout. Authors arguments about the tightness of the bound of Eq (8) and Eq(9). I think it would be clearer to directly introduce the weighted power mean instead of the standard power mean in Section 3.2.
The authors seek to make it practical to use the full-matrix version of Adagrad's adaptive preconditioner (usually one uses the diagonal version), by storing the r most recently-seen gradient vectors in a matrix G, and then showing that (GG^T)^(-½) can be calculated fairly efficiently (at the cost of one r*r matrix inversion, and two matrix multiplications by an r*d matrix). adagrad, adadelta are both popular adaptive variations of sgd. When you say that full-matrix computation "requires taking the inverse square root", I assume you know that is not really correct? The paper considers adaptive regularization, which has been popular in neural network learning. Overall, I think that this is an elegant idea and I'm convinced that it's a good algorithm, at least on a per-iteration basis. Given that rxr is a small constant sized matrix and that matrix-vector multiplication can be efficiently computed on GPUs, this matrix adapted SGD can be made scalable. Instead, it is a low-rank approximation to the full matrix. If this method is to be useful, understanding how these spectral properties change during training for different types of networks is essential.
The submission describes a method for smoothing a non-differentiable machine learning pipeline (such as the Faster-RCNN detector), so that gradient-based methods may be applied to jointly train all the parameters of the pipeline. It is not clear that the proposed method would outperform an arbitrary black box optimization method such as simulated annealing, Nelder-Mead, cross-entropy method, etc. It is not clear that the proposed method would outperform an arbitrary black box optimization method such as simulated annealing, Nelder-Mead, cross-entropy method, etc.
This paper proposes a generalization of variational auto-encoders to account for meta-data (attributes), learning new ones, in a way that these can be controlled to generate new samples. 2018. This paper introduces a new framework for learning an interpretable representation of images and their attributes. The authors do point to the Appendix for their Experiments section, however this is not a good idea. I think the significance of this work lies in the fact that this can be a starting point for several interesting future works in this direction. 2.- Almost absence of experiments: The paper only has one experiment, which is in the appendix, and is about sampling using the MNIST dataset.
The paper proposes a new algorithm for implicit maximum likelihood estimation based on a fast Nearest Neighbor search. Pros: The primary contribution of this paper is an algorithm for implicit likelihood maximization with theoretic guarantees. - Experiments are using Parzen window for estimating likelihood which  are known to be unreliable in high dimensions. Minor points for improving presentation: - Section 3 can be made more concise and to the point. I would be very interested in having a closer look. Since it is crucial for the proposed method to be scalable it is worth presenting this algorithm at a high level in the main paper. - Experiments are using Parzen window for estimating likelihood which  are known to be unreliable in high dimensions.
The new thing is that the authors found that quantization of activation function improves robustness, and the approach can be naturally combined with FGSM adversarial training. The new thing is that the authors found that quantization of activation function improves robustness, and the approach can be naturally combined with FGSM adversarial training.
This paper proposes a method to train a machine translation system using weakly paired bilingual documents from Wikipedia. Positives - Large improvement over previous attempts at unsupervised MT for the En-De language pair. Do you do normalization for P(w^Y;d_i^X,\\theta) in eq.6 which is defined on the entire vocab's distribution? - What is the total number of sentences in the weakly paired documents in Table 1? It would be useful to know the proportion of sentences you managed to extract to train your models. 2) Have the authors considered matching sentences to any other sentence in the monolingual corpus as opposed to sentences in the comparable document?
The paper proposes a new graph pooling method by learning the node assignments from a CRF based structure prediction formulation. Strength: -- An interesting idea to use CRF idea to cluster the nodes on a graph for pooling purpose --  On a few datasets and task, the proposed method works pretty well
- The authors do not describe their baselines for several experiments. I strongly encourage the authors to carefully edit the paper before publication so that their nice work will be properly presented. At a high level, this paper is experimentally focused, but I am not convinced that the experiments are sufficient for acceptance.
In order to identify which particular features the neural networks are paying attention to, the paper used Deep Taylor Decomposition, which allowed the authors to identify "clever-hans"-type phenomena (network attending to meaningless experimental setup differences that actually gave a way the ground truth classes). BACKGROUND: Hypothesis: Prey movements in zebrafish are characterized by specific motions, that are triggered by a specific pathway involving an area called AF7. The paper presents a case study of training a video classifier using convolutional networks, and on how the learned features related to previous, hand-designed ones. In particular observations like " looking for salient features in the trunk of the tail while largely disregarding the tip", are typically absent from most deep learning studies and it's quite interesting. Validation: Semmelhack et. al. (2014) removed the AF7 neuropil and observed that they failed to respond to prey stimuli This allowed for the authors to mask out such features and make the network attend to more meaningful ones. it illustrates how model interpretability and human intuition and domain knowledge can be useful. Perhaps the authors are also not aware that the fallacies that causes CNNs to overfit on some characteristics in the input data are also present in other machine learning tools such as SVMs. It is not explained why the authors chose to pretrain on ImageNet, since ImageNet does not have any image classes that are comparable to the dataset the authors use. they show that, relying on the technique of deep taylor decomposition, their CNN relies its prediction on a different part of zebra fish than existing understanding.
Moreover, the authors introduce an additional compensation term and derive a novel optimization method, MaSS. This paper shows the non-acceleration of Nesterov SGD theoretically with a component decoupled model. The authors present a new first order optimization method that adds a corrective term to Nesterov SGD.
This paper studies impossibility results of GNN in the worst-case sense. But I do think this paper provides a solid contribution to broaden the community's understanding about what the limitations of GNNs are. Overall, I tend to accept it and would like to increase the score based on authors' feedback.
The paper proposes a using pixel-adaptive convolutions to leverage semantic labels in self-supervised monocular depth estimation. === Post rebuttal update === The authors have addressed many of my initial concerns and provided valuable additional experimental evaluations. === Post rebuttal update ===
This paper studies the emergence of compositional language in neural agents. While this is also an intuitive result, it's nice to have in the paper. I think this is a nice contribution, but the main question for me is whether this is enough for an *CONF* acceptance.
# 1. Summary The paper introduces a pre-training procedure for visual-linguistic representations. This paper proposed a pre-trainable generic representation for visual-linguistic tasks call VL-BERT. Although the paper doesn't provide insights around what the representations have learned and how they differ from representations learned / used by existing methods, they have provided substantial evidence to suggest that pre-training helps in a lot of downstream tasks. * What is the performance/accuracy on the pre-training tasks?
The paper proposes a metric for unsupervised model (and hyperparameter) selection for VAE-based models. Based on the understanding of "why VAEs disentangle" [Burgess et al. 2017, Locatello et al. 2018, Mathieu et al. 2019, Rolinek et al. 2019], the authors adopt the assumption that disentangled representations are all alike (up to permutation and sign inverse) while entangled representations are different, and propose UDR method and its variants. Equation (3) looks problematic. Note that it is possible to train a Bidirectional Generative Adversarial Network (BiGAN) that can generate complex images based on a uniform distribution (Donahue et al., 2016). I am inclined to accept the paper for the following reasons: 1. The proposed approach is clear and easy enough to understand and well motivated The problem this paper focuses on is essential because we usually apply unsupervised disentangled methods to analyze the data when the labels are unavailable.
This paper presents ReMixMatch an improved version of MixMatch. The main drawback of the paper is that it seems to be more engineering-focused, and doesn't provide much insight into semi-supervised learning. I there fore recommend it for acceptance.
This paper proposes to use a semi-supervised VAE based text-to-speech (TTS) for expressive speech synthesis. The idea is interesting and new.
Summary: This paper presents a family of architectural variants for the recurrent part of an RL controller. The primary claim is that simple components which compute elementwise sum/average/max over the activations seen over time are highly robust to noisy observations (as encountered with many RL environments), as detailed with various empirical and theoretical analyses. # UPDATE after rebuttal I have changed my score to 8 to reflect the clarifications in the new draft.
Equipped with the proposed techniques, the authors obtain promising results when training deep models with various batch sizes. The paper performs an empirical study of four batch-normalization improvements and proposes a new normalization technique for small batch sizes, based on group and batch normalizations. 3. By combining all the techniques, the proposed method yields promising performance when training deep models with different batch sizes. (2) In Section 3.1, "Batch Normalization has a disparity in function between training inference". 4. The authors draw different conclusions about the usage of weight decay from a recent work (He et al, CVPR2019).
They learn a threshold value for which all activation values above the threshold are learned at full precision, while all below are learned at reduced precision. According to the experiments, the method achieves better performance and computational savings as compared to other quantization method baselines. This paper outlines a new method that allows using a variety of precision in the numerical representation of the network to increase performance (both in terms of accuracy and speed). Even though at the moment it is unclear to me how statistically significant the results are, and I strongly recommend commenting on this in the paper, I think the idea of PG and the demonstrated benefits make the paper interesting enough to be accepted at *CONF*.
(VHE) randomized generative adversarial network (GAN) that integrates a probabilistic text decoder, probabilistic image encoder, and GAN into an end-to-end multimodal model. Summary: The authors design a new model for bidirectional joint image-text modeling using a variational hetero-encoder (VHE) randomized generative adversarial network (GAN) that integrates a probabilistic text decoder, probabilistic image encoder, and GAN into an end-to-end multimodal model. This paper proposes a combined architecture for image-text modeling. This paper proposed VHE-GAN for the text-to-image generation task. The authors also incorporate a deep topic model, a ladder-structured image encoder, and StackGAN++ into their framework for improved photo-realistic images. (VHE) randomized generative adversarial network (GAN) that integrates a probabilistic text decoder, probabilistic image encoder, and GAN into an end-to-end multimodal model. Combined with the included code release, this paper should be of interest to many.
The problem is challenging because one has to map natural language as observations to appropriate representations to partially infer the state space of the world, and actions are also defined in vast space of natural language sentences. I think it is a better way to construct a structural representation of the world rather than assuming the agent gonna learn everything via single hidden state vector. The paper is very well written, especially the introduction section, demonstrating novelty in the context of fictional games literature, and showing good empirical results. I think it is more convincing to have a baseline which leverages the same entity extraction and template-action space. If the model is merely trained on one map as shown in figure 5, it may just memorizes it in the knowledge graph and overfit to this map.
The authors rigorously construct a learning framework that can satisfy the desiredata and then show how this can be tractably instantiated. If the authors can address my comments, I will be willing to increase my score.
This paper studies robustness to adversarial examples from the perspective of having 'topology-aware' generative models. thereby making them more robust to adversarial examples. in this paper. While this is perfectly adequate in the sense of connected components being a particular concept from topology, I would expect this to be clarified much earlier in the paper. - I would not state that the main goals of the experiments are to This paper studies robustness to adversarial examples from the perspective of having 'topology-aware' generative models.
This paper proposes to use a flat array instead, and obtain each of the C_out filters of shape C_in x H x W by indexing this array with stride. Compression of the convolution operation is done with weight sharing: unwrapped kernel (channel-major) is packed into 1D vector by having intersected segments (shared weights). "efficiency searching scheme" This paper proposes a method, termed as Filter Summary (FS), for weight sharing across filters of each convolution layer. - In Table 4 it would be better to have results for FSNet-1 too (without quantization).
Statistics themselves are calculated using 32 bit floating point numbers. Those per tensor statistics are used to map 8-bit representation into a rational number. * Equation (3) uses "i-prime" in the argument for "max", but "i-prime" is not used. Overall, this is a good paper that presents an important contribution. The paper is well written, easy to follow, and provides a detailed background for readers who are not knowledgeable in this field. [1] https://en.wikipedia.org/wiki/Bfloat16_floating-point_format Good ideas Important area Impressive results. Overall, this is a good paper that presents an important contribution.
1) converting the trained ANN to a "spike" neural network (SNN), The authors present a biologically inspired sleep algorithm for artificial neural networks (ANNs) that aims to improve their generalization and robustness in the face of noisy or malicious inputs. They hypothesize that "sleep" could aid in generalization by decorrelating noisy hidden states and reducing the overall impact of imperceptible perturbations of the input space. The core concept behind the authors' work is novel and interesting, and the experimental design is thorough and well controlled. It would be a good idea to re-run this experiment with a binary classification problem (e.g. only two digits of MNIST) and see if this phenomenon still occurs. I have some questions and concerns which I will detail per-section below, but overall, I believe that this paper is a valuable contribution to the literature and should be accepted once the authors have made a few necessary revisions.
The paper probably be condensed in the first 4 pages, so that more experimental results could be presented and this would make the paper stronger. Generally, this paper is interesting and well-written.
This paper studies the situation in which a two-layer CNN with RELU nonlinearity is fit to a single image and the observation that it is able to fit a "natural" image in fewer iterations than a "noisy" image. There is a link to a figure in the appendix that is broken on page 5 This paper studies the situation in which a two-layer CNN with RELU nonlinearity is fit to a single image and the observation that it is able to fit a "natural" image in fewer iterations than a "noisy" image.
Overall, this paper studies an important problem in computer vision with a novel solution using unsupervised feature learning. Results demonstrate the strengths of the proposed view-contrastive framework in feature learning, 3D moving object detection, and 3D motion estimation. This paper show that view prediction learning to help 3D detection. Moreover, the proposed model is evaluated on the downstream 3D object detection tasks to demonstrate the utility of the learned 3D visual representation. I appreciated the limitation section, which is transparent and honest, and clearly states the strength and weaknesses (such as image downscaling) of the approach. - A natural follow-up to this paper is Contrastive Predictive Losses (which had several successes in pure vision setting[1]). Any insight here? (4) The setting of SEMI-SUPERVISED LEARNING OF 3D OBJECT DETECTION is quite unclear and sloppy. I am positive with respect to accepting this work, but find that there are a few unclear points in the evaluation that should be clarified to strengthen the empirical results.
This paper tackles the problem of learning with noisy labels and proposes a novel cost function that integrates the idea of curriculum learning with the robustness of 0/1 loss. ======================================================== Significance: The proposed paradigm is interesting and I am convinced that it can be useful under label noise. I would like to vote accept for this paper but the following point highly concerns me and I am not sure about the correctness (see the concern below).
Results show that these methods fail to beat epsilon-greedy on other Atari games, even if the parameters of these methods are tuned. The paper concludes that methods that perform well on Montezuma's revenge do not necessarily perform well on the other games, sometimes, even worse than the eps-greedy approach. The authors combine Rainbow with different exploration methods, such as count-based bonus methods, curiosity-driven methods, and noisy networks. I am confused if the paper is making a narrow point that (1) dont focus on Montezuma's revenge OR (2) is it admitting a broader point that focussing on even ATARI is probably not a good choice. The empirical study offers some insights into deep RL methods for ATARI games and raises some key questions. The empirical study offers some insights into deep RL methods for ATARI games and raises some key questions.
I think the paper is well written and provides a nice discussion about how quantum computing can be applied to CNNs. I appreciate that both the forward and backward passes are studied although most of the technical details are in appendices. Preliminaries: - Maybe explain what the ith vector in the standard basis is in terms of |0> and |1>? I would suggest that for the conference presentation the authors try to bring out the essential within a less formal setting to open it to a wider ML audience. - There's a clear separation of background (which is concise and well explained) and contributions, but maybe it would be worth connecting the introduced algorithm more closely to existing work in non-convolutional quantum neural networks?
In this paper, the authors take a MobileNet v2 trained for ImageNet classification, and adapt it either (i) semantic segmentation on Cityscapes, or (ii) object detection on COCO. Concrete comments 1. The paper's overall method is a novel one, unifying NAS on det/seg tasks, while prior works mostly only focus on one task. - Lack of error bars or comparison to random search. But it is also interesting to see that this naive method works, and actually beat some of the more advanced alternatives in Section 4. On segmentation, the adapted model achieves ~1% mIOU improvement using  similar or less iterations and similar size of model with the methods it compared to, and GPU hours' saving is more significant. It also "eliminates" the need for pretraining each instance of the subnetwork. The paper is also clearly organized and written. On a related note, the authors write that this network is used for its "generality". I am giving this paper a weak reject, as there is insufficient experimental evidence that the technique works, or generalises beyond Mobilenetv2.
The results on synthetic datasets (2D, MNIST image) and real-world datasets (RNA sequence) show that the learned transport cost outperforms the Euclidean distance and Procrustes-based OT. # Significance - This paper seems to present a neat and sensible idea for learning OT with neural networks given subset correspondence information. The authors formulate it as a transport cost learning in optimal transport framework with constraints giving by side information. # Significance - This paper seems to present a neat and sensible idea for learning OT with neural networks given subset correspondence information.
# Significance - This paper seems to present a neat and sensible idea for learning OT with neural networks given subset correspondence information. If the author(s) would like to show good performance, I would suggest to compare the algorithms with the state-of-the-art algorithms in Deep Learning such as Adam, SGD-Momentum.
In this paper, the authors proposed two methods of Nesterov Iterative Fast Gradient Sign Method (NI-FGSM) and Scale-Invariant attack Method (SIM) to improve the transferability of adversarial examples. Experiments on ImageNet can prove the effectiveness of the proposed methods. This paper studies how to generate transferable adversarial examples for black-box attacks. In this paper, the authors apply the Nesterov Accelerated Gradient method to the adversarial attack task and achieve better transferability of the adversarial examples.
This paper studied the problem of "deep" GCNs where the goal is to develop training methods that can make GCN becomes deeper while maintaining good test accuracy. The extensive experiment results also show that for deeper GCNs, DropEdge always win over other baselines (see Tab 1) despite most of them are marginal except the backbone being GraphSAGE on Citeseer. The extensive experiment results also show that for deeper GCNs, DropEdge always win over other baselines (see Tab 1) despite most of them are marginal except the backbone being GraphSAGE on Citeseer.
This paper proposes a way to compress past hidden states for modeling long sequences. Attention is used to query the compressed representation. The paper also introduces a new benchmark for long-range dependencies modelling composed of thousands of books. The idea is to compress distant past memories into a coarse-grained representation while keeping a fine-grained representation for close past memories. The key novelty of this model is to preserve long range memory in a compressed form, instead of discarding them as previous models have done. The model is also evaluated on two other tasks: speech generation and reinforcement learning on videos. For testing and evaluating the modeling of really long context sequence modeling, the authors introduce PG-19, a new benchmark based on Project Gutenberg narratives. P.S. Thanks for the rebuttal. I have lifted my score. ## Updated review I have read the rebuttal. The latest version of the paper adressed all my concerns, hence I change my rating to Accept. Overall, I found the work interesting and experiments are thorough and strong. - The WikiText-103 evaluation is interesting, specially Table 6, which shows the advantages of the model. I think this paper should be accepted, mainly because: - The proposed model is novel as far as I can tell.
This paper studies the convergence of CHOCO-SGD for nonconvex objectives and shows its linear speedup while the original paper of CHOCO-SGD only provides analysis for convex objectives. The results show the algorithm generally outperforms the baseline. The momemtum version of CHOCO-SGD is also provided although no theoretical analysis is presented. This paper studies non-convex decentralized optimization with arbitrary communication compression. The results show the algorithm generally outperforms the baseline. Further clarification on this is needed.
Summary: This paper is about developing VAEs in non-Euclidean spaces. Fairly recently, ML researchers have developed non-Euclidean embeddings, initially in hyperbolic space (constant negative curvature), and then in product spaces that have varying curvatures. --Past works have considered VAEs on single constant curvature spaces and hence it is well-motivated to consider a more flexible model that enables usage of products of such spaces. Evaluation: Overall this seems to be a nice work, with balanced discussion of the empirical results, and is clearly written. Overall, I recommended weak accept, since a lot of these issues seem like they can be cleaned up.
This paper is on building binary network. My biggest concern is that ResNet is itself a very wasteful architecture in terms of compute and parameter count. This paper is on building binary network. The first method is to use a teacher-student mechanism that uses a fully real-valued network to teach a binary network.
This paper attacks the problem of pruning neural networks to obtain sparser models for deployment. In introduces a principled importance sampling approach for which independence of samples allows one to obtain bounds easily. In contrast, all the results of this method gets worse results; this is less desirable. Besides, Author should also consider an experiment in modern lightweight network, vgg and resnet like model are out of fashion and so big that any one can make a sound result on it. ImageNet model has great impact on most CV problem, and the current release models are flooding in the open source world. In general, this paper is very well written and organized. This paper gives rise to a fully-automated procedure for identifying and preserving the filters in layers that are essential to the network's performance.
Alike other HRL agents, their method has two types of policies (manager and subpolicies), but different from other works they do not keep parameters fixed in post training for new tasks. They show that their method has a better performance and is more robust against sensor errors and physical parameter alterations. The motivation of this paper is "most methods still decouple the lower-level skill acquisition process and the training of a higher level that controls the skills in a new task." The paper proposes a method to learn higher-level skill selection and lower-level skill improvement jointly. What I like in this paper: 1. The paper, in general, is well-written so that I can understand it well. This behaviour is not described anywhere. It seems that the author is not aware of this point as the paper claims a particular way of achieving HRL is the HRL itself (in section 4.1 "In the context of HRL, a hierarchical policy with a manager πθh(zt|st) selects every p time-steps one of n sub-policies to execute."). This paper is under the topic of hierarchical reinforcement learning.
This paper describes an approach to applying attention in equivariant image classification CNNs so that the same transformation (rotation+mirroring) is selected for each kernel. For example, if the image is of an upright face, the upright eyes will be selected along with the upright nose, as opposed to allowing the rotation of each to be independent. Overall, this is a good idea that appears to be well implemented and well evaluated. - I think it would have been easier just say that you are using a roto-translation or p4m equivariant CNN with attention after each convolution.
- I think it would have been easier just say that you are using a roto-translation or p4m equivariant CNN with attention after each convolution. Since the proposed method is using RSB as it's core part, and claims to be a non-linear extension of it, it would be crucial to have a comparison with RSB, at least on those experimental setups, where high-level features are used (Tiny Imagenet with ResNET features, Reuters-21578, and 20 Newsgroups).
This is achieved by having a set of random networks (i.e. neural networks where their parameters are randomly initialized) and then computing an uncertainty value based on the difference in the predictions between those random networks and networks that are trained to mimic them on a finite collection of points. This is achieved by having a set of random networks (i.e. neural networks where their parameters are randomly initialized) and then computing an uncertainty value based on the difference in the predictions between those random networks and networks that are trained to mimic them on a finite collection of points. </update> The paper shows that the MSE of a deep network trained to match fixed random network is a conservative estimate of uncertainty in expectation over many such network pairs.
In this paper, the authors outline a method for system control utilizing an "agent" formed by two neural networks and utilizing a differentiable grid-based PDE solver (assuming the PDE describing the system is known). They have compared their method with several baselines and demonstrated that the proposed approach is both more effective and efficient in several challenging PDEs, including the incompressible Navier-Stokes equations. ## Summary The authors propose a method for training physical systems whose behavior is governed by partial differential equations. I think it would be a great addition to *CONF*. The paper presents an interesting mix of neural networks and traditional PDE solvers for system control, and I vote for acceptance.
EITI uses mutual information to capture the influence of one agent on the transition dynamics of others,  while EDTI uses an intrinsic reward called Value of Interaction (VoI) to quantify the influence of one agent's behavior on expected returns of other agents. The use of the decision-theoretic influence is novel as far as I can tell and it also seems to be quite effective on the tasks used for evaluation. * Eq 5: What is the difference between I and MI? Update: I thank the authors for their response and I will maintain my score, my main hesitation being the overall clarity and readability of the paper.
This paper discusses an extended DSL language for answering complex questions from text and adding data augmentation as well as weak supervision for training an encoder/decoder model where the encoder is a language model and decoder a program synthesis machine generating instructions using the DSL. They show interesting results on two datasets requiring symbolic reasoning for answering the questions. This paper presents a semantic parser that operates over passages of text instead of a structured data source. This paper discusses an extended DSL language for answering complex questions from text and adding data augmentation as well as weak supervision for training an encoder/decoder model where the encoder is a language model and decoder a program synthesis machine generating instructions using the DSL. I have a ton of questions about this method, but they are good questions. The rest of this review focuses on things that I thought could be more clear, or that raise new questions, and might sound negative. With the weak supervision that you have, are you actually able to find more complex programs during your search? The three claimed contributions are (1) better numbers, (2) better compositionality / domain applicability, and (3) better interpretability. They show interesting results on two datasets requiring symbolic reasoning for answering the questions. Overall, I like the paper and I think it contains simple extensions to previous methods referenced in the paper enabling them to work well on these datasets.
Similarly authors give a variational form of the wasserstein natural gradient . A well-known difficulty in using natural gradient is that it is tedious to compute the Fisher matrix (if one is using Fisher-Rao metric) and the Wasserstein information matrix (if one is using Wasserstein metric). I find this work interesting with some important merit, as it tackles an important problem in statistical learning. I find this work interesting with some important merit, as it tackles an important problem in statistical learning.
Summary: The authors proposed a method for generating hierarchical importance attribution for any neural sequence models (LSTM, BERT, etc.) Towards this goal, the authors propose two desired properties: 1) non-additivity, which means the importance of a phrase should be a non-linear function over the importance of its component words; Results show that their proposed context-independent attribution correlates better with a trained linear model's coefficient, achieves higher human trust. Summary: The authors proposed a method for generating hierarchical importance attribution for any neural sequence models (LSTM, BERT, etc.) Towards this goal, the authors propose two desired properties: 1) non-additivity, which means the importance of a phrase should be a non-linear function over the importance of its component words;
Finally, the authors demonstrate that K-matrices can be used instead of the decoder's linear layers in a Transformer-based architecture on the IWSLT-14 German-English translation benchmark which allows obtaining 30% speedup of the inference using a model with 25% fewer parameters with 1.0 drop of BLEU score. Even though in the worst-case complexity is not optimal, the authors argue that for matrices that are commonly used in machine learning architectures (e.g. circulant matrix in a convolution layer) the characterization is optimal.
This paper proposed a new synthetic dataset (CATER) for video understanding. They further conduct a variety of experiments to benchmark state-of-the-art video understanding models and show how those models more or less struggle on temporal reasoning. The dataset is an extension of CLEVR using simple motions of primitive 3D objects to produce videos of primitive actions (e.g. pick and place a cube), compositional actions (e.g. "cone is rotated during the sliding of the sphere"), and finally a 3D object localization tasks (i.e. where is the "snitch" object at the end of the video). It is a well-argued, thoughtful dataset contribution that sets up a reasonable video understanding dataset. The paper introduces CATER: a synthetically generated dataset for video understanding tasks. It does a good job at summarizing the deficiencies in existing datasets, clearly motivating the need for a new dataset. - p9 phenomenon -> phenomena; the the videos -> the videos; these observation -> these observations; of next -> of the next; in real world -> in the real world This paper introduces a new synthetic video understanding dataset, borrowing many ideas from the visual question answering dataset CLEVR.
The method consists of a Deep Score Network and a Post-Process Network (PPN). The authors proposed an end-to-end method (E2Efold) to predict RNA secondary structure. This method is creative, could be applied to other tasks with constraints, and would be interesting to the wider deep learning community. I advocate for acceptance. *Comments* The actual specification of the output constraints doesn't occur until late in the paper.
This mutual information can be visualized in the input image, but it also has a clear, quantitative meaning that is readily interpretable. ii) Proposal of a novel quantitative measure to compare quality of pixel-level attribution maps in image classification, and extension of a previously reported method. Table one shows that different beta would lead to very different downstream task accuracy. [1]: Adebayo, Julius et al. "Sanity Checks for Saliency Maps." NeurIPS (2018).
The paper proposes a method for learning options that transfer across multiple learning tasks. The task or a set of tasks? One obvious limitation here is that they also have a hard imposed constraint here is that the options cannot run for more than 20 time-steps in total, to make the objective function a suitable choice. Please provide clarifications. In experiments: FR rooms experiments are interesting, in the visualization of the option policies, do the figures here show the flattened policy of the options? Finally, I wonder how this method can be compared to skill embedding learning methods such as [1], which have been shown to be able to compactly represent skills in a latent space and reuse those skills in high-dimensional robotic manipulation tasks. Please provide clarifications. In experiments: FR rooms experiments are interesting, in the visualization of the option policies, do the figures here show the flattened policy of the options? Please provide clarifications. In experiments: FR rooms experiments are interesting, in the visualization of the option policies, do the figures here show the flattened policy of the options?
First it argues that one should consider region-based measures rather than single nodes. The paper studies active learning in graph representations. To decide which nodes in a graph to label during the active labeling, the paper proposes two approaches. The authors present an algorithm for actively learning the nodes in a graph that should be sampled/labeled in order to improve classifier performance the most. This is supported neither in Table 1 nor Table 2, where APR is frequently not highest performing 1.2.1. Also e.g. "Region Margin" is worse than random on 5% Email-EU; or "Region Margin AE" on 3% SubeljCora (Table 2) [It is unclear how to select with or without AE] Weaknesses: 1. The paper contains several confusing and contradicting statements or claims which are not supported by the experimental results: For example: 1.1. 2.4. The decision what is bold and what is not is not consistent throughout the table 2. This is supported neither in Table 1 nor Table 2, where APR is frequently not highest performing
In particular, they study local interpretable models, which are used to study interpretability at the level of one or a few data points. This paper studies the problem of interpreting predictions of blackbox models. The aim of this work is to address this issue by learning how to select representative samples from a dataset for training local linear models to reproduce predictions of black-boxes. * I.e. if the weighting function is actually high-entropy, randomly sampling a (large) batch and weighting it might work just as well. * Would be nice to show the sizes of datasets and how many samples end up being used for different values of lambda. I've given a weak accept, conditioned on being provided more evidence regarding 1) comparisons to simple differentiable alternatives, 2) sample efficiency of the RL method, and 3) basic analysis of the weighting function. * Pros: * Considers an interesting dataset subsampling variant of the sample weighting meta-learning problem. This function needs be updated in settings where the underlying dataset changes. [1] Learning to Reweight Examples for Robust Deep Learning.
The claimed finding is that there are no cells that are "sufficiently" selective to be called object detectors. Previous works have used different measures of selectivity (with sometimes contradictory results), and the authors investigate the degree to which these units qualify as "object detectors". It is also noticed that the existing metrics for selectivity do not adequately discriminate highly selective units in CNN. Overall, I think that the authors have presented a strong meta-analysis and compelling argument for further study in rigorously identifying the presence (or lack thereof) of selective units in neural networks and the degree to which they may be considered "object detectors. The paper empirically studies the category selectivity of individual cells in hidden units of CNNs. It is a sort of "meta-study" and comparison of different metrics proposed to identify cells with a preference for a specific target category. - is an indeed important problem for *CONF* community: Personally, I feel the "existence" of selective units in RNN could be interesting, but the "non-existence" in the case of CNN is not that surprising for some readers, as it seems much likely (at least to me): The final layer of CNN would be surely selective across classes, but it may be not the case for the hidden layers For example, I find it quite remarkable that some unit has 8% recall at perfect precision. It is a laudable effort that someone took on that job. In the words of the paper, the "selective units are sensitive to some feature that is frequently, but not exclusively associated with the class" - I thought this is the standard majority view, not a surprising finding. And vice versa, there could be a highly specific "Ferrari" detector that is so specialised that it has low recall for the "sports car" class (this case includes, among others, the case of viewpoint-specific detectors for certain categories). - In Section 2 - Network and Dataset - "...
It is a laudable effort that someone took on that job. 3. Is it possible to slow down the diffusion speed with the proposed ballistic filter? This paper proposed a new diffusion operation for the graph neural network. 3. Is it possible to slow down the diffusion speed with the proposed ballistic filter?
While (a) is very interesting, and an important contribution, (b) and (c) are contradictory. 3. Is it possible to slow down the diffusion speed with the proposed ballistic filter? Moreover, being able to capture the equivalence relation can be important for various graph learning tasks, e.g., to facilitate that two topologically equivalent graphs are be classified similarly. For instance, the SYNTHETIC dataset includes continuous node attributes that are essential for classification and make the graphs non-isomorphic (when considering, for instance, each attribute vector as a unique node label).
PAPER SUMMARY: This paper proposes a fast inference method for Gaussian processes (GPs) that imposes a sparse decomposition on the VI approximation of the posterior GP (for computational efficiency) using the KNN set of each data point. This results in a sparse factor of the covariance matrix which can be used for efficient computation. (3) For example, instead of forcing such local information in the posterior surrogate q(f), we could alternatively let it be reflected in the test conditional p(f_* | f_I, Y_n(*)) such that the test output depends on both the inducing output and a local partition of data (e.g., via K-mean), which has been previously explored in [*] and later incorporated in the conventional VI paradigm of Titsias (2009) without incurring extra intractability [**]. There are also a few technical ambiguities that need to be clarified. ------ Post-Rebuttal Update ------ Thank you for the rebuttal & I have read it in detail.
The authors prove that (1) SGD with their procedure will find a stationary point under the Robbins-Monro conditions for a fixed L and (2) SGD with their procedure will converge for convex problems as L is decreased to 0. - "random chosen point" -> "randomly chosen point" Decision and reasoning This paper should be rejected because
This paper proposes an adversarial detection method via Fourier coefficients. However, I have several concerns: Major: 1. It seems that the whole process assumes that there is difference for the parameters in the environment of GGD with adv/benign samples, and the goal is to search for the major components of it and use a classifier to detect.
The paper then follows this framework by constructing deep neural network mapping from "observations so-far" to "sufficient statistics" and by universal approximation theorem this is possible. What is the moment of probability space? Then, the resulting RNN-based filter is shown to be able to approximate well the optimal filter of the original SS model. To me it seems utilizing sufficient statistics? It considers a general state space model and uses feedforward neural nets (FNN) to learn the filtering and forecast distributions.
Further, I think that the loss-function for the classification task does not work in the general case. What is the moment of probability space? Then, the resulting RNN-based filter is shown to be able to approximate well the optimal filter of the original SS model.
What is the moment of probability space?
The problem is important and interesting. It is difficult to draw insights that are generally applicable from a single ensemble.
The paper proposes to explain a phenomenon that the increasing robustness for adversarial examples might lead to performance degradation on natural examples. In general, this paper seems technically sound. Moreover, not providing context makes it difficult to determine which parts of the paper are original and which are the result from previous work. ===== Review ===== The problem that the paper addresses is very significant to the robust optimization field and the study of adversarial robustness in neural networks. In summary, it is good that a theoretical bound can be derived from the paper, but this paper's quality may need more enhancement particularly on its writing and experimental parts. I an inclined to increase my rating and would suggest to weak accept this paper.
I would like to see an empirical analysis of that as well. I believe the objective in Eq. 1 is approximated, not calculated exactly?
This is a new metric they are proposing. first of all, it can be high while the extracted concepts are meaningless to humans, secondly, using it as a measure of comparison to rival methods is not quite fair as the introduced method is directly optimizing for this metric. Overall, I'm not impressed with the models' performances. The paper is introducing a new measure *and* new model, and it's hard to be persuaded the model is doing well based on this new measure, when there is little ground to know what this measure really measures. It is also interesting to see that the performance is comparable to non-self-nterpretable baselines which would make a case for the use of self-interpretable models. The idea of unsupervised extraction of concepts for interpretability was introduced before (https://arxiv.org/pdf/1902.03129.pdf) and is not discussed by the authors (although the utilized terminology is very similar). Is it for efficiency reason?
For this generalization error, the authors give both bounds for a fixed generator and a uniform bound for a class of generators. (Edit on 11/14/19: I have read the response and checked the revision. ---------------------- After rebuttal: I have read the authors' response. You might want to explain how these different definitions relate to each other. 5) Generalization bounds for all generators: Again, here the novelty and final result is very limited since the bounds achieved by a union bound arguments and does not really go beyond that. It also is not clear how they get the bound that they attribute to Bartlett, et al from the bound in that paper. However, since the generalization bound in Arora et al (2017) is based on a different definition of generalization error where empirical distributions are considered for both discriminators and generators, the comparison seems not fair.
In order to address this problem, the paper proposed a framework called LDMGAN which constrains the generator to align distribution of generated samples with that of real samples in latent space by introducing a regularized AutoEncoder that maps the data distribution to prior distribution in encoded space. The relative novelty over VEEGAN is also limited, the description of the method is exceptionally similar to the description used in the VEEGAN paper (going so far as to copy-paste a figure straight from VEEGAN without attribution), and the comparison to VEEGAN in the related work section is not sufficiently fleshed out. (5) There is a mistake in the second term of equation 11, it should be ⋯〖-D〗_KL (p^* (y)||p(y))  ) The relative novelty over VEEGAN is also limited, the description of the method is exceptionally similar to the description used in the VEEGAN paper (going so far as to copy-paste a figure straight from VEEGAN without attribution), and the comparison to VEEGAN in the related work section is not sufficiently fleshed out.
ICCV 2019. In this paper, the authors tackle the problem of multi-modal image-to-image translation by pre-training a style-based encoder. The style-based encoder is trained with a triplet loss that encourages similarity between images with similar styles and dissimilarity between images with different styles. I think the idea of pre-training a style-based encoder is straightforward. I think the idea of pre-training a style-based encoder is straightforward. Secondly, the generator is trained on a supervised image translation tasks: the original image and the style, extracted from the target image, are fed to the generator, and the output is a translated image.
This paper studies the problem of applying attention to the problem of image captioning. The authors then compare their TVMax approach with softmax and Sparsemax attention for image captioning and show improvements on the MSCOCO and Flickr datasets. This paper produces a new method call TVmax and presents that the selective visual attention could improve the score in the Image Captioning task. It is not clear that the motivation for these sparsifying objectives is sound. Moreover, for generalization one can use attention dropout which is simpler instead.] This paper proposes two sparsifying methods of computing attention weights, dubbed sparsemax and TVmax, which appear to slightly improve objective and subjective image captioning scores. In any case it is not clear why this should necessarily be a good inductive bias for all images, although it is plausible that it helps in some cases. Moreover, for generalization one can use attention dropout which is simpler instead.] This paper proposes two sparsifying methods of computing attention weights, dubbed sparsemax and TVmax, which appear to slightly improve objective and subjective image captioning scores. It would be interesting to see if their approach could benefit other tasks such as machine translation, image generation etc.
Also, SMiRL can be used for imitation learning by pre-training the parametric state distribution with data from a teacher. Section 4.1: "...as shown in Figure Figure..."->"...as shown in Figure..." The reinforcement learning problem of maximizing intrinsic rewards does not know how the intrinsic reward signal is altered in the course of the future, i.e. how the parametric state distribution is updated.
The paper proposes an approach to learning domain invariant representations using the adaptive decomposition of the convolutional filters. The main advantage of the proposed approach is that by only introducing a few model parameters, the proposed approach could quickly adapt to new domains. * Please do not use the Office dataset, it is commonly used in unsupervised domain adaptation papers, especially older ones, but it's hard to tell anything about proposed methods from this dataset as there is label pollution and not enough samples per class to be used with neural nets. Clearly state your decision (accept or reject) with one or two key reasons for this choice. Clearly state your decision (accept or reject) with one or two key reasons for this choice.
different techniques: using tensor regression layers (Kossaifi et al., Also in this section, the authors mentioned Tucker decomposition for the tensor regression. 2.4 line 6, "with A and. In 2.3, there is a lack of definition for  \\Lambda_1 and \\Lambda_2.
It argues and formally establishes that (1) the expressivity of an attention head is determined by its dimension and (b) fixing the head dimension, one gains additional expressive power by using more heads. In response to such observations, the paper proposes Fixed Multihead Attention, where the constraint that `head_size * number_of_heads = embedding_size` in standard multihead attention is lifted; and it allows for using more attention heads without making each head smaller. It would be nice if the authors and discuss this in the revision I'm happy to revise the score if the authors can address my concerns.)
The paper presents expected gradients which is a method which looks at a difference from a baseline defined by the training data. Data shows that the proposed approach shows better generalization performance (i.e. better performance in test dataset) than baselines. The structure of the paper is strange because it discusses attribution priors but then they are not used for the method. In section 2.2. I think a few papers to have a look at are a survey article about graph based biasing http://www.nature.com/articles/s41698-017-0029-7 as well as methods for using graph convolutions with biases based on graphs: https://arxiv.org/abs/1711.05859 and https://arxiv.org/abs/1806.06975 . Would be nicer to do for example "... 2. When the authors refer to Figure 2 and Figure 3 multiple times in the main text, they are referring to either left or right panel. The experiments conducted in that paper seems to be similar to the ones that are done in this paper. It is not clear if the paper is presenting "expected gradients" or existing attribution priors. This is a general framework that the users can define different attribution priors for different tasks. It would be nice to see how integrated gradient method perform in the three experiments (image, drug data, mortality prediction), does the expected gradient method always outperform? Some of these should serve as baselines. I am concerned that only a limited set of expert-invented human priors can be used in this approach. This would imply that (human-understandable) information needs first to be transferred from a model to humans. Three different datasets (i.e. image, gene expression, health-care) are chosen to evaluate the proposed model's effectiveness, while different regularizers (i.e. image prior, graph prior, and sparsity prior) are explored for the respective task. 2. Incorporating humans into the modeling process? I agree (and personally like) the motivation that a method is needed to align a model's behavior with human knowledge or intuition -- model's behavior may be explained by feature attribution methods while making models accept human knowledge is challenging.
The paper deals with accurately encoding and decoding 3D atomic positions and the crystal's species using 2 sets of neural networks PAPER SUMMARY: This paper addresses the problem of encoding and decoding 3D chemical structures, with the ultimate goal of generating 3D crystal structures. The authors propose an auto-encoder framework for encoding the 3D locations of atoms in the crystal to a latent representation and then decoding that representation back into 3D structure. I think this is a main drawback of this work. Without such scores in the crystal generation domain, it is not easy to judge how good a generated crystal is. I appreciate that the paper addresses an interesting problem that is not sufficiently explored and can motivate the development of novel methods that generate 3D molecules with particular structure and multiple types of atoms, however the current work combines existing methods, without any architectural modifications that exploit the new domain. Results about the distance of generated atoms w.r.t to their true location, the predicted atom counts, predicted atom types etc. The paper's contributions can be summarized as follows: 1) A data representation that converts the 3D atom locations to a 3D voxel density map, so that they can be encoded by a standard 3D convolutional network. It would be more appropriate to submit this paper to a domain-specific venue rather than to *CONF*.
This paper addresses a limitation of BatchNorm: vulnerability to adversarial perturbations. Experiments on more datasets and the sensitivity of the proposed method to \\rho would have validated the claims of the authors.
The paper proposes an approach for learning graph convolutional networks for inferring labels on the nodes of a partially labeled graph  when only limited amount of labeled nodes are available. Using self training is not new in GCN but the way it is used here, computing adaptively a threshold for incorporating pseudo labels and using weights according to the confidence off predictions is new. 1. As the self-training is going on, are there different computational costs or are they about the same? The authors do not change the GCN but extend the self-training portion as per the prior GCN paper by introducing Dynamic Self-Training that keeps a confidence score of labels predicted for unlabelled nodes. 2. For CiteSeer 20 and 50, why does \\beta = 0.45 switch from the other experiments? Evaluation of the proposed framework is performed on four networks for semi-supervised node classification task with varying label rates. The main idea here consists in relying on self training to get a better coverage of labeled nodes enabling learning with less deep models, this translates to a simple and intuitive algorithm.
This work extends the wasserstein uncertainty modeling  to the robust MDP setting. The experimental results are very minimal and not very convincing. The experimental results are very minimal and not very convincing.
This paper proposed SE-SNN, a type of stochastic neural networks that maximize the entropy in stochastic neurons along with the prediction accuracy. 2 (Max-entropy Regularization). - There are things unclear in the derivation (last line of Eq. 2), since log(\\sigma_2) trends to infinity.
In general, I like the idea of making recurrent cells operate with nearly independent transition dynamics and interact only sparingly through the attention bottleneck. I mean, the modules are not necessarily incentivized to be used as often as possible, so could it be the case that a module learns to set its weights to zero? This may have been obvious to the authors, but spelling them out may help the reviewer/readers to understand the contribution.
This paper introduces a simple measure of tunability that allows to compare optimizers under varying resource constraints. My major concern is that the authors assume the hyperparameters to be independent (section 3.2), which is not necessarily true. * minor: in figure 8 in the appendix, the results after 100 iterations is, as far as I understand, over a single replication, so is not particularly reliable (and will always be 100% of a single optimizer) as the main contribution. However, I do not think the metric they introduce is good enough to be recommended in future work, when comparing tunability of optimizers (or other algorithms with hyperparameters). The assumption of independent hyperparameters might be fine for black box optimization or with the assumption that practitioners have no knowledge of the importance of each hyperparameter, then the tunability of the optimizer could be different based on the prior knowledge of hyperparameter and their correlations. Comparisons which, while mentioned, should perhaps have been discussed and compared more in detail in this work.
Based on this motivation, the authors proposed a spatial shuffling layer which is aimed at shuffling the original feature responses. In the model analysis in experiment section, the presentation and explanations are also vague and not clear to me.
In the model analysis in experiment section, the presentation and explanations are also vague and not clear to me. When designing the annotation process, it does not seem like a good idea to use CommunityMPA over asking for a minimum of 40 annotations per annotator and use MPA. I am wondering of the connection between community and sparsity. In addition, I'm not convinced with the idea of "breaking the larger player workloads into smaller batches" for simulating the sparsity and communities. I see no major issues with accepting the paper. This paper extends the unpooled mention pair model of annotation (MPA) (Paun et al., 2018b) with the hierarchical priors (e.g., mean and variance) on the ability of the annotators.
In this paper, the authors investigate the use of ellipsoidal trust region constraints for second order optimization. b) I have checked Theorem 6.6.8 in Conn et al. (2000). method, both in terms of number of backpropagations and asymptotic loss value on a variety of tasks"). The method overall doesn't seem to be able to match first order gradient methods, and it is not clear whether this is because of using the RMSProp/Adam preconditioner as a curvature matrix. I can not support acceptance for current version.
This paper proposes distillation attacks to generate transferable targeted adversarial examples. This paper proposes distillation attacks to generate transferable targeted adversarial examples. There are a lot of typos in the paper.
This paper presents a method for doing RL from demonstrations in continuous control tasks. They use demonstrations obtained from a trained agent and experiment their method on several mujoco tasks. Given a set of expert demonstrations, this work provides a policy-dependent reward shaping objective that can utilize demonstration information and preserves policy optimality, policy improvement, They claim that using demonstration data in a supervised manner "cannot generalize supervision signal over those states unseen in the demonstrations," but most of these approaches are using neural networks and definitely are generalizing those signals to other states. Technical concerns: The stochasticity assumption of expert policy in Asm. 1 can be contradicted with that expert policy is optimal in policy invariance proof. https://ieeexplore.ieee.org/document/8794074 is another method built on DDPG that has both a critic and actor loss like yours and would make a useful comparison. The description of DQfD and DDPGfD in the related work is not accurate. The revised version of the paper addresses many of my concerns about the motivation, related works, and comparisons with GAIL, so I'm updating my score to Weak Accept. They actually propose exactly the same framework as a special case in the appendix of that paper. The related work section should also discuss and compare/contrast to GAIL, I was surprised that wasn't in there, especially since you also use a discriminator to differentiate expert and agent actions. The authors use demonstrations coming from a pre-trained network which is known to make the imitation learning part much easier. For the experiments, I wonder about the impact of only using sparse reward tasks. I would be more impressed by experiments on stochastic environments and sparse rewards.
In this paper, the authors propose a new adaptive gradient algorithm AdaX, which the authors claim results in better convergence and generalization properties compared to previous adaptive gradient methods. This paper points out that existing adaptive methods (especially for the methods designing second-order momentum estimates in a exponentially moving average fashion) do not consider gradient decrease information and this might lead to suboptimal convergences via simple non-cvx toy example. In this context, Zaheer et al. (2018, Adaptive methods for non-convex optimization) propose a large epsilon value (numerical stability parameter) such as ϵ=10−3 for better generalization. Overall I think this work requires quite a bit of work before it is ready for publication, and would benefit from a much more thorough empirical evaluation of the algorithm.
This paper proposes to provide a novel gradient-based meta-learning framework (Meta-Graph) for a few shot link prediction task. The approach basically takes advantage of meta-learning and is expected to generalize well across graphs. My concerns are as follows: •    I am wondering if you can adopt R-GCN [1] instead of the GCN model for extending the Meta-Graph to multi-relational graphs? •    I suggest considering ranking metrics such as MRR and HITS@ to further evaluate the performance of Meta-Graph.
The paper proposes  a two-phase reduction approach to select representative samples based on heuristics. The paper develops methods to reduce the test data size while maintaining the coverage and the effectiveness on large test data. The paper presents a new approach to create subsets of the testing examples that are representative of the entire test set so that the model can be tested quickly during the training and leaving the check on the full test set only at the end to validate its validity. The first sentence on page 5 seems to be incomplete as it is written. This work tries to build a sub-pile of the test data to save the testing time with minimum effect on the test adequacy and the output distribution. On page 8, at the beginning of the first sentence after Table 3, there is a comma that seems to be useless after the word "that". Other comments to the proposed manuscript are: 1. In Definition 1 the authors declare that the goal is to satisfy f(T,M)=f(T'M) and g(T,M)=g(T'M), and then in the following paragraphs they change it to f(T,M)≈f(T'M) and g(T,M)≈g(T'M) with no justification. To improve the readability a bit further, I would suggest trying to move equation 1 after or close to its reference, or at least to describe before it what KL is.
For most experiments of this paper, "shallow network" refers to a width of 64 and "wide network" refers to a width of 2048. In Section 5.2, the authors did not show the network details, and also it is not fair to compare the networks with a linear classifier. Given the above observations, my current decision of this paper is that it doesn't meet the bar.
This paper proposes content-based sparse attention to reduce the time/memory complexity of attention layers in Transformer networks. This paper proposes a novel way to increase efficiency for self-attention based sequence modeling neural networks. However, the cluster attention seems to group the words together, and there is no cross-cluster attention (i.e., the graph is broken into smaller components). In particular, although the routing mechanism avoids computing A, having to deal with each of the n clusters means that one will need to process the cluster-based attentions sequentially (and, as mentioned, you have 8 heads for local attention and 8 for routing attention, which I think are also processed in two steps? Is there any reason that you abandoned this design and used Eq. (2)? My guess is that the actual, rather than theoretical, difference would not be that great. Or do you change the softmax normalization such that it is over C_i? (2), it seems that you did not add layer normalization and residual connection to the self-attention block. 6. The authors acknowledge at the end of Section 4 that their method of assigning clusters "does not guarantee that each point belongs to a single cluster". Or could position i in query and position i in key be in different clusters? When combined with prior work on local attention (i.e. half of the heads are local attention, the other half are the newly proposed routing attention), but model is found to outperform, or be on par with, existing Transformer models despite generally being smaller. + The paper addresses a very important (efficiency) question in Transformers, and gave a proper review to prior related works (such as Child et al.). Pros: + The math notations are generally clear (e.g., dimensionality) and the paper is well-organized. The paper is also very well written and easy to follow and understand.
The authors present a framework to perform meta-learning on the loss used for training. About the Baikal loss itself, I fear that it could produce models that have very poor calibration, it might be nice to evaluate that (even if it is only in the appendix). It's a compelling idea that is well-motivated. It would be beneficial to clarify when it is happening: a) For each individual of the population during step (1), b) before performing CMA, c) after CMA.
This paper presents a framework for evaluating offline reinforcement learning (RL) algorithms. This paper proposes a unifying framework, BRAC, which summarizes the idea and evaluates the effectiveness of recently proposed offline reinforcement learning algorithms, specifically BEAR, BCQ, and KL control. The paper introduces a general framework for behavior regularized actor-critic methods, and empirically evaluates recent offline RL algorithms and different design choices. Based on prior work, the authors state that there are two variants of regularizations to the behavior policy, value penalty (vp) and policy regularization (pr) and three choices of divergence functions along with their sample estimate that measures the distance between the learned policy and the behavior policy. I commend the authors for performing a valuable test and comparison of existing offline RL methodology. The authors provide extensive results; but it wasn't clear whether these were "apples-to-apples" comparisons with the previous results in the papers that proposed the "unnecessary" technical complexities. A challenging open problem is a good thing! is an challenging open problem."  Unfortunately?! If so, this should be made more clear and stated prominently in the paper so that the reader knows that BRAC is, in this reproduction of previous results sense, reliable. Could the authors suggest why certain complexities are unnecessary? Though BRAC summarizes offline RL methods in a neat way, it would be more technically sound if a general theoretical analysis/insights of offline RL algorithms can be offered in the paper, e.g. showing the reason that vp is outperforming pr through convergence analysis in the tabular case. Though BRAC summarizes offline RL methods in a neat way, it would be more technically sound if a general theoretical analysis/insights of offline RL algorithms can be offered in the paper, e.g. showing the reason that vp is outperforming pr through convergence analysis in the tabular case. Also, the paper could be improved by being more clear about the nature of the evaluations. Though BRAC summarizes offline RL methods in a neat way, it would be more technically sound if a general theoretical analysis/insights of offline RL algorithms can be offered in the paper, e.g. showing the reason that vp is outperforming pr through convergence analysis in the tabular case. For example, I didn't see the authors say that they reproduced the results of previous works, only that they tested previous methods in certain tests. If not, how if the reader to know that the "unnecessary" technical complexities, are truly unneccessary? Minor issue:  In the Conclusion Section, the authors say, "Unfortunately, off-policy ... Does the BRAC framework reproduce the results for previous papers?
The paper is clear and well written, the idea is interesting and the experiments seem well designed and convincing. This paper proposes a multi-task dynamical system for sequence generation. - The main motivation of this paper is to treat each sequence as a task in the training set (customization of the individual data sequence).
The evaluation is performed on two small in-distribution image datasets and four out-of-distribution datasets with three types of generative models. This paper tackles the out of distribution detection problem and utilizes the property that the calculation of batch-normalization is different between training and testing for detecting out-of-distribution data with generative models. The likelihood difference itself seems like it could be a good indication for OoD detection. This is consistent with your batch normalization experiments: in training mode, the likelihood is computed from mean activations over a batch of OoD samples, several of which probably contribute to the low likelihoods. This is consistent with your batch normalization experiments: in training mode, the likelihood is computed from mean activations over a batch of OoD samples, several of which probably contribute to the low likelihoods. In other words, I think there is a mistake made here: it is the phenomenon that *batch likelihoods*, not *batch norm*, that is responsible for this method working well.
This paper presents a new reversible flow-based graph generative model wherein the whole graph i.e., representative attributes such as node features and adjacency tensor is modeled using seperate streams of invertible flow model. It is not possible to train model with variable number of nodes. [Page 5, Sec 3.3.1] Can you explain the gain of masking?
This paper presents a M-product based temporal GCNs to handle dynamic graphs. Comments: this paper is mathematically interesting. The tensor eigendecomposition used in this paper and [Kilmer and Martin] is for slices of the tensor, similarly for FFT and convolution. Given the current status, I could not accept the paper. Is it possible to formulate M such that (A \\times M)_::t will depend heavily on A^(t), and less on the farther matices?
A measure of global accuracy is proposed to reflect the global accuracy of the embedding. 1. Many important technical decisions on this method seem arbitrary, including the parametrization of functions (e.g., s, \\omega, \\zeta, etc) and values of hyperparameters (e.g., \\gamma and \\delta). The authors didn't clarify why the proposed method is theoretically faster than the baselines.
This paper proposes a flatness measure that is invariant to layer-wise reparametrizations in ReLU networks. They did address some of my concerns. This seems to be a missing step in relating flatness/feature robustness of a layer to the generalization of the whole network. While this is interesting, it is not clear to me that this guarantees generalization for deep neural networks. On the theoretical side, I think the major issue is that the paper cannot connect the measure to generalization properly and ends up decomposing the test error to the sum of the robustness measure and the gap between test error and the robustness measure which is not informative. This result only talks about feature robustness and representativeness for a particular layer. However, the other two issues are still present. **************************** After author rebuttals: Author have added discussion of related work which was missing in the original submission (thanks!).
At inference time F an \\pi_G are frozen and are evaluated on similar tasks to the ones in training, where however the (unseen) causal graph is new. I was a bit disappointed to see that training is mostly supervised (both providing the ground truth causal graph and an oracle policy as target) but on the other hand it is impressive to obtain these results with raw images as input and the comparative results are good. In Section 3.1, the authors said that "N is the number of actions in the environments," which is a bit confusing. Again, the assumption that we know the ground truth causal graph may not be feasible in the real world. --- post-rebuttal  addition --- The authors have satisfied most of my concerns and I have upgraded my rating to weak-accept. --- post-rebuttal  addition --- The authors have satisfied most of my concerns and I have upgraded my rating to weak-accept.
In this paper, the authors developed GNN by integrating an interpolation based regularization. Instead of trying to incorporate an augmented dataset into the graph, this paper uses a seperate fully-connected network (FCN) that shares weights with a graph neural net (GNN). For example, the authors may need to explain two random samples, i.e., (x, y) and (x', y') are drawn from the data distribution D, and how it is used in GraphMix more clearly.
This paper presents a set of statistical tools, that are applicable to quantitatively measuring the mode collapse of GANs. The authors consistently observe strong mode collapse on several state-of-the-art GANs using the proposed toolset. It further showed that the proposed blackbox approaches increases the proposed diversity metric without sacrificing image quality. Unlike most existing works that address the model collapse problem, a blackbox approach does not make assumptions about having access to model weights or the artifacts produced during model training, making it more widely applicable than the white-box approaches. This work addresses the important problem of generation bias and a lack of diversity in generative models, which is often called model collapse. In addition, some explanations in this work are very hard to parse, e.g., the first paragraph of the methods section. 2. The statement "IS, FID and MODE score takes both visual fidelity and diversity into account." under "Evaluation of Mode Collapse" is contradictory to the description in sec 2.1 that IS in fact does not measure diversity. In addition, some explanations in this work are very hard to parse, e.g., the first paragraph of the methods section.
[Overview] In this paper, the authors proposed a new method called knowledge acquisition (KA) for distilling the learned knowledge from the teacher model to the student model. This is a bit strange to me because, KA will focus on the precision instead of recall. 2. The authors presented a thorough analysis on the proposed KA strategy and compared it with KL strategy in terms of the precision and recall for the student models.
I find the paper not easy to follow, with a non-negligible amount of typos in the notations and results. * Questions / Comments * However, the term "interpretability" is very vague and it is not properly defined in this paper. For example, the terms "roles" and "filler" are not defined. the paper is not well written, and 2. I think this paper is not yet ready for publication: the proposed model is interesting and relevant but its validity could be better assessed and the paper needs some thorough proof-reading.
[p.8] Discussions -> Discussion This paper proposes bounding the Wasserstein term in WGAN with an aim to stabilize training. To this end, the author(s) have proposed to combine both the primal and dual formulation of Wasserstein distance. Is it meant to be P_1(X)? Although the main bounding strategy seems to be a promising idea, this work does not meet the quality requirements of *CONF*.
The authors provide a transformer based model to predict the reactants. The novelty is quite low and it's not clear if this will transfer to another domain. In addition, a discrete latent variable model is used in the model to encourage the model to produce a diverse set of alternative predictions.
1. The Bayesian Reinforcement Learning problem this work considered is important.
This paper proposed a BO-based black-box attack generation method. 2018. This paper applies Bayesian optimisation (BO), a sample efficient global optimisation technique, to the problem of finding adversarial perturbation. 1) The benefits of BO? ############ Post-feedback ########## Thanks for the clarification and the additional experiments. I wonder if the gradient estimation-based attack methods can apply the similar trick and yield the similar performance.
This paper studies the effect of quantization on training reinforcement learning tasks. The results are also not entirely surprising or impactful: how is quantization impacting reinforcement learning in a different way than supervised learning? These are all questions that could potentially make the results in this paper novel (i.e., quantization as a form of regularization), but as it is now, the results are not that surprising. This paper investigates the impact of using a reduced precision (i.e., quantization) in different deep reinforcement learning (DRL) algorithms. Could you provide some discussion as to why this is the case?
This paper proposes a model that learns to disentangle visual scene into objects (slots), and simultaneously learns a dynamics model to capture how these objects interact with each other. 1. Most modeling decisions are clear and well-motivated, however the choice to make the transition model f_trans always be applied only "slot-wise" might be too restrictive. The experimental results are reasonable but can be strengthened. Specifically: 1) It is unclear what this paper is claiming to improve over prior work: is the goal to a) learn a good forward model, or b) show that emergent entities allow better downstream tasks. As of now, my recommendation is a clear reject.
The context is encoded with a BERT model and the CLS representation is used as the representation of context. As a result, I think the entity linking section needs major re-writing and explanation of the results.
(approach) Actdiff: 1) The Actdiff loss requires a mask that highlights areas of the input image which have signal and not distractor regions. (evaluation - Multi-Site dataset) A final task tries to construct another synthetic dataset out of real X-ray images collected at two different places. Actdiff is compared to 5 other methods including a reconstruction loss and Gradmask (previous work). For this purpose, the authors considered a situation where task relevant parts of the images are annotated as masks by the human experts. (evaluation - Medical Segmentation Decathalon) I think the problem considered in this paper is interesting and important. - This approach is not very compelling (e.g., comments about limited novelty and lack of concrete examples to boost intuition). [1]: Gatys, Leon A. et al. "A Neural Algorithm of Artistic Style." ArXiv abs/1508.06576 (2015): n. This is a necessary control to be sure that any benefits from masking are due to domain transfer and not other regularization effects. That may also help drive intuitions later on in the paper.
In this paper, authors propose to design an unsupervised learning framework, which can capture pose representation by reconstructing images or videos. It extends this approach by introducing an additional separation of foreground and background in the image. + Clear and well written 1. what are the details of the color jitter process? - Why are there more than 8 points in Fig. 2 for "Ours8" (and more than 12 for "Ours12")?
The objects in subsets A and B may have the same category. - How many objects per environment are there e.g., in sets A and B? ========================================================= After Rebuttal: I thank the author for the response.
This paper studies how to construct confidence intervals for deep neural networks with guaranteed coverage. In this work, the authors develop the discriminative jackknife (DJ), which is a novel way to compute estimates of predictive uncertainty. The whole study is concluded with toy and real-world examples showing the proposed algorithm is competitive with existing methods while also achieving the desired coverage. Their technical innovation is to combine a marginal error term that does not depend on x (which ensures coverage) with a local variability error term that does depend on x (to allow for greater variability in areas where the model is more uncertain and there is less data). - I think it would be beneficial to the reader if you could please provide a discussion and/or formula for how large n has to be for Theorem 2 to apply. Section 3.4 provides the theoretical guarantees for DJ. Are they true in such a general setting? - Throughout the paper (e.g., in and around eq.1), you seem to assume that there exists a unique minimiser of the objective which generally won't be true (especially in your application to deep neural networks). I am currently leaning towards recommending rejection of the paper. Can you please provide a discussion of how this would affect the reported results?
The paper proposes an approach to train NMT models on extremely large parallel corpora. Different strategies are proposed to split the dataset effectively. Table 2 reports results with "Small" and "Large" models. The different models are combined to form an ensemble model. It is impossible to reproduce the results of the experiments conducted in this paper in future validation. Table 2 suggests that a single model, even trained with 40B sentence pairs, does not outperform a single model trained with 20M sentence pairs as in "He et al., 2019", while being significantly more expensive to train.
This paper introduces directional adversarial training (DAT) and UMixUP, which are extension methods of MixUp. DAT and UMixUp use the same method of MixUp for generating samples but use different label mixing ratios where DAT retains the sample's original label. DAT is referred to in this paper as a scheme that only input feature vectors are mixed, while MixUp also incorporates their corresponding labels. This paper shows that UMixUp and DAT are equivalent when the number of samples tends to infinity. arXiv 1801.02929 This paper proposes a novel data augmentation method, untied MixUp (UMixUp), which is a general case of both MixUp and Directional Adversarial Traning (DAT).
[Summary] This paper proposes a GAN with an attention-based discriminator for I2I translation, GuideGAN. [Summary] This paper proposes a GAN with an attention-based discriminator for I2I translation, GuideGAN. The paper should clarify what is done at test time, and clearly state the shortcomings as a result of this, i.e. different procedures are used for training and testing, which is not principled. - Why post hoc and RAM are evaluated on different datasets from each other in qualitative results?
The motivation of this work is to address the issue of inconsistent and missing data in longitudinal clinical studies. "... to provide value in predicting patients' diagnosis." is better written as "... It is not straightforward to understand whether the proposed method is effective in reducing the time consuming effort required by the computation of alfa hyperparameter, as stated in the premises as motivation of this work.
The method differentiates itself, in large part, by formulating model outputs in terms of m distinct softmax layers, each corresponding to a hash of output space Y. The novelty of the idea is mostly to integrate these codes with transformers. While the technical contribution is limited, because most of the principles are already known or straightforward, the main contribution of the paper is to show that random hash functions are sufficient to create significantly shorter codes and maintain good performances. If I understand clearly, the text is filtered out and only links are kept (?). detailed comments: - The paper really is *not* about bloom filters (Bloom filters are data structures that represent sets and efficiently answer membership queries). Since the method is applicable to any problem involving natural language data (and more generally categorical values, such as knowledge base completion), I would have expected experiments on tasks with a well-defined state-of-the-art. The authors propose to learn a Transformer in embedded spaces defined via m hash functions, with application to (fixed length) sequence-to-sequence classification for NLP.
Summary: This paper proposes to use a combination of a pretrained GAN and an untrained deep decoder as the image prior for image restoration problem. Summary: This paper proposes to use a combination of a pretrained GAN and an untrained deep decoder as the image prior for image restoration problem. [Original reviews] This paper proposed to modeling image as the combination of a GAN with a Deep Decoder, to remove the representation error of a GAN when used as a prior in inverse problems. However, I would still appreciate if the authors can provide an overall model figure in the model section to help understanding. Summary: This paper proposes to use a combination of a pretrained GAN and an untrained deep decoder as the image prior for image restoration problem.
This paper presents a method for creating saliency maps reflecting what a network deems important while also proposing an interesting method for visualizing this. This paper presents a method for creating saliency maps reflecting what a network deems important while also proposing an interesting method for visualizing this. - Abstract: "it is also quantitatively similar or better in accuracy" -> shouldn't it be "and" instead of "or"? I believe the writing of the paper could be wrapped around the speed of the method and in which context it would be important (robotic, medical?). The method is interesting as it does not require multiple backward passes such as other gradient-based method and thus prove to be more time-efficient. I find that the proposed method appears to be theoretically sound and is interesting in revealing differences to other information theoretic methods especially in the early layers.
There are 4 major issues I have found so far. See also the public comment posted by Nontawat when a special symmetric condition is assumed on the surrogate loss function. While I am not sure about the area of peer prediction, in the area of learning with noisy labels (in a general sense), there were often 10 to 15 papers from every NeurIPS, ICML, *CONF* and CVPR in recent years. I have to say this may not be enough for *CONF* that should be a more deep learning conference. I tried several times to go through the details but failed.
AAAI 2018. - Tang et al. Learning to Collaborate for Question Answering and Asking. The proposed pretrained model is then used to finetune on a standard question generation task, which is then used to generate synthetic QA pairs for data augmentation in QA. The proposed pretrained model is then used to finetune on a standard question generation task, which is then used to generate synthetic QA pairs for data augmentation in QA. I am happy to increase the score after rebuttals.) **** Update on Nov 10 **** Increasing the score to 6. -------------------------------------------------------------------------------------------------------------------------------------------- Now, here are clarification questions. Regarding Section 2.1 1) Did you attempt to predict 'number of answer candidates' by regression or classification?
They then exploit this decomposition to (a) decouple the problem into both RL and supervised learning, and (b) provide localised pre-training to make the problem more tractable. In contrast, an agent which is trained directly on the hypothesis verification task is unable to learn to do it. Overall, the paper is well-written and the literature review section is quite excellent. For instance, it looks like the pretraining proceeds for 1e8 steps and finetuning for 5e7 steps, based on the plots (these values should be stated more explicitly in the paper). Up to section 3.3.1 (and - really - until I read the appendix...), the writing sort of led me to assume that (1) the "(pre-condition, action sequence) -> post-condition" split was a fairly standard manner of compose a hypothesis, and that (2) the templates were mostly symbolic. I have a bit of hard time interpreting the results though since there are no direct comparisons with the triplet pretraining scheme; it would be helpful if these results could be included in these figures too. I think that the fact this works is not that interesting. ================== #Post Rebuttal Remark I have gone through the authors' response and I thank them for it, particularly for making some of the suggested enhancements. However, my score remains unchanged. At this point, I cannot recommend the article for acceptance, but I'd be willing to change my rating if the authors were to address some of the above points. To improve this paper, I would like to see: - Better clarity on how the hypothesis setup stands to previous literature.
Motivated by the observation that powerful deep autoregressive models such as PixelCNNs lack the ability to produce semantically meaningful latent embeddings and generate visually appealing interpolated images by latent representation manipulations, this paper proposes using Fisher scores projected to a reasonably low-dimensional space as latent embeddings for image manipulations. Defining a feature space using the Fisher kernel of a generative model is a very well-known idea, and there is a large body of work around that. As mentioned in 1), it's obvious that Fisher scores contain more information than latent activations for deep autoregressive models and are better suited for manipulations. Defining a feature space using the Fisher kernel of a generative model is a very well-known idea, and there is a large body of work around that.
This paper proposes to address the problem of spatio-temporal forecasting in urban data, in a way that can accommodate regions with highly distinct characteristics. The authors do not take care to point out which parts of their design are original and which are borrowed - it took much sleuthing to determine that the MGAAT differs from the GAT only in its introduction of a masking factor.
This work proposes an outlier detection method based on WAE framework. This paper proposes a novel outlier detection approach, based on Wasserstein auto encoders. Authors claim that their method will over-come this issue. Eg: I. Chong You, Rene Vidal, Provable Self-Representation Based Outlier Detection in a Union of Subspaces, CVPR 17 Eg: I. Chong You, Rene Vidal, Provable Self-Representation Based Outlier Detection in a Union of Subspaces, CVPR 17 Overall, I am hesitant to recommend the paper before cross-checking the issue with contamination proportion and learning more about how a VAE framework is indeed important for anomaly detection.
(approach - confidence) An explanation is confident if the masked images it produces still have high condidence under the classifier. The authors compared against zero and gray masking for correctness. The quality of the paper is my reason for the low rating. Now I understand it and think it is a useful metric.
It would be good to define this. My main concern here is the technical novelty of the proposed method: it seems that once we have the labels (which are limited to programmable functions), all we need to do is to learn a policy that conditions on the labels. Does it come with a simulator? An experiment with explicitly different levels of diversity would strengthen understanding of this method.
A lossy transform coding approach was proposed to reduce the memory bandwidth of edge devices deploying CNNs. For this purpose, the proposed method compresses highly correlated feature maps using variable length coding. In the experimental analyses, the proposed method outperforms some of the previous work in terms of the compression ratio and accuracy for training ResNet-34 and MobileNetV2. However, the paper and the work should be improved for a clear acceptance: - Some parts of the method need to be explained more clearly: – In the statement "Due to the choice of 1 × 1 × C blocks, the PCA transform essentially becomes a 1 × 1 tensor convolution kernel", what do you mean by "the PCA transform becomes a convolution kernel."? For the experimental results are reported in Section 4, we do not know how much memory and how much cache is used.
A new framework for certification is proposed, which allows to use different distributions compared to previous work based on Gaussian noise. Summary: This paper investigates the choice of noise distributions for smoothing an arbitrary classifier for defending against adversarial attacks. About the main results: there seems to be a discrepancy between the results reported for Cohen et al. and the original paper for both CIFAR-10 and ImageNet L2 certification. Why not smooth it with a cube of appropriate radius? But a fundamental trade-off means that *any* method that attains good accuracy must sacrifice robustness and vice versa; this requires a "for all" statement, i.e. a lower bound. Also, not enough experimental details are provided for Table 3. About the main results: there seems to be a discrepancy between the results reported for Cohen et al. and the original paper for both CIFAR-10 and ImageNet L2 certification. I think the paper should be rejected because (1) For \\ell_2 perturbations, there is no major difference between this new family of distributions (d-k \\chi^2) and a Gaussian with different variance.
General: The paper proposed to use a causal fairness metric, then tries to identify the Pareto optimal front for the vectorized output, [accuracy, fairness]. The authors propose a novel joint optimisation framework that attempts to optimally trade-off between accuracy and fairness objectives, since in its general formal counterfactual fairness is at odds with classical accuracy objective. As main contributions, the paper provides: * A Pareto objective formulation of the accuracy fairness trade-off Then, there will be a measurable causal effect of A on h(). 3) Why do we want U to be small, i.e., why do we want the causal effect of A to be small, is never justified. There is nothing specific in the method or analysis that relates to neural networks, except for the use of the causal estimand in a 'hidden layer'. Then, there will be a measurable causal effect of A on h().
I like the high-level idea of this work and agree that there is not much work on using prediction explanations to help improve model performance.
### Questions 1. What is the relation between "random distance prediction loss" and "task-dependent auxiliary loss"? ### Questions 1. What is the relation between "random distance prediction loss" and "task-dependent auxiliary loss"? 1.  It would be better to reorganize Section 1 and Section 2, please describe the contribution in a more systematic way.
This paper describes a sensor placement strategy based on information gain on an unknown quantity of interest, which already exists in the active learning literature. The authors propose a framework for sensor placement called Two-step Uncertainty Network (TUN) based on the idea of information gain maximization. Experimental results on the synthetic data clearly show that TUN outperforms current state-of-the-art methods, such as random sampling strategy and Gaussian Process-based strategy. Fig. 2: I find it surprising that with a single observation, it is possible to generate the instance/imagined spectrum in orange that resembles that of the true spectrum. For example, (a) The configurations and training procedure of generator NN G and deterministic NN D for the experiments are not sufficiently described for each experiment. What the authors have done differently is to consider the use of neural nets (as opposed to the widely-used Gaussian process) as the learning models in this sensor placement problem, specifically to (a) approximate the expectation using a set of samples generated from a generator neural net and to (b) estimate the probability term in the entropy by a deterministic/inspector neural net.
Another set of experiments demonstrate that the importance of different semantic attribute dimensions for different scene categories varies in an interpretable way, and also that certain attribute dimensions influence each other strongly (e.g. "indoor lighting" and "natural lighting"), whereas other ones are decoupled (e.g. "layout" and other dimensions). The claim here is that with the same perturbation of the resulting codes (lambda=2) at the output of different GAN layers, the change in the visualized output demonstrates what kind of, if any, semantic is being captured by different layers of GAN. Figure 3(a) illustrates how these "Variation Factors" emerge in the layers of the StyleGAN generator. Some of my primary concerns were regarding the presentation, and I feel they have been mostly addressed with the changes to the introduction and abstract (I'd still recommend using 'layerwise latent code' instead of 'layerwise representation' everywhere in the text). Are the four semantic abstractions decided based on the desired output? The additional qualitative results showing the benefits of manipulating 'z' vs y_l were also helpful. 5) This is not a really weakness, but perhaps an ablation that may help. With the separation boundary (in the form of a normal vector) known for each of the four scene semantics, different feature activations are obtained by moving the latent code towards/away from the separation boundary. It would be interesting to know if this adversely affects constancy of some aspects e.g. maybe objects also change in addition to layout. Finally, I agree that given the popularity of StyleGAN like models, the investigation methodology proposed, and the insights presented might be useful to a broad audience. How many Convolution layers are present in its generator? The paper analyzes the relation of various scene properties w.r.t the latent variables across layers, and does convincingly show that aspects like layout, category, attribute etc, are related to different layers. The results are visualized in Fig 3(c). Despite these positives, I am not sure about accepting the paper because I feel the investigation methods and the results are both very specific to a particular sort of GAN, and the writing (introduction, abstract, related work etc.)
CVAE is used as a generative model to get new samples. Overall the paper is well-written and well-organized. The proposed method is based on the idea from theoretical analysis, and is reasonable and valid. Overall the paper is well-written and well-organized. 2. Experimental results are not convincing: in the paper, only grayscale datasets, such as MNIST and FMNIST, are considered to evaluate the proposed method and I think it is not enough. The proposed method is based on the idea from theoretical analysis, and is reasonable and valid.
ICML [4] Tessler, Chen, et al. "A deep hierarchical approach to lifelong learning in minecraft." Thirty-First AAAI Conference on Artificial Intelligence. Summary: The authors propose a method for learning hierarchical policies in a multi-task setting built on options and casts the concepts into the Planning as Inference framework. JAIR, 53, 375-438. [2] Konidaris, G., & Barto, A. The results in moving bandits alone are very convincing. * Should there be \\xi(i) multiplying the last term in (3)? There seems to be no other term that incentivizes the option posterior to deviate, and I do not see how the options are adapting to tasks. I liked the flow and the organization of this paper. Detailed Comments: A primary weakness of this approach is that it seems like there is one network that learns the options and is shared across all task (that would be the prior) and then there is a task-specific network for all options (posterior), wouldn't this be very difficult to scale if we want to learn reusable options over the lifetime of an agent? * The term 1,2,3 in (6) are weighted equally by beta and cannot be fine-tuned to desired trade-offs. Once the prior is learned, it is fixed. In directional Taxi (2c) Distral(+action) manages to reach the same final performance (if we care about that), can you please comment on this.
They key addition to the classic BERT model is the introduction of the R and S embeddings. The aim in both is to obtain a decomposition of the form x(t) = S a_s(v_t) a_r(v_t) R where S and R are shared matrices of parameters and v is the output of BERT. They key addition to the classic BERT model is the introduction of the R and S embeddings. In order to effectively learn R and S embeddings, the authors propose two possible ways to do so: LSTM (Fig 2) and 1-layer Transformer (Fig 3). For this reason, I feel the authors should have continued showing results for the other baselines from the first experiment. This aligns with some recent findings that BERT is undertrained (Liu et al. 2019) https://arxiv.org/abs/1907.11692
*Summary* This paper compares network pruning masks learned via different iterative pruning methods. In terms of presentation, some of the figures are unreadable (figure 4). First, a clarification on the figures: are lines for pruned weights terminated where they are pruned? weights in 6(a) are a spaghetti tangle and the FC weights in 7(a) are constantly increasing in magnitude. I dislike writing short reviews, but I fear this paper falls too far short of *CONF* standard. (1) *Overlap in pruned sub-networks*: In the middle of Sec. 4, Fig 3-5 examine the similarity of pruning masks between methods.
This paper investigates the asymptotic spectral density of a random feature model F(Wx + B). This paper analyzed the asymptotic training error of a simple regression model trained on the random features for a noisy autoencoding task and proved that a mixture of nonlinearities can outperform the best single nonlinearity on such tasks. (3) The authors have explained the results in a clear way. In practice, we may consider an input with additional constant feature, X <- [X,1], to deal with both models in a unified manner.
The main contribution of this paper is that the authors have proved the convergence to the iterated dominance solution for two RL algorithms: REINFORCE (Section 3.1, binary action case only) and Importance Weighted Monte-Carlo Policy Improvement (IW-MCPI, Section 3.2). [1] Michael Bowling, "Convergence Problems of General-Sum Multiagent Reinforcement Learning", Sec. 5.2 The applications of the convergence result result to "noisy effort" games is pretty standard and the results expected based on the theory. For example, for agent i "its possible actions are the strategies in S_i" (section 2); any action "a \\in S_i" (section 2,1); for agent i "for all s_i \\in S_l" (Algorithm 1 line 2). This work is clear and well-written, but I do not understand what the contribution of this work is to the literature. I'll wait to hear the author response to this). I did not check the proofs thoroughly. To the current status of the paper, I have a few concerns below. The fact that standard MARL learning rules (e.g. independent Q learning) converge in games with iterated dominance solutions is a very well-known result in Learning in Games (see [1], [2]).
**Minor comments** In  references section : (Kingma & Dhariwal, 2018) is not in a proper format (nips 2018) I am rating the paper "weak reject" mostly due to the limited set of comparisons in experimental results.
The paper explores a transformer for reinforcement learning. The hypothesis and intuitive analysis are not very convincing.
The authors conduct extensive experiments on image classification and segmentation and show that dynamic convolutional kernels with reduced number of channels lead to significant reduction in FLOPS and increase in inference speed (for batch size 1) compared to their static counterparts with higher number of channels. === Summary === The authors propose to use dynamic convolutional kernels as a means to reduce the computation cost in static CNNs while maintaining their performance. As far as I can see, it is very similar to the former SENet especially in Figure (3) and Equation (2). - Discussing the number of the parameter as well. - The parameter gt is defined as 6. - Testing the ImageNet trained network of the proposed method into an object detection task (as the pre-trained backbone).
This paper presents a modification to policy gradient methods that are computed from advantage function estimates. On a walking talk show that the min-approach can outperform state-of-the-art on-policy RL (PPO); the paper suggests this is because the min-approach is implicitly risk sensitive. Further, the fact that using a smaller number of advantage estimates worked better (point #2 on pg 5, Effect of Ensemble Size in Appendix A) suggests that the ensemble size is an important hyperparameter, and that risk-seeking / risk-aversion (i.e., regulatory vs promotion focus) cannot alone explain why the proposed method works. This paper could be accepted as it presents an interesting idea with extensive experiments showing where it works and where it fails, along with some justification for the hyperparameter choices.
This manuscript discusses the problem of bias shortcut employed by many machine learning algorithms (due to dataset problems or underlying effects of any algorithmic bias within an application). ### Decision and reasons I vote for a weak accept. Is that so? 3. How well do other methods do in these domains?
The paper proposes a framework for learning with rejection using ideas from adversarial examples. More specially, The definition of "suspicious example" in Sec.3.1 has no relationship with adversary examples. [1] Adversarial Examples For Improving End-to-End Attention-based Small-Footprint Keyword Spotting, ICASSP 2019 In the last equation of page 2, there is a rejection function, so minimizing this loss is a "separation-based approach". [2] SelectiveNet: A Deep Neural Network with an Integrated Reject Option, ICML 2019 But I still think this paper has not been ready to be published yet. ### Reply to rebuttal: I thank the reviewers for their detailed reply.
The authors propose a framework to incorporate additional semantic prior knowledge into the traditional training of deep learning models such that the additional knowledge acts as both soft and hard constraints to regularize the embedding space instead of the parameter space. Overall I feel that this is a potentially interesting paper, addressing an important question in a novel way, but I found the current version a highly-frustrating read (and I read the paper carefully a number of times); 2. In Section 2, the authors say "constraints on the parameter space of a model are often non-intuitive". How are they "non-intuitive" and why the proposed method is more intuitive in terms of theory? 2. In Section 2, the authors say "constraints on the parameter space of a model are often non-intuitive".
This paper proposes to model the architecture distribution using a VAE instead, where the encoder and decoder are implemented using LSTMs. As for the authors' comments for Q1, I'd like to point out that a "larger" search space is not necessarily more difficult (a more meaningful metric would be the average accuracy of random architectures). As for the authors' comments for Q1, I'd like to point out that a "larger" search space is not necessarily more difficult (a more meaningful metric would be the average accuracy of random architectures). As for the authors' comments for Q1, I'd like to point out that a "larger" search space is not necessarily more difficult (a more meaningful metric would be the average accuracy of random architectures).
By encouraging diversity in the pool of trajectories for self-imitation, the idea is to encourage faster learner -- this basic concept is also used in approaches like prioritized experience replay, albeit at the entire trajectory level rather than individual state/action level. Unlike other self-imitation learning methods, the proposed method not only leverages sub-trajectories with high rewards, but lower-reward trajectories to encourage agent exploration diversity. This paper proposes an approach for diverse self-imitation for hard exploration problems. The authors view this approach as a generalization of Go-Explore, since it does not rely on having a reset mechanism. It seems a bit of a cop-out to say that Go-Explore is not applicable, and misses out a huge opportunity for real scientific understanding. Note: the style-formatting of this paper has been heavily tweaked, and so the evaluation should be calibrated for a 9-page paper. 2. In appendix D, the authors discussed what the parameter \\delta_t controls, however, it is unclear how \\delta_t should be chosen in implementation. It seems a bit of a cop-out to say that Go-Explore is not applicable, and misses out a huge opportunity for real scientific understanding.
Authors demonstrate this issue with a simple MDP model, and emphasize the importance of behavior policy and data generation process. *Summary* This paper considers the effect of partial models in RL, authors claim that these models can be causally wrong and hence result in a wrong policy (sub optimal set of actions). For example, the MDP example is just an off-policy policy evaluation problem, and it is very well known that in this case you need to consider the behavior policy, for example with importance sampling. POST-RESPONSE COMMENTS: In my opinion, the authors adequately addressed both my own concerns, and also several valid concerns from the other reviewers. Therefore, I'm raising my score to "accept. 2. What are the partially observable parts of the environments in Figure 1 (a) & (b)? The flow of the paper proceeds in learning a causally correct model in the sense that the model is robust to any intervention changes. I vote to (weak) reject the paper due to the major issues with section 2. As you don't cover the meaning of the do() operator until a later paragraph, provide a quick description of it as it is not common knowledge to a general AI audience, e.g., where do() indicates that the action was taken. *Decision* I vote for rejection of this paper, based on the following argument: To my understanding authors are basically solving the "off-policy policy evaluation" problem, without relating to this literature.
The authors provide a general application on sequential data for continual learning, and show their proposed model outperforms baseline. The model is constructed by combining an Autoencoder and LSTM/LMN for each task. [1] Kirkpatrick, James, et al. "Overcoming catastrophic forgetting in neural networks." Proceedings of the national academy of sciences 114.13 (2017): 3521-3526. - It is better to compare it with a larger dataset. The description of the tasks is very informal and hard to follow. For example, if task 1 and task 2 sample from the same distribution, they can share the same LSTM/LMN and AE. Thus, It is interesting to see that continual learning is used in sequential data. Overall the task descriptions should be in a separate section where the setup is described in a lot of detail and motivated properly.
This paper proposed a DFO framework to generate black-box adversarial examples. The tiling trick is not something new, it is introduced in (Ilyas et al., 2018) and also discussed in (Moon et al., 2019). However, I am not satisfied with the response "But clearly our methods aim to reach the boundary of linf ball, so the distortion might be large" to the second question. 2) In addition to attack success rate and query complexity, it might be useful to compare different attacks in terms of ℓp distortion, where p≠∞.
In this paper, the authors proposed a training method called global momentum compression (GMC) for distributed momentum SGD with sparse gradient. I realize that one can enforce this with a projection, as argued in the paragraph rationalizing this assumption. 1. Regarding the assumptions in the paper, I think assumption 2 need some validation / support to show that it is a proper one. 2. I notice that the experiments uses conventional momentum SGD for a few epochs as warm up, is there any specific reasoning on using this warmup approach instead of the sparsity level warmup as used in DGC? I also find Assumption 3 to be strange.
The paper proposes a theoretically founded method to generate subsets of a dataset, together with corresponding sample weights in a way that the average gradient of the subset is at most epsilon far from the average gradient of the full dataset. [1] Zhao, Peilin, and Tong Zhang. Based on the experiments provided in the paper, it does appear to yield a significant speedup in training time. It is interesting to observe how the order of the datapoints matter significantly for training, and that CRAIG is also able to naturally define a good ordering of the datapoints for SG training. The approach is novel and has well-developed theory supporting it. 2015. [2] Defazio, Aaron, and Léon Bottou. - In Theorems 1 and 2, what is the bound on the steplength in order to obtain the convergence result for τ=0? In the figure, (a) is MNIST, but in the caption, (b) is MNIST In addition, there is no experimental analysis of the epsilon bound and the actual difference of the gradients for the subset and the full dataset. - In Theorems 1 and 2, what is the bound on the steplength in order to obtain the convergence result for τ=0?
This paper propose to add a regularization loss on the stein divergence between the generator G (implicit model ) and the explicit model (E). In theorem 2 , the proof is too short and swapping of min and E is not backed rigoursly.
2) proposing a model called TransComplEx. Furthermore, the paper proposes TransComplEx -- an adaption of ideas from ComplEx/HolE  to TransE -- to mitigate issues that can not be overcome by a simply chosing a different loss. A loss minimization won't make equalities in (3) and (5) hold exactly, which the analysis do not account for. Theory: Equation (2) and (4) do not seem to bring much compared to the conditions in Table 1. Paper writing: * The manuscript should be improved with a thorough revision of the style and grammar. Regarding the experimental evaluation: The paper compares the results of TransComplEx and the different loss functions to results that have previously been published in this field (directly, without retraining). However, it seems from Section 5 (Dataset), that this paper is using a modified dataset, as the TransE models are only trained on high-confidence triples. Eq. (3) and (5) show "a" loss function rather than "the" loss function since multiple choices are possible.
In this paper, authors propose a way to speed up the computation of GNN. These theoretical results are nice. The revised version has clarified some of my concerns. I put 6 (weak accept), since we cannot put 5. --------------------------------------------------Update------------------------------------------------ Thanks very much for the authors' feedback.
This paper studies the connection between sensitivity and generalization where sensitivity is roughly defined as the variance of the output of the network when gaussian noise is added to the input data (generated from the same distribution as the training error). All told, if taken in isolation from prior work, I think the insights and empirical results presented in this paper are quite interesting and certainly sufficient for acceptance to *CONF*.
This paper uses reinforcement learning for automated theorem proving. Isn't that contrary to the focus of the paper? I would appreciate someone with more experience on that topic weighing in. I suggest you to add some further explanation so that a reader can share your sentiment and excitement on the improvement brought by your technique. OVERALL: I don't work on ATP and am not particularly well suited to review this paper, but I am slightly inclined to accept for the following reasons.
This paper suggests a method for detecting adversarial attacks known as EXAID, which leverages deep learning explainability techniques to detect adversarial examples. However, it has been shown that these interpretation methods are not reliable and easy to be manipulated [1][2]. There are a plenty of works on visual explanation methods, such as guided-backprop[1], excitation-backprop[2], integrated gradient[3], Grad-CAM[4], real-time saliency[5] and so on.
This work nicely proposes a new theoretically-sound unequal bit allocation algorithm, which is based on the Lagrangian rate-distortion formulation. The paper primarily shows that the mean squared error of the final output of a quantized network has the additive property of being equal to the sum of squared errors of the outputs obtained by quantizing each layer individually. It means that some weights in some layers can be quantized with higher or lower bits per weight.
This is an analysis paper of pretraining with the tool "influence function". In this case, can influence function be used? To calculate the influence function of a model with pretraining, the authors use an approximation f(w)+||w-w*||, where w* is pretrained. 1. The idea of converting a pre-trained model with f(w)+||w-w*|| is interesting. I believe that these are useful technical contributions that will help to broaden the applicability of influence functions beyond the standard supervised setting. To do so, the authors make two methodological contributions: 1) working through the calculus for the pre-training setting and deriving a corresponding efficient algorithm, and 2) adding L2 regularization to approximate the effect of fine-tuning for a limited number of gradient steps. Is the influence equation well defined (or the Taylor approximation justified) if H is not positive definite? frog examples being used for both pretraining and finetuning? But I do not think the conclusion is very promising and convincing. To do so, the authors make two methodological contributions: 1) working through the calculus for the pre-training setting and deriving a corresponding efficient algorithm, and 2) adding L2 regularization to approximate the effect of fine-tuning for a limited number of gradient steps.
Overall, I think there may be some really nice ideas in this paper that could help shape our understanding of neural network loss surfaces, but the current paper does not explore those ideas fully and does not convey them in a sufficiently clear manner. I do not buy the argument that "it is possible to apply it [the method] to large-scale modern neural networks". One can define a gradient flow in a linear space X and for a function F: X->R, e.g., as  a smooth curve R->X, such that x'(t) = -\\nabla F(x(t)); is that what is meant? I am unfamiliar with prior work in this direction, and I was also unable from the paper to infer what the main improvements were relative to the existing algorithms. The paper is also unclear in many parts.
This work provides  theoretical analysis for the NAS using weight sharing in two aspects: 1) The authors give non-asymptotic stationary-point convergence guarantees (based on stochastic block mirror descent (SBMD) from Dang and Lan (2015)) for the empirical risk minimization (ERM) objective associated with weight-sharing. What is the advantage of ASCA comparing to SBMD? When should I use ASCA and when SBMD? The author proposed ASCA, as an alternative method to SBMD. Also, comparing to first order DARTS, search cost is the same and this is hard to justify the better convergence rate for EDARTS.
My major concerns are as follows. Claim is that this has not been successfully done in a RL setting before, so a new problem is proposed (multi-agent pac-man) and results are presented on this problem.
To study this problem, this paper proposes two models, Graph Feature Network (GFN) and Graph Linear Network (GLN). This paper conducts experiments on graph classification task and finds GFN gives a reasonable performance, whereas GLN's performance is weaker. Suggestions for improvement: 1) Considering the experimental results in this paper, it is possible that the existing graph classification tasks are not that difficult so that the simplified GNN variant can also achieve comparable or even better performance (easier to learn). However, I cannot accept the paper in the current form because of the following reasons.
To perform functional regularization, they introduce small coreset which are selected from previous dataset instances, called memorable past. This might explain the reason for the huge forgetting reported for VCL with coreset (−9.2 ± 1.8) as opposed to −2.3 ± 1.4 for EWC which is really strange as VCL even without coreset (on permuted mnist for example) is reported superior to EWC by a large margin (6%) in the original VCL paper. Particularly I suggest that the authors elaborate more on their claimed differences stated on page 4, paragraph 5 such as "tractability of the objective function only when we assume independence across tasks". Therefor, it is important to mention how they are obtained.
I Summary The paper directly answers two sanity checks for saliency maps proposed by Adebayo et al (2018): 1. Overall, I find this paper to be interesting and to address a problem worthy of further consideration. Moreover, the citation is a little abrupt "as we can see in XX" would work better - Section 3 "This figure highlights" -> which figure? Because as of now, it only seems to answer the two aforementioned sanity checks. " This is not very well articulated, "a lot" is vague and a little familiar, "significantly" could be used here.
Also, the paper redefines the decoder part for self-supervised from minimizing reconstruction loss with background segmentation to maximize reconstruction error with learning a foreground segmentation. Croitoru et al. also relies on video to extract the object features, and this requirement is not as explicit in this work. My decision is Weak Accept.
This paper works on empirically demonstrating the connection between model connectivity and the lottery ticket hypothesis, which are individually explored in the literature. This paper works on empirically demonstrating the connection between model connectivity and the lottery ticket hypothesis, which are individually explored in the literature. or alternatively modify the claim (to what it actually shows) and highlight the significance of the connection between matching subnetworks and stability in this highly sparse subnetwork regime.
This paper proposes a novel approach for the loss function of matrix completion when geometric information is available. (1) The proposed approach (formulation (10)) involves too many parameters (including the weights w in (9)) that need to be tuned. (4) As a followup question, without such implicit regularization, it is unclear why the proposed approach does not suffer from overfitting. Though the authors include the connection between [Arora et al. (2019)], this is not convincing enough since as explained above, the implicit regularization there depends on the smallness of the initialization. I vote for a weak reject of the paper at the current pace and would like to increase my score if the following questions can be clearly answered.
This theoretical paper exploits a recent rigorous correspondence between very wide DNNs (trained in a certain way) and Neural Tangent Kernel (a case of Gaussian Process-based noiseless Bayesian Inference). Although the expansion breaks when the noise term goes to zero, a renormalized kernel is introduced for which an accurate perturbative expansion is possible. I suspect that only a small fraction of the community will have the adequate background to get much out of this paper. It is my fault that I didn't bring this point up in my review. I agree that there could potentially be great ideas in this paper. 3) I am concerned about the writing style of this paper. It would be nice to cite related literature and compare the results.
This paper presents a system for predicting evolution of graphs. First, the graph encoder embeds a graph into a feature vector that represents the topology of the graph. First, the graph encoder embeds a graph into a feature vector that represents the topology of the graph. Authors use GNN and multiple RNN's, what was the model capacity used and how it impacted the performance? Authors use GNN and multiple RNN's, what was the model capacity used and how it impacted the performance? If not, why is this a novel approach? If not, why is this a novel approach? - Why was Graph size used as a statistic to report? - Why was Graph size used as a statistic to report?
And then they use the weight to initialize the Lieanr Memory Networks(LMN). I am not too sure how the proposed initialization helps in this case. My concerns lie with the novelty of the proposed model and the insufficiency of the experiments. Overall I think the novelty contribution is marginal and I suggest the authors to test their models on larger-scale real problems. It would be helpful to include some experiments indicating that this was the case (for the baseline) and that this method does indeed help with this problem. Equation 1 and 2 suggest that there is a vector m^t per timestep (as oppose to having 1 for the entire sequence). The proposed initialization is aimed at helping to maintain longer-term memory and instability during training such as  exploding gradients (due to linearity). Hochreiter, Sepp and Schmidhuber, Jürgen.
The paper explores multi-task learning in embodied environments and proposes a Dual-Attention Model that disentangles the knowledge of words and visual attributes in the intermediate representations. *Additional feedback In conclusion, "interpretablew" -> "interpretable I thank the authors for their detailed response and appreciate their hard work in bringing us this paper. I would recommend for acceptance, as the experimental results show that the proposed approach successfully transfers knowledge across tasks.
The paper proposes a differentiable coarsening approach for graph neural network (GNNs). This paper proposes an unsupervised hierarchical approach for learning graph representations. However, in Equation (4), a and b should come from the input G and G_C , and it is not clearly explained how to obtain them from the input. It seems that it is not used in Algorithm 1. How the coarsening matrix is derived is more of a technical point (it looks like the results would be much more sensitive to a switch of metric than to a switch of parametrization for S).
However, in Equation (4), a and b should come from the input G and G_C , and it is not clearly explained how to obtain them from the input. However, in Equation (4), a and b should come from the input G and G_C , and it is not clearly explained how to obtain them from the input. This makes the advantage of F-pooling over the existing AA-pooling unclear. Also, from the three Tables in the experimental part, the improvement of F-pooling over AA-pooling (developed by the main reference of this work) does not seem to be significant or consistent. Are there any other advantages for F-pooling s.t. people might want to use it as opposed to AA-pooling? It seems that it is not used in Algorithm 1. This makes the advantage of F-pooling over the existing AA-pooling unclear.
The paper introduces a problem "few-shot few-shot learning" that aims to firstly transfer prior knowledge from one domain to the domain where the base training tasks reside, and then train a few-shot learning model on training tasks and apply it to novel test tasks. For the pre-trained model, they will not only use its weights but also use it to generate a spatial attention map and help the model focuses on objects of images. In their algorithm, they use a model pre-trained on another dataset as the prior knowledge and fine-tune it on training tasks. ========================================================= After Rebuttal: I thank the author for the response. However, I doubt the novelty and effectiveness of the attention way used in the paper. The proposed new setting is very meaningful since we already have many powerful pre-trained models and why not exploit its usage for few-shot learning problems.
The paper proposes to distill the predictions of an ensemble with a multi-headed network, with as many heads as members in the original ensemble. Overview: This work introduces a new method for ensemble distillation. Distillation proceeds by minimizing the KL divergence between the predictions of each ensemble member with the corresponding head in the student network. - In OOD detection tasks, Hydra underperforms Prior Networks on 5 of 8 datasets (note that PN (2.60) is better than Hydra (3.11) in the case of MNIST (test)). It is unclear that the marginal improvements demonstrated justify the increased cost and how this approach would scale to larger ensembles. The paper would have been more interesting if the authors had managed to demonstrated significant improvements over competitors on not toy (MNIST / CIFAR) problems. - The proposed scheme provides the same advantages of the ensemble in terms of uncertainty estimation and predictive performance, but it is computationally efficient compared to the ensemble. To verify the effectiveness of the proposed distillation method, other large-sized datasets should be tested, e.g., CIFAR-100, ImageNet.
Such an analysis of P_l^k as a function of the tasks (and for several layers) would be interesting to see, for example for EMNIST-47(10 tasks). The authors propose a method based on principal components projection to tackle this issue. This paper introduces Principal Components Projection, a method that computes the principal components of input vectors, using them to train on a transformed input space and to project gradient updates. However, all experiments are on similar tasks, and no cross domain tasks are considered, e.g. going from MNIST (task1) to EMNIST-26 (task2) etc. However, all experiments are on similar tasks, and no cross domain tasks are considered, e.g. going from MNIST (task1) to EMNIST-26 (task2) etc. It would be better if the authors can show the proposed method can generalize to other tasks.
The paper describes a new method called Atomic Compression Network for constructing neural networks. Strengths: a lot of nice experiments with clearly advantageous results are given. Also, I think this work should be compared with compression schemes that work via kronecker product, which seem very similar to this scheme (but where the kronecker matrix is binary to produce replication) (1) Is there missing a delta in the first half of line 6 in Algorithm 1?
In this paper, the authors propose a framework towards 4-bit auantization of CNNs. Specifically, during training, the proposed method contains a full precision branch supervised by classification loss for accurate prediction and representation learning, as well as a parameterized quantization branch to approximate the full precision branch. Strengths: + Well-written paper with good clarity and technical correctness. It is a well-written paper. However, it seems to me that this drastic scheduling strategy sounds like very similar to the traditional approach that trains the floating point network first and then finetune the quantized one, except for the fact that this proposed algorithm repeats this process a few times. - How do you ensure and ub > lb when you learn the quantizer? Is it GQ or DQ? Nevertheless, I do have some comments that would hopefully help in improving this work: - It does seem that GQ-Nets need extra tricks in order to perform well, and those tricks come with their own set of hyperparameters that need to be tuned. The results on ImageNet under 4-bit quantization are strong and convincing, but the paper could benefit from conducting additional experiments on different datasets and bitwidth configurations.
The paper proposes to use Contrastive Predictive Coding (CPC), an unsupervised learning approach, to learn representations for further image classification. The authors augment contrastive predictive coding (CPC), a recent representation learning technique organized around making local representations maximally useful for predicting other nearby representations, and evaluates their augmented architecture in several image classification problems. The extensive experiments show that CPC enables data-efficient image classification and surpassed other unsupervised approaches. ==== AFTER REBUTTAL ==== I would like to thank the reviewers for their rebuttal. However, I doubt if this is enough for a full conference paper. This paper only proposes some minor improvements based on the original CPC method and use a deeper network to get better performance. But they are not well motivated. In line with that, I think their work would be improved by some commentary on this, in particular by any concrete suggestions they have about how similar augmentations to CPC could be carried out in text, audio, and/or video data. Verdict: Owing to the reasons given above, I recommend acceptance.
The main strategy is to condition a Music Transformer architecture on this global "style embedding". Additionally, the Music Transformer model is also conditioned on a combination of both "style" and "melody" embeddings to try and generate music "similar" to the conditioning melody but in the style of the performance embedding. [ref2] Conditional image-to-image translation, CVPR'18 This paper presents a technique for encoding the high level "style" of pieces of symbolic music. ## summary In this paper, the author extends the standard music Transformer into a conditional version: two encoders are evolved, one for encoding the performance and the other is used for encoding the melody. I am not working on music generation but I list two CV related papers about conditional image translation, which mathematically describes "an image with specific style". It took me a couple of passes and reading the Music Transformer paper to realise that in the melody and performance conditioning case, the aim is to generate the full score (melody and accompaniment) while conditioning on the performance style and melody (which is represented using a different vocabulary). Why use this feature compared to existing techniques for measuring similarity between symbolic music pieces? Since it is defined but never used. Finally, it would be useful if the authors comment on existing methods for measuring music similarity in symbolic music and how their proposed feature fits into existing work. ## Questions 1. In section 4.2, how do you use the Y? 3.     It is better to give some mathematical definition of music generation with specific style. 5. In section 5.2, a conditioning sample, a generated sequence and an unconditional sample are used to compute the similarity measure. I find the description of the "performance feature" to be lacking in necessary background and detail. 6. I like the experiments performed in Section 5.3 with the linear combination of 2 performance embeddings. Maybe a comment on the melody vocabulary or a reference would also be useful. [1] A Survey of Query-By-Humming Similarity Methods: athitsos/publications/kotsifakos petra.pdf" target="_blank" rel="nofollow">http://vlm1.uta.edu/ athitsos/publications/kotsifakos petra.pdf Firstly, I think the algorithmic novelty in the paper is fairly limited. This point can be easily clarified in Figure 1, by adding the input to the encoder as input to the decoder for computing the loss.
The authors use an enhanced loss scaling method and stochastic rounding method to stabilize training. Is it a sensitive hyper-parameter or not?
This is more-or-less expected thanks to the superior performance of implicit updates in general. While potentially offering a faster convergence with respect to epochs, the nonlinear updates have two major drawbacks: 1) While there are preliminary theoretical results (fixed points of the method are critical points), it remains unclear whether the computed update is still a descent direction on the original energy.
The paper proposes a differentiable Bayesian neural network. Summary of the Paper: This paper describes a method for training Bayesian neural networks in the context of stream data. The paper is unclear. There are several steps of the proposed method that are not well described. 2. I think the paper might need a bit more explanation about codevector, since it's not a very well-acknowledged concept in this field. However, there are a lot of modern BNN that are both sampling-free and differentiable. I believe that this paper needs for work and is not yet suitable for acceptance.
The paper suggests to merge the front part of the student network and back part of the teacher network into the collaboration network. I believe that this paper needs for work and is not yet suitable for acceptance. And it is still unclear how many layers in student and teacher are concatenated to form the 'collaboration network'. To the best of my knowledge, it is first proposed in And it is still unclear how many layers in student and teacher are concatenated to form the 'collaboration network'. Possible improvement of the paper is the instruction on how to choose the intermediate layer from where to teach the representation, i.e. where the student sub-network ends and teacher sub-network begins.
The paper provides an iterative linear method to identify causal influences of putative cause matrix to signal matrix. ############## After reading the author's feedback and the comments from other reviewers, I keep the current rating but tend to a borderline score and it is ok if it must be rejected because of the concerns of limited applicability and the experimental. However, the authors do not provide enough evidence that this method is generally useful and better than established methods to merit acceptance to *CONF*.
They propose to use compression based distance measures off the shelf from standard compression techniques to detect spatial feature patterns in feature space and demonstrate its effectiveness on several datasets and comparison with baselines is reported and well discussed. The motivation of the proposed approach is clear, and the method seems novel. After reading the other reviews and comments, I appreciate the effort by the Authors, but it looks like the paper still needs some work before being ready. It is unclear to me as it was not presented in the work when or if the problem that is being solved by the paper is particularly either important or frequent. However, the method for comparison is not properly set. However, according to the original paper, simple FGSM is used for validation, so I am not sure such a huge difference can actually happen. The out-of distribution samples pose a danger in safety critical applications such as autonomous driving, for example a car deployed in environment that it has not seen during the training might crash. Ideally, if their method is evaluated in the same condition, it should outperform prior works in any case. In this kind of case, I suggest the authors to put {the numbers in the original paper} as well as {their replication} and claim that they fail to replicate the number. concatenation on the proposed method as well? - Comments: 1. As addressed by the authors, feature concatenation ("assemble") is not effective for the Mahalanobis method but the proposed method. I remark that this paper still requires a lot of revision; comparison in the main paper is somewhat unfair and all new results are in the appendix. 2. I am happy to see that their revised method has better performance. For this reason, I am borderline unless that caveat is addressed as described below, in which case I would be happy to accept.
The approach is implemented in a synchronous stochastic gradient decent (SGD) scheme. A first mention of the use of such techniques for "communication efficiency" dates from (at least) 2015 [2].
This paper performs empirical study on the influence of overparameterization to generalization performance of noisy-or networks and sparse coding, and points out overparameterization is indeed beneficial. This paper investigates benefit of over-parameterization for latent variable generative model while existing researches typically focus on supervised learning settings. As the authors point out (and I agree), the paper constitutes a compelling reason for theoretical research on the interplay between overparameterization and parameter recovery in latent variable neural networks trained with gradient descent methods. The generative models to obtain disentanglement representation could be investigated in the frame-work of this paper. I am expecting some theoretical analysis for tasks simple as noisy-or and sparse coding, or some experiments for more complicated (deep) models need to be done, to make the paper more solid. - the effects of extreme overparameterization The motivation of this paper is interesting. The paper "aims to be a controlled empirical study making precise the benefits of overparameterization in unsupervised learning settings. Hence, I think what investigated in this paper can be discussed by relating sparse coding theories. - the effects of extreme overparameterization On the other hand, I have the following concerns on the significance of the paper. - the effects of extreme overparameterization
The paper first discusses various potential causes for posterior collapse before diving deeper into a particular cause: local optima. This paper tries to establish an explanation for the posterior collapse by linking the phenomenon to local minima. 3. Minor: Sec 3 (ii) assumI -> assuming (v) fifth -> four, forth -> fifth Summary: This paper is clearly written and well structured. The points below are all related. If the autoencoder can not reconstruct well, it is not reasonable to expect a regularized autoencoder such as VAE to reconstruct, better, and therefore the VAE is already is a regime where it is not useful anyhow. One source of confusion for me was the difference between sections (ii) and (v) --- in particular I believe that (ii) and (v) are not mutually exclusive. All in all, I think using a standard gaussian prior is not a good idea, and that fact renders the explanations provided in this paper obsolete in my opinion.
This paper aims to identify the primary source of transfer error in vision&language navigation tasks in unseen environments. Summary: This paper provides a thorough analysis of why vision-language navigation (VLN) models fail when transferred to unseen environments. Experiments then show that semantic-level features dramatically reduce the transfer gap, although at a cost of absolute performance. A few small questions/comments below. - Perhaps the biggest problem with the paper as written is that I am not convinced that the 'performance gap' between the seen and unseen data is a metric I should want to optimize. In this section, the authors mention that 'a multilayer perceptron is used' but do not provide any training or structure details; these details should be included in an appendix. I recommend this paper for acceptance; my decision is based on the thorough analysis of the ultimate cause of a recurring problem in this field. -------- After discussing with the reviewers about the methodological issue of the validation set, I have lowered my score to a weak accept, but I think this paper should still be published.
I can not understand in anysense that I know. Here are my concerns and questions: 1). Based on the above comments, I think the work will benefit from further developments before being ready for publication. Based on this, I give my rating.
They assess the different representations through cosine similarity within/between categories and through comparison with human judgments in an odd-one-out task. - 4.2 plots for visualization are mentioned to be in the appendix, but are not there would all likely give different ratings.
Can the authors give a detailed discussion why is the expression of f(x) = g(x) + s(x) in equation 9 the right one to be minimized in practice (e.g., in the context of materials and drug discovery)? Isn't G_1 a GP? Why is it able to accept x_i and D as inputs? experimental uncertainties? Fig. 1 shows that the noise peaks with a relatively high frequency at a single error magnitude value. Since no convergence guarantee is given, a more extensive empirical analysis with real datasets needs to be provided to better understand the performance and behavior of the proposed BO algorithms.
This paper proposes a fractional graph convolutional networks for semi-supervised learning. The authors design a new graph convolutional filter based on Levy Flights, and propose new feature propagation rules on graphs. ------------------------------------------------- The response from authors addressed many of my concerns. The rating has been updated. The key approach of the proposed method is to apply a classification function (equation (3)) obtained by solving a GSSL problem to graph convolutional networks. I believe the experimental results could justify an accept, but I would not claim I am an expert in semi-supervised learning on graphs.
This paper presents a technique for model based RL/planning with latent dynamics models, which learns the latent model only using reward prediction. This is in contrast to existing work which generally use a combination of reward prediction and state reconstruction to learn the latent model. The paper suggests that by removing the state reconstruction loss, the agent can learn to ignore irrelevant parts of the state, which should enable better performance in settings where state reconstruction is challenging. I tend to reject this work, because although I support the premise and believe it is very important, and like the style of experiments run with the use of distractors, I believe it is not impactful if only looking at the dense reward setting. Showing that the proposed method can outperform such approaches in robot manipulation settings would be a powerful result. It seems to be different results from intuition, because the authors emphasize that the strength of the proposed method is efficiency of learning in RL tasks with irrelevant information.
This paper proposes a new kind of episodic finite MDPs called "deep hierarchical MDP" (hMDP). I have not checked the proofs in detail but in part because it does not seem surprising and that a precise assessment is hindered by many typos (see Min2 and Con2). 5. (6), what is n(k-1, e)?
This paper proposes a novel approach to estimate the confidence of predictions in a regression setting. This paper proposed deep evidential regression, a method for training neural networks to not only estimate the output but also the associated evidence in support of that output. Pros: 1. Novel approach to regression (a similar work has been published at NeurIPS last year for classification [3]), but the extension of the work to regression is important. - (p.10) In equation (13), due to the change of variable, there should be a - (p.9) There is a typo in the name of Jøsang in the references. - (p.10) In equation (13), due to the change of variable, there should be a I think that the authors should consider adding a section similar to Section 3 of Sensoy et al. [3] should be considered.
The author(s) posit a Mixture of Gaussian's prior for a compressed latent space representation of high-dimensional data (e.g. images and documents). Using an approximation to deal with GMMs, the authors derive a bound on the cost function generalizing the ELBO. I much prefer this article's method, but for comparison purposes, the author(s) should similarly use a KNN classifier on their latent space to compute accuracy in the same manner. I much prefer this article's method, but for comparison purposes, the author(s) should similarly use a KNN classifier on their latent space to compute accuracy in the same manner.
They propose learning a CPC representation from some random data and fix it. 2. I am concerned about the current policy learning scheme (i.e. tiered policy (1) go to the correct cluster (2) go to the goal) which seems to only be used by your approach. As the paper discuss in introduction, learning in sparse reward environment is hard because it relies on the agent to enter the goal during exploration. Given these concerns I am unwilling to recommend accepting this paper, unless several of these concerns are addressed.
However, for the two base architectures that are examined in this work, UATs where already provided in the original manuscripts. The presentation in this paper does remove the assumption of a fixed cardinality, but since this seems to be a mild assumption, it is not clear what is gained by this (beyond mathematical elegance). === Post rebuttal update === I'd be grateful if the authors could comment on this. While the theorems proved in the paper are original and novel, they are a refinement of the already known results regarding approximation theorems for PointNet and DeepSets, respectively, hence only a marginal improvement in understanding these function classes. However, the rebuttal does not alleviate my concerns about additional impact beyond the UATs in the original paper. It would be interesting to investigate empirically the limitations of these architectures, for instance by playing with the diameter and center of mass functions as suggested in 3.3. - The paper is clearly targeted at a specialist audience and invokes dense and advanced mathematical concepts. Again, it seems that this is a mild restriction and I'd like the authors to elaborate on the importance of removing this restriction. Deep sets) can approximate uniformly real-valued functions that are uniformly continuous with respect to the Hausdorff (resp. It might find a better audience at a venue that is more specialized in this type of work (e.g. applied mathematics or more theory-focused machine learning venues). This paper brings a valuable theoretical contribution to the existing state of the art of their approximation abilities.
The hypothesis is that if the regressors demonstrate good accuracy, then the word embeddings contained information relevant to "numerical common sense". This paper aims to predict typical "common sense" values of quantities using word embeddings. In fact, if the correlation coefficients for this case is comparable to the case with concatenated features, it would mean that the word embedding for the object is not helping at all! In fact, if the correlation coefficients for this case is comparable to the case with concatenated features, it would mean that the word embedding for the object is not helping at all!
In the end, the paper is essentially arguing that it's better to use different learning rates (for the inner loop) during meta-training and meta-testing. Do you use a sigmoid to constrain them to real numbers in [0, 1]? When this is mentioned again in the introductory section, it is followed by a statement indicating that meta-learning an initialization is one solution.
Given that it is implemented on the new SEED RL framework, so it would be better if the implementation code can be published. As a final comment, this is a solid work and will be very helpful to the community. Overall, this is a strong paper and I recommend it for publication.
This paper shows a relationship between the project rule weights of a Hopfield network (HN) and the interaction weights in a corresponding restricted Boltzmann machine (RBM). The paper is overall very well written. All my concerns are addressed and reflected in the revision (though some are much better done than the rest). I congratulate the authors on their spirit of maintaining a high standard on the theory, experiments and descriptions, and therefore significantly raise my score. Recommendation I'm in favour of rejection, but some concerns can be addressed fairly easily (with experiments) so I'm open to raising my score if questions are well-addressed.
This paper proposes a novel NAS method that searches the model architectures by grows the networks. The authors conduct a series of solid experiments to verify the effectiveness of their proposed methods.
Summary: This paper presents a generative model based on stochastic differential equations (SDEs), which generalizes two other score-based generative models score matching with Langevin dynamics (SMLD) and denoising diffusion probabilistic modeling (DDPM).
This paper proposes a model that corrects VAE by an energy-based model defined on image space. The model is learned in two phase. Overall, it is a good submission that proposes a principled method to combine VAE and EBM and demonstrates strong empirical results.
Summary In this paper, the authors study the problem of neural LTR models. Overall, it is a good submission that proposes a principled method to combine VAE and EBM and demonstrates strong empirical results. Finally, the technical contribution of the paper is also quite limited. Then, it presents a few tweaks related to feature transformation and data augmentation to improve the performance of neural models. They discuss why neural LTR models are worse than gradient boosted decision tree-based LTR models, and introduce some directions to improve neural LTR models. Proposed DASALC framework is quite simple and uses mostly standard techniques, and this is an advantage as a reference point. I both enjoyed this paper and think it's a strong contribution to the ranking literature. Is the few percent improvement worth it? LightGBM is very fast. How long does it take to train your model? It was well written, clear, and nicely organized.
Therefore, they can adversarially train the perturbations and model to obtain a robust model and robust word embeddings. Then, it presents a few tweaks related to feature transformation and data augmentation to improve the performance of neural models.
For example, in the experiments shown in this paper, they  compare performance of deep equilibrium linear models with linear models and deep neural networks.
This paper proposes replacing the old communication actions with up-to-date actions as the transitions are sampled, and shows that this leads to greatly improved convergence speed and higher performance plateaus. ---- Summary ---- The paper proposes a method for modifying an experience replay when learning in communication environments, by relabelling messages using the latest policy. Summary: This paper considers communication games when agents use experience replay. This is hinted at in the main text, but I think it is central enough to the interpretation of the experiment that it should be moved there. Questions to clarify recommendation: The three environments presented in the paper, if I've understood them correctly, are pretty straightforward in that Questions to clarify recommendation: The three environments presented in the paper, if I've understood them correctly, are pretty straightforward in that
This, coupled with the fact that their readouts leverage retinotopy, it is surprising that the authors never discuss the spatial segregation of the "held-out" neurons (say H) from the neurons in the training set (say T). Introduce a novel readout mechanism that allows models to be shared fully across neurons which in turn helps transfer learning. Strong points: Empirical modelling of neural responses has a long tradition, and the results in this paper are state-of-the-art. (iv) The authors report that transfered "core" representations work better than direct-training in their generalization experiments. (v) The authors report that task-driven cores (such as VGG-16 pretrained on imagenet) perform badly in generalizaing across animals.
Summary One important application of Neural Architecture Search is to find neural network architectures with good accuracy/inference time or accuracy/energy tradeoffs on a specific hardware device. The benchmark is based on extensive measurements on real hardware. Contributions The paper proposes a benchmark for hardware-aware neural architecture search (HW-NAS). Recommendation after Author Response I have read the author response and appreciate the effort spent by the authors on this response. Recommendation after Author Response I have read the author response and appreciate the effort spent by the authors on this response. I hope that the author's statement "All the codes and data will be released publicly upon acceptance" also includes the code for conducting the measurements. I thus lean towards accepting the paper, in particular if the points raised above would be adressed.
Summary This paper proposes a linear time and space attention variant that matches (or exceeds) the accuracy of standard attention while maintaining the speedup of prior work in linear time/space attention. The paper presents a linear time and space attention mechanism based on random features to approximate the softmax. The results are strong. Unlike Linear Attention, the proposed RFA outperforms the original multi-head attention baseline on both LM and MT tasks. and feature in d dimension. The results are strong. Unlike Linear Attention, the proposed RFA outperforms the original multi-head attention baseline on both LM and MT tasks. (It would be even better if they could compare to it in a future version.) The logic in the introduction is a bit contradictive to me: Some are able to achieve better asymptotic complexity (citations). I think I'd like to see a discussion of sufficient number D analytically or empirically.
The generalization performance of learning algorithms characterizes their ability to generalize their empirical behavior on training examples to unseen test data, which provides an intuitive understanding of how different parameters affect the learning performance and some guides to design learning machines. Then, it also provides an instantiation of the lemma applicable to residual networks, an explicit compression analysis via pruning with a corresponding generalization bound, and empirical supports. Different from the traditional error analysis, this paper focuses on bounding the divergence bettween the test error and the training error by the the corresponding distillation error and distillation complexity, e.g., test error  is bounded by training error + distillation error + distillation complexity. That is a good idea and something that is currently very relevant I think and the approach seems to be the natural one to take. That is a good idea and something that is currently very relevant I think and the approach seems to be the natural one to take.
It achieves that by parallel transporting features along edges and spanning a space of gauge equivariant kernels. The work presents a novel message passing GNN operator for meshes that is equivariant under gauge transformations. The result is a Mesh-CNN that is equivalent to GCNs with anisotropic gauge equivariant kernels. Features defined on a mesh may be vector-valued and defined with respect to a frame of reference at each point on the mesh. Many of these works compute some form of a point cloud normal (thus a tangent plane) and choose a direction orthogonal to it (hence fix a gauge). Far better would be to develop a signal natively on the mesh, for example by solving a PDE directly on the mesh. I would be interested in a execution time breakdown for the whole method, showing the bottlenecks. I actually would like to give an accept score. I would welcome, though, if computational efficiency would be analyzed in the work. Transforming to sample space (i.e. embedding in the regular representation) to apply a pointwise non-linearity and then transforming back is a nice idea for addressing this.
The problem of group-equivariance is studied in the most general setup, thus encompassing the previous achievements of Cohen and Welling, Cohen, Geiger, and Weiler, Weiler and Cesa, etc. However, in that case, we are still back to solving the problem on a group by group basis. 7.Appendix E, U(1) is isomorphic to SO(2), so it is strange to use both notations. If I had a student who needed this material I would instead give him or her the original Cohen Welling paper and a representation theory textbook such as Hall 2015 or one of the several textbooks they cite. It would be better to use something more standard. The application section is in particular way too sketchy to convince the novice that this impressive work will be useful to the machine learning community and an effort in this direction should be made to clarify the expected impact.
Summary: This work presents an uncertainty aware continuous convolutional layers for learning from continuous signals like time series/images. Also, given that your approach seems to outperform existing (deterministic?) models or some tasks, how could you change the existing models to gain a similar advantage? Also, given that your approach seems to outperform existing (deterministic?) models or some tasks, how could you change the existing models to gain a similar advantage? This is presented clearly and in a fair bit of detail. This work is most useful in the setting of irregularly sampled data.
The authors propose a regret bound for the algorithm. This paper analyses an existing algorithm (LSVI-UCB) with generalized linear function approximation instead of conventional linear function approximation. Under this generalized linear setting, they propose a so-called "optimistic closure" assumption which is shown to be strictly weaker than the expressivity assumption in the conventional linear setting. I am in favor of acceptance, given that it provides a non-trivial extension to what is known and the Optimistic Closure assumption seems to me to be closer to the reality than the linear MDP assumption.
--Summary: They proposed a robust method for the adversarial attack on VAE using a hierarchical version of β-TCVAE and conduct analysis on the relationship between disentanglement and robustness to support their choice of approach. --Strongness: The paper is well organized. The experiments are sound and well documented (results are reported across latent space dimensions, and adversarial attack parameters) (Update): The score has been updated after a rebuttal from the authors.
In this submission the authors are trying to tackle the very important problem of safe RL with safety guarantees. Quality & Clarity The authors provide regular and clear comparisons of their approach to related techniques described in other works. I believe that this paper introduces an important contribution to the RL community that is concerned with safety. Finally, I would be interested to see how this work could be extended with non-binary safety constraints. Quality & Clarity The authors provide regular and clear comparisons of their approach to related techniques described in other works.
It would have been better if they also had compared with prior state-of-the-art (e.g. HDP, REGAL, Placeto, or (the unmentioned) GDP / GO), but it is somewhat understandable given that their code does not seem to be open-sourced. How does the work compare to the methods described in [3,4]? While EGRL's action space is larger than [5], the action space in [1] is much larger - for a graph with 2000 nodes to be placed on 2 devices, there are 2^2000 possible choices ~ 10^603 Device placement optimization with reinforcement learning.
Using this, they defined their procedure for training SNN to mimic ANN as follows: they trained the ANN with their modified ReLU (which is closer to the SNN activation function but more readily differentiable), and then used the weights from that ANN in their SNN. Nice performance was obtained in all cases: better than using a normal ReLU, or other comparison activation functions, in the "target" ANN. This relationship suggests a mapping between the two models which is imperfect, a loss seems to be derived to reduce this mismatch along the network training. This is desirable for energy-efficient inference, although the training process becomes challenging due to the discrete nature of the spiking process. As one might expect, lower thresholds, and longer simulation times, both of which lead to potentially higher spike counts and thus lower discretization errors, lead to smaller conversion errors. The authors seek a mechanism to train a spiking neural net to duplicate the function of a non-spiking one. I left a comment to the authors in the discussion below and they appropriately addressed my new recommendations. Overall, this is a reasonably nice piece of work.
(8)  to the paper's formulation in (12). "diffirentiable" (several times) I have seen similar considerations (using ICNN to fit gradient of convex functions) in https://openreview.net/pdf?id=rklx-gSYPS
"diffirentiable" (several times) I have seen similar considerations (using ICNN to fit gradient of convex functions) in https://openreview.net/pdf?id=rklx-gSYPS The way it utilizes a small amount of OOD data is novel (eq.3). This work investigates a classic unsupervised outlier detection problem, in which we do not have any label information and need to learn a detection model from those unlabeled data to identify any inconsistent data points as outliers. Third, why is the cluster-based outlier scoring method used? Cons: Their method is a pretty-straightforward combination of two established methods, contrastive self-supervised representation learning and the Mahalanobis distance as a metric of distance from a point to a distribution. Some closely related methods are: self-supervised methods such as GT and E3Outlier that learns feature representations using a pre-text task in a self-supervised way; unsupervised outlier detection methods such as RDA, REPEN, ALOCC, OCGAN, etc.; methods that use a few labeled outlier data such as Deep SAD, DevNet, REPEN, etc.
The proof technique using analytic combinatorics seems novel, and the main results are useful for theoretical understanding of neural networks. Overall, this article is a solid theoretical contribution to our understanding of the NTK. I didn't go much deeper into the Appendix,
This paper studies how to improve the worst-case subgroup error in overparameterized models using two simple post-hoc processing techniques: (1) learning a new linear classification layer of a network, or (2) learning new per-group threshold on the logits. There are case (normalization) issues in the references: "ml", "t-sne" (not exhaustive, a through check is recommended). What's going on there? ============== Update after rebuttal: Thank you for clarifying the numbers in Table 1 should match the main text. That being said, it feels the study/paper builds on a few earlier studies heavily, and I am not fully convinced that there is enough new findings in the present paper to warrant publication in *CONF*.
This paper proposes a simple but effective way to avoid model stealing. Five datasets and three attacks are investigated in the evaluation. My understanding is that since JBDA and JDBA-TR do not reply on a fixed OOD dataset, EDM trained on auxiliary OOD dataset may be well generalized to these attacks' OOD data. However, my first concern is that is also naturally true for benign users.
And then it generate a sequence of future frames corresponding to the semantic segmentation maps. Variational video prediction is used to generate a sequence of segmentation masks. The real authors of this paper are Nevan Wichers and Ruben Villegas.
This paper addresses the limitation of the existing adversarial robustness certificates that ignores that a single shared input is present, and thus assumes an adversary can use different perturbed inputs to attack different predictions. This paper studies classifiers that collectively output many predictions based on a single input. Pros: This is the first effort that considers collective robustness certificate. The arguments are valid on the limitations of independent based certificates for collective tasks. The paper is well-motivated, well-written and easy to follow. Pros: This is the first effort that considers collective robustness certificate.
Through a series of experiments, the authors show that the two measures are highly correlated and correlate well with generalization. Original Review: This paper presents an empirical evaluation of whether flatness correlates with generalization using a few different definitions of flatness - local energy and local entropy. With this the authors aim to find a correlation between networks with close to zero entropy and networks with lower local energy. A paper like this with carefully constructed constructed and a clear conclusion is also a valuable addition to this debate. (4)" and "Eq. (4)". Update after response: I appreciate the authors making their contributions clearer, and adding details about the training loss and error. (4)" and "Eq. (4)". Update after response: I appreciate the authors making their contributions clearer, and adding details about the training loss and error.
[1] Yang Liu and Hongyi Guo. Peer loss functions: Learning from noisy labels without knowing noise rates. [2] Zhilu Zhang and Mert Sabuncu. EDIT------------ I think the authors replied to some of my concerns in a convincing way, hence I raise the score to 6. All in all, with the lack of novelty addressed above, I think the submission is marginally below the acceptance threshold. iv) One motivation of Confidence Regularizer is that confident prediction counters the overfitting of noise labels. However, it would be better if the authors can explain why the proposed method can avoid this, namely which "component" helps to avoid the estimation for noise rate?
There is a submitted paper (to this *CONF*) that includes continuous relaxation of discrete network structure optimization for network growing (not pruning). (3) Justification of the usage of two functions (logistic and heaviside function) is not enough. Therefore, I recommend accepting this paper.
The paper under review introduces a number of geometric measures (isoperimetric, isocapacitory ratios that relate to Brownian motion or heat diffusion probabilities) that are applied to study neural network decision boundaries locally. UPDATE TO REVIEW FOLLOWING AUTHOR REVISIONS AND COMMENTS
This is accomplished by learning classifiers that distinguish transition in the source domain from transition in the target domain. This reward is used to augment the environmental reward. This paper presents a method to do domain adaptation. The empirical evidence shows that the proposed method has very similar performance to the RL on target baselines while improving over other domain adaptation baselines in four continuous control environments. Post-rebuttal Update The authors have shown new experiments on icy environments that show good results for the proposed method (DARC). As such I am inclined to increase my score from 7 -> 8, recommending acceptance of the paper and entrusting the authors to include the new experiments in the main paper.
This improves supervised transfer performance from ImageNet to the other tasks. It is introduced very late in the paper and it is not clear where the proposed loss helps. Reasons for score: Overall, I vote for accepting.
2019. The authors propose two meta-learning algorithms in the reproducing kernel Hilbert space (RKHS) induced by the recently proposed Neural Tangent Kernels (NTK). Summary In the attempt to create an adaptation-free meta-learning method, authors construct an RKHS based on the NTK and explain how to do (gradient-based/MAML-style) meta-learning in this space (instead of parameter space). Based on these insights, they develop two meta-learning algorithms that avoid gradient-based inner-loop adaptation. Good points The benefits of the presented method are obvious: problems associated with a long adaptation loop is a common yet unsolved problem contemporary methods struggle with. This is of merit since it is known that MAML type approaches are far too sensitive to the outlier tasks. Overall, I feel that this is an interesting  and novel contribution, particularly in terms of mathematical concepts, though the approach does not necessarily outperform similar methods by a significant margin except in the case of out-of-the-distribution tasks or adversarial attacks. Thus, I recommend acceptance. Strengths This paper is generally well written and proceeds to develop insights into gradient-based few-shot adaptation on first principles from NTK theory.
In particular, through a series of experiments, the paper investigates their uncertainty properties and answers the question "how calibrated are the predictive uncertainties for in-distribution/out-of-distribution inputs?": i) a comparison between GP classification with the infinite-width neural network kernels and finite width neural network classification was provided to test the calibration, (iii) a study of using GPs with these neural network kernels on features extracted from a pre-trained network, aka, deep kernel learning of Wilson et al with neural network kernels. The stated goal of this paper is very ambitious: how NNGPs provide better confidence prediction, in terms of calibration, OOD data  and distributional shift. Paper summary The authors empirically investigate the calibration performance of NN-GPs in CIFAR10 and several UCI data sets, in three forms: Bayesian inference for the NN-GP function-space prior, through a softmax link function However, I do think this paper is a meaningful contribution, that puts together a few ideas that were lying around and shows that you can use them to make progress in calibration in NNs. Thus, I will keep my score as is -- 7: good paper, accept. Detailed comments: For a reader such as myself who is not an expert in GP but interested in their application to calibration and OOD data, the general introduction in Eq.(1) and (2) makes no sense. The one that seems to come out on top is to change the last layer of a network to a Bayesian linear regression layer.
Such deep generative models, once learnt (in an unsupervised way) for an environment, allows one to hallucinate a sequence of poses and observations, given the learnt map and control inputs. ELBO is used to optimize the model. The presentation of the paper is great. However, the advantages of the approach are not demonstrated. A transition model describing the evolution of the dynamics of the agent is also learnt. Neither is emission model (should be measurement model).
CTNs consist of a base network and a controller, which outputs task-specific feature modulators. (3) a bilevel optimization scheme where controller parameters are updated in an outer loop and base parameters adapted in an inner loop is employed. Summary of paper This paper introduces a continual learning method called Contextual Transformation Networks (CTNs). Some good additional experiments are also provided (different memory sizes, smaller datasets, ablations of the three major parts of CTNs). Pros: Results are generally strong in comparison to other memory based CL techniques on accepted benchmarks. But CTN has very strong performance in continual learning benchmarks. The semantic memory and the  episodic memory are a bit confusing to me. 1), but also θ(t) (e.g., line 2 of procedure Forward, algorithm 1).
Looking at Figure 2, it seems that the performance of DisentanGAIL w/o Prior Data and DisentanGAIL w/ domain confusion loss are near-equivalent which suggests that the access to the additional prior data might be the main factor that contributes to DisentanGAIL's superior performance Summary The paper proposes a novel approach for third-person visual imitation learning from observations, ie for imitating a different agent in a potentially different environment purely from visual demonstrations. [3] Kim, Kuno, et al. "Domain adaptive imitation learning." arXiv preprint arXiv:1910.00105 (2019). Post-rebuttal comments Thank you for answering my all questions and updating the manuscript with some of my suggestions. The notion of "prior data" is used in the paper, but I cannot find a clear description of it anywhere. Other comments S4.2 prior data constraint -- the inequality is backwards (MI is nonnegative) Some questions: What is the difference between DisentanGAIL with DCL and TPIL? There's description of the differences to it in various places throughout the paper, but it would be nice if there were a clear section on the comparison of objective functions. Significance The significance of this paper is that it demonstrates a more performant method for performing observational imitation learning, which is potentially more applicable than standard IL approaches that require state or state-action traces. [2] Lu, Yiren, and Jonathan Tompson. "High" is subjective, and is perhaps not the most appropriate adjective to describe 7 dimensional tasks. The comparisons would be more informative if training were run for more steps (e.g. 1e6 or 1e7). --> since this is a different assumption from prior work on cross-domain imitation it would be good to mention this earlier, maybe in a dedicated "Problem Statement" section for qualitative matching results in Fig 4 in the appendix it would be nice to show the corresponding matches found when using the domain confusion loss instead of the proposed regularizations to see whether some of the failure cases are interpretable
Summary In this work, the authors present a method for learning audiovisual (AV) representations from videos using a Transformer-based model architecture. To allow for end-to-end learning, the paper argues for shared parameters (across the network), primarily: a) sharing weights in CNNs of the same model [understandable] 2020. The paper is a nice read. The use of a Transformer-based model architecture is well-motivated, given its success on other multi-modal problems. (3) Unfair comparison in Table 2(b). This makes the readability of the experimental section below acceptable bar IMO.
The first additional loss is a sentence-level one - where a [CLS] token is trained to be close to the positive sample, the paired sentence, with other sentences as negative samples. The main difference to most other models is that the new losses are contrastive losses (however, as pointed out by the authors, other contrastive losses had been used before in e.g. ELECTRA). The constrastive losses introduced in the paper are interesting. Do you have an answer for this? The constrastive losses introduced in the paper are interesting.
This paper proposes that recent methods that used graphical neural networks to help solve the multitask reinforcement learning problem and assume that there's an advantage from being able to encode the agent's morphology using a graphical neural network do not provide additional generalization and benefits for learning. The paper includes ablation experiments that clearly show that current works that use the body morphology structure to constrain the graph structure of graph neural network based approaches do not actually improve the performance. The paper is well written, and methods and analysis approach used are clear. The strong performances (none of which seem to have converged yet) compared to baselines speak for themselves. While I do agree that training a graphical neural network to be able to produce a quality policy for a number of control tasks from the opening item environment is difficult the author of the paper might be missing at least one of the key points from the previous work in that you can learn a stronger modularization of policy. Suggestions The paper mentions in passing that this work involves agents "with each non-torso node having an action output". As the paper explains, "transformers can be seen as GNNs operating on fully connected graphs". In other places, the paper contrasts transformers with GNN-based methods ("substantially outperforms GNN-based methods"), as if transformers were not GNNs. To avoid confusing readers, it would help to explain that GNNs are a broad class that includes both transformers and SMP, which differ in their message passing schedules, etc. There needs to be an ablation with respect to the residual connections added to the Transformer based network to make sure the improvement for amorphous is not working well just because of these residual connections.
Questions: How is SAC(theta) computed? Is it a policy with its own parameters? (I guess the states, but this is not explicitly told) (2) The derivation for equation (1) is unclear to me. In equation (3), is \\tau' independent of \\tau_-T:-1, so the right-hand term (in red) can be moved outside the blue expectation? I think the choice of evaluation environments is a little odd and simplistic. Is this related to the GAIL baseline? This paper introduces an algorithm, called deep reward learning by simulating the past (deep RLSP), that seeks to infer a reward function by looking at states in demonstration data. While the paper does not have strong methodological novelty, it is well written, the approach is sensible and combines well with state of the art deep RL, and the results are certainly interesting. For this reason, I am unable to recommend acceptance at this stage, due to major clarity issues.
1508-1518. 2018. This paper proposes a new memory mechanism based on the Kanerva Machine inspired by computer heap allocation. The paper proposes a generative memory (K++) that takes inspiration from Kanerva Machine and heap memory allocation. In contrast to the Kanerva Machine, the authors simplify the process of memory writing by treating it as a fully feed forward deterministic process, relying on the stochasticity of the read key distribution to distribute information within the memory. 7083–7093, 2019. This paper proposes a generative memory modeling method. The authors show the efficiency of Temporal Shift Module (TSM) (Lin et al., 2019) in the encoder of memory models. Strengths: They designed a new Kanerva Machine having a simplified writing mechanism and sharable part-based memory. How is the memory used in the read model?
For the action localization task, J-HMDB-21 dataset is used. The problem being addressed is a practical and important issue in deploying video models to real applications. We know that Gflops is not a good indicator for speed comparison. Directional Temporal Modeling for Action Recognition, ECCV2020 Rating Aiming at acquiring an efficient model in a data-driven manner is indeed important for video models. Summary The paper presents a framework to reduce internal redundancy in the video recognition model.
The approach is validated with leading performance on ResNet and VGGNet under various datasets. Summary This paper proposes a differentiable architecture search approach for splitting a deep network into locally-trained blocks to achieve training speedup. The approach achieves better performance than using backprop on small datasets (CIFAR10 and TinyImageNet), and comparable or slightly improved performance on ImageNet with 2x claimed training speedup. The approach is validated with leading performance on ResNet and VGGNet under various datasets. S3: On ImageNet, the method achieves slightly improved performance with claimed 2x training speedup. One way of assessing this would be to also provide training loss or accuracy values.
This paper proposes a learning framework for predicting the labels of dynamic systems. It uses a teacher model to learn to interpret a trajectory of the dynamic system, and distills target activations for a student model to learn to predict the system label based only on the current observation. Summary: This work tries to find a compromise of model-based and model-free methods, using a teacher and student network . This paper proposes a teacher-student training scheme to incorporate the useful information of trajectory to improve the predictive performance of model-free methods. Unlike existing model-based approaches and model-free approaches, the proposed model takes a middle ground and uses a knowledge distillation-based framework. This paper proposes a learning framework for predicting the labels of dynamic systems. Update after author response: I appreciate the authors' efforts to address my comments. It uses a teacher model to learn to interpret a trajectory of the dynamic system, and distills target activations for a student model to learn to predict the system label based only on the current observation. It would be good to add a running example to explain the various concepts and definitions used in the paper.
A simple theoretical architecture is presented as another universal architecture. For a simple class of networks and for TFNs, the authors prove D-spanning. When the F_feat class satisfies a "D-spanning" criterion and the pooling layer is universal, the network is universal. Recommendation: The authors proof the useful statement of universality of a prominent class of neural networks, which is why I recommend the acceptance of this paper. Clearly state your recommendation. Accept. See Strengths. Arguments for your recommendation.
The paper proposes a novel Channel Tensorized Module (CT-Module) to construct an efficient tensor separable convolution and learn the discriminative video representation. This paper presents a new CNN module to learn video feature representations for action recognition, with a particular focus on increasing channel interactions for spatio-temporal modeling. Strengths: The paper's novelty is the first method for exploring the spatial/temporal tensor separable convolution along each sub-dimension. This manuscript proposes a novel convolutional operation for learning representations from video data. Experimental results outperforming state-of-the-art results. Strengths: The paper's novelty is the first method for exploring the spatial/temporal tensor separable convolution along each sub-dimension. Experimental results outperforming state-of-the-art results.
I am a little bit worried that the paper is studying a quite different regime, in which the E neurons are dominating. Other that this comment I learn and enjoy from reading this paper. Another related concern is that, in cortex, despite of a smaller number, I neurons are often responsible for controlling the dynamics/computation due to the dense connectivity from I to E neurons. This is a great investigation on how to scale the gain of the inhibitory weights to balance the impact that the changes that the excitatory and inhibitory connections have on the layer's output. Pros:1.To my knowledge, this is the first E/I network that could achieve comparable performance with the standard ANN model on MNIST task (although at the same time, I have to say that not too many papers have studied and reported this issue). Drawing from that experience, the mutual inhibition within layer may provide a natural mechanism to keep balance in the output distribution as shown for example in mean field models that investigate the regulation of activity in a dynamical neural layer (see for example https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003133).
The authors of this paper introduced a new acquisition function of active learning for optimal Bayesian classifier. An algorithm is provided in the appendix but some comment on complexity as compared to prior arts in the main text would be appreciated. The theoretical analysis of the convergence of the proposed method seems to be sound. In Bayesian approaches, these issues can be interesting and valuable. classification error." This sentence is probably the most important summary of this work, but it's so long and dense that it's very difficult to parse. I feel that there can be room to be improved in this paper.
A model for discrete vector y(t) is proposed in the form of coupled ODEs (one for each x_i) with a sparse coupling arising from a neighbouring graph on spatial inputs x, and sharing the same transition function. The paper proposes to use graph-based networks for evaluations of PDEs with continuous time formulations. This is good to see and makes sense. Previously proposed methods either would not work on continuous time, or unstructured grids, or would not be applicable to settings with unknown governing PDEs. This work combines all these features. Previously proposed methods either would not work on continuous time, or unstructured grids, or would not be applicable to settings with unknown governing PDEs. This work combines all these features. Overall, given the "cons" described above, notably the potential lack of strong novelty in the proposed method, and the lacking experimental description and results, I am for now classifying this paper as marginally below the acceptance threshold.
--The visualization of the key indicators may be helpful for understanding how batch normalization works and how to remove batch normalization.--The experiment results seem that the proposed method achieves good performance in large-scale ResNets. --update--- I am upgrading to 7: Good paper accept; as my concerns have been addressed by the additional experiments. UPDATE: The author has addressed most of my concerns, but regarding the motivations and the benefits for the community, I still keep my score. Can you give the visualization of the same indicators of other initialization methods like Fixup initialization and make some comparison? (3)    It's better to add some accuracy comparisons with other removing batch normalization works. It is not clear that the authors pick RegNet and tune it highly and compared with EfficientNets.
The authors propose a stronger lottery ticket hypothesis in this paper – the multi-prize lottery ticket hypothesis. Pros: The authors try to express in a way that every step of logical connections in this paper can be clearly understood by readers. The paper has many simulation results to support the theoretical guarantees, and the proposed approach on binary-weight networks has advantages over existing methods. Post rebuttal Thanks the authors for clarifying and revising the paper.
Summary This paper aims to present a method that allows efficient learning in neural networks architecture that present optimization blocks. Proposed method is robust to changes in hyperparameters like the number of inner loop iterations during inference. It is benchmarked in a variety of fields (1) energy-based learning, (2) robotic control, and (3) portfolio management. Cons There are some cases (although not in general) of meta-learning for adaptation, for example where the update can be described in an implicit fixed point way or when the method used in FirstOrderMAML , which allows not needing to unroll (when backpropagating) the function to be optimized. Cons There are some cases (although not in general) of meta-learning for adaptation, for example where the update can be described in an implicit fixed point way or when the method used in FirstOrderMAML , which allows not needing to unroll (when backpropagating) the function to be optimized. Suggestions In Figure 1 both (b) and (c) visibly look really similar, I would suggest plotting the difference between them, so a reader can understand better via visualizing the energy function the advantages/disadvantages of (not) unrolling. I would like further explanations of this, and some experiments with (U-)NOVA on meta-learning. Another small suggestions: On Page 4 "desirable properties of optimization" seems rather vague, perhaps it should be stated more specifically (most likely what is meant is smoothness of the resulting objective function). Finally, I would like further clarifications on why the graph decoupling to get a better initialization is justifiable with NOVA and not other procedures.
The authors also propose a measure of gradient alignment which they show correlates with generalization performance It shows that this alignment measure can capture generalization performances for other architecture such as ResNet or DenseNet on the CIFAR-10 dataset. Figure 2 shows that the norm(grad)/norm(weight) decreases significantly with the scaling-up the initalization. It then proposes an alignment measure which correlates with generalization for different initial scale. The authors also propose a measure of gradient alignment which they show correlates with generalization performance I strongly recommend the paper to be accepted. The combination of things is too much for me to recommend acceptance out of the box, but the things are relatively small and I think easy to address, and I'd be happy to increase my score.
To train this end-to-end, we need a transformation matrix T such that T*A = E (E is V\\times d embedding matrix). This paper introduces a row-rank approximation of embeddings using "anchors". And the authors perform experiments with both frequent token vectors and random anchor vectors (both have their merits, random seems to be a robust choice). The authors provide a statistical interpretation of their approach using a generative formulation to the embedding vectors in terms of the latent vectors (using a Indian Buffet Process membership matrix Z). Hence the paper proposes to only store a few anchor/latent vectors (the matrix is A with |A|<<|V|). It's not obvious to me how to guarantee that for every row of T, there is at least 1 non-zero element. The authors took two steps forward: 1) instead of in [1] where the entire vocab is used for anchoring purposes, the authors used a subset of tokens which reduces the amount of parameters. Although this paper is probably related to other strains of research (e.g. leaning manifolds for IR/NLP where anchoring is also a key concept, which the authors could have admittedly surveyed more), I particularly liked the fact that the two-step procedure decomposes two tasks that are often mixed together for embedding tasks: learning representation vs learning relations. Normally the embedding size is around 16 to 64 in real systems.
The paper studies generalization properties of preconditioned gradient descent on linear/kernel regression problems. The main preconditioner that is studied in addition to vanilla GD is the (population) Fisher matrix (natural gradient descent or NGD), its empirical counterpart, and its interpolation with GD. What conclusions are we to draw from this part of the result? [2] - D. Richards, J. Mourtada, L. [2] - D. Richards, J. Mourtada, L.
2020." (2) Sattler, Felix, et al. "Robust and communication-efficient federated learning from non-iid data." IEEE transactions on neural networks and learning systems (2019). Strength: The paper compares two algorithms, i.e., distributed compressed SGD (DCSGD) and compressed communication with error feedback (EF), by analyzing their convergence rates. Why not use an unbiased compressor (e.g., C2) directly? accuracy. Does the proposed approach also work well for non-iid data?
The paper builds on the Neural ODE framework by using delay differential equations (DDEs) instead of ordinary differential equations (ODEs). The paper builds on the Neural ODE framework by using delay differential equations (DDEs) instead of ordinary differential equations (ODEs). As for NODE I understand that the complexity in space is favorable. As for NODE I understand that the complexity in space is favorable. However I stay on my hunger on different points, there are pending questions that require to be answered before acceptance.
To this end, a drop probability is learned for each dimension. The approach is demonstrated in experiments in (1) robust exploration setting for RL, (2) adversarial attacks on ImageNet, and (3) an experiment showing that their approach is able to maintain performance on ImageNet with reduced dimensionality. Key idea is to instantiate the compression term of the information bottleneck framework with learned term that sets irrelevant feature dimensions to 0. Evaluation: I found this paper to be clear and the experiments seem reasonable. Would that perform as good as DB? When some of the Xis are correlated (e.g. consider a vision task), there could be quite a gap between I(Z; X) and the independent assumption version. DB cannot provide the same generality as other IB objectives: the input (latent) has to be sufficiently disentangled already as the objective itself does not encourage further disentanglement by itself. However, the fact that individual dimensions (i.e. specific pixel locations) are identified as irrelevant is still a limiting factor. Overall, I score this paper as an accept.
This paper proposes a method for deep learning with noisy labels, which distinguishes the critical parameters and non-critical parameters for fitting clean labels and updates them by different rules. The proposed method is novel and effective. I recommend to accept this paper, and hope that the authors can address the above issues carefully. (3) The parameter (noise rate) τ still needs to be estimated, which may be challenging. ------Issues------ I only find the illustration of comparison between CE and CDR in the case of noisy CIFAR-100. Could the authors add some introduction for the baselines and more detailed discussion for experimental results. Could the authors add some introduction for the baselines and more detailed discussion for experimental results.
The authors propose a novel framework named MetaD2A. In a nutshell, the framework learns a "dataset-to-neural-network-architecture" transformation using a database of datasets and architectures. Each dataset is encoded via a "set encode" and the architecutres are obtained via a "graph decoder". The experiments demonstrate the usefullness of the approach and its improvements over conventual NAS approaches. And I prefer to see the effect of predictor part with different predictors. I think there are some other perspectives to perform ablation study. Your experiment should prove that your model can generate variety of architectures. Overall Review: This paper proposes a new scene of fast adaption of NAS, which may be a good direction of NAS & meta-learning.
This is based on using Bayes rule and a Gaussian generative model for the latent representations. Everything makes sense, and the MC approach in equation (3) seems cleaner to me than the somewhat ad hoc "VI like" approach in equation (2). p6: "conditional model with an decoder operating on". p6: "conditional model with an decoder operating on". Weaknesses: The evaluation is missing an important baseline model, which are (A)NP models that have self-attention in the encoder for processing the contexts (c.f. model figure in ANP paper (Kim et al., 2019b)). p6: "conditional model with an decoder operating on".
This paper identifies a limitation (a biased objective) in a commmon formulation of empowerment [Gregor 16], and proposes a method to correct for this. Strengths The paper provides a sound theoretical analysis of the limitation of the VIC implicit-option algorithm, the proposed fix and a practical algorithm (Algorithm 2). Feedback to authors The paper introduces extremely dense notation. The frequent overloading of symbols or use of similar looking symbols (e.g. p,pp,ρ) makes it quite difficult for the reader to parse each expression. In light of this, I am increasing my score from 4 -> 6, slightly leaning towards acceptance. Additional experiments are needed. In addition to experiments justifying the extra term, it would also be useful for the authors to include more motivation and intuition about why and when it is important. This is because empowerment is not an important objective in and of itself. I agree with the authors that the derivation has theoretical value and is not a simple re-derivation of VIC. Pros: The missing term highlighted, and the derivations of solutions generally looked correct (at least at the level I followed them). Additional experiments are needed. In addition to experiments justifying the extra term, it would also be useful for the authors to include more motivation and intuition about why and when it is important.
Additional experiments are needed. In addition to experiments justifying the extra term, it would also be useful for the authors to include more motivation and intuition about why and when it is important. Comment (1) hints at a larger (but vague) point that the paper is trying to characterize a stochastic optimization procedure with a solution of a deterministic gradient flow ODE. Additional experiments are needed. In addition to experiments justifying the extra term, it would also be useful for the authors to include more motivation and intuition about why and when it is important. In my opinion, this paper fails to deliver that, which is why I recommend rejection.
This is an empirical work assessing some of the recent works of early pruning methods in an effort to understand why early pruning methods perform worse than pruning after training methods. Extensive analysis shows that there is a performance gap of PaI methods compared to Pruning-after-Training (PaT) methods (understandably) and attempts to explore the potential reasons. However, this comparison is unfair as LTR has additional information which is obtained after training (pruning mask is obtained after training but applied during training) and those PaI methods are not specifically designed to be performed during/after training (even so some perform reasonably well).
It is trained to do this using mixture invariant training to separate synthetic mixtures of mixtures. Summary of the paper: This paper proposes a multi-modal sound source separation framework in which they aim to separate on-screen sound. Take Owens and Efros (2018) for example. 2) or spectrogram (fig. 1) for audio? Second, I know the authors said this is the first system to do so, however, I would still expect the authors to compare to some baseline. Unsupervised source separation, especially for open-domain is an interesting and important research direction.
AdaSpeech is a paper on practical TTS custom voice adaptation with the aim of reducing the amount of adapted parameters per voice to allow cloud serving of a large number of custom voices while maintaining high adaptation quality and similarity. The model is based on the TTS model in FastSpeech 2, with several additional components. This paper proposes AdaSpeech, a Transformer-based TTS architecture derived from FastSpeech, but multi-speaker, and focussed on the task of low-resource, robust, and low-dimensional speaker adaptation. Overall, this is very exciting work, as it not only promises space-efficient voice cloning, but, in doing so, suggests better disentanglement of speaker and phoneme properties in multi-speaker synthesis. Pros This paper takes one important issue of current speech synthesis area: TTS adaptation to new voice. In paper, it is said that the phoneme-level acoustic encoder uses phoneme-level Mel features as its input. There is also a phoneme-level acoustic embedding which is used in the same way, which at inference is taken from random sentences (why not in training?), and, I guess, is supposed to cover phoneme-level idiosyncrasies of the speaker, although this isn't clear to me. MSE? How is it determined that acoustic conditions such as loudness or room conditions are actually captured by the utterance- and phoneme-level acoustic condition modelling? In the inference, the phoneme-level acoustic predictor uses phoneme hiddens as its input to predict phoneme-level vectors. The result is that, within the margin of error, this method is just as good in terms of speaker similarity as fine-tuning the entire decoder. 1 without them? Some typos: In pages 2 and 7, describe full representation of MOS, SMOS, and CMOS, respectively. This would be useful, or, even more welcome, an ablation study with the acoustic embeddings but not the speaker embedding.
Following the rebuttal: I checked comments of other reviewers and response of authors. "The results show that HeteroFL can boost clients' performance with low computation and communication capabilities by allowing the training of heterogeneous models with larger computation complexities." -> This sentence is unclear and leads to a wrong statement. However, it is worth noting that the core idea of this paper: HeteroFL, is a very simple and elegant way to deploy FL on an heterogeneous client set.
By doing so, it is possible to have only partial labels (weak labels). == SUMMARY == This is a well-written paper that discusses how to learn disentangled representations for the learning from demonstrations (LfD) task in robotics. The results show that the models using the weak labeling out-performed models with no labeling. == QUALITY & CLARITY == It is shown that using weak-supervision on top of unsupervised learning frameworks (that use the variational autoencoder for instance) can work well in this case. However, the idea of learning "interpretable representations" using "weak supervision" is interesting and probably the most significant bit in this work. However, the underlying concepts essential for tasks lie in a much lower-dimensional manifold. This paper proposes and interesting and novel way to handle weak labels from human demonstrators. This model was applied to a task where a human would teleoperate a robot arm and apply a dabbing motion in relation to an object in the scene. Comparing the method to related work (DMP, or ProMP-variants, or any other competitive method) in the real-robot experiments would also be crucial.
Is this a general trend? I'm willing to increase my score if these concerns are properly tackled during the rebuttal period.
Summary: This paper propose a population-based AutoRL framework for hyperparameter optimization of off-policy RL algorithms. To achieve this goal, they integrate three technologies, i.e., evolutionary RL for hyperparameter search, evolvable neural network for policy network design, and shared experience replay for improving data usage. This innovation itself leads to 10x improvement on sample efficiency; Motivated by the sensitivity of RL algorithms to the choice of hyperparameters and the data efficiency issue in training RL agents, the authors propose a population-based automated RL framework which can be applied to any off-policy RL algorithms. Without architecture adaption, there is no observable difference.
This paper studies the mean-field limit of the policy gradient method (with entropy regularized) and proves that any stationary point under this setting is a global minimizer. Under certain regularity conditions, the paper shows that if the training dynamics converge to a stationary point, this limiting point is a globally optimal policy. The convergence (section 4.2) to the many-particle limit. For example, would it be possible to establish some compactness under additional regularity conditions and use it to show the convergence of a subsequence?
This paper proposes an easy-to-implement algorithm for the efficient exploration, which is a temporally-extended version of \\eps-greedy. Thus, it is very hard to verify the technical contributions (in terms of models and algorithms) of this paper. This paper presents a generalized overview of temporally extended e-greedy exploration. This is an especially important contribution of this paper since it makes the point to the RL community that simple exploration strategies may be more effective in practice, but there is still room to innovate while maintaining simplicity and generality. I think the paper provides a clear argument for simple and general exploration strategies and that ϵz-greedy seems to be an algorithm that achieves these goals.
The results show that high dimensional and high entropy label representations are more useful, which is observed in the experiments related to robustness and a limited amount of training data. More specifically, the authors use audio labels rather than traditional categorical probabilities for model training and get surprising and interesting results. This paper starts an interesting direction and conducts nice experiments. The proposed claim in this work seems quite bold and is mostly built on empirical observation. Since TTS system is utilized to generate pronunciation of label, such other information is naturally used in high-dimensional labels (the information used in the TTS system). What's the performance with high dimensional and high entropy label representations, comparing to text label, for other kind of the classification problems, such as NLP problems.
Summary This paper considers the problem of adapting a pre-trained model for few-shot learning in case there is a shift of distribution from the meta-training set. This paper considers a setting (as I understand) where the test task is out-of-distribution of P(T). The paper also proposes to add task adversarial examples to the training set to help the meta fine-tuning process. In MAML, we assume that tasks are (i.i.d.) sampled from a distribution of tasks P(T). It is quite novel to leverage adversarial learning as data augmentation for meta-testing in MAML. If no, and you use running stats, then a simple baseline would be to use test time statistics, so I would add this comparison to your experiments. It is an important problem in industry since there are some industrial tasks, especially meta-learning tasks, that have very limited data.
The authors show how complex tasks can be modularly formulated thus yielding a joint monolithic learning possibility. "...primarily interested in the extent to which different tasks may interfere,..." (in a multitask setting) Pros: This paper is quite novel in many aspects, including modularity v.s. monolithic, constructing task codes by SQL-style aggregation queries, "inverse counterpart" of multitask learning, connections to cognitive science. I could see this paper be re-written almost as a proper tutorial paper in this topic of research. The idea is quite interesting to encode the objectives as task codes and then to write a smooth approximation to the predictor function as a weighted sum of indicators and the try training a net to learn this smoothening. COMMENTS AFTER REVISION I've looked through the revised paper, and the authors has addressed my comments. If not, it would be best to put in the proof here since this isnt obvious at all. This, in my opinion, could be suitable and a definite ACCEPT for *CONF* conference. Hence, I am happy to recommend an accept.
One exception is a fairly good description of the SR. Pro: the paper shows that a simple model based on grid cells and SR representation can perform navigation in some simple environments. This paper shows how SR representation theory can be used in a model of grid cells to plan and navigate towards a target. It is unclear how it is implemented in the network model, and how this information can get to the grid cells. Clearly, the proposed model is related to many of the previous models, but to go one step further and say that it unifies these previous models, that would seem to be a over-claim in my view. The demonstrations in Figures 1, 2, and 3 are made in small gridworlds -- 50x50 is the largest. What does the "sense of direction" mean exactly? Figure 3.H provides the only piece of quantitative data, and it implies the prediction error increases with transition noise? (Am I misinterpreting this?)  Also, it is not clear exactly what are the inputs and outputs of the grid cell system. This feels quite restrictive and potential wasteful in terms of computation. How was the data gathered and why does it appear to increase monotonically in discrete steps? Is there a way to falsify the hypothesis/model? Can they demonstrate that there are sufficiently rich problems in the gridworld space where this method provides significant utility? Can the authors provide examples of more interesting domains where this strategy is feasible?
In this work, the authors provide a method for a posteriori calibration of DNN uncertainty with emphasis on constructing a classifier that has PAC uncertainty guarantees. I would appreciate if the authors could help me understand this case as I think it is indicative of a misunderstanding on my part. Strong points: The proposed method provides a provable guarantee on the reliability of a pre-trained methods prediction, which is a very nice property to have in the reliability/safety problem. Pros: Paper is well written Important and timely problem, motivating arguments are well constructed This approach is a simple but good idea, seems grounded in a good motivation and the explored use cases are informative and interesting. Paper appears to be mathematically sound though I did not check all the proofs in the appendix. This is a paper that focusses on the timely and important problem of uncertainty quantification for the predictions of deep neural network classifiers. Experimentally, the method shows improvements over a naïve baselines, and demonstrate that it can obey a given error or safety threshold in practice, an important property I think this is a OK trade-off to make when in safety-critical scenarios, but then the authors give "fast inference" as one of their primary applications, it seems like a bit more discussion of this may be warranted. -above eq 2, should this be \\kappa_x ?
The representation can be used for several downstream applications ranging from semantic segmentation as well as action learning for robotics applications. As a result, it is unclear to me why ESM performs worse than ESMN in Tab. 1 for DR-Ego-S but comparable for all other tasks in the table, or why ESM and not ESMN is used for some of the experiments. As a result, it is unclear to me why ESM performs worse than ESMN in Tab. 1 for DR-Ego-S but comparable for all other tasks in the table, or why ESM and not ESMN is used for some of the experiments. As such, it is hard to recommend acceptance.
How would your results compare to these approaches?
The numerical results are impressive I liked the paper a lot, and it's definitely a big step-forward in neural operators. The subsequent experimentation was extremely thorough (e.g. demonstrating that activation functions help in recovering high frequency modes) and, of course, the results were very impressive. However, a uniform discretization is required." Strengths: Overall, the paper is well written. I like the idea of learning a mapping for a class of PDEs, rather than optimizing per instance I'm assigning a score of 8 (a very good conference paper), and I think that the paper is more or less ready for publication as is. The theoretical and experimental sections are, for the most part, clear and concise, although some important details remain unclear/lacking.
It is demonstrated that i) better calibration of individual members of the ensemble may lead to the worse calibration of the ensemble predictions ii) this is the case when mix-up / label smoothing are used during training. The confidence criteria are computed once in an epoch. The CAMixup is an adaptive mixup data augmentation based on per-class calibration criteria. The paper explores the interesting relations of Mix Up and Uncertainty, which is useful and will be the right fit for the conference.
The proposed approach is evaluated on Pushing and Locomotion tasks. a hypernetwork that conditions on the latent vector and generates all parameters of a dynamics model dedicated to the observed system, and a target dynamics model constructed using the generated parameters that predicts the future state by taking the current system state and the input action as input. It's a clever idea and most flaws that I'm about to point out are easily addressable by the authors. Pros: The proposed approach for conditioning dynamics models on rollouts to model system-specific properties using the hypernetworks idea seems novel and is interesting. Why does a "1-dimensional code" lies in a 2d space? You can't move the amount of training data to the appendix and it's not good practice to only include the network architecture by name in the main paper. Also in the introduction, you present (i-iv), and you mention how your method is better/different than (i-iii) but you never address (iv). == Update == Thank you for your detailed response.
Experiments on several toy MARL benchmark demonstrates the effectiveness of the proposed method. The method involves agents producing imagined future trajectories using learned environment dynamics, and then communicating some parts of these trajectories to other agents. However, in general, this is not the first to use intention. Machine Theory of Mind. ICML-18 I have read over the rebuttal and discussion and will keep my evaluation score as it was since the concerns about the weak performance result still remain. +) The paper is overall clear and well-written.
Summary This paper extends neural compression approaches by fine-tuning the decoder on individual instances and including (an update to) the decoder in the bit-stream for each image/video. They demonstrate that this approach yields a superior rate-distortion curve than the non-finetuned model on a set of I-frame video data. Summary The paper describes an instance specific finetuning method for image and video compression including finetuning the decoder. The proposed approach is evaluated on the UVG dataset and the authors find a 1db improvement (PSNR) relative to their own baseline. The method is sound, and incorporating the entropy cost of model update during fine-tuning offers a conceptually appealing (and likely more performant, though not empirical verified (see below)) approach compared to previous methods (Lam et al., 2020, Zou et al., 2020) that tackles model update quantization after fine-tuning. I think these give a nice feel for the way the method works and the finetuning progresses on this particular instance. This paper considers the problem of per-instance model adaptation for neural data compression, and proposes a new method for end-to-end finetuning the model that is quantization-aware, by introducing an additional term that measures the compression cost of model update to the typical rate-distortion loss. Instead, the typical thing to do in literature (due to Balle et al.) is to actually minimize -log p[\\bar δ], where \\bar δ = round(δ), and the rounding can be either approximated by uniform noise injection or STE.
(e.g., detection of person category having a more diverse appearances can be more affected by the number of instances used in training.) However, increasing the number of classes also increasing the number of training samples in your experiments, and using more training data could have higher performance. Can this claim be applied to any kind of category? Strengths: The paper is well written and it's easy to follow the story. It provides a comprehensive review on related papers on object detection especially one-shot detection and their limitations.
The paper proposes a novel method for inverse reinforcement learning: inferring a (distribution over) reward functions from a set of expert demonstrations. It's unclear to me due to the expectation in (4) and (5). In my understanding, CϵE is a class of sets of trajectories. (p.2, Introduction) In general, the solutions to the IRL problem are not always best-fitting in the previous approaches because a highly nonlinear inverse problem with the limited information is very likely to get trapped in a secondary maximum in the recovery. The algorithm is evaluated on a 10x10 gridworld and compared with MaxEnt-IRL and DeepMaxEnt-IRL. I have never seen such a thing done before and it is interesting and possibly a route to robustness, but I would have liked more explanation and discussion. (p.1, Abstract) a global viewpoint (p.2, Preliminary) T:=P(st+1=s′|st=s,at=a) T(s′|s,a):=P(st+1=s′|st=s,at=a) (p.2, Preliminary)  a sequential of state-action pairs a sequence of state-action pairs?
This paper presented an adversarial augmentation technique for graph neural networks. The proposed technique consists on adding adversarial perturbations to the nodes' features solving the standard min-max problem for adversarial training. The authors claim that nodes that are far away from a target (labelled) node will have lower effect on the prediction for that node, thus they increase the adversarial step size αu for the unlabelled nodes. ogbg-code: +2: GCN+virtual node+FLAG, +4: GIN+virtual node+FLAG, +4: GIN+FLAG, +2: GCN+FLAG This paper investigates adversarial feature augmentation for improving the generalizability of graph neural networks. I really like the analysis of why this method works on graph data, which shows that the data distribution shift is important. For instance, the impact of biased perturbation is statistically insignificant in table 2, and those limited numbers are not sufficient to make such a deduction. ---- Summary This paper proposes FLAG (Free Large-scale Adversarial Augmentation on Graphs), an adversarial data augmentation technique that can be applied to different GNN models in order to improve their generalization. In sum, although the paper provides new and valuable findings, the experiment analysis and conclusions that are made are not strong enough for a purely empirical study. Adversarial Training for Free, Neurips 2019 This work applies FreeLB adversarial training [1] to graph neural networks. Just because augmentation hurts the performance of MLP on images but improves on graphs doesn't mean data distribution is the primary determinant of the efficacy of augmentation.
(2) Why it is small? ################################## Post-rebuttal: The idea is good, but the experiments and analysis are not enough to validate the proposed idea.
Summary This paper presents a new type of brain-inspired dual-pathway DNN model where the coarse (faster, less accurate) and fine (slower, more accurate) visual pathways augment each other during training and inference (via imitation and feedback) to boost the network's robustness to various noises. The two pathways are named as FineNet and CourseNet. During inference, the FineNet received recurrent feedback signals from the CoarseNet via an attention layer and memory. In sectino 3.3, in the FineNet-only models, it is unclear how the feedback loop is resolved in the absence of CoarseNet. In section 3.3 it is stated that "this highlights an important goal for the brain employing two-pathway processing". In Table-1, it is unclear what "our model" is and how is it different from FFL and SFL? The outreach to backward masking oversold a computational analogy as a neural computational model while providing a vague explanation of the background and results of the experiments. Also, as the field has started to more directly use neural data to guide better network design [8], it's unclear why the authors seem to have completely omitted this approach. References [1] Low Frequency Adversarial Perturbation, UAI, 2019 References [1] Low Frequency Adversarial Perturbation, UAI, 2019
Although studying aggregation function is interesting, this paper doesn't propose a new aggregation function beyond analyzing the combinations of existing ones. There is both a drop and gain in performance with the adoption of the generalized aggregation functions. --- Post rebuttal: I've read the author's response and there is no change in my scores. Update after Rebuttal: I have read the authors' response but do no change my scores. (3) This paper is well organized and easy to follow. —Summary: The authors propose a generalized neighborhood message aggregation function for GNNs. The proposed choice of generalized aggregation functions is SoftMax and PowerMean, which generalizes Max and Mean functions and interpolates them. (3) This paper is well organized and easy to follow. A comparison of efficiency between proposed aggregation functions and existing simple functions should be included.
A comparison of efficiency between proposed aggregation functions and existing simple functions should be included. The scalability of this method is limited. significance: I have carefully checked the quality of the generated video sequences, which are not so satisfying. However, all recent (here, I mean in the past decade) methods that related to video generation are missed. (2) It is not true that existing methods fail to generate more than a short sequence of frames, e.g., (Lee et al. 2019) in theory can generate videos with arbitrary lengths. The general idea is starting from a prior work (Video Textures) and extending this work with a learning framework. Second, this method seems to be example-specific, which needs retraining if fed a new video sequence. Are they different from the work (Video Textures) or not? (i) a new pipeline for modeling and calculating probabilities of transitioning between frames of the same videos. Moreover, the video interpolation is directly borrowed from previous work without further improvements, where I think is still challenging and worth to explore. No analysis is provided to show the contribution of this module. It is highly recommended that the authors could present more comparison with the previous baselines in both general idea and model details. First, although there may not exist any resampling method that can directly perform the video texture synthesis, I believe many related graph-based methods could be used to model the transition probabilities of frames. (2) Extend the proposed approach to audio conditioned video synthesis I am interested in if the proposed method can perform these tasks. Second, although the authors pointed out that the video resampling (textures) strategy is different from the recent generation-based strategy, they should provide visual results/comparisons to support their claims. clarity: The pipeline of the proposed method is clearly presented in the method part. The analysis of the quantitative and qualitative results is convincing and logical.
ArXiv, abs/2007.03730. In this paper, the authors propose a certifiable watermarking method for neural networks. Moreover, the video interpolation is directly borrowed from previous work without further improvements, where I think is still challenging and worth to explore. It is highly recommended that the authors could present more comparison with the previous baselines in both general idea and model details. Since the proposed method is quite close to adversarial training, one concern is that models trained with adversarial training might be falsely detected as the watermarked model. I think there is a lack of experiments on the robustness and model performance of watermarks under different ϵ. (2) Extend the proposed approach to audio conditioned video synthesis Can we say that the suspicious model is truly the watermarked model?
This paper proposes NAHAS for co-designing neural network architecture and hardware architecture. [1] Neural-Hardware Architecture Search, NeurIPS 2019 Workshop on Machine Learning for Systems. It also needs to revise the claim that it demonstrate effectiveness of hardware aware NAS for first time. It is a little unclear why the papers by Jiang and Yang and the papers above are dismissed? Is it typical to design an accelerator for just one network? The authors should discuss the difference between this paper and [1]. The authors should discuss the difference between this paper and [1].
This paper presents a weighted balanced accuracy to evaulate the performance of multi-class classification. This paper proposes a simple and general-purpose evaluation framework for imbalanced data classification that is sensitive to arbitrary skews in class cardinalities and importances. Specifically, they introduce an additional weighted term in the formulation of balanced accuracy. Pros: The proposed framework is simple and effective. This term is not clearly explained in the paper. Some of this in the abstract would help. However, there is nothing in the formulation of this concept which requires that this is an importance and could in fact be any form of weighting.
Empirically, the proposed regularized term works well along with the original MINE estimator and ReMINE  has better performance in the continuous domain To this end, this paper investigates why the MINE succeeds or fails during the optimization on a synthetic dataset. Based on the observations and discussions, the paper then proposes a novel lower bound to regularize the neural networks and alleviate the problems of MINE. They investigate a few of the issues of this specific estimator and propose a regularization to help with one of them. In light of this, the author's approach is to add a regularized term to prevent the drifting phenomenon. However, the theoretical work in MINE is also very weak and only focuses on estimation consistency and not convergence rates (i.e. the statistical bias and variance of the estimator). EDIT: I thank the authors for their detailed response. EDIT: I thank the authors for their detailed response.
The authors propose an algorithm to enlarge the training set for image classification problems in certain medical applications where training data of the target modality is scarce. a) What is the distribution of actual age in the different datasets from the different modalities? The proposed approach has been described for a medical imaging task that involves macro anatomical features only.
This paper addresses the problem of an unbalanced dataset and tries to equalize the accuracy for different classes (labels). This is certainly nice to see, but it makes a direct comparison to prior work (that is DP) difficult, and a little unfair. In Equation (2) you describe DP-SGD as adding scalar noise * vector of ones (same noise value to each entry). I am not even entirely sure that the proposed algorithm is actually differentially private because the step that finds the optimal clipping thresholds seems to use the non-noisy mini-batch gradients without any privatization (please clarify if my understanding is not correct). In order to make the experiment more informative, I suggest authors compared FairDP with other algorithms that have been designed for addressing unbalanced datasets.
This paper studies how to do distributed training for GNNs. For GNNs, nodes are connected so that it is not trivial to do distributed training, because it needs message passing across machines, incurring communication costs. In my opinion, because different nodes carry different amounts of information, we should select the set of nodes that carry the most information, for example, a node should be added to a partition if it has the most number of connections with the nodes in that partition. Training GCNs for large graphs is important for real-world applications. This paper addresses the problem of training GNNs in a distributed environment (e.g., with multiple machines communicated through a network).
The authors extend a hierarchical clustering algorithm from prior work for this purpose. This paper proposed a learning algorithm of meta-learning: TreeMAML, to share information across tasks in meta-learning models. The authors refer to [2] in the section 2 of the paper and mention that it is not task agnostic. The submission proposes a meta-learning algorithm attuned to the hierarchical structure of a dataset of tasks. Recommendation I currently recommend a clear reject (3).
This model is then trained, along with the masks, for a few epochs. The work is well-thought through and authors do a good job of explaining their approach and other existing works using lottery tickets. The main contribution of this work is to use Early Bird Lottery Tickets to reduce pre-training and fine tuning time for BERT. The work is well-thought through and authors do a good job of explaining their approach and other existing works using lottery tickets. It seems to not be that important, but would using separate values for attention and FC make a difference? around 1% might be reasonable for 30-40% reduction in training time, but it is certainly a reduction in accuracy. The difference here is that the authors find the model early in the training run, but it seems like the EarlyBERT procedure could be run once and the resulting model architecture could be saved and re-trained like NAS models are. Baselines: Experiments on pre-training compare with no baselines. Training a BERT model for some epochs, and then distilling it into a smaller network for the rest of the training. (2020). The cost of training NLP models: A concise overview. I cannot recommend accepting this paper in its current form, but am looking forward to reading the authors' response which might clarify things.
The results show this method can achieve state-of-the-art performance on the two datasets. Organisation: method and results should be presented separately: the current flow of the paper alternates between empirical findings (motivation), a formal approach (methodology) and experimental results. [2] Adaptive Subspaces for Few-Shot Learning Simon et al CVPR 2020 [6] Wang, Yan, et al. "Simpleshot: Revisiting nearest-neighbor classification for few-shot learning." arXiv preprint arXiv:1911.04623 (2019). "Few-shot learning with localization in realistic settings." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.
This type of behavior of gradient dynamics is different from that of the mean-field regime. In particular: The paper shows for certain artificial target functions with low-dimensional structures, the neurons start out from a random-feature behavior and then a few are selectively activated, distinct from the rest of the neurons which are "suppressed". In particular, can we know in advance which neuron is going to be activated, even in the simple case of single neuron target function? This phenomenon seems to be limited to a few iterations where it is an almost trivial observation considering that the second-layer weights are initialized at zero (which implies a vanishing gradient for first layer weights). It would be good if the authors can (heuristically) explain which neuron will become activated (any random neuron, or a neuron that satisfies some initial condition?), and how long it will take for those neurons to become activated (perhaps this depends on the initial weights of the neurons).
This paper investigates the importance of incorporating structure and modularity in MBRL. [1] Physically Embedded Planning Problems: New Challenges for Reinforcement Learning, https://arxiv.org/abs/2009.05524 Based on the above reasons, I do not think this paper is ready to publish. In addition, this paper only compares existing models with or without structures, but I fail to see any novel or interesting ideas that this paper tries to deliver. It merely means that directed relationships can be modelled. (2019). Phyre: A new benchmark for physical reasoning.
2017. [2] Li, Yandong, et al. "Nattack: Learning the distributions of adversarial examples for an improved black-box attack on deep neural networks." arXiv preprint arXiv:1905.00441 (2019). from theorem (3) it seems that this detection method works for advanced attack, which requires r2<r1, what if the attacker is a bad algorithm causing adversarial samples far from the boundary? Questions: The idea of this paper is interesting and i would like to raise my rating if the authors can clarify my questions.
Summary: This paper proposes to use label smoothing to determine the labels of augmented samples. Is this a contradiction to the main motivation of using a smoothed label for augmented data? [Cons] -- The problem of adjusting labels for augmented data is indeed of interest for the community. Is this a contradiction to the main motivation of using a smoothed label for augmented data?
Summary: This paper shows that introducing an abstention class for out-of-distribution (OOD) works well for detecting it when the in-distribution dataset is CIFAR and TinyImageNet is available during training as an OOD dataset. Training with a large OOD dataset like [Hendrycks et al.] is not common, and the observation in this paper is limited to this setting. (2) The comparison is unfair, as authors didn't re-evaluate baselines in the same setting (they had to make it the same as much as possible) but just pasted numbers from original papers. Results on CIFAR-10 -> CIFAR-100, and CIFAR-100 -> CIFAR-10 would be good. E.g. one combo could be Places365 -> ImageNet. No conceptual reason for why the K+1-th method does better (I am still happy to vote to accept without this, but this would make the paper more compelling). Again, [Hendrycks et al.] considered a similar setting, but they proved the effectiveness of their method in image and natural language domains, with 7 in-distribution datasets and 3 large OOD datasets. I am not sure this observation is consistent in other settings, so I recommend to conduct more thorough experiments, as done in [Hendrycks et al.]. In fact, this was a question in my mind when I read Hendrycks et al last year. [Lee et al. (a)] Training confidence-calibrated classifiers for detecting out-of-distribution samples. In *CONF*, 2019. [Hsu et al.] Generalized ODIN: Detecting Out-of-distribution Image without Learning from Out-of-distribution Data.
Pros: The proposed method can predict how a continuous-time time series will evolve under a sequence of interventions. In light of this, instead it might be a better idea to provide some counterfactual bounds (Pearl, 2009) for the quantities of interest.
It shows that the variance of stochastic gradient is a decreasing function of minibatch size for linear regression and deep linear network. For a deep linear model, the result shows that the variance of gradient is a polynomial in 1/b with no constant term. Having a small total variance conditioned only on the initial point means that somehow the trajectories for different samplings cannot diverge too much. Given that the gradient is a high-dimensional vector and the "variance" is a matrix, it is not clear that what the meaning of "the variance is a decreasing function of minibatch size" is. Given that the gradient is a high-dimensional vector and the "variance" is a matrix, it is not clear that what the meaning of "the variance is a decreasing function of minibatch size" is.
The UniMP first employs graph Transformer networks to jointly propagate both feature and label information. Proposed Graph Transformer unifies feature and label propagation in conjunction to provide a better performance in semi-supervised node property classification task. [A] Gilmer, Justin, et al. "Neural Message Passing for Quantum Chemistry." ICML. Page 2: there are different -> they are different In addition, a masked label prediction strategy is proposed to reduce the negative influence of the label leakage problem. In [A], a unified model for neural message passing is already established, and the proposed model seems to be a special case of the neural message passing module in [A]. Minor Comments/Typos: Section 1: In addition, there are different between → In addition, there are differences between Section 4: To verified our model → To verify our model Page 2: there are different -> they are different In [A], a unified model for neural message passing is already established, and the proposed model seems to be a special case of the neural message passing module in [A].
Although the authors claimed that CNV-Net is the first tool to use a CNN to detect CNVs, this is not true. Page 2: there are different -> they are different
Then use GNNs to extract the hidden representation hu=GNN(Gu). Summary: The authors proposed to first extract a subgraph Gu for each node u. Without this study, it is hard to tell what is the novelty of this paper and whether the local clustering is useful. Without this study, it is hard to tell what is the novelty of this paper and whether the local clustering is useful. In this works => In this work The idea is to form local graph for each node using PPR-Nibble, a local clustering method proposed before, and then use transformer on top of the local graph as encoder for node classification and link prediction. What is the time complexity of this method? [Summary] In this paper, the authors study the connection between GNNs and local clustering, and find that short random-walks in GNNs have a high probability to be stuck at a local cluster.
Summary: The author extends generative models with multi-generators by restricting the generators to share weights and all bias to be regularized in order to enforce that the inverse maps of the generators can be represented by a single encoder. Is the quotient of this relation defined somewhere? Post-Rebuttal: Unfortunately, the authors neither did update their paper nor addresses my comments.
Building on these two types of factorization, the paper presents: (a) derivations of the entropy and KL-divergence for these policy factorizations; 2) sequential/autoregressive policies (an ordering of the sub-action spaces is assumed a priori and the sub-policies receive as input the state and the selected sub-actions for the preceding sub-action spaces). Also, the paper does not set a clear agenda for what would be interesting to see in the results; Is scalability to large action spaces being investigated (in which case, comparison with the non-factored baselines of PPO and SAC should be included)? Autoregressive critic of FSAC is the same as that in Metz et al. (2017) (also stated in the paper I believe). ########################################################################## Questions during the rebuttal period: In light of new related works together with those included in the paper, I believe the novelty of the paper currently is in developing the policy optimization updates for autoregressive policies. Update: After reading the other reviews and the responses, I have changed my score to 5: marginally below acceptance, due to the framing and related work issues, as discussed by R2 and R4. ########################################################################## I would be happy to revise my score post clarifications from the authors. Also, This splitting is referred to as "Factorization of Action Space". ########################################################################## Questions during the rebuttal period: In light of new related works together with those included in the paper, I believe the novelty of the paper currently is in developing the policy optimization updates for autoregressive policies.
This paper considers the problem of private sign recovery for sparse mean estimation and sparse linear regression in a distributed setting. Furthermore, the paper states that this is the first deterministic algorithm with a provable high-probability privacy guarantee. To me, this modification on differential privacy is very big, but it is not well discussed in the paper. Typos and minor comments: (1) Page 2: the definition of the supp(v) is not very clear. And this shows that it might be very easy to design deterministic algorithms under this new privacy notion.
This suggests that the key component in a deep neural network with RELU activations is the gating structure, which defines active subnetworks, as opposed to the values. This paper builds on recent work characterising deep neural networks in terms of Neural Tangent Kernels and Neural Path Features. I was not very familiar with the work on neural tangent kernels and encountered (Lakshminarayanan and Singh, NeurIPS 2020) for the first time when reviewing this paper. For this, I think the authors need to make concrete comparisons with methods that are deeply rooted in kernels such as GPs or BNNs. For instance, does using a particular composite kernel structure give you the same predictive performance as when using a GP? For this, I think the authors need to make concrete comparisons with methods that are deeply rooted in kernels such as GPs or BNNs. For instance, does using a particular composite kernel structure give you the same predictive performance as when using a GP? A recent paper (Lakshminarayanan and Singh, NeurIPS 2020) provided a new perspective on Neural Tangent Kernels for Gated Neural Networks, by decomposing the network into independent paths. Paper proposes and extension of neural path framework to include composite kernels which comprise of a) FC networks (Hadamard product of gram matrices), b) residual networks (sum of products of base kernels), and c) CNN max-pooling layer.
This paper proposes a CutMix variant where the mask is sampled by a low-pass filter. Both of mixup and cutmix are worse than baseline, which contradicts the existing results. Compared to mixup and cutmix, the improvement reported in Table 2 is marginal.
Can over-parameterization can be a factor for such poor generalization?
This paper provides new approximation theorems for a family of functions representable by hybrid quantum-classical circuits. Using a technique best on Taylor polynomial approximations, the paper finds that a large class of smooth functions can be approximated using O(log(1/\\epsilon)^(n/d)) quantum gates, qubits,  and classical width.
I find the construction proposed in the paper quite interesting. Overall, I think that the paper makes good contributions to the growing field of ML for communications. Minor comments: It seems that WBP is not defined (is it weighted BP?) The paper focuses on improving the computational complexity of permutation decoding. Still, the most important advantage is that it actually should not decrease significantly the efficiency, as the forward pass required during test could be run in parallel for all permutations, as the authors suggest. To the best of my knowledge, this is the first application of self-attention in ML for communications. Thanks to the possibility of freely generating training samples on these schemes, it is possible to achieve very satisfactory training for permutation embedding and classification. It is unclear how this attention looks between the permutation vectors, but in the end what matters is the embedding obtained, and how it captures the similarity between them, and also, I believe, some relations with the syndrome. In permutation decoding, one aims to decode a permutation of the received codeword in the hope that it will lead to successful decoding as compared to applying the decoding algorithm on the received codeword. page 2: "a self-attention model (introduced in Section 2)" should be "a self-attention model (described in Section 2)". However, except for some intuitive reasons it is not clear that the approach would have practical merit. ================================================================= [Main Weaknesses] The paper's main weakness is that it seems the motivations for choosing four different BCH codes (in Section 5) are not justified clearly. For example, Fig. 3 (a) contains the BP lower bound and ML bound. Instead of plotting the top k (>1) performance, it would be better to include the comparison of performance over the best existing decoding schemes (in terms of top 1 performance given a reasonable complexity). Decision, and key reasons Accept, after discussing and further elaborating some of the previous concerns. Unfortunately, it seems that the experiments were run on a very limited set of codes. How is the same node embedding v being used for all i in wi=ui+v? Is there not any other, more advanced, methods for selecting at least a subset of permutations?
Paper proposes Hybrid Discriminative Generative training of Energy based models (HDGE) which combines supervised and generative modeling by using a contrastive approximation of the energy based loss This yields a simple objective to optimize. This is the strength of this paper, and the community might be able to leverage the idea like this to extend the application of EBM to other domains in the future. To name a few, (1) As the authors write themselves, the approximation in eq (13) is crude. I remain my score of clear rejection.
Major points / suggestions for improvement above, I believe the experiments on synthetic data as they stand now are barely a "sanity-check" for the model. All in all, this represents an original contribution of relevance to the field that I wish to see published eventually. I would encourage the authors to show results pertaining larger models (e.g. ResNet-based architectures with > 10 layers).
Summary of Contributions The paper explores adversarial perturbations in deep RL, providing a new thread model where the perturbation is computed based on a single state. Paper Summary: This paper aims at discovering transferability of perturbations across different environments in RL. Summary of Contributions The paper explores adversarial perturbations in deep RL, providing a new thread model where the perturbation is computed based on a single state. The conclusions of this submission are unclear and questionable. I am hardly convinced by this statement and led by this statement, the proposed approach in this work. Equations 1 and 2 do not make sense. When we consider transferability in machine learning, we assume that there are something common to learn between the two domains.
In particular, the paper proposes a robust loss function and an algorithm for learning from complimentary labels. In particular, the paper proposes a robust loss function and an algorithm for learning from complimentary labels. I am unaware of this definition of robustness of a loss function as it seems very specific to the complementary label learning problem. Though conditions (10)/(20) are insightful for determining robustness, for a reader who is encountering them for the first time, it may help to intuitively explain the conditions. Comments: The paper addresses an important problem but it is written in a hurry which makes it hard to assess its contribution. However, in this paper it means if the loss function with ordinary and complementary labels has the same minimizer.
This paper proposes an approach that adaptively decides when to update the simulation policy, based on the difference between it and the current learned policy. I am not completely familiar with the literature on RL with low switching cost, but the proposed approach appears to be novel. Cons: I did not find the theoretical justification for the proposed approach to be very convincing for RL, since it is based on a construction in a simplified linear regression case. This is often detrimental for the applications considered, such as medicine, in which robustness is also desirable.
This paper studied a simplified image classification task with orthogonal non-overlapping patches and is learned by a 3-layer CNN. This relates the weight to the patterns in the dataset. The authors suggest a new property of convents where filters have large dot products with patterns occurring in images classified as 1 and small dot products with patterns appearing with images classified as 0. All patterns are assumed to be orthogonal to each other. We observe that the statistics of patterns in the training data govern the magnitude of the dot-product between learned pattern detectors and their detected patterns.
This paper proposes an algorithm called AdaMa for multi-agent reinforcement learning (MARL). This paper proposed AdaMa, which can automatically use adaptive learning rates for each agent in cooperative Multi-Agent Reinforcement Learning (MARL). Pros: The topic and idea of using adaptive learning rates to avoid hand-tuning are quite interesting and important. In Figure 3 (a), (b) and (d), AdaMa has similar performance with Fixed lr (fixed learning rate). However, the proposed method is not convincing in terms of the lack of larger-scale experiments or theoretical results.
This paper proposes a Bayesian optimization algorithm in the context of federated learning. For example, the convergence analysis for (U-)SVGD, even for the most simplified case, and compares with the existing work. --- post-rebuttal feedback --- The authors have addressed most of my concerns. Following the above summary, I will give my opinions regarding several aspects of this paper below. I can not recommend the acceptation of this work for the following reasons: The originality of method is low because it directly builds on top of two well-established approaches PVI and SVGD.
I found it easy to read. The paper was well written, and was to easy follow. I only list them as evidence to disprove the conclusion's assertion that "this paper is the first study showing that effective opponent modelling can be achieved without access to opponent observations (at execution time)", as that is definitely untrue. Recommendation and Justification: I think the paper should be accepted. I'm still in favour of accepting the paper. Negatives: The paper is sometimes inconsistent in its description of techniques that need opponent observations at training time versus execution time. If so, cite this (The MADDPG paper that is already cited for opponent algorithms?) The authors of this paper study opponent modelling in partially observable Markov games, following the centralised training, decentralised execution paradigm. It sounds like it from the text, but it wouldn't be useful for reward, so I'm guessing not? 1) an A2C implementation that observes last_reward and last_timestep to see if NOM (or LIOM (Act,Rew)) improves, or However, the authors appear unfamiliar with other opponent modeling work (I'm particularly familiar with the computer poker domain, although they cite two Ganzfried and Sandholm papers from that area) where there is a rich literature of opponent modelling being successfully used under these conditions (opponent observations needed only at training time, and never at execution). Could an LSTM learn that?
Response to the author feedback: We appreciate the authors for the extra effort to demonstrate the abiltiy of FLAP by adding more experimental results and discussions. Response to the author feedback: We appreciate the authors for the extra effort to demonstrate the abiltiy of FLAP by adding more experimental results and discussions. In this work this is restricted to tasks which share the same state and action space. Because of this difference, the method in this paper cannot be called RL^2 and it could be claimed that this paper explores a method that is not explored previously. There are many pieces of related work using shared embeddings to transfer between tasks that should be discussed. In Figure 1, the proposed method showed about -200 reward in Cheetah-Vel (hard) tasks. Recommendation I recommend rejecting this paper because it is not clear why "linear representation meta RL" is better in general.
Summary: The authors advocate for the use of Robustness curves, plotting the adversarial accuracy as a function of the size of the neighbourhood region of allowed perturbation. Cons: Overall, this paper is impressive. Similar architecture is used for the robustness curves in Figures 3 and 4. While I agree that you are going to get more information if you compute a full robustness curve than if you sample it at a bunch of points, I'm not convinced that it is worth the effort. The authors talk in the introduction about "recently proposed robustness curves" and cite a paper from 2020 for them, but it seems like those curves were already in use before that. As a result, it's hard to decouple the robustness curve from the attack that it used internally. The author argues that robustness for a specific epsilon may not be enough and suggests robustness curves as an alternative. However, I haven't seen any works on improving the robustness for all epsilon values globally. This would be a much cheaper solution (and is essentially what reporting experimental results for a few chosen eps achieves).
Synthetic experiments illustrate performance of the proposed procedure when the data is sampled from a topic model with varying degree of sparsity. Overall, I admit that the suggested algorithm is a sound method to construct the document representation. Questions I think the landmark documents are important for constructing representation. So it seems to me like the advantage of the generative model, the interpretability, is stripped away, and the model is repurposed for classification. And the authors explain the relatedness of the representation function and topics in a document. Using topic modeling as a tool to understand representation learning is interesting. I think it is hard to say that this is a fair comparison. Is it a errata in Lemma 1? In the beginning you say your approach is to use landmarks and the Direct variant is rather suddenly introduced in a later part without discussing the differences and implications in much detail.
This paper proposed a semi-supervised learning approach to improve the regression model trained on output-skewed data. This method contains an adversarial network that forces the regression output distribution to be similar to the assumed true label distribution. (1)     The paper assumes that the training data are often highly skewed (intentionally) but the true distribution of the output can be easily estimated or obtained. For instance, the examples discussed in Introduction appear to be the ones in which both labeled and unlabeled data are skewed. For example (Kim et al. 2020)? Issues: Section 3.2: "To be a useful feature for Rpost, latent vectors should be arranged in a similar way to p(y), which possesses information about how the labeled dataset is skewed." - p(y) is a distribution of labels right? Updates: I thank the authors for their response. How is the assumed true label distribution selected? (2)    The paper did not explain where the target distribution in the adversarial part of AAE comes from. Updates: I thank the authors for their response. I will keep my original score.
ii) Graph Neural Networks with Generated Parameters for Relation Extraction, In ACL'19 The authors propose a method for simultaneously learning the graph structure (or a graph generative model) and the parameters of a GNN for node classification. Overall, the paper is well written and easy to follow. But then in the next sentence you wrote that 80 and 89% of nodes are not directly connected to a labeled node for the standard benchmark graphs. In this case, creating the kNN graph is a discrete operation and it is not clear to me how to differentiate through such an operation. It seems bizarre that only LDS is adopted as the baseline in Table 2 since the codes and datasets are ready. [Relevance] The topic of GNNs has gained increasing attention recently such that a significant portion of the *CONF* community should be interested.
However, the advantage of (a) has not been empirically verified with ablation studies and (b) is already common nowadays. Sec 2.2: models -> model This is not true—the method still relies on continuous relaxation because of \\bar{\\alpha} in equation (4), and is still subject to discretization discrepancies due to the quantization function q.
pixels are selected by SSS, transmitted and classification is performed on another device. Summary stochastic subset selection (SSS) is a method to learn to compress a set D by selecting a subset Ds such that the loss of a task performed on Ds is as close as possible to the loss if the task had been performed on the original D. And why is there a period in the middle of the expression? (iii) Removing aspects of the models, such as removing r(D) as an input to ρ, or DC as an input to f.
Summary The paper studies a certain notion of spectral sparsification of directed graphs. mehtods. Also, for the general case of directed graphs which are not strongly connected, you should compare with existing sparsifiers for directed graphs but whose analysis requires them to be strongly connected. Authors propose a novel method to approximate a given directed graph with a´nother one (the sparsifier) which has fewer edges. In general I have doubts about fit to the venue; while *CONF* scope is broad and inclusive and spectral sparsification has certain potential connections to ML, this paper does not highlight any of them, and it is not entirely clear what it is attempting to achieve.
The auxiliary classifier is a binary classifier that discriminates training data versus background/noise data. This submission proposes a training strategy that leverages background/noise data to learn robust representations. This paper proposes a training method for classification, with the goal of training with less data. Experimental results show that the use of this strategy generally leads to improved performance. It seems that the most natural and meaningful task is where the auxiliary classifier is trained on all in-domain data, both labeled and unlabeled, while the main classifier is trained on a small number of labeled data. The experiments are not sufficient to support the claims: there is little results on training with less data; certain critical experiments are missing; some comparisons are not fair. The auxiliary classifier is designed to encourage the early layers to learn more meaningful features, and Section 3 supports this relation.
The writing is good. This paper proposes a new method for applying the TRUST-TECH method to the ensemble of deep neural networks (DNNs). Since it uses more budget, the performance should be higher, but it seems that FGE is not implemented properly. Furthermore, I believe that the method could be explained and analyzed a bit better. ########################################################################## Reasons for score: Overall, I vote for accepting.
To address this task, the paper proposes a method consisting of three steps: (1) detecting out-of-class samples in the unlabeled set, (2) assigning soft-labels to the detected out-of-class samples using class-conditional likelihoods from labeled data, and (3) using auxiliary batch normalization layers  to help mitigate the class distribution mismatch problem. The paper uses a contrastive representation learning paradigm to learn a feature encoder and a similarity measurement. Although results across multiple benchmark datasets report significant improvement over other SSL techniques these improvements could be artificial as other techniques have no way of handling out-of-class samples. ########################################################################## Summary: The paper proposes a new approach for open set semi-supervised learning, where there are unlabeled data from classes not in the labeled data. The learned encoder can encode the semantic information into the feature for both labeled and unlabeled data in an unsupervised way. Experiments are conducted on CIFAR-10, CIFAR-100, ImageNet datasets. I found the paper clearly written and easy to follow. Clarify: The preliminaries section clearly describes the setting of semi-supervised learning concerned in this paper and also clearly describes the contrastive representation learning. Again, this is not a compelling argument. While the setting considered in [a] (for metric learning problems) is a bit different from that concerned in this submission (for image classification tasks), the high-level idea (learning representations that can be used to describe unlabeled images with labels different from those in the training set) is very similar.
In short, this is not an algorithm that a practitioner would attempt to implement.
This paper studies decentralized gradient methods for training deep networks. Theory is provided for the case of synchronous symmetric averaging methods, and the paper is complemented with detailed experiments on CIFAR and tiny-ImageNet. This is a nice contribution to the growing literature on decentralized training for deep neural networks. Summary: This paper studies the problem of decentralized training where several computing units are used simultaneously to process the data, and computing units are assumed to be connected over a network. The authors identify the consensus distance as the key factor that affects the generalization performance of decentralized training. I have a few suggestions and comments, about which I look forward to hearing from the authors. Is there a cite for Lemma 4?,  there seems to be studied in the literature before. Reasons for score: I believe the paper is well written and the results are useful for the literature. update after rebuttal After reading the author's response, the authors stated that they indeed identify the optimization difficulty and consensus distance in theory, while only empirically justify its generalization on training performance. update after rebuttal After reading the author's response, the authors stated that they indeed identify the optimization difficulty and consensus distance in theory, while only empirically justify its generalization on training performance. Is it possible to show something similar in this setting?
This paper proposed a self-supervised learning method of 3D shape descriptors for 3D recognition through multi-view 2D image representation learning. Summary: This paper proposes a self-supervised learning framework for 3D object classification and retrieval based on multi-view representation, where a sub-task of transformation estimation is adopted as a regularizer. Summary of the Submission: This submission proposes a self-supervised learning scheme for 3D object recognition. Areas for improvement: -Firstly, the representation of the transformation that the author used in the paper is not well specified. Why not using a loss function that penalizes the amount of rotation? I am not sure why in the rebuttal, the authors claimed, "Their proposed method distinguishes from AET significantly in two aspects". I am not sure why the authors answered that "3D objects are unavailable at the testing stage." The proof of Autoencoding Variational Transformations for 3D data directly should not depend on the availability of 3D data. I am not sure why in the rebuttal, the authors claimed, "Their proposed method distinguishes from AET significantly in two aspects". For this question, I think the authors should prove the Transformation Equivariant Representations directly on a 3D object (point cloud, voxel, 3D mesh) instead of multi-view 2D images.
I would like to hear the authors' responses to make my decision. The paper can be seen as another proof-of-concept paper for acting based on a manual, but it should be noted that it is not the first one of its kind [1]. While the paper is clear and seems to be very accurately and correctly executed, I have concerns (which might be considered subjective) about the limited real-world impact of this kind of work. the use of the term validation here is confusing, it seems you are both interested in zero-shot (on test games) and transfer learning performance (which is referred to as validation)? More specifically: (1) The proposed model is a fairly straightforward application of self-attention to text, which has been similarly used (albeit with BiLSTMs) in Zhong et al 2020. NeurIPS 2019 workshop Summary This is a significantly improved extension of prior work in this area.
Instead of using validation accuracy that requires training, a score S is defined. Although I have significant concerns about the practicality of the method, I believe it establishes a sufficiently distinct direction for NAS research that could merit acceptance. I notice that the correlation (tau) value in Figure 3 is not high. How is this design choice (using data augmentations of the SAME image) related to the two motivations (flexible & invariant)? Why does this happen? Is it possible that the proposed method overfit to CIFAR-10?
In this paper, the authors propose a variant of FedAvg that not only produce the global training, but also a mixture of the local model and the global model, which is called personalized model. In this paper, the authors propose a variant of FedAvg that not only produce the global training, but also a mixture of the local model and the global model, which is called personalized model. (1), personalized model is a convex combination of two models. Your analysis is for a fixed mixing parameter, but since it is not possible to know it in advance, learning it from data seems to be more reasonable. The empirical study is not conducted carefully: Allowing for a separate local model for personalization increases the number of parameters which is not accounted for [1] Three Approaches for Personalization with Applications to Federated Learning
This paper proposes a policy architecture that embeds graph search within it. Weakness: i) The manuscript is missing very relevant pieces of works that should have been discussed in detail and included as baselines in the experimental results section. Overall, I think this is a very solid work, and I recommend acceptance. Savinov et al., Semi-Parametric Topological Memory for Navigation, *CONF* 2018 Thank you for the response and updates to the paper. [3] Learning latent dynamics for planning from pixels, Hafner et al. ICML-19. [4] A benchmark and evaluation for multi-task and meta reinforcement learning, You et al. CoRL 2019. [2] Learning Neural-Symbolic Descriptive Planning Models via Cube-Space Priors: The Voyage Home (to STRIPS), Asai and Muise IJCAI-20.
Overall The paper proposes a different approach compared to the currently-existing explanations for graph networks. It claims that other method leads to confounding association that (shorts, on, man), and (man, has, hand) are correlated with the prediction, rather than causing it. (4)) seems strange to me. If so, what are the results of the cluster-based method for w.r.t. contrastivity and sanity check? The proposed method now only considers the edge importance while other comparing methods consider the importance of edges, nodes, and features. It's better to start the "Task Description" section by something similar to "we define a graph of interest …". The reviewer believes the approach is better suited for graph networks, due to the feasibility arising from the structuredness of graphs. First, Eq. (1) and Eq. (3) do not guarantee to achieve the same graph, because Eq. The technical contribution may not be enough for *CONF* publication. The technical contribution may not be enough for *CONF* publication.
They propose a solution by exploiting the invariance property in the tasks. This paper proposes an approach to reducing the sample complexity in multi-task reinforcement learning using permutation invariant policies. In particular, they present an algorithm that exploits permutation invariance, study its theoretical properties, and propose examples where this property holds and their algorithm can be leveraged. I generally agree with the story, however, there are two major issues. I can understand this but not the def in the paper. Is it exponential or not? So sigma is a permutation of items in a set? However, the way paper defines it is not clear to me. Finally, what does this PI means in real-life? In this case it seems the set is the output of policy network. I dont understand the aim of this paper and unfortunately, the paper did not help me either. This is however already clearly pointed out in the paper and placed as future work, so this is somewhat fine to me.
I enjoyed reading it. This paper introduces a new method for computing the backward updates of a neural network called Direct Kolen-Pollack learning (DKP). Summary This work proposes an approach to update feedback weights in DFA using modification of kolen-pollack method, which helps in training deep CNN network. (2) In the experiments, the authors only compare the DKP with the DFA and BP. Therefore, I hope the authors can make it clear the main contributions of this work.
The authors then propose a relaxed definition of disentanglement and show that it can be realized by means of a shift operator in latent space. This paper studies the notion of disentanglement in a group representation theoretic setting. The insight is not new to me personally, but I can't find a reference that explains it and I think it is not widely understood, so I consider this an important contribution to the (very muddled) discourse on disentangling. It is not clear how this would be learned. This analysis culminates in a general impossibility theorem for this type of disentanglement.
Original Review: This paper describes a new type of regularization for the parameters of an autoencoder - one that forces the decoder to be an isometry. In the experimental part, the authors compare the merits of this approach on synthetically generated low dimensional manifolds in high dimensional ambient spaces, against other standard manifold learning algorithms, and show that the paper's method outperforms other method using a measure of distortion of triangle edges on a grid. It is noted that for a linear architecture, this gives PCA, therefore, this can be seen as a nonlinear PCA approach. The math formulation primarily sticks with a linear version of the autoencoder. p. 2 Manifold learning generalizeS p. 4 If not, how are the latent codes computed? The projection operator that is used to define the pseudoinverse of the encoder is not necessarily a function, since there could possibly be many points on the manifold that correspond to the same L2 distance from the point being projected. Maybe I am missing something, but would it be impossible to generate, say, a 50 dimensional manifold in 100 dimensions? For instance, can IAE be useful for semi-supervised learning (Like VAEs)? Maybe "AE's try to reconstruct"? Can the author provide some comments on this?
In the clustering phase, the aggregator uses a clustering technique to identifies the weight matrices that have been manipulated by the adversary. This paper suggests a new solution to protect FL models from backdoor attacks. Code is not provided, I can not see the reproducibility of this work. The author(s) have created many splendid terms to describe the modules used in this work, however, their implementation uses both clustering and median, which is very engineering and may not reliable with a different clustering algorithm or data set is severely unbalanced (just like the non-iid data sets among clients). Code is not provided, I can not see the reproducibility of this work. The author(s) have created many splendid terms to describe the modules used in this work, however, their implementation uses both clustering and median, which is very engineering and may not reliable with a different clustering algorithm or data set is severely unbalanced (just like the non-iid data sets among clients). The mathematical motivation of this paper is missing and this causes the impression of untrustedness on the model design. Clipping and noising are the means of eliminating weak manipulations. Some analysis and ablation experiments are needed. Code is not provided, I can not see the reproducibility of this work. Results are versatile, many comparison tables are provided cons: Whole article is not self-contained, feel the connections between modules are very loose The author(s) have created many splendid terms to describe the modules used in this work, however, their implementation uses both clustering and median, which is very engineering and may not reliable with a different clustering algorithm or data set is severely unbalanced (just like the non-iid data sets among clients). The mathematical motivation of this paper is missing and this causes the impression of untrustedness on the model design.
The technical details related to (iii) are interesting. (i) interpreting that the mathematical formulation of SDEs is directly comparable to the ML formulation of GANs, Still, I believe that there could be some improvements to do.
Summary: In this paper, an extension of nonnegative CP decomposition called hierarchical nonnegative CP decomposition (HNCPD) is proposed. Short summary: The paper introduces a promising new method, hierarchical nonnegative CP decomposition (HNCPD), as well as a training method for the HNCPD, neural NCPD, for topic modeling problems. SUMMARY: This paper presents a hierarchical nonnegative CP tensor decomposition method. The hierarchical nature of the method makes it possible to group the topics into supertopics in multiple steps. Several decomposition results of synthetic data, video data, and Twitter data are presented. It is not clear how the Standard NCPD in Section 3 is computed. In the experiments, do you use a combination of the loss functions in Equations (11) and (13) (e.g., C+E), or just one of them? Here, the true structure of chromatic interaction is hidden and we cannot observe it. In particular, in the discussion on approximation in Section 2.1, it is not clear if this idea is used in the implementation, which might make it difficult to replicate the results. A quantitative measure like the reconstruction loss would most likely be of value.- Sections 3.2 and 3.3 also lack a comparison to other methods. It seems like the authors combine existing ideas (hierarchical and neural NMF, NCPD) into a new method. \\argmin limitsS is not introduced. Further, it is not shown how the derivative of the argmin function with respect to
The paper proves a universal approximation theorem for equivariant maps by group convolutional networks in an extremely general setting. Universality is then proved for the generator by a fully connected network, and separately an approximation theorem of FCNs by CNNs is proved. See the comments below. Strong points: Important problem - invariant/equivariant models provide a very helpful inductive bias for many tasks on symmetric inputs. Universal approximation theorems are considered to be an important kind of result, and this paper proves a very general one for equivariant maps. The authors made a considerable effort to address my concerns. Having said that, I am still not sure that the paper is ready for publication in its current form. The condition (C1) in Theorem is not clear to this reviewer. Anyway, this proof should be provided in the paper or supplamentary. I think that the basic idea of this subsection can be written in a much simpler way. My main concern is still the accessibility/readability of the results in this paper, which I think can be further improved for the benefit of both the community and the authors (more accessible paper => more imapct). In Theorem 16: How  do we make sure the first layer can be seen as a generator? If this is true then how the FNN found from the universality result of FNN (e.g., Theorem 12 and 14) are guaranteed to satisfy this condition? Are these normal subgroups? Should HT be a strict subgroup of FS?
In this paper, the authors study the effect of weight decay across different optimizers. Summary In this paper the authors introduce the notion of stable weight decay. ============= Update avec rebutal and discussion with AC and reviewers. I think this paper has done a decent investigation on this topic. Comments and questions: I think the concept of weight decay rate and total weight decay should be explained better, and earlier in the paper. A minor point, in Eq 3, how did the authors arrive at −2t−1 in the superscript of weight decay rate, not −2t+1? Verifying the stable weight decay property is actually not optimal, because it is not isotropic. There is no need to give Definition 1 formally for Stable Weight Decay as that doesn't sound like a definition. For example, Statement 1 that says "Equation-1-based weight decay is unstable weight decay in the presence of learning rate scheduler." can be quickly summarized even from an intuitive sense without any derivation, which makes it trivial. Additionally, I am a little confused about the statement that the effect of weight decay can be interpreted as flattening the loss landscape of θ by a factor of (1−ηλ) per iteration and increase the learning rate by a factor of (1−ηλ)−2 per iteration. It would have been interesting to see the effect of AdamS on other type of tasks. We agreed that the methods is sound and likely to work better than AdamW, the proofs are not sufficient. However, the current theoretical analysis is not enough to support this conclusion. In particular, there is no theoretical justification that this is the case. In the draft, the authors can directly say constant or time-varying weight decay. The only way to prevent vt from going to zero is to have β2→1 (i.e. the previously mentioned delay going to infinity), but in that case v¯t won't go to zero neither. The language used is not precise at some points in the text. The paper main point then is to equate the learning rate in the weight decay coefficient by the effective learning rate and they show that this might be enough to bridge the gap between Adam and SGD. Even though some shallow analysis has been presented in the draft, it is not enough. Still,  I recommend acceptance. Remarks In the Introduction, talking about adaptive methods: "are a class of dominated methods to accelerate", I'm not sure what dominated means here.
This paper provide a method for high-order structure prediction problem. It is important to distinguish between the settings for which the proposed method and the existing work are designed for. In Definition 3, it looks like it is a vertex set, but in the time complexity analysis it becomes a number. Perhaps the experiment should show its advantage when dealing with much higher-order structure predictions rather than these simple cases.
The close correspondence shown between the accuracy in classification tasks and the entanglement entropy of the models (Figure 3) is interesting, and hints at the possibility of a compelling link between theoretical quantum many-body physics and practical considerations in ML. In other words, not only is the word-GTN removed, but the order of words is lost as well!
This paper proposes another variant of phrase-based MT for African languages, That being said, I strongly agree with the authors that neural machine translation of African low-resourced language is important. That being said, I strongly agree with the authors that neural machine translation of African low-resourced language is important. I think this paper can reasonably be rejected, but I'd like to give actionable of constructive criticism, since I do think the work on this low resource language is important for the NLP community.
This paper proposes a novel Gaussian mixture-based attention mechanism by incorporating the source (key) information, enabling a flexible representation of the Gaussian attention pattern with the well-described formulation. Summary: This paper introduces "source-aware" GMM attention and applies it to offline, online, long-form ASR. It would be good to provide this motivation earlier in the paper. Some of the concerns can be fixed, and some will need additional experiments. Or does the encoder use conventional "soft attention"? Is there a reason it was included?
Center-wise Local Image Mixture For Contrastive Representation Learning (iii) baseline + proposed positive sampling + CutMix, The method is easy to implement and reproduce. Results on linear classification using features learned in unsupervised way; in few-shot learning task (using 1% of available labels) on  ImageNet and in transfer learning on VOC object challenge show small but consistent improvement over state-of-the-art. Although the augmentation proposed is simple (in the good sense) and seems to work well (in some cases), I found that the paper somehow failed at motivating it, which I think it's important for a paper like this. - both k-means clustering and knn neighbors are computed, and then for a given anchor image x, and images x' that fall within the same cluster and are a knn neighbor (and additionally closer to the cluster center than And the contribution of this paper is applying CutMix in the context of contrastive learning, which is yet another augmentation among a huge variety of possibilities. Recommendation My initial recommendation is leaning towards reject. E.g. from 75.3 (SwAV) to 75.5 (proposed method) on linear classification on ResNet using features learned in unsupervised way; 82.6 (SwAV) to 82.8 (proposed method) in transfer learning on VOC object chanllenge. It would have been interesting to see what's the improvement that CLIM brings rather than a direct comparison with other methods. Recommendation My initial recommendation is leaning towards reject. (ii) baseline + proposed positive sampling,
They incorporate a variational approach to GCNs, as a novel architecture that iteratively refines the node labels and the graph. The main hesitation with this paper is the novelty of the proposed method. The paper is well written and clearly describes the proposed method. The paper is well written and clearly describes the proposed method. It seems the proposed method has many hyperparameters, such as p, epsilon in Eq. (9), S in Eq. (11). Could the authors provide the results of a similar analysis, at least for the models for which this is possible? Maybe we can obtain a perfect classification model by this way, but the embeddings are still failed to represent the property of each node, and they are useless to be applied to other tasks (e.g., anomaly detection). In addition to the AdaEdge, LDS and TO-GCN mentioned in the paper, other works, e.g., "Graph-Revised Convolutional Network" (ECML-PKDD 2020, arxiv: 1911.07123), "Deep Iterative and Adaptive Learning for Graph Neural Networks" (arxiv: 1912.07832), and "Graph Structure Learning for Robust Graph Neural Networks" (arxiv: 2005.10203), also study the same problem.
The paper studies "butterfly networks", where, a logarithmic number of linear layers with sparse connections resembling the butterfly structure of the FFT algorithm, along with linear layers in smaller dimensions are used to approximate linear layers in larger dimensions. It is motivated by the theoretical results involving the Fast Johnson Lindenstrauss Transform (FJLT). Specifically, the proposed method replaces a dense linear layer by a composition of three layers, which are smaller and can be computed faster by FJLT. And in the experiments, it seems that all the n are powers of 2 (except Tech).
The structure of the approach is to first pretrain the model on synthetic tasks that are designed around three principles of mathematical reasoning: deduction, induction, and abduction. They construct 3 synthetic datasets corresponding to 3 basic reasoning patterns: deduction, induction, and abduction. Then, any pretraining is "learning inductive bias." It would be great if the authors clarify more about "pretraining" and "inductive biases" in the next revision.
By this the authors claim to establish a relationship between these two approaches and Elastic Weight Consolidation, which approximates the diagonal of the Fisher. It shows that MAS and SI approximate the Absolute Fisher matrix. The paper is written well, with good detail and very good experiments. The paper is also written well, with an emphasis on good research practices. The accompanying experiments are crucial and well-conducted. Cons of paper I am not convinced that the minibatching that the authors suggest (both for SI as an approximation to the AF and for EWC in the last paragraph of Section 5) is correct ("Batch-EF"). For example, consider a full-batch calculation. Unifying these regularisation methods is great, and not obvious (particularly in the case of SI). So simply taking absolute instead of squared gradients and stating that this is "a natural variant" is not a sufficient basis for a paper, especially considering that the term has not appeared anywhere in the literature before as far as I could tell. 4 is not discussed later in the text, or in other words, if ω~(SI) is similar to ω(EWC), what about ω(SI)? To summarise, I think the authors need to more clearly explain and establish the impact of their work. In more recent versions, Pytorch also provides autograd functions for computing jacobians natively -- I'm not sure how efficiently they are implemented, but in any case the empirical comparison here needs to use an efficient, batched implementation for calculating the Fisher in order for it to be meaningful. The similarity alone is not enough to be a theoretical explanation for effectiveness. I do not know why, in this paper, the authors found that the two gave same results (Table 1); perhaps it only works for specific hyperparameters. In the github repo of MAS (it's not entirely clear from their paper), they seem to consider the function F to be the score for each class (i.e. the output of the last linear transformation), while in your paper your qX is the class probability (i.e. the softmax). I think these are vital parts of a proper theory. Overall evaluation It is hard for me to agree with this paper's fundamental motivation: a unified framework for regularization methods. Intuitively, this must affect the EF calculation in a bad way. So overall my recommendation is to reject the paper. ** POST DISCUSSION UPDATE ** Review summary I really like the majority of this paper.
This paper uses a reconstruction BLEU or BT BLEU [1] metric to compare the effect of the inside-model with that of cross-model, and finds that cross model translation has a lower back-translation effect, which shows that the diversity is enhanced. References: [1] Data Diversification: A Simple Strategy For Neural Machine Translation, Nguyen et al. [2] APE at Scale and its Implications on MT Evaluation Biases, Freitag et al. [3] On The Evaluation of Machine Translation Systems Trained With Back-Translation, Edunov et al. [4] Multilingual Denoising Pre-training for Neural Machine Translation, Liu et al. [5] Leveraging Monolingual Data with Self-Supervision for Multilingual Neural Machine Translation, Siddhant et al. [6] When Does Unsupervised Machine Translation Work?, Marchisio et al. In this paper, two unsupervised agents are utilized at cross-model by using the dual nature of the unsupervised machine translation model, in which forward translation of agent_1 is combined with the backward translation of agent_2, more synthetic translation pairs are obtained to train a new supervised machine translation model. This paper introduces a new component to the unsupervised machine translation framework called cross-model back-translated distillation. This paper describes a method to enhance unsupervised machine translation through data augmentation. The idea is pretty straight-forward, if not altogether intuitive, you begin by training two bidirectional (i.e.: they can translate source to target and target to source) unsupervised MT systems A and B. In general, the CBD method in this paper is a simple and effective data enhancement method to improve the performance of the model. I suggest that the author should use (y_s, x_t) data to train based on the (ott et al., 2018) model, and report the effect comparison (In my experiments, the second stage model implemented with fairseq trained only on (y_s, x_t) surpass both agents trained with XLM due to more efficient implementation in fairseq). In Appendix Summary: The paper proposes an additional stage of training for unsupervised NMT models utilizing synthetic data generated from multiple independently trained models. They can directly add the synthetic data decoded by cross model to continually train the original XLM model with a supervised translation objective (which is naturally supported in XLM from my experience), and report the effect comparison between them. In the training data (x_s, y_t), (z_s, y_t), (y_s, x_t), (y_s, z_t) for the second stage of CDB,  x_t, golden language sequences as translation target is stronger than synthetic language sequences (silver) as target. I think I would like to have seen more discussion of the highlighly related work in sections 5.3 and 5.4. I think I would like to have seen more discussion of the highlighly related work in sections 5.3 and 5.4.
It contributes a formula for the equivalent learning rate if the gradient step was to be taken on the unit sphere for SGD and Adam and shows an approximate equivalence between gradient steps and normalized gradient steps taken on the unit sphere. The AdamG* considered in the paper does not use element-wise learning rate. I believe the manuscript would benefit from major revisions to be of interest to the community and my initial recommendation is a rejection.
This paper begins with the empirical observation that adversarially trained models often exhibit a large different in clean (and robust) accuracies across different classes. More on this later. The paper proposes an algorithm, Fair Robust Learning (FRL), to address this issue. This paper begins with the empirical observation that adversarially trained models often exhibit a large different in clean (and robust) accuracies across different classes. If that is the case, it would be good to see that the observation may not happen in other settings. There were some points in the paper which I believe could be improved.
This paper studies online test for qualitative treatment tests. This paper proposed a powerful online sequential test which can efficiently detect qualitative treatment effects (QTE). === Contributions === This paper proposes a new framework for A/B testing in the frame of randomized online experiments. The authors propose a scalable online algorithm for Type 1 error control. This new framework enables testing whether qualitative treatment effects for some specific segment(s) of the tested population can be detected or not. The meaning of Eqs. (6) and (7) are very difficult to grasp
This paper proposes PABI (PAC-Bayesian Informativeness?), a way of measuring and predicting the usefulness of "incidental supervision signal" for a downstream classification task. PABI is proposed as a very general framework. In particular, when labeled data is only available in noisy or partial form, or over a different domain than the target test domain, this data may still be used to improve a classifier, but it's unclear how to tell which forms of incidental supervision will be most useful. Summary This paper proposes a unified measure for the informativeness of incidental signals (ie, not standard ground truth supervised labels) derived from the PAC-Bayesian theoretical framework. Mathematical developments of PABI are given for these cases, and experiments show that PABI is nicely positively correlated with the relative improvement that comes with various methods for integrating incidental supervision signal (including one which is developed as a side note by the authors). This paper provides several such methods, particularly focusing on "inductive" learning (from constraints or partial/noisy gold labels) or "transductive" learning (from complete gold labels on different input domains). In NER and QA tasks, they showed the strong correlation signals between PABI and the relative improvements for various incidental signals. This and other questions about the breadth of application of PABI are left for future work. In particular, it seems that in this case the approximation method proposed for transductive learning would indeed have to reduce to training a combined model. Recommendation (accept or reject) with one or two key reasons for this choice.
Search is a complex problem, and people designed various data structures to handle different kinds of search problems. At the end of section 3, after presentation of SSWR, it is not clear why we are minimizing for a search sequence generator G that is aggregated over database-query pairs (D,q) -- wouldn't we learn a data structure per database (as is done for data structures used for nearest-neighbor search)? At the end of section 3, after presentation of SSWR, it is not clear why we are minimizing for a search sequence generator G that is aggregated over database-query pairs (D,q) -- wouldn't we learn a data structure per database (as is done for data structures used for nearest-neighbor search)?
[Paper Weakness] The self-supervision between segmentation masks and detection bounding boxes is the main contribution. [Paper Weakness] The self-supervision between segmentation masks and detection bounding boxes is the main contribution. [Paper Weakness] The self-supervision between segmentation masks and detection bounding boxes is the main contribution. The self-supervised idea is interesting that uses the segmentation mask to get the pseudo bounding box label for object detection, which could ensure the consistency of object mask and bounding box. Although the self-supervised loss is intuitive, incorporating it into MONet is non-trivial and it does outperform MONet. Despite that such self-supervised works are hard to work on real scenes, this paper does have some merits. Clarification of Methods: How to learn mk in a self-supervise way is unclear? The experiments are limited to two toy datasets with a fixed number of simple objects (which must be known beforehand), which show no background interference and little occlusion. Post rebuttal comments: Thank you authors for the detailed response - I think some of of my concerns have been answered - the paper may be a valid contribution to the community and I am raising my score. Update: In general, I am happy with the authors' responses. This ablation is probably the single most important experiment present in the paper - I would want to see it reported on both datasets.
Finally, the manuscript is poorly written and needs to be largely reworked to be considered for publication. Strong and weak points of the paper Strong points Provided the novel time scaling analysis for the cross-entropy loss with many empirical validations.Weak points Most importantly, the updated theory section explains why small beta can be bad: it slows training. The analysis primarily concerns the initial/early phases of the training, or what the authors refer to as short times --- note to authors: I think there should be a better phrasing than using "short times" --- where τ is small. Rating Clarity: The authors should clarify which part corresponds to the previous work proposed or this work proposed I am leaning towards rejecting the paper.
Summary This work claims to address the problem of learning the structure of interactions between multiple point processes. p.2: of the model 'are'. Usually, a multi-dimensional / spatial poisson process is a single point process defined on RD, and a realization of that process is a collection of points in D-dimensional space. Each ti is the time of occurrence for the i-th event across D processes and T is the observation duration.
The paper proposes an efficient long-range convolution method for point clouds by using the non-uniform Fourier transform. Overall, the paper is clearly written with high quality. What could be the significance of this finding for a practical application is not discussed, therefore not made clear. What could be the significance of this finding for a practical application is not discussed, therefore not made clear. The method is demonstrated to be effective by a N-body problem. What could be the significance of this finding for a practical application is not discussed, therefore not made clear.
E is used as an input of DNN and Z is used as an additional feature of the input of the last layer. The paper proposes to separate the dominant factors and the residuals,  train the original DNN on residuals with a much faster SGD learning rate,  and then recombine with a shallow small NN learned on the dominant factors trained using its own (slower) learning rate. E is used as an input of DNN and Z is used as an additional feature of the input of the last layer. However, the dimensions of MNIST and CIFAR10 are not quite ultrahigh (28^2=784 and 32^2=1024). The baselines trained with vanilla SGD or other optimized (Adam, etc.) are not clearly explained. In terms of criticisms,  there is very limited scholarship of related ideas that have been used both for linear models and for DNNs, in particular (a) various factor-based models that already exist,  (b) preconditioning of linear systems,  (c) neural nets trained on some other sort of residuals The experiments are not very convincing. I think they are not converged, because the training and testing curve is perfectly smoothing without any fluctuations. All training comparisons are measured only as a function of wall-time. Many models in the chart are not fully converged. However, the dimensions of MNIST and CIFAR10 are not quite ultrahigh (28^2=784 and 32^2=1024).
This paper proposes a contrastive autoencoder approach that only requires small data to perform a multi-label classification on the long-tail problem. The naming is not intuitive, such as (SLpf,S(+S)Lpf). I think the paper requires another round of revision before it is ready for publication.
The paper proposed a learned variant of the well-known iterative Hessian sketch (IHS) method of Pilanci and Wainwright, for efficiently solving least-squares regression. It shows how such learned sketches can be used in two types of problems: Hessian sketching (Sec. 3) and Hessian regression (Sec. 4). SUMMARY: Sketching is a popular technique in numerical linear algebra for achieving various desirable properties (e.g., lower complexity, one pass methods). The present paper considers a particular kind of sketch for which the sketch matrix is learned from data. The paper proposed a learned variant of the well-known iterative Hessian sketch (IHS) method of Pilanci and Wainwright, for efficiently solving least-squares regression. It seems like learned sketching has not been used for Hessian sketching and regression before. While getting a learned variant for IHS is an interesting direction, the current theoretical contribution of this paper is only incremental, and most importantly, the reviewer is unconvinced for the practicality of the current approach. I like the paper, but there are a few issues that must be addressed before it can be published.
In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. The availability of good benchmarks stands to channel that interest and energy into improvements that matter. The availability of good benchmarks stands to channel that interest and energy into improvements that matter.
To improve the practical performance of meta-learning algorithms, this paper proposes two regularization terms that are motivated by two common assumptions in some recent theoretical work on meta-learning, namely [2] HOW TO TRAIN YOUR MAML, *CONF* 2019 The main motivation of this paper is based on the theoretical results of meta-learning. Summary: In this paper, the authors aim at bridging the gap between the practice and theory in meta-learning approaches. Results show that these regularization terms improve over vanilla meta-learning. Some results on few-shot learning benchmarks show the proposed method improves w.r.t. those baselines. Specifically, they propose two regularization terms to 1) capture the diversity of the tasks and 2) control the norm of the prediction layer, thereby satisfying the assumptions in meta-learning theory. ########################################################################## Summary: The paper reviews common assumptions made by recent theoretical analysis of meta-learning and applies them to meta-learning methods as regularization. (1) the optimal (linear) predictors cover the embedding space evenly, and Ref: [1] Andrei A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu, Simon Osindero, Raia Hadsell: Meta-Learning with Latent Embedding Optimization. Strength: The motivation of this paper is interesting, before proposing the methodology. The paper is well-organized and clearly written. Thus, I think the regularization proposed in this paper is known. *CONF* 2019 Above all, since the contribution and the technical details to calculate the subgradients are not clear to me, I have to currently recommend a weak reject.
In this paper, the authors proposed two graph pooling methods, i.e., Neural Pooling Method 1 and 2. 2).. The writing needs to be improved. Propose to perform graph representation learning with Neural Pooling. The writing can be improved, In the abstract and introduction, the author should describe the approach briefly and explain its characteristics including why it can handle variable number of nodes, invariant to isomorphic graph structures, capture information of all nodes, and especially why it can collect second-order statistics. The process in Equation (6) can be viewed as a weighted summation. This paper proposes two fully-connected layers based neural graph pooling methods for graph neural networks, named Neural Pooling Method 1 and Neural Pooling Method 2.
To the authors: was there anything that was surprising or not obvious to you? It's not clear to me that the agent "learns" a new skill, since there is only exploration, and no exploitation. Summary: This paper observes that in meta-RL (and evolutionary biology), sometimes it is advantageous to learn behaviors that adapt to the particular task, while other times not adapting to the task, and instead relying on a task-agnostic "hard-coded" behavior is sufficient. And it was not clear that this was one of the main takeaways of the paper, as these concepts do not appear anywhere else in the paper. This section also convincingly shows that existing meta-RL agents roughly learn the Bayes-optimal policy in this case. This paper provides an analysis of RNN-based meta learning approaches. learning. Then they train an RL^2 agent and verify that it behaves as expected in these regimes. Several times throughout the paper it is claimed that the work "investigates the interplay of  three considerations when designing meta-task distributions: The diversity of the task distribution, task complexity and training lifetime." I don't see how the first two are analyzed in this paper. It seems to me like exploration and learning are being conflated here. ----Update---- After reading all the other reviews and ensuing discussions, I maintain my original score.
The paper proposes an approach for handling noisy labels in predictive models without removing them. The above observation indicates that the proposed method do not work as expected if the training problem is solved appropriately. where m(⋅;θ) is a model and θ is its parameter. For this purpose, the authors considered adjusting the softmax prediction using an additional term α as follows: PC(i|x;θ)=exp⁡(mi(x;θ)+αi(x))∑jexp⁡(mj(x;θ)+αj(x))
Feedback Identification of causal effects in the presence of proxy variables for unobserved confounders is an important but subtle problem. Strong points: This work provides a simplified and yet still practically useful framework that leverages recent nonlinear ICA result to provide an identification result in the causal inference framework. Could the authors comment on this? Overall, I vote for reject.
This paper targets at alleviating this IR bottleneck by proposing hybrid-regressive translation (HRT), which combines AT and NAT in two stages. Experiments on two WMT translation tasks (four translation directions) demonstrate the effectiveness of HRT, which consistently accelerates decoding by >50% compared to the AT baseline and yields comparable or even better translation quality. I think this is an excellent investigation. What if you apply them to the baselines, like MP and semi-autoregressive model? This paper proposes a hybrid-regressive machine translation (HRT) approach—combining autoregressive (AT) and non-autoregressive (NAT) translation paradigms: it first uses an AT model to generate a "gappy" sketch (every other token in a sentence), and then applies a NAT model to fill in the gaps with a single pass.
The paper proposes a model for variable selection in Mixed Integer Programming (MIP) solvers. This approach has been used in recent works on learning to branch. Is there a reason for that ? p.4 Equation 4: I do not see the point of introducing a Lagrangian relaxation here. p.7 Table 1: I suggest that you group FSB and RPB together, since they can not be compared to the other methods in terms of number of nodes (unfair node counting). However, I remain concerned about the experimental setup in the paper, and therefore my final recommendation is still rejection.
This paper proposes ProxylessKD method from a novel perspective of knowledge distillation. The paper proposes a knowledge distillation method for face recognition, which inherits the teacher's classifier as the student's classifier and then optimizes the student model with advanced loss functions. The paper is well organized and well written. In ablation, how would the number of teachers influence the student performance? Strength: The proposed method is simple and easy to implement. It considers the situation of single teacher model and multiple teacher models. Would the comparison of using student model for extracting both template and query feature be possible? Current experiments lack the comparison to the state-of-the-art methods, i.e. ArcFace and CosFace.
In ablation, how would the number of teachers influence the student performance? Would the comparison of using student model for extracting both template and query feature be possible? (Note that currently it only shows up to e=0.4.) In addition, I think it would be better to put all other assumptions (if any) on the noise model in the Theorem. This paper formulates a framework for reinforcement learning and behavior cloning from weak supervisions (i.e., noisy rewards or imperfect expert demonstration).
Five different models are evaluated on three (partially novel) benchmarks, providing a unifying perspective on the relative performance of these models. The results are not entirely conclusive, in that there is no clear best model, and their relative quality varies with datasets and metrics. Overall, this paper is interesting in setting up a benchmark for unsupervised object representations which is a very important problem in computer vision, reinforcement learning, etc. It is good to combine both in one paper. In particular: the dataset associated with the benchmark are mostly based on existing works - they might be appropriate for evaluating this task, but the level of contribution is a bit limited; The paper is actually very well written and tries to answer the question of how various unsupervised learning of object-centric representations to on controlled tasks (synthetic datasets). Given the cons and specifically on not a clear actionable suggestion on how to improve models and no analysis beyond synthetic datasets I am leaning towards a rating of below acceptance threshold. Given the increasing need for such analysis papers, and the competent execution, I recommend acceptance.
The paper proposes a federated learning framework using a mixture of experts to trade-off the local model and the global model in a federated learning setting. The paper proposed a novel personalized federated learning method using a mixture of global and local models. Step 3 is to train a personalized local model by mixing local and global models. The only novelty part of the method is to apply the mixture-of-experts (Jacobs et al., 1991) method to combine the local and global models. Step 3 is to train a personalized local model by mixing local and global models. Suggestions I encourage the authors to do a deeper analysis and a better experimental design.
This paper proposes a method for generating policies in cooperative games, using a neighbourhood-based factorisation of reward, and an iterative algorithm which independently updates policies based on neighbour policies and then propagates the policy to neighbours using function space embedding. Is it exact? What are the complete set of parameters? And it (2) requires agents have access to the global states. What makes this principled? This would seem to need a clear statemen Is it exact? What are the complete set of parameters? It is a little bit unclear what assumptions are required for all the theoretical and experimental claims of this paper. J is a loss: which one? The cited PRL article (Levine 2018) seems to retain this standard use of optimal: it uses a distribution over trajectories with an equation similar to here (a softmax over accumulated trajectory rewards), and makes use of the property that trajectories corresponding to an optimal policy have maximum probability in that distribution. One of the claimed contributions is this is principled method. Is this the future accumulated reward given the current state and selected action? eta and kappa might be described elsewhere, but it would be helpful to reference where. Following that definition, this proposition wouldn't be true, so it seems like it needs more explanation, or more careful wording. What makes this principled? This would seem to need a clear statement: what are the exact assumptions, and what precisely is the quality of the output? Despite being in the appendix, the algorithm is less than half a page, and doesn't explain the variables.
It is straightforward to think that the joint optimization of quantization step size for weight and activation would result in better quantization results. I have to lower the score. Summary: The paper studies the problem of Post-Training Quantization of NNs, where no fine-tuning is performed to quantize the model. Page 7: an significant advantage -> a significant advantage good performance. clear presentation. easy to read and follow Also, it seems that the "per-channel" quantization method is utilized in this work, but the formulation in (2) seems to be for "per-layer" optimization. It is not clear which of the pipeline options (light, advanced?) include what kinds of techniques. It is immediately not clear if the lower reported accuracy is due to the weaker FP32 baseline used or if it is an inherent problem with the method (most probably it is the former but it would be to show this). "MAC operations." -> acronym not previously introduced (unless mistaken) CONS The organization of the paper can and should be easily improved (see below). how B>= Ck^2/(HW) is derived for the convolution case?) BOPS proposed by (https://arxiv.org/pdf/2005.07093.pdf) is a good metric to measure the total reduction in computations for mixed precision quantization. The experiment of Fig.1  should be introduced with some level of detail (there is none outside the caption). This is a good result but please note that other work in the literature (arxiv:2001.00281) reports 72.91% for INT8 quantization of MobileNetV2 (this comparison is actually missing from the paper). "and [is] much less prone to over-fitting" There is no clear explanation of how AdaQuant increases the generality of the quantized model, and the discussion about the sample size (B) is hard to understand (why there's infinite solution when B << N? What is the definition of "compression ratio"? Also, it seems that the "per-channel" quantization method is utilized in this work, but the formulation in (2) seems to be for "per-layer" optimization.
It proposes to use Hamiltonian Monte-Carlo (HMC) to sample the next states (instead of IID samples) and matrix completion to learn a low-rank Q matrix. This work focuses on dynamic programming in the tabular setting. Do Fig.2(a) to (c) correspond to the same (optimal) actions? More descriptions about the ocean sampling problem would be helpful for the readers to understand the task.
I found this to be an interesting work that provided a non-trivial insight, backed it up with clear and easy-to-follow theory and demonstrated their observations held on some medium-scale experiments. My recommendation: I am not an active member of the GAN community so I am more than willing to accept if my recommendation goes against more senior folks who work in that field. Also, for eq. (7), technically the optimal discriminator is only uniquely defined at the real data points (see Sinn & Rawat, AISTATS 2018) because the GAN is trained on a finite sample. They are unreadable unless zoomed in very far on a screen. Since a near 20-point increase in FID can be achieved with a few tweaks to the NS-GAN objective (SN-GAN), I am left wondering if the presented improvement from the MM-NSAT objective will vanish once those improvements are applied or if it will still hold. Sect. 2.4 on "MM-GAN Interaction with ADAM" is not very mathematically rigorous and relies primarily on an assumption that the value of the logits of the discriminator approaches the optimum linearly. It sheds light on the weaknesses of the log -D variant of GANs. Weaknesses: Paper title is broader than what the paper shows - the proposes explanation only applies to GANs with the log -D generator objective and does not apply to other GAN variants, e.g.: original GAN (with cross-entropy generator objective), WGAN, LSGAN etc. I would present all of the results in Figure 8 in a table instead. So technically the paper's claim on the discovery of new modes cannot be justified by "g(x) ≈ 0 ⇒ 1 − D_p(x) ≈ 0", because D_p(x) could take on any value at locations other than the data points. Strong areas: I am a very big fan of work that questions standard assumptions that are taken almost as fact within our community. Similarly, on pg. 4, in the paragraph below eq. It is unclear how the number of samples from O in the minibatch could cause a difference between MM-GAN and NS-GAN - this observation is true for both MM-GAN and NS-GAN! This model uses the NS-GAN objective (to my knowledge) so, I am confused as to why the authors did not simply replicate their setup If the experimental setup was more in line with prior work and the same trend in results held, then I would be more likely to recommend acceptance of this paper.
======== I keep the score after reading the rebuttal / author comments. I thank the authors to conduct a lot of additional experiments. ======== I keep the score after reading the rebuttal / author comments. This is trivial to calculate in MiniGrid (as it's given by default) but it is not accessible in more complicated settings (e.g., what about a procedurally generated robot arm manipulation task?). This is trivial to calculate in MiniGrid (as it's given by default) but it is not accessible in more complicated settings (e.g., what about a procedurally generated robot arm manipulation task?).
The authors explore cases where e is known or not and come up with some algorithms that draw connections between recent work on domain generalization, specifically invariant risk minimization (Arjovsky et al 2019) and fairness. The authors explore cases where e is known or not and come up with some algorithms that draw connections between recent work on domain generalization, specifically invariant risk minimization (Arjovsky et al 2019) and fairness. Cons: The paper lacks a clear theoretical motivation for the specific optimization objective that the authors end up using (eq 3). Thanks for the revisions made to the theoretical results. Overall, I'm able to see what the authors are trying to get at with this example, but unfortunately the revisions aren't sufficient to address all of my concerns regarding the theoretical results. I still find parts of the discussion in Appendix F to be unclear. Strength: (1) The connection between domain generalization and algorithmic fairness shown by the paper is interesting.
They are rated by annotators on a spectrum from bad to excellent, and segmentation masks are collected from human annotators for the "worst" images. They demonstrate improved performance relative to a batch of competing models which are not updated using this procedure. Weakly-supervised labeling is more practical for segmentation; and (2) extending to active training/tuning, leveraging the selected hard examples to improve the segmentation model for multiple rounds. This is particularly relevant in high-stakes environments when failure in rare cases can have a disproportionate impact (e.g., autonomous vehicles, healthcare, etc.). The dataset in question is selected to be hard (as far as I understand), so it is not surprising that the methods perform worse on it and does not say much about generalization. That is, they consist of examples that the proposed segmentation model disagrees with the "competing" models the most on. "indicating that many images in T(1) are able to falsify both the target model ft...", the images are not really falsifying the model. Comparing against models which are not updated, in particular when it's clear that none of them generalize, is a weak baseline that could likely be outperformed by far simpler uses of the external data. The dataset in question is selected to be hard (as far as I understand), so it is not surprising that the methods perform worse on it and does not say much about generalization.
The dataset in question is selected to be hard (as far as I understand), so it is not surprising that the methods perform worse on it and does not say much about generalization. I would feel confident to implement this approach myself. I'm open to adjust my recommendation, assuming these concerns are sufficiently discussed in the paper and additional ablation is conducted.
The pre-trained representations and policies can be used for RL from pixels, obtaining faster convergence and higher end scores than the considered baselines in both DMControl and Atari. (1) as reward also? SUMMARY The paper proposes a method to simultaneously learn effective representations and efficient exploration in a reward-free context. The learned representations are unlikely to be useful for observations that are out of the pre-training distribution, so it is desirable to perform representation learning on data that is representative of the full state space. This casts some doubts on the actor-critic procedure APT employs to optimize the rewards. This casts some doubts on the actor-critic procedure APT employs to optimize the rewards.
The attention heads of the model focus on different dependency based masks for training. The model is trained end-to-end on masked language modeling (MLM). Following previous work, the distances yield constituency parse while the heights, in conjunction with the constituency parse yield the dependency tree. In the central equations (4) and (5), it is difficult to reason what it means for a word to be higher than the all the boundaries in a constituent. STRENGTHS The observation that dependencies can be recovered from syntactic heights given constituents is insightful and motivates a natural joint parsing algorithm (Algorithm 1). I think it's confusing to use i in both head_i and {head_i}, because i is (I think) being used as an index which is iterated over. Or is it supposed to be calling some other function that's not part of this algorithm? The model is trained for masked language modeling (MLM) and evaluated via MLM on held-out data and its ability to induce constituency and dependency trees. Updates after discussion/revision period: It appears that the paper has improved. However, the changes appear to be so substantial that the paper is now essentially a different paper which would require a new review process. Unfortunately, however, the current submission needs a lot of work before it will be ready for publication.
This paper discusses an approach to perform importance sampling by reviewing performance over past batches and suggesting future batches. This work presents an interesting exploration of learning optimal data sampling probability. First I will comment on the listed contributions: • To our best knowledge, we are the first to propose to directly learn a robust sampling schedule from the data themselves without any human prior or condition on the dataset. l    This paper is well organized and written. From this description I believe this paper has done it before: "CASED: Curriculum Adaptive Sampling for Extreme Data Imbalance". This method is comprised of exploration step and exploitation step which are conducted alternatively. If so this does not seem sufficient to confirm that this method works because the data you sample from is always the same. It is not clear to me what the intuition of P(x) is. It seems that very small margins are observed in comparison with random exploration. However, the empirical validation seems finished in rush and not sufficient. To address the issue of optimizing high-dimensional sampling hyper-parameter in data sampling and release the requirement of prior knowledge from current methods, the authors introduce a searching-based method named AutoSampling.
CN is a twin invention that randomly swaps the mean and variance statistics of features of two channels. Selfnorm recalibrates style in features to reduce texture sensitivity. Pros It is great news to the field that such simple recipes introduce gains in the performances. Under this terminology, I find it hard to agree that texture is not content. What is the effect of location for SN in a CNN (equivalent analysis for CN is presented in Tab4)? Under this terminology, I find it hard to agree that texture is not content. I do observe a few improvements introduced by the two modules here and there, but I can't forgo the impression that these are only selected highlights that comply with the authors' arguments. .  Section  . .  Data  . .  Arch  . .  Evaluation  . .  Baselines  . .  Authors' methods  . .  Tab1  . .  CIFAR  . .  4 archs  . .  mCE,CleanAcc  . .  Cutout,Mixup,Cutmix,AA,Advtr,AugMix  . .  SNCN, SNCN+AugMix .  Fig2  . .  CIFAR  . .  28-2WideResNet  . .  mCE,CleanAcc  . .  WA,RA  . .  CN .  Fig4  . .  CIFAR  . .  40-2WideResNet  . .  mCE  . .  VanillaModel  . .  SN,CN .  Tab4  . .  CIFAR  . .  40-2WideResNet  . .  mCE  . .  VanillaModel  . . CN .  Tab5  . .  CIFAR  . .  40-2WideResNet  . .  mCE  . .  VanillaModel  . . SN,CN,SNCN,SNCN+Crop,SNCN+Crop+CR .  Tab2  . .  ImageNet  . .  ResNet50 . .  mCE,CleanAcc  . .  PU,AA,MaxBlur,SIN,AugMix  . . CN,SN,SNCN+AugMix CA is also a unit that is inserted in the ResNet block so that it's interesting to have an experimental comparison as well. Recommendation As it is right now I think the paper has to be rejected because the write up is just too chaotic and vague. Conversely I felt the paper would profit from more figures and visualizations (e.g. Figure 7).
This paper is concerned with 3D molecule learning. They propose a collection of existing and new datasets (curated from existing datasets). The authors argue that these datasets will serve as a stepping stone for machine learning researchers interested in developing methods for atomistic learning and rapidly advance this field. This is a strong point for this paper. In QM9, N-Gram XGB (See table 2 from [2]), performs very well (top 1 performance on 9 out of 12 tasks). 2) earlier attempts at making use of 3D information have often found that it did not improve performance (see Swamidass et al. (2005) or Azencott et al. (2007)), either because of the aforementioned incompleteness or because the methods were not up to par. Suggestions I feel that it would be interesting to have a more detailed discussion on why the atom-level data improves performance on each task. While it is true that most current techniques rely mostly on 2D (for small molecules) or 1D (for large molecules) representations, it is not for lack of trying to incorporate 3D information, but because What information is provided in the different data sets (a single conformation? In addition, although some authors have already used "atomistic machine learning" in the context of chemoinformatics (see Schütt et al. (2018)), the term "atomistic learning" is already often used in opposition to "holistic learning" in education. This is obviously essential to the paper and I would feel more comfortable accepting a version of the paper that includes this information (possibly with URLs withdrawn if there is a concern about maintaining the review process blind). My overall recommendation is a weak accept.
At the core of this paper, the authors argue that the effective gradient flow (grad norm from only activate model weight dimensions) is an effective indicator on the model accuracy attained by sparse training. I also would like to make sure that my point is not misunderstood when I said that the sparse model requires twice as many parameters to be stored (the value and the index),  compared to the dense model.
The authors propose an algorithm to select radar return regions that potentially contain objects inside. While it is generally a great idea to guide the selection of radar regions to be sampled at a higher rate the paper is very application-focused and lacks novelty in its method. It's not clear that the dataset used in this paper. It's not clear that the dataset used in this paper. The author(s) show experimental results on Oxford Radar RobotCar dataset. Overall, I think the paper is not good enough to be accepted by *CONF*.
Strengths: The paper focuses on the important problem of exploiting weakly labeled video data, by exploiting its structure, for example by recovering temporal structure in an autoencoder fashion. For example, a "concept" in the paper is actually an "event", not a "concept". Introducing a two-level hierarchy into concept learning is also not new. The introduction explaining demonstrations in a robotics scenario does not feel related to the content of the paper. This is a bit of bias. Final recommendation Overall, I believe the paper as it stands is not ready to be presented to *CONF* and I recommend a rejection. This paper addresses a relatively new topic to learn the hierarchical concepts in videos and commentary in an unsupervised manner. The pros of this paper include: The task setting of this paper is important and applicable. For example: Regeneration of low level concepts from high level concepts: what are we expecting from a network that moves from a "high in the hierarchy" concept to a "low in the hierarchy" concept? (last line of page 4 -- I suggest adding equation numbers). This is, the idea of hierarchy would disappear, but this idea is not used in the experiments anyway. I am not convinced this metric provides a faithful assessment of the capability of the model.
(2) The meaning of n and T are not formally defined. That is, the number of edges connected to one node is the same for all nodes. Update The authors' response addresses some concerns, and I would like to keep the initial scores. (8) The authors use multiple variables to denote the number of nodes, including n, P and m. Recommendation: Weak reject. As of the current version, the proofs need to be improved. Below are some comments and questions. For (14) and (19), use rλ2≤r2λ22 to get rid of the first order term. define T (global number of edge updates) and H (number of local updates in between edge communication); where and when quantization is applied and why it helps in reducing communication complexity in the main text. The H2 term in Theorem 4.1 and 4.2 may not be good enough. This bound however stands for the average of all models obtained at each global step t, meaning that it is not necessarily a tight bound for the second moment of the last obtained model, which is the bound we are ultimately interested in. Further questions: Is it possible to merge Section I with Theorem 4.1 or show the proof? It would be also interesting to report communication complexities, with and without quantization, and compare them to state-of-the-art methods. This is not suggested in general. Optional improvements: It may be better to remove some small terms to make rate more clearer. The benefit of local steps is not clear. For example, For Theorem 4.1, use 1≤r2λ22 can get rid of the constant 1. The 1st equation in Section E has an extra '-'. The 3rd equation in Section D, h~is also depends on g~i, which is not reflected. However, I believe the authors can improve in the next version.
This being said, the application of LSH in this context is (seemingly) new, and the two basic similarity measures are interesting. For (14) and (19), use rλ2≤r2λ22 to get rid of the first order term.
Questions during rebuttal period I think several questions have already been raised in the rest of my review. Thanks for the discussions. The primary reason for my score increase is discovering that the power of the framework is finding a representation that is quick at exploiting new opponents. After seeing the authors' responses to my concerns, I am open to raising my score. Science, 2019. After rebuttal: The responses address most of my main concerns, and I have increased the rating from 5 to 6. Re-reading after the paper update, I am worried that a significant portion of readers may fall into the same trap despite the authors' additional edits. Summary The paper suggests a novel framework (coined L2E) to learn a policy that is optimized to adapt quickly (and exploit) a wide range of unknown opponents. The various opponents that are used for the training of this base policy are generated in two steps. Questions during rebuttal period I think several questions have already been raised in the rest of my review.
The paper propose a new meta-learning algorithm ADML that uses adversarial and clean examples during meta-training (both for train-train and train-test). Recommendation: rejection Motivation: While the idea of adversarial meta-training is well motivated and generally sound, the specific method in this paper is primarily proposed and not really explored in any depth. Originality In principle, combining gradient-based meta-learning such as MAML with adversarial training (similar to the proposed baseline MAML-AD) is a natural fit that does not require novel research. Experimental setup: you mention that 15 adversarial attack mechanisms where leveraged in the experiments, but the tables suggests that you only use 1 (at a time)? Perhaps the least obvious choice in ADML is to swap clean and adversarial data in the meta-update. Recommendation and reason: Weak Reject.
The paper proposes the problem of fully offline meta-RL. This paper proposes a method for "fully" offline meta-RL. Summary: This paper makes two contributions: Formalizing the offline meta-RL paradigm, where we meta-train on pre-collected (offline) data for several RL tasks and adapt to a new task with a small amount of data. The paper also proposes a method for the fully offline meta-RL problem based on the MAML method. Strong Points The paper is well written and the problem setting is well explained. Overall I like the paper and think the problem setting is very interesting, and I like the proposed method. The proposed problem setting is timely and relevant for the metaRL community. For now I give a score of 5, but I'm open to increase this and look forward to the author's response! In experiments they show that this outperforms the offline metaRL method PEARL, and combining multi-task offline RL with AWR in a naive way. The question is how the setup in this paper is sensible and important at all? based on this definition, can't we just randomly initialize the algorithm and do a meta-test and get the same results? Can you please comment on the worse performance of MACAW on this more realistic benchmark for meta-RL? others. Why this is the case? For instance, IMO figure 1 should contain multiple examples of the same "RL task" that are different "offline RL tasks"; i.e. learning to swim using guidance from a 3-year-old and learning to swim using guidance from Michael Phelps. It may be fine to first introduce the correct general version and then say something like "it may be useful to assume each RL task is given by an expert of roughly the same characteristics", i.e. we can assume behavior policy is constant across tasks.
Summary of the paper: The authors analyze the effect of sources of uncertainty on neural network performance. Positives: The paper offers some interesting revelations such as : all sources of uncertainty have similar effects, which is surprising as the authors note, and hence a valuable insight. The empirical analysis is systematic and the two main results are thought provoking and interesting: 1) Different sources of nondeterminism (such as random initialization, data augmentation, data shuffling, etc.) causes similar levels of variability (based on standard deviation and correlation metrics), and The relationships between various sources and the graphs describing their dependencies have to be analyzed in determining the sources that need to be adjusted for in determining causal effects. For example, a WideResNet-28x10 can give approximately 95% test accuracy for CIFAR-10 and has a much larger capacity than the ResNet-14. Or are there no such sources? ######################################## Recommendation: Overall I lean towards rejection.
The problem of scaling transformers to longer sequences is an important one since transformers cannot deal otherwise with long sequences due to their quadratic complexity. There is a missing link between the theory (and motivation arising from it) and the best-performing implementation (AFT-softmax). The evaluation shows that it can reach the performance of a vanilla transformer in most of the examined tasks while having fewer memory requirements in general. (5) Recent studies have shown that it is possible to speed up inference time using efficient transformers (see above).
======================== Paper Summary: This paper proposes a new form of multi-head attention. This paper analyzes the multi-head attention in transformers and suggests to use collaboration instead of concatenation of multiple heads. It is that suspicious that collaborative MHA takes 18% less time in practical since it requires many factors e.g., GPU kernel fusion. Overall, the paper is well motivated and provides a deep analysis of redundancy of the multi-head attention. Therefore, I can not consider this as a contribution and think that this part is misleading for a reader. If we take a closer look, in case of Dk^=768, the performance on the large tasks (e.g. MNLI) dropped significantly from 84.1 to 83.4 in terms of accuracy, and its improvement is from small tasks (e.g. RTE). It is better to have a deeper analysis and explanation. While the paper does not provide such comparison, it is clear from the results that the simple head pruning is likely to be superior (and is simpler implementation-wise). Weaknesses (main) While the main contribution is a more efficient attention layer without a significant drop in performance, this claim is not supported empirically. I think you need to modify the things you highlight, and with proper discussion it would be much better. I think now this part is not misleading and can be of interest. Overall recommendation Overall, I can not recommend accepting this paper. In the current state, I think it is ok :)
This paper presents a method to combine step-based exploration with trajectory-based exploration (in the form of action-space noise and parameters-space noise) in continuous MDPs, which is scalable to deep RL methods. There exists a prior work that bridges a gap between the two exploration methods for linear policies, and this paper generalizes the prior work for various deep RL methods: on-policy (A2C, PPO) and off-policy (SAC). Originality: As far as I know, the proposed technique is novel in the literature of undirected exploration. For on-policy methods (A2C, PPO), the proposed method has large performance gain on Mujoco tasks. For SAC, the proposed method is not much effective and it even degrades the performance of the HalfCheetah task. Is the proposed method sensitive to these hyper-parameter choices? But for the three bullet points in section 1, the first point of "Generalizing Step-based and Trajectory-based Exploration" should not be one of the main contributions of this paper, because this paper follows the formulation of policy in van Hoof et al. (2017) and the latter proposed the generalized exploration connecting step-based and trajectory-based exploration. Assessment This work explores an important problem in RL and proposes a promising method that would be of interest to many in the community, and I think it would be a valuable contribution to *CONF*.
In this paper, the authors address main limitations of Normalizing Flows (NFs) method for estimation of density functions on manifolds. In relation to the above, it may be good to have a comparison experiment with denoising auto-encoder and VAE. This is a pure question, is it possible to know the dimensions of the manifold through this technique? Can you give some way to test it in practice?
This needs to be clarified. This needs to be clarified. Strengths of this work: The key idea of this work is to decouple the search of network topology and the search of operators.
Moreover, if the TD error is a bound (which I think isn't with neural networks as I discuss in the next point) on the empirical EVB, can't I just drastically overestimate Q-values and get a larger empirical EVB value to be super high and prioritize on those examples? Agreed that PER is a reasonable choice, and it can upper bound the EIB and EVB metrics (i have issues with this too, more on this next), it just seems to me that the paper doesn't make any convincing claim for why this helps us understand why PER works. I think that if the paper showed more evidence of zooming out and thinking deeply about the core problem, this would be an excellent paper. A careful read of the paper for proper grammar, making sure the right propositions are used and that there are no missing words in sentences would help the flow and readability of the paper greatly.
Page 8: "eg" should be "e.g." Summary: The paper provides an interesting algorithm for tensor PCA, which is based on trace invariants. The authors provide a detection algorithm (Algorithm 1) and a recovery algorithm (Algorithm 2), as well as the corresponding phases. The authors claim that: 1) they "build tractable algorithms with polynomial complexity", "a detection algorithm linear in time"; 2) the algorithms are very suitable for parallel architectures; 3) an improvement of the state of the art for the symmetric tensor PCA experimentally. The problem consists of recovering a (single-spike/multiple orthogonal spikes) tensor corrupted by a Gaussian noise tensor. What are the matrices here? I am not able to follow the proofs in this paper due to missing definitions of terms and notations. In Theorem 5, what are the intermediate graphs/matrices? This is what is implicitly being used in the proofs? What is the setup here: what are the v's, how many iterations of tensor power method are applied, how many MC replicates are run to produce the error bars, what is the y-axis, what are the runtimes here, what is Random in Figure 6?
They further provide an algorithm for enforcing fairness on these invisible demographics using this context set. They assume access to a "context set," which is an additional unlabeled dataset that does contain the invisible demographic categories of interest. The two zero-shot settings presented in this paper are both very interesting, and the paper did a good job decomposing the two scenarios in the methods and experimental section. It's useful to see a comparison between their clustering + balancing + disentangling method and the baseline methods of ZSF, which has balancing + disentangling but no clustering, and ZSF + bal. This seems to be a prerequisite for the disentangle algorithm to perform well. In ICML'19. For a situation where the sensitive attributes are missing, there are several works, including Is this the set of elements from \\mathcal{Y} that are contained in the training set? #Minor comments and questions In the experiments, for colored-MNIST, a comparable portion for each quadrant is retained for the context dataset, have you tried different retained portions and how does that affect clustering quality? Overall, my recommendation is 5: Marginally below acceptance threshold.
In this paper, the authors propose Sandwich Affine strategy to separate the affine layer in BN into one shared sandwich affine layer, cascaded by several parallel independent affine layers. (2)What is the difference between the searched architectures by using BN, CCBN and SaBN? It seems to me that the paper organization is poor. It may be that the reparameterization provided by SaBN yields the optimization trajectories that lead to better-generalizing solutions, but it is not explained in the paper whether, or why, this happens. What is the difference of the architecture parameters (i.e. alpha) learned by BN and SaBN?
This paper proposes an extension of the RL as Inference framework, and demonstrates how to use it to express an object-centric RL model and train it on simple environments. The authors propose a framework for joint perception and control as inference (PCI) to combine perception and control for the case of POMDPs. It is certainly a good idea to work out an approach in its full generality, but some of the components taking up space in the presented derivation are immediately cut in the experiments section (like the DKL(π || p(at∣a<t) term), so you might as well present a simplified version of the result that focuses on the method actually used. Is it that feature layer that buys performance or a deeper interactions through the joint model they propose such that the actions resolve uncertainty about objectness in a nontrivial way they would not if used in a pipeline that doe snot perform joint inference. (2018). Variational inference for data-efficient model learning in pomdps. However, this paper is promising and I look forward to seeing it mature. Would it generalize to other environments? (2020). Making sense of reinforcement learning and probabilistic inference. Decision I think the paper is borderline, and I tend towards rejecting it in its current form.
The proposed framework combines conditional computation (exploiting extra information available about the problem data) with a task specific neural architecture. U-Net" and "Fully Cond. U-Net" is. Tables 1 and 2, (overall) IoU score on transfer set for "U-Net + GN": There is probably a small typo what concerns the values "63.71" (table 1) and "63.79" (table 2). U-Net" and "Fully Cond. U-Net" is.
