2018-610	This paper analyzes the role of skip connections with respect to generalization in recent architectures such as ResNets or DenseNets.	abstract
2018-610	The authors perform an analysis of the performance of ResNets and DenseNets under data scarcity constraints and noisy training samples.	abstract
2018-610	They also run some experiments assessing the importance of the number of skip connections in such networks.	abstract
2018-610	The presentation of the paper could be significantly improved.	weakness
2018-610	The motivation is difficult to grasp and the contributions do not seem compelling.	weakness
2018-610	My main concern is about the contribution of the paper.	weakness
2018-610	The hypothesis that skip connections ease the training and improve the generalization has already been highlighted in the ResNet and DenseNet paper, see e.g. [a]. [a] https://arxiv.org/pdf/1603.05027.pdf	weakness
2018-610	Moreover, the literature review is very limited.	weakness
2018-610	Although there is a vast existing literature on ResNets, DenseNets and, more generally, skip connections, the paper only references 4 papers.	weakness
2018-610	Many relevant papers could be referenced in the introduction as examples of successes in computer vision tasks,  identity mapping initialization, recent interpretations of ResNets/DensetNets, etc.	weakness
2018-610	The title suggests that the analysis is performed on DenseNet architectures, but experiments focus on comparing both ResNets and DenseNets to sequential convolutional networks and assessing the importance of skip connections.	weakness
2018-610	In section 3.1. (1st paragraph) proposes adding noise to groundtruth labels; however, in section 3.1.2,.	weakness
2018-610	it would seem that noise is added by changing the input images (by setting some pixel channels to 0).	weakness
2018-610	Could the authors clarify that?	suggestion
2018-610	Wouldn't the noise added to the groundtruth act as a regularizer?	suggestion
2018-610	In section 4, the paper claims to investigate the role of skip connections in vision tasks.	abstract
2018-610	However, experiments are performed on MNIST, CIFAR100, a curve fitting problem and a presumably synthetic 2D classification problem.	abstract
2018-610	Performing the analysis on computer vision datasets such as ImageNet would be more compelling to back the statement in section 4.	suggestion
2018-610	The ms analyses a number of simulations how skip connections effect the generalization of different network architectures.	abstract
2018-610	The experiments are somewhat interesting but they appear rather preliminary.	weakness
2018-610	To indeed show the claims made, error bars in the graphs would be necessary as well will more careful and more generic analysis.	weakness
2018-610	In addition clear hypotheses should be stated.	weakness
2018-610	The fact that some behaviour is seen in MNIST or CIFAR in the simulations does not permit conclusion for other data sets.	weakness
2018-610	Typically extensive teacher student simulations are required to validly make points.	weakness
2018-610	Also formally the paper is not in good shape.	weakness
2018-610	The paper studies the effect of different network structures (plain CNN, ResNet and DenseNet).	abstract
2018-610	This is an interesting line of research to pursue, however, it gives an impression that a large amount of recent work in this direction has not been considered by the authors.	weakness
2018-610	The paper contains ONLY 4 references.	weakness
2018-610	Some references that might be useful to consider in the paper: - K. Greff et. al.	misc
2018-610	Highway and Residual Networks learn Unrolled Iterative Estimation.	misc
2018-610	- C. Zang et. al. UNDERSTANDING DEEP LEARNING REQUIRES RETHINKING GENERALIZATION	misc
2018-610	- Q. Liao el. al. Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex	misc
2018-610	- A. Veit et. al. Residual Networks Behave Like Ensembles of Relatively Shallow Networks	misc
2018-610	- K. He at. Al Identity Mappings in Deep Residual Networks	misc
2018-610	The writing and the structure of the paper could be significantly improved.	weakness
2018-610	From the paper, it is difficult to understand the contributions.	weakness
2018-610	From the ones listed in Section 1, it seems that most of the contributions were shown in the original ResNet and DenseNet papers.	weakness
2018-610	Given, questionable contribution and a lack of relevant citations, it is difficult to recommend for acceptance of the paper.	decision
2018-610	Other issues: Section 2: "Skip connection ….	weakness
2018-610	overcome the overfitting", could the authors comment on this a bit more or point to relevant citation?	weakness
2018-610	Section 2: "We increase the number of skip connections from 0 to 28", it is not clear to me how this is done.	weakness
2018-610	Section 3.1.1 "deep Linear model", what the authors mean with this?	weakness
2018-610	Multiple layers without a nonlinearity?	weakness
2018-610	Is it the same as Cascade Net?	weakness
2018-610	Section 3.2 From the data description, it is not clear how the training data was obtained.	weakness
2018-610	Could the authors provide more details on this?	weakness
2018-610	Section 3.2 "…, only 3 of them are chosen to be displayed…", how the selection process was done?	weakness
2018-610	Section 3.2 "Instead of showing every layer's output we exhibit the 3th, 5th, 7th, 9th, 11th, 13th and the final layer's output", according to the description in Fig. 7 we should be able to see 7 columns, this description does not correspond to Fig. 7.	weakness
2018-610	Section 4 "This paper investigates how skip connections works in vision tasks…" I do not find experiments with vision datasets in the paper.	weakness
2018-610	In order to claim this, I would encourage the authors to run tests on a CV benchmark dataset (e.	suggestion
2018-610	g. ImageNet)	misc

2018-752	In the paper, the author tried to address the training issue of SSL-GANs. Arguing that the main problem is the gradients vanishing, it proposed a co-training framework which combining the Wasserstein GAN training.	abstract
2018-752	The experiments were executed on MNIST and CIFAR-10.	abstract
2018-752	I think the paper made two strong claims, which are not reasonable for me: firstly, it argued that this is the first work to address training issue of SSL-GANs.	weakness
2018-752	Actually, the Fisher GAN paper [Youssef et al., 2017] proposed the "New Parametrization of the Critic" for SSL and showed it was very stable.	weakness
2018-752	In [Abhishek at al., 2017], the author also addressed how to make the SSL-GANs stable, following the improved GANs paper idea.	weakness
2018-752	Secondly, it made an impression that the author thought the main issue of SSL-GANs is the gradient vanishing.	weakness
2018-752	Following the paper [Zihang et al., 2017], it is hard to make claim like this.	weakness
2018-752	The co-training framework is not so novel for me, which combined the Wasserstein loss and general GAN loss.	weakness
2018-752	Meanwhile, the experimental results are not solid.	weakness
2018-752	The baselines listed are not the state-of-the-art.	weakness
2018-752	I suggested that the author should compare with some very recent ones, such as [Youssef et al., 2017], [Zihang et al., 2017], [Abhishek et al., 2017], [Jeff et al., 2016].	suggestion
2018-752	* Summary * The paper addresses the instability of GAN training.	abstract
2018-752	More precisely, the authors aim at improving the stability of the semi-supervised version of GANs presented in [1] (IGAN for short) .	abstract
2018-752	The paper presents a novel architecture for training adversarial networks in a semi-supervised settings (Algorithm 1).	abstract
2018-752	It further presents two theoretical results --- one (Theorem 2.1) showing that the generator's gradient vanish for IGAN, and the second (Theorem 3.1) showing that the proposed algorithm does not suffer this behaviour.	abstract
2018-752	Finally, experiments are provided (for MNIST and CIFAR10), which are meant to support empirically the claimed improved stability of the proposed method compared to the previous GAN implementations (including IGAN).	abstract
2018-752	I need to say the paper is poorly written and not properly polished.	weakness
2018-752	Among many other things: (1) It refers to non-existent results in other papers.	weakness
2018-752	Eq 2 is said to follow [1], meanwhile the objectives are totally different: the current paper seems to use the l2 loss, while Salimans et al. use the cross-entropy;	weakness
2018-752	(2) Does not introduce notations in statements of theorems (Jθ in Theorem 2.1?) and provides unreadable proofs in appendix (proof of Theorem 2.1 is a sequence of inequalities involving the undefined notations with no explanations).	weakness
2018-752	In short, it is very hard to asses whether the proposed theoretical results are valid;	weakness
2018-752	(3) Does not motivate, discuss, or comment the architecture of the proposed method at all (see Section 3).	weakness
2018-752	Finally, in the experimental section it is unclear how exactly the authors measure the stability of training.	weakness
2018-752	The authors write "unexpectedly high error rates and poor generate image quality" (page 5), however, these things sounds very subjective and the authors never introduce a concrete metric.	weakness
2018-752	The authors only report "0 fails", "one or two out of 10 runs fail" etc.	weakness
2018-752	Moreover, for CIFAR10 it seems the authors make conclusions based only on 3 independent runs (page 6).	weakness
2018-752	[1] Salimans et al, Improved Techniques for Training GANs, 2016 Summary of paper and review: The paper presents the instability issue of training GANs for semi-supervised learning.	abstract
2018-752	Then, they propose to essentially utilize a wgan for semi-supervised learning.	abstract
2018-752	The novelty of the paper is minor, since similar approaches have been done before.	weakness
2018-752	The analysis is poor, the text seems to contain mistakes, and the results don't seem to indicate any advantage or promise of the proposed algorithm.	weakness
2018-752	Detailed comments: - Unless I'm grossly mistaken the loss function (2) is clearly wrong.	weakness
2018-752	There is a cross-entropy term used by Salimans et al. clearly missing.	weakness
2018-752	- As well, if equation (4) is referring to feature matching, the expectation should be inside the norm and not outside (this amounts to matching random specific random fake examples to specific random real examples, an imbalanced form of MMD).	weakness
2018-752	- Theorem 2.1 is an almost literal rewrite of Theorem 2.4 of [1], without proper attribution.	weakness
2018-752	Furthermore, Theorem 2.1 is not sufficient to demonstrate existence of this issues.	weakness
2018-752	This is why [1] provides an extensive batch of targeted experiments to verify this assumptions.	weakness
2018-752	Analogous experiments are clearly missing.	weakness
2018-752	A detailed analysis of these assumptions and its implications are missing.	weakness
2018-752	- In section 3, the authors propose a minor variation of the Improved GAN approach by using a wgan on the unsupervised part of the loss.	weakness
2018-752	Remarkably similar algorithms (where the two discriminators are two separate heads) to this have been done before (see for example, [2], but other approaches exist after that, see for examples papers citing [2]).	weakness
2018-752	- Theorem 3.1 is a trivial consequence of Theorem 3 from WGAN.	weakness
2018-752	- The experiments leave much to be desired.	weakness
2018-752	It is widely known that MNIST is a bad benchmark at this point, and that no signal can be established from a minor success in this dataset.	weakness
2018-752	Furthermore, the results in CIFAR don't seem to bring any advantage, considering the .1% difference in accuracy is 1/100 of chance in this dataset.	weakness
2018-752	[1]: Arjovsky & Bottou, Towards Principled Methods for Training Generative Adversarial Networks, *CONF* 2017	misc
2018-752	[2]: Mroueh & Sercu, Goel, McGan: Mean and Covariance Feature Matching GAN, ICML 2017	misc

2018-775	This paper shows that an idealized version of stochastic gradient descent converges when learning autoencoders with ReLu non-linearities under strong sparsity assumptions.	abstract
2018-775	Convergence rates are also determined.	abstract
2018-775	The result is another one in the emerging line of proving convergence guarantees for non-convex optimization problems arising in machine learning, and aims to explain certain phenomena experienced in practice.	abstract
2018-775	The paper is generally nicely written, providing intuitions, but there are several typos (both in the text and in the math, e.g., missing indices), which should also be corrected.	weakness
2018-775	On the negative side, while the proof technique in general looks plausible, there seem to be some mistakes in the derivations, which must be corrected before the paper can be accepted.	decision
2018-775	Also, the assumptions in the in the paper seem quite restrictive, and their implications are not discussed thoroughly.	weakness
2018-775	The assumptions are the following: 1. The input data is coming from a mixture distribution, in the form x=w_I + eps, where {w_1,...,w_k} is a collection of unit vectors, I is uniform in {1,...,K}, eps is some noise (independent for each sample).	weakness
2018-775	2. The maximum norm of the noise is O(1/k).	weakness
2018-775	3. The number n of hidden neurons in the autoencoder is Omega(k) (this is not explicitly assumed but is necessary to make the probability of "incorrect" initialization small as well as the results to hold).	weakness
2018-775	Under these assumptions it is shown that the weights of the autoencoder converge to the centers {w_1,...,w_k} (i.e., for any i the autoencoder has at least one weight converging to w_i).	weakness
2018-775	The rate of convergence depends on the coherence of the vectors w_i: the less coherent they are the faster the convergence is.	weakness
2018-775	First notice that some assumptions are missing from the main statement, as the error probability delta is certainly connected to the probability of incorrect initialization: when n=1<k, the convergence result clearly cannot hold.	weakness
2018-775	This comes from the mistake that in Theorem 3 you state the bound for the probability P(F^\\infty) instead of the conditional probability P(F^\\infty|E_o) (this is present everywhere in the proof).	weakness
2018-775	Theorem 3 should also depend on delta_o, which is used in the definition of F^\\infty.	weakness
2018-775	Theorem 2 also seems incorrect.	weakness
2018-775	Intuitively, the question is why it cannot happen that two neurons contribute to reproducing a given w_i, and so neither of their weights converge to w_i: E.g., assuming that {w_1,...,w_k,w_1',...,w_k'} form an orthogonal system and the noise is 0, the weight matrix of size n=2k defined as W_{2i-1,*}^T = 1/sqrt{2}(w_i + w'_i) and W_{2i,*}^T=1/sqrt{2}(w_i	weakness
2018-775	- w'_i), i \\in [k], with 0 bias can exactly recover any x=w_i (indeed, W_{2j-1,*} x= W_{2j,*} x = 1/sqrt{2}, while the other products are 0, and so W^T W x = W^T W w_j = 1/sqrt{2}(W_{2j-1,*}+W_{2j,*})^T = w_j).	weakness
2018-775	Then SGD does not change the weights and hence cannot recover the original weights {w_i }, in particular, it cannot increase the coherence in any step, contradicting Theorem 2.	weakness
2018-775	This counterexample can be extended even to the situation when k>d, as--in fact--we only need that the existence of a single j such that w_j and w'_j are orthogonal and also orthogonal to the other basis vectors.	weakness
2018-775	The assumptions are also very strange in the sense that the norm of the noise is bounded by O(1/k), thus the more modes the input distribution has the more separable they become.	weakness
2018-775	What motivates this scaling? Furthermore, the parameters of the algorithm for which the convergence is claimed heavily depend on the problem parameters, which are not known.	weakness
2018-775	How can you instantiate the algorithm then (accepting the ideal definition of b)?	weakness
2018-775	What are the consequences? Given the above, at this point I cannot recommend the paper for acceptance.	decision
2018-775	However, if the above problems are resolved, I would be very happy to see the paper at the conference.	decision
2018-775	Other comments ----------------------- - Add a short derivation why the weights of the autoencoder should converge to the w_i.	suggestion
2018-775	- Definition 3: C_j is not defined in the main text.	weakness
2018-775	- While it is mentioned multiple times that the interesting regime is d<n, this is actually never used, nor needed (personally, I have never seen such an autoencoder--please give some references).	weakness
2018-775	What is really needed is n>k, which is natural if one wants to preserve the information, and also k>d for a rich family of distributions.	weakness
2018-775	- The area of the spherical cap is well understood (up to multiplicative constants), and better bounds than yours are readily available: with a cap of height 1-t, for sqrt{2/d}<t<1, the relative surface of the cap is between P/6 and P/2 where	weakness
2018-775	P=1/(t \\sqrt{d}) (1-t^2)^{(d-1)/2}; see, e.g., A.	misc
2018-775	Brieden, P. Gritzmann, R. Kannan, V. Klee, L. Lovasz, and M. Simonovits.	misc
2018-775	Deterministic and randomized polynomial-time approximation of radii.	misc
2018-775	Mathematika. A Journal of Pure and Applied Mathematics, 48(1-2):63–105, 2001.	misc
2018-775	- The notation section should be brought forward (or referred the fist time the notation is actually used).	weakness
2018-775	- Instead of unit spherical Gaussian you could simply say uniform distribution on the unit sphere	weakness
2018-775	- While Algorithm 1 is called "norm-controlled SGD training," it does not control the norm at all.	weakness
2018-775	The paper considers training single-hidden-layer auto-encoders, using stochastic gradient descent, for data generated from a noisy sparse dictionary model.	abstract
2018-775	The main result shows that under suitable conditions, the algorithm is likely to recover the ground-truth parameters.	abstract
2018-775	Although non-convex dictionary learning has been extensively studied for linear models, extending such convergence results to nonlinear models is interesting, and the result (if true) would be quite nice.	strength
2018-775	Unfortunately (and unless I missed something), there appears to be a crucial bug in the argument, which requires that random initialization lead to dictionary elements sufficiently close to the ground truth.	weakness
2018-775	Specifically, definition 1 and lemma 1 give a bound on the success probability, which is exponentially small in the dimension d (as it should, since it essentially bounds the probability that an O(1)-norm random vector has \\Omega(1) inner product with some fixed unit vector).	weakness
2018-775	However, the d exponent disappears when the lemma is used to prove the main theorem (bottom of pg.	weakness
2018-775	10), as well as in the theorem statement, making it seem that the success probability is large.	weakness
2018-775	Of course, a result which holds with exponentially small probability is not very interesting.	weakness
2018-775	I should also say that I did not check the rest of the proof carefully.	weakness
2018-775	A few relatively more minor issues: - The paper makes the strong assumption that the data is generated from a 1-sparse dictionary model.	weakness
2018-775	In other words, each data point is simply a randomly-chosen dictionary element, plus zero-mean noise.	weakness
2018-775	With this model, dictionary learning is quite easy and could be solved directly by other methods (although I see the value of analyzing specifically the behavior of SGD on auto-encoders).	weakness
2018-775	- To make things go through, the paper makes a non-trivial assumption on how the bias terms are updated (not quite according to SGD).	weakness
2018-775	But unless I'm missing something, a bias term isn't even needed to learn in their model, so wouldn't it be simpler and more natural to just assume that the auto-encoder doesn't have a bias term (i.e., x-> W's(Wx))?.	weakness
2018-775	The authors study the convergence of a procedure for learning an autoencoder with a ReLu non-linearity.	abstract
2018-775	The procedure is akin to stochastic gradient descent, with some parameters updated at each iteration in a manner that performs optimization with respect to the population risk.	abstract
2018-775	The autoencoders that they study tie the weights of the decoder to the weights of the encoder, which is a common practice.	weakness
2018-775	There are no bias terms in the decoder, however.	weakness
2018-775	I do not see where they motivate this restriction, and it seems to limit the usefulness of the bias terms in the encoder.	weakness
2018-775	Their analysis is with respect to a mixture model.	weakness
2018-775	This is described in the abstract as a sparse dictionary model, which it is, I guess.	weakness
2018-775	They assume that the gaussians are very well separated.	weakness
2018-775	The statement of Theorem says that it concerns Algorithm 1.	weakness
2018-775	The description of Algorithm 1 describes a procedure, with an aside that describes a "version used in the analysis".	weakness
2018-775	They write in the text that the rows of W^t are projected onto a ball of radius c in each update, but this is not included in the description of Algorithm 1.	weakness
2018-775	The statement of Theorem 1	weakness
2018-775	includes the condition that all rows of W^t are always equal to c, but this may not be consistent with the updates given in Algorithm 1.	weakness
2018-775	My best guess is that they intend of the rows of W^t to be normalized after each update (which is different than projecting onto the ball of radius c).	weakness
2018-775	This aspect of their procedure seems restrict its applicability.	weakness
2018-775	Successful initialization looks like a very strong condition to me, something that will occur exponentially rarely, as a function of d.	weakness
2018-775	(See Fact 10 of "Agnostically learning halfspaces", by Kalai, et al.)	misc
2018-775	For each row of W^*, the probability that any one row of W^o will be close enough is exponentially small, so exponentially many rows are needed for the probability that any row is close enough to be, say, 1/2.	weakness
2018-775	I don't see anything in the conditions of Theorem 1	weakness
2018-775	that says that n is large relative to d, so it seems like its claim includes the case where k and n are constants, like 5.	weakness
2018-775	But, in this case, it seems like the claim of the probability of successful initialization cannot be correct when d is large.	weakness
2018-775	It looks like, after "successful initialization", especially given the strong separation condition, the model as already	weakness
2018-775	"got it". In particular, the effect of the ReLUs seems to be limited in this regime.	weakness
2018-775	I have some other concerns about correctness, but I do not think that the paper can be accepted even if they are unfounded.	ac_disagreement
2018-775	The exposition is uneven. They tell us that W^T is the transpose of W, but do not indicate that 1_{a^t (x') > 0} is a componentwise indicator function, and that x' 1_{a^t (x') > 0} is its componentwise product with x' (if this is correct).	weakness

2018-909	The manuscript proposes to estimate the number of components in SVD by comparing the eigenvalues to those obtained on bootstrapped version of the input.	abstract
2018-909	The paper has numerous flaws and is clearly below acceptance threshold for any scientific forum.	decision
2018-909	Some of the more obvious issues, each alone sufficient for rejection, include: 1. Discrepancy between motivation and actual work.	weakness
2018-909	The method is specifically about determining the rank of a matrix, but the authors motivate it with way too general and vague relationships, such as "determining the number of nodes in neural networks".	weakness
2018-909	Somewhat oddly, the problem is highlighted to be of interest in supervised problems even though one would expect it to be much more important in unsupervised ones.	strength
2018-909	2. Complete lack of details for related work.	weakness
2018-909	Methods such as PA and MAP are described with vague one-sentences summaries that tell nothing about how they actually work.	weakness
2018-909	There would have been ample space to provide the mathematical formulations.	weakness
2018-909	3. No technical contribution. The proposed method is trivial variant of randomised testing, described with single sentence "Bootstrapped samples R_B are simply generated through random sampling with replacement of the values of R." with literally no attempt of providing any sort of justification why this kind of random sampling would be good for the proposed task or what kind of assumptions it builds on.	weakness
2018-909	4. Poor experiments using really tiny artificial data sets, reported in unprofessional manner (visual style in plots changes from figure to figure, tables report irrelevant numbers in hard-to-read format etc).	weakness
2018-909	No real improvement over the somewhat random choice of comparison methods that do not even represent the techniques people would typically use for this problem.	weakness
2018-909	The authors propose the use of bootstrapping the data (random sampling entries with replacement) to form surrogate data for which they can evaluate the singular value spectrum of the SVD of the matrix to the singular values of the bootstrapped data, thereby determining the number of latent dimensions in PCA by the point in which the singular values are no greater than the bootstrapped sampled values.	weakness
2018-909	The procedure is contrasted to some existing methods for determining the number of latent components and found to perform similarly to another procedure based on bootstrapping correlation matrices, the PA procedure.	weakness
2018-909	Pros: Determining the number of components is an important problem that the authors here address.	strength
2018-909	Cons: I find the paper poorly written and the methodology not sufficiently rooted in the existing literature.	weakness
2018-909	There are many approaches to determining the number of latent components in PCA that needs to be discussed and constrasted including: Cross-validation: http://scholar.google.dk/scholar_url?url=http%3A%2F%2Fwww.academia.edu%2Fdownload%2F43416804%2FGeneralizable_Patterns_in_Neuroimaging_H20160306-9605-1xf9c9h.pdf&hl=da&sa=T&oi=gga&ct=gga&cd=0&ei=rjkXWrzKKImMmAH-xo7gBw&scisig=AAGBfm2iRQhmI2EHEO7Cl6UZoRbfAxDRng&nossl=1&ws=1728x1023 Variational Bayesian PCA: https://www.microsoft.com/en-us/research/publication/variational-principal-components/	weakness
2018-909	Furthermore, the idea of bootstrapping for the SVD has been discussed in prior publications and the present work need to be related to these prior works.	weakness
2018-909	This includes: Milan, Luis, and Joe Whittaker.	misc
2018-909	"Application of the Parametric Bootstrap to Models That Incorporate a Singular Value Decomposition." Journal of the Royal Statistical Society.	misc
2018-909	Series C (Applied Statistics), vol.	misc
2018-909	44, no. 1, 1995, pp. 31–49. JSTOR, JSTOR, www.jstor.org/stable/2986193.	misc
2018-909	Fisher A, Caffo B, Schwartz B, Zipunnikov V.	misc
2018-909	Fast, Exact Bootstrap Principal Component Analysis for p > 1 million.	misc
2018-909	Journal of the American Statistical Association.	misc
2018-909	2016;111(514):846-860. doi:10.1080/01621459.2015.1062383. Including the following package in R for performing bootstrapped SVD: https://cran.r-project.org/web/packages/bootSVD/bootSVD.pdf	suggestion
2018-909	The novelty of the present approach is therefore unclear given prior works on bootstrapping SVD/PCA.	weakness
2018-909	Furthermore, for sparse data with missing entries there are specialized algorithms handling sparsity either using imputation or marginalization, which would be more principled to estimate the PCA parameters.	weakness
2018-909	Finaly, the performance appears almost identical with the PA procedure.	weakness
2018-909	In fact, it seems bootstrapping the correlation matrix has a very similar effect as the proposed bootstrapping procedure.	weakness
2018-909	Thus, it seems the proposed procedure which is very similar in spirit to PA does not have much benefit over this procedure.	weakness
2018-909	Minor comments: Explain what SW abbreviates when introduced first.	weakness
2018-909	We will see that it PA a close relationship with BSVD-> We will see that PA is closely related to BSVD	weakness
2018-909	more effective than SVD under certain conditions (?).	weakness
2018-909	– please provide reference instead of ?	suggestion
2018-909	But table 4 that shows -> But table 4 shows that	weakness
2018-909	We can sum up with that the result seems ->To summarize, the result seems The authors propose a bootstrap-based test for determining the number of latent dimensions to retain for linear dimensionality reduction (SVD/PCA).	weakness
2018-909	The idea is to retain eigenvectors which are larger than a bootstrap average.	weakness
2018-909	The resulting approach is evaluated on two simulated datasets (dense and sparse)as compared to common baselines and evaluated.	abstract
2018-909	The results suggest improved performance.	abstract
2018-909	The paper addresses an important problem, but does not seem ready for publication: - The evaluation only uses simulated data.	decision
2018-909	Ideally, the authors can evaluate the approach on real data -- perhaps using out of sample variance explained as a criterion?	suggestion
2018-909	- There is limited technical novelty.	weakness
2018-909	The bootstrap is well known already.	weakness
2018-909	The authors do not provide additional insight, or provide any theory justifying the technique.	weakness
2018-909	- It's not clear if the results are new: Paper with related discussion: http://jackson.eeb.utoronto.ca/files/2012/10/Jackson1995.pdf and a blog post: https://stats.stackexchange.com/questions/33917/how-to-determine-significant-principal-components-using-bootstrapping-or-monte-c	weakness

2019-871	The paper presents an approach to infer optimal strategies by learning the payoff function of 2 player games with a neural network Q(s, a), where a are the agent actions and s the context (e.g., action of the other player).	abstract
2019-871	The strategy is inferred by considering the inputs as free variables at test time and maximizing the learnt Q over its input variables by backpropagation.	abstract
2019-871	The structure of the neural network in itself is not particularly original.	weakness
2019-871	The originality of the paper is to show that experimentally, in some 2-player games (and small sequential games, using an RNN), the policy that is inferred is close to a Nash equilibrium.	abstract
2019-871	While this is an interesting result in itself, the games used in the experiment are pretty easy to solve with existing algorithms, so the experimental evidence that this approach can work in practice in difficult cases is weak.	weakness
2019-871	The motivation and intuition fail to be convincing.	weakness
2019-871	There is an excessive usage of analogies with intelligence and life in general that are not particularly enlighting (e.g., "Even though its hardware is damaged, the software in the cloud (or the eternal soul, arguably) of the mosquito [...]", the value of the analogy between the cloud and the soul is unclear), and in the end there is no clear explanation of why it should work in practice.	weakness
2019-871	I think the paper in its current form is not ready for publication.	decision
2019-871	More formal arguments and/or stronger experimental evidence are necessary.	weakness
2019-871	This paper tries to build a neural net to learn Nash equilibrium of games, even though it has been proved that no uncoupled algorithm can do that, except on specific games, as the ones considered in the example (0-sum, potentiel, solvable by iterated elimination of dominated strategies, etc.).	abstract
2019-871	The algorithm proposed is a classical neural net without any insight (I believe its behavio must more or less be similar to regret matching).	abstract
2019-871	In table 10, I do not think that the underline case is the NE.	abstract
2019-871	In table 12, the algorithm si conveniently initiated at the NE.	weakness
2019-871	The paper proposes a method of searching for a Nash equilibrium strategy in games where the strategy-to-payoff mapping is defined by a neural network.	abstract
2019-871	The idea is to perform gradient optimization of the payoff w.r.t. the strategy.	abstract
2019-871	Preliminary results on tic-tac-toe and variations of the prisoner's dilemma task are presented.	abstract
2019-871	The paper has an interesting idea at the core.	strength
2019-871	However, it is poorly written, does not properly discuss the related works and does not present a convincing method or experimental results.	weakness
2019-871	Pros: * The paper considers an interesting question of exploring the applications of neural networks to the game theory problems.	strength
2019-871	* The idea of the paper is reasonable.	strength
2019-871	It makes sense to me to perform gradient-based search over the strategies (assuming that the payoff is differentiable).	strength
2019-871	Cons: * Writing - The paper is over the mandatory length limit of 10 pages.	weakness
2019-871	- The paper makes a grandiose claim: "this paper provides a revolutionary way for reinforcement learning and a possible road toward general A.I." However, there are arguably no revolutionary ideas, and certainly no reinforcement learning experiments!	weakness
2019-871	- Despite the claim, the novelty of the paper is limited.	weakness
2019-871	There is no discussion of the related work: optimization of the neural networks w.r.t. the inputs [1]; related RL ideas such as model-based learning [2,3] and Monte-Carlo Tree Search [4].	weakness
2019-871	- The problem being solved is never formally stated.	weakness
2019-871	As far as I understand, Nash equilibrium is usually defined (1) in mixed strategies, while the paper seems to consider pure strategies; (2) in the scenario where every player attempts to maximize their payoff, while in the paper the players attempt to achieve some pre-fixed value of the payoff.	weakness
2019-871	- The flow of the paper is generally poor.	weakness
2019-871	Instead of presenting a general solution and then showcasing its applications, the paper iterates on similar ideas multiple times.	weakness
2019-871	For example, all four algorithms are just gradient-based optimization of either the weights or the inputs to a model.	weakness
2019-871	- The paper provides extremely misleading analogies and explanations.	weakness
2019-871	I am quite sure that a mosquito brain is not a one hidden layer fully-connected neural network!	weakness
2019-871	Also, the example of avoiding a moving hand is poor: since the outcome is life or death, the learning should happen via evolution, not during the lifetime of a single insect.	weakness
2019-871	The claim that the neural networks with sigmoid activation functions are less prone to local optima is questionable as well.	weakness
2019-871	* Method and experiments - The proposed method is essentially a greedy gradient-based planning procedure.	weakness
2019-871	For this to work, we need to have a very good environment model.	weakness
2019-871	This is a strong assumption that is not discussed.	weakness
2019-871	- The experiments are performed on very simple synthetic problems: matrix games and tic-tac-toe.	weakness
2019-871	They do not suggest that the method is general and can work on harder problems, say, Sokoban [2].	weakness
2019-871	- The experiments do not present any baselines, so it is unclear how well the method performs compared to the alternatives.	weakness
2019-871	One obvious candidate is gradient-free optimization, such as Nelder-Mead, and gradient descent with momentum, which can be less prone to local optima.	weakness
2019-871	[1] Brandon Amos, Lei Xu, J.	misc
2019-871	Zico Kolter "Input Convex Neural Networks", ICML 2017	misc
2019-871	[2] Racanière et al. "Imagination-Augmented Agents for Deep Reinforcement Learning", NIPS 2017	misc
2019-871	[3] David Ha, Jürgen Schmidhuber "Recurrent World Models Facilitate Policy Evolution", NIPS 2018	misc
2019-871	[4] Thomas Anthony, Zheng Tian, David Barber "Thinking Fast and Slow with Deep Learning and Tree Search", NIPS 2017	misc

2019-1340	This paper presents the idea of splitting the training process into two phases: fast training on a subset of the original dataset and finetining on the full dataset.	abstract
2019-1340	To find a good subset of the training dataset it is proposed to train an autoencoder and use its embeddings to choose examples that have large values of the embedding features.	abstract
2019-1340	The experiments show that on CIFAR-10 dataset this may speed up the convergence.	abstract
2019-1340	In general, I like the idea of being smart about which data and in which order to feed to the learner.	strength
2019-1340	Nonetheless, I disagree with several premises of this paper.	weakness
2019-1340	The paper claims that by making the dataset smaller one can speed up the training by the means of fitting the dataset into the accelerator memory and thus avoiding slow memory copies from CPU to accelerator memory.	weakness
2019-1340	However, modern deep learning data pipelines are built in a way that has virtually zero overhead, since the data is loaded from disk and preprocessed on CPU and then copied on the accelerator asynchronously (i.e. the GPU doesn't have to wait for the data, it can process the current batch and at the same time load the next one).	weakness
2019-1340	Moreover, moving the data to GPU will introduce additional overheads in the case of random data augmentation, since this additional work would have to be done by GPU (while current deep learning frameworks asynchronously do this work on CPU).	weakness
2019-1340	And finally, the authors claim that most modern datasets can fit to the accelerator memory if reduced 10x, but in my experience the network and it's activations (which are stored during training) occupies most of the GPU memory even on high end accelerators, not leaving enough space to store a large dataset even after data reduction.	weakness
2019-1340	The paper cites Dunner  et al. (2017) as related work that focus on the similar problem: how to find a subset of the dataset to fit it into the GPU memory.	weakness
2019-1340	However, I would argue that their setup is very different because they are using linear models (such as SVM): their learning steps are very fast compared to CNNs (which makes the memory bandwidth much slower in comparison), they don't have to store activations of the layers (which allows them to fit much more training samples into GPU memory), and they don't use data augmentation.	weakness
2019-1340	Also, I don't think that the experimental comparison provides a strong enough evidence supporting the benefits of the proposed scheme.	weakness
2019-1340	First, the experiments are only done on a small scale dataset (CIFAR-10), which is OK in general, but questionable when the proposed method explicitly targets big data regime and making the training faster.	weakness
2019-1340	Second, the only baseline considered is choosing subset of data randomly.	weakness
2019-1340	Third, the optimization method is plain SGD with momentum, while when presenting techniques for faster convergence it would make sense to compare on at least several standard optimization algorithms (e.g. Adam).	weakness
2019-1340	Finally, the presented results are weak: in Fig 4 any improvements over random baseline are noticeable only after degrading the performance of the network by a large margin (to less than 67% accuracy on CIFAR-10);	weakness
2019-1340	Fig 5 looks like it has an error: training on the full dataset performs on the level of random guess after some training, which contradicts the fact that the same network converged to something reasonable in Fig. 6.	weakness
2019-1340	Also, I believe that the training on the full dataset is strictly better than training on a random subset of data for a few epochs and then finetuning on the full dataset (with the same time budget).	weakness
2019-1340	The latter sees the same number of updates but with less data, which should only decrease the test performance.	weakness
2019-1340	If it's correct, the results in Fig 5 for the full training should look similar (or better) than the results in Fig 4 for the random subset baseline, but it's very far from being the case.	weakness
2019-1340	In Fig 6 I'm not sure what is being compared.	weakness
2019-1340	Is a train or test loss?	weakness
2019-1340	If it's train, then it's not a fair comparisons, since the two network are optimizing different train losses.	weakness
2019-1340	I'm also very surprised not to see the moment of training mode transition on the plot (i.e. the moment when the model switched from restricted dataset to the full one), the lack of it can indicate an implementation error.	weakness
2019-1340	And finally, I would like to see the text being improved.	weakness
2019-1340	Right now the language is confusing, for example: "this technique is shown to be effective" (what does it mean "effective" and compared to what?	weakness
2019-1340	), "Unfortunately, while these techniques may be viable for smaller networks or datasets, large datasets have shown that they do not scale well."	weakness
2019-1340	(who have shown that the techniques doesn't work on large dataset?	weakness
2019-1340	), "the testing network is initialized using a weighted average of the final weights learned during training" (what does it mean?	weakness
2019-1340	), "Qualitatively, the trained autoencoder succeeded in learning an adequate embedding."	weakness
2019-1340	(what does it mean? ), etc.	weakness
2019-1340	Also, there is a typo in formulas 1, 2, and 3: it probably should sum up to n-1.	weakness
2019-1340	And I didn't get what formula 4 means, what is "union of (for all i in n)"?	weakness
2019-1340	This bit I also didn't get: "This simple loss function, in essence, forces the network to learn to extract the key features from the input, so that it can reproduce it using said features only.	weakness
2019-1340	If desired, one could elect to use a more sophisticated loss, such as the Wasserstein distance metric (Gulrajani et al., 2017; Arjovsky et al., 2017), that takes more into account than raw pixel values.".	weakness
2019-1340	How can you substitute L2 loss in an autoencoder with Wasserstein metric (which is a metric between probability distributions, not images)?	weakness
2019-1340	There is also some missing related work, e.g. the idea mentioned in conclusion on augmenting the dataset in the latent space is presented in DeVries et al. "Dataset augmentation in feature space".	weakness
2019-1340	It would be interesting to connect this work with importance sampling off-policy RL (see e.g. "Prioritized Experience Replay") and look into sampling dataset points proportional to some importance probability with importance sampling correction.	suggestion
2019-1340	On the positive side, I really enjoyed the look of the figures and diagrams.	strength
2019-1340	This paper proposes a way to speed up initial training a model.	abstract
2019-1340	The key idea is to: 1. Train an autoencoder on the full dataset and select a subset of training examples.	abstract
2019-1340	The subset is the union of examples that maximally activate each of the dimensions of the autoencoder's low-dimensional embedding.	abstract
2019-1340	2. Then a target classifier is trained on the subset,	abstract
2019-1340	3. followed by final fine-tuning on the full dataset.	abstract
2019-1340	The paper is understandably written, although some crucial experimental details need a bit of guesswork.	strength
2019-1340	Their proposal is evaluated on only one dataset, CIFAR10, using an autoencoder and classifier of roughly similar design from the initial convolutional layers.	strength
2019-1340	They mention a baseline [classifier training, I presume] classifier training over ~200 epochs in 736 s (~12 min) to get 83% accuracy.	strength
2019-1340	This skips steps 1. and 2.	strength
2019-1340	Since this is already fast, CIFAR10 is perhaps too small a dataset to spur readers to use their proposed method (which does require them to additionally train an autoencoder) when tackling more ambitious problems.	weakness
2019-1340	They do not report the time taken to train their autoencoder for 800 epochs	weakness
2019-1340	(step 1.). For larger networks and images, it might also be important to investigate whether an autoencoder considerably simpler than the classifier model can suffice for subset selection; for example, if I want to train a	weakness
2019-1340	Resnet-152 classifier can I use a poorer quality autoencoder?	weakness
2019-1340	Since using a randomly selected subset 20% of the original size works about as well as step 1 for CIFAR10, I cannot judge whether the time taken to set up and train an autoencoder makes it worthwhile to further reduce the training subset from 20% to ~8% of the original size.	weakness
2019-1340	They do not consider alternative subset selection (1.) methods.	weakness
2019-1340	For example, one might use a pretrained network to select examplar images by a clustering method (ex.	weakness
2019-1340	[2]), possibly providing representative images per class.	weakness
2019-1340	Other selection criteria are also possible -- for example, [1] evaluates subset selection based on "representativeness" vs "diversity" criteria.	weakness
2019-1340	They do not compare with many existing approaches to training set compression.	weakness
2019-1340	Instead, they dismiss (Sec. 3 "Related Work") most previous work on selecting a small subset of training examples.	weakness
2019-1340	However, googling will quickly find many papers on subset selection (exactly what they do) as well as related dataset optimization techniques (such loss-based revisiting of training examplars, or training example weighting etc.).	weakness
2019-1340	For example, review-type article [3]	weakness
2019-1340	provides a good introduction to existing subset selection techniques, as well as references to earlier papers.	weakness
2019-1340	It is unclear whether the autoencoder training time is included in their experiments that fix the total training time to 7 minutes and compare results with different numbers of fast epochs (step 2.).	weakness
2019-1340	No guidelines are given for how to select the dimensionality of the autoencoder embedding, and how the selection procedure should be done in cases with large numbers of classes, although they mention the possibility of using combinations of activations for subset selection.	weakness
2019-1340	I do not understand how in problems with larger numbers of classes I can guarantee that the training subset will contain at least one representative from each class.	weakness
2019-1340	Some alternative subset selection methods can provide such guarantees, which might be important for training datasets with class imbalance.	weakness
2019-1340	Given that they do not use a very large dataset, where their technique would really be needed, and that they provide no comparison with other possibly faster and better ways to select a subset of training examples, I cannot argue for acceptance of this paper.	decision
2019-1340	[1] "Learning From Less Data: Diversified Subset Selection and	misc
2019-1340	Active Learning in Image Classification Tasks", Kaushal et al. https://arxiv.org/abs/1805.11191	misc
2019-1340	[2] Li, D., & Simske, S.	misc
2019-1340	(2011). Training set compression by incremental clustering.	misc
2019-1340	Journal of pattern recognition research, 1, 56-64.	misc
2019-1340	[3] Borovicka, T., Jirina Jr, M., Kordik, P., & Jirina, M.	misc
2019-1340	(2012). Selecting representative data sets. In Advances in data mining knowledge discovery and applications.	misc
2019-1340	InTech. Summary: The manuscript introduces a dataset filtering technique for the purpose of speeding up training of machine learning models.	abstract
2019-1340	The technique filters the training set, yielding a subset of examples that are as diverse as possible, according to an autoencoder embedding of the input space.	abstract
2019-1340	First, one trains a deep autoencoder, whose code layer is used as embedding of the input space.	abstract
2019-1340	Then, for each element of the embedding the top k training samples are selected which activate that element.	abstract
2019-1340	This reduced training set is then used for rapid training of the model in the first optimization stage, followed by slower fine-tuning on the complete data set.	abstract
2019-1340	The experimental section presents a comparison of accuracies after training a simple CNN on CIFAR10 with and without the proposed data filtering under several constraints.	abstract
2019-1340	Strengths: The proposed technique addresses the important problem of long training times.	strength
2019-1340	The description is very clear and detailed.	strength
2019-1340	Weakness: My main criticism of this manuscript is that the experimentation is not nearly sufficient to support the central claim that dataset filtering via embeddings, as described in this manuscript, is a "general technique" that "any tasks [...] could in principle benefit from [...]".	weakness
2019-1340	The evidence from the presented experiment is rather weak, as only one architecture and one dataset is selected.	weakness
2019-1340	Furthermore, there are quite a few confounding factors that I don't think are compensated by averaging the performances of four training runs.	weakness
2019-1340	A few recommendations on how to improve the experimental section: - How are hyperparameters selected?	suggestion
2019-1340	For a fair comparison, separate hyperparameter searches should be performed for training with the full training set and with the filtered set.	suggestion
2019-1340	Simple hyperparameters can influence the performance strongly for a given dataset.	suggestion
2019-1340	- It requires extensive experimentation to "show the technique's merits as a generally applicable technique that is not bound to certain types of architectures", for instance trying different types of architectures and datasets.	weakness
2019-1340	Of course the technique can be applied to most architectures and datasets.	weakness
2019-1340	However, the question is whether it often helps, not whether it is technically possible.	weakness
2019-1340	Does it for example improve convergence speed or performance in a state-of-the-art network trained on ImageNet?	weakness
2019-1340	- The heavy use of data augmentation is a confounding factor which adds randomness that is not likely to be compensated by averaging a few training runs.	weakness
2019-1340	Maybe you could present performances without augmentation.	suggestion
2019-1340	- You mention momentum is used.	weakness
2019-1340	For reproducibility, it would be good to state the coefficient used.	suggestion
2019-1340	- Testing is performed on checkpoints with some form of weighted averaging of final weights.	weakness
2019-1340	Could you describe the steps in detail for better reproducibility?	suggestion
2019-1340	- Is the result stable over multiple autoencoder trainings?	weakness
2019-1340	- It would be interesting to see the performance before the finetuning stage!	suggestion
2019-1340	I feel the discussion section could benefit from a few thoughts on the limitations of this approach.	suggestion
2019-1340	For instance, the method might not be the best choice for highly imbalanced classification datasets.	suggestion
2019-1340	Literature on dataset resampling for such scenarios might be worth mentioning in the related work section.	suggestion
2019-1340	Also, the autoencoder's embeddings are trained to reconstruct the whole image, an objective that gives more importance to patterns that occupy a larger portion of the image.	suggestion
2019-1340	If the downstream task needs attention to detail (e.g. counting of small objects, segmentation in remote sensing or medical imaging, street-number or road-sign detection), the filtering method might also not be much better than random subsampling.	suggestion
2019-1340	The related work section could also be improved.	rebuttal_process
2019-1340	I see only one work on data set optimization.	suggestion
2019-1340	I've seen work using a reducedMNIST dataset, which is probably created by random subsampling, but still more relevant than many of the aspects of embeddings cited in this section (the paragraph about arithmetic operations for instance).	weakness
2019-1340	Katharopoulos and Fleuret (2018) seems like highly relevant recent work, which should be cited and contrasted against.	weakness
2019-1340	The evaluation in that work seems very thorough in comparison.	strength
2019-1340	A general recommendation on writing: Try to limit the content to relevant details.	suggestion
2019-1340	For example, a description of hardware specifics (support for NVLink, which is not used) or stating the well-established speed-up when using GPUs for CNNs are not relevant.	weakness
2019-1340	Figure 6 could be improved by marking on the time axis, when the fine-tuning sets in.	suggestion
2019-1340	To summarize my feedback, I like most of the presentation and it is good to see effort towards reducing training times by selecting good training samples, but I think the manuscript requires significant effort to justify acceptance.	decision

2020-693	[Summary] This paper studies the impact of initialization noise on the theories of wide neural networks in the Neural Tangent Kernels (NTK) regime.	abstract
2020-693	The paper proves that the difference between the trained neural net and the kernel interpolator (with the NTK) can be bounded by O(\\sigma^L + 1/\\sqrt{m}), where \\sigma^2 is the initializing variance of each individual weight entry.	abstract
2020-693	Relationships between the generalization error of these two functions are derived from the above bound.	abstract
2020-693	[Pros] The general message that this paper conveys is interesting -- the initial network f_{\\theta_0}(x), which is typically omitted (or made small by making \\sigma small) in NTK analyses, can deviate the converged NN from the kernel interpolator in terms of generalization error.	strength
2020-693	[Cons] There are fundamental mistakes in the statements/proofs of Theorem 2, 3, 4: -- Theorem 2: the statement is "whp over W, the bound … holds uniformly for x".	weakness
2020-693	The proof relies on Lemma 3, whose statement is also uniform over x, but the proof applies the Markov inequality *for a single x* and is thus valid only for a single x.	weakness
2020-693	(As it's Markov, it seems not sensible to apply the union bound upon it.)	weakness
2020-693	-- Theorem 3: the difference between L^NN_test and L^int_test should be on the order of (\\sigma^L + 1/\\sqrt{m}) rather than it squared.	weakness
2020-693	To bound the difference in squared loss we have a^2 - b^2 <= O(1) * |a-b| (if a, b are bounded by O(1)).	weakness
2020-693	We don't have a^2 - b^2 <= |a - b|^2.	weakness
2020-693	-- Theorem 4: J(X_test) as defined is a vector whose dimension grows with the number of test data points, where the theorem requires it to be a scalar.	weakness
2020-693	Indeed the treatment of test data as a fixed matrix (rather than samples from a distribution) is already a bit atypical.	weakness
2020-693	*** I have read the authors' rebuttal and the other reviews, and I'm glad to see the issues with Theorem 3 and 4 pointed out above are fixed in the revision.	rebuttal_process
2020-693	However, I also agree with the other reviewers that the paper in the present stage has not yet demonstrated sufficient technical contributions, and thus I am keeping my original evaluation.	rebuttal_process
2020-693	This paper studies the solution of neural network training in the NTK regime.	abstract
2020-693	The trained network can be written as the sum of two terms --- the first is the minimum RKHS norm interpolating solution, and the second term depends on the initialization.	abstract
2020-693	When the initialization scale is small, the second term almost vanishes, but when the initialization scale is large, it's likely that the second term becomes very large, leading to worse generalization.	abstract
2020-693	The technical contribution of this paper is pretty low.	weakness
2020-693	The most important formula is (14), which only appears in the second half of the paper (the first half of the paper is almost all known results).	weakness
2020-693	The bounds in later part of the paper are also straightforward.	weakness
2020-693	Moreover, another paper https://arxiv.org/abs/1905.07777 already studied the same question and showed that non-zero output can increase the generalization error.	weakness
2020-693	----------- update: I have read the authors' response.	rebuttal_process
2020-693	My assessment stays the same since I still think that the technical contribution of this paper is quite limited.	rebuttal_process
2020-693	Also there is a negative effect of using small init, which the authors might have overlooked: when the init is smaller, you'd need a larger width for the NN to be in the NTK regime.	rebuttal_process
2020-693	See e.g. "Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks.	misc
2020-693	Sanjeev Arora, Simon S. Du, Wei Hu, Zhiyuan Li, Ruosong Wang.	misc
2020-693	ICML 2019". The paper considers the impact of initialization bias on test error in strongly overparameterized neural networks.	abstract
2020-693	The study uses tools from recent literature on the generalization of overparameterized neural networks, i.e. neural tangent kernels and interpolating kernel method, to provide useful insights on how the variance of weights initialization affects the test error.	abstract
2020-693	I have a few questions about theoretical results, but the paper has a convincing experiment that supports its theoretical claims.	strength
2020-693	Addressing the following points will improve the exposition of the paper.	suggestion
2020-693	1. Please provide a little hint on how Lemma 2 rewrites the equation (13) for linearized function for easier readability without referring to the Appendix.	suggestion
2020-693	2. In the case of cross-entropy error, would the effect be similar?	suggestion
2020-693	Could this be verified with a similar experiment as for MSE?	suggestion
2020-693	3. To what extent this result is observed in not as strongly overparameterized settings?	weakness
2020-693	In other words, it would be interesting to see what happens if you fix the architectural choice while increasing the number of training parameters, how long does the test error effect persist?	suggestion
2020-693	Minor remark: - a few typos are present on pages 4, 5, 7, 8 This paper studies overparameterized fully-connected neural networks trained with squared loss.	weakness
2020-693	The authors show that the resulting network can be decomposed as a sum of the solution of a certain interpolating kernel regression and a term that only depends on initialization.	weakness
2020-693	Based on this, the authors also derive a generalization bound of deep neural networks by transferring it to a kernel method.	abstract
2020-693	My major concern about this paper is the novelty and significance of its results: In terms of connection to NTK, It seems that the connection between neural networks trained with squared loss and the result of NTK-based kernel regression has already been well-studied by	weakness
2020-693	Arora, Sanjeev, Simon S. Du, Wei Hu, Zhiyuan Li, Ruslan Salakhutdinov, and Ruosong Wang.	misc
2020-693	"On exact computation with an infinitely wide neural net." arXiv preprint arXiv:1904.11955 (2019).	misc
2020-693	which is a missed citation.	weakness
2020-693	Without a clear explanation on the difference between the submission and this paper above, I don't think this paper is ready for publication.	decision
2020-693	In terms of generalization, it is also very difficult to judge whether this paper's result is novel.	weakness
2020-693	In fact this paper misses almost all citations on generalization bounds for neural networks.	weakness
2020-693	Moreover, the generalization bound given in this paper does not seem to be very complete and significant, since the authors do not show when can L_{test}^{int} be small.	weakness
2020-693	To demonstrate the novelty and significance of the result, the authors should at least compare their generalization result with the following generalization bounds for over-parameterized neural networks in Section 4: Allen-Zhu, Zeyuan, Yuanzhi Li, and Yingyu Liang.	suggestion
2020-693	"Learning and generalization in overparameterized neural networks, going beyond two layers." arXiv preprint arXiv:1811.04918 (2018).	misc
2020-693	Cao, Yuan, and Quanquan Gu.	misc
2020-693	"A generalization theory of gradient descent for learning over-parameterized deep relu networks." arXiv preprint arXiv:1902.01384 (2019).	misc
2020-693	Arora, Sanjeev, Simon S. Du, Wei Hu, Zhiyuan Li, and Ruosong Wang.	misc
2020-693	"Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks." arXiv preprint arXiv:1901.08584 (2019).	misc
2020-693	Cao, Yuan, and Quanquan Gu.	misc
2020-693	"Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural Networks." arXiv preprint arXiv:1905.13210 (2019).	misc
2020-693	Overall, I suggest that the authors should make a clear discussion on the relation of this paper to many existing works mentioned above.	suggestion
2020-693	As long as the authors can give a convincing demonstration of the novelty and significance of their results, I will be happy to increase my score.	suggestion
2020-693	A minor comment: how can the bound in Theorem 3 be derived based on Theorem 2?	suggestion
2020-693	Should there be a constant factor in the bound?	weakness

2020-759	How to quickly learn control policies with minimized number of environment interactions have long been an important problem.	abstract
2020-759	To tackle this problem, this paper proposed a "hierarchical Bayesian optimization (HIBO)" algorithm to optimize the "feature parameter \\phi" (which I don't know what that is) and the "policy parameter \\theta" hierarchically.	abstract
2020-759	Under the formulation of maximizing reward J(\\theta), the algorithm firstly uses EI to select \\phi.	abstract
2020-759	Given the selected \\phi, the algorithm selects the policy parameter \\theta.	abstract
2020-759	The proposed algorithm is evaluated on a Humanoid Postural Balancing task, and shows achieves high rewards faster than the standard EI acquisition.	abstract
2020-759	However, the paper is awfully written such that I cannot understand what the "feature parameter \\phi" is.	weakness
2020-759	Given my limited understanding, I think the paper should be rejected.	decision
2020-759	Strengths, 1, The paper deals with an interesting task: Humanoid Postural Balancing.	strength
2020-759	A Humanoid is expected to learn how to balance as quick as possible to reduce the interactions with the environments, which suits well with Bayesian optimization.	strength
2020-759	Weakness, 1, The paper is awfully written.	weakness
2020-759	The problem statement subsection is unreadable.	weakness
2020-759	I don't see anywhere explaining how the states x_t, commands u_t, \\theta, and feature \\phi are related?	weakness
2020-759	What is \\phi ? It is super wired why the feature parameter \\phi is jointly maximized with the policy parameter.	weakness
2020-759	Because I don't understand the formulation, I can hardly understand anything else.	weakness
2020-759	2, From my very limited understanding on the formulation, the proposed HIBO is trivial.	weakness
2020-759	3, The experiments are limited.	weakness
2020-759	The paper only conducts one experiment on the Humanoid control balancing.	weakness
2020-759	And they paper only compares with the EI acquisition, while the state-of-art acquisition MES should be also be compared with.	weakness
2020-759	4, The proposed mental replay is not well justified, qualitatively or empirically.	weakness
2020-759	After rebuttal: Thank you to the authors for responding to my review.	rebuttal_process
2020-759	1) The title of the conference is "...	weakness
2020-759	on Learning Representations". As I stated in the review ("no, e.g., neural networks are employed"), neural networks are an *example* of, but do not subsume, all representation learning methods.	weakness
2020-759	Therefore, I agree that papers that do not cover neural networks are welcome at the conference.	decision
2020-759	However, as I stated in the review, my evaluation of the method proposed in the submission is that it does not concern representation learning ("The employed features in Table 3 are handcrafted").	strength
2020-759	I believe this evaluation is defensible, but of course the final evaluation is up to the chairs.	misc
2020-759	However, I note that the authors did not respond directly to my evaluation that the method is not engaging in representation learning.	rebuttal_process
2020-759	2-7) As the other reviewer notes, the paper lacks clarity in many places, and does not sufficiently discuss prior work, including in postural control (there is one citation in the references that is not mentioned in the main text), hierarchical Bayesian optimization within or without a Gaussian processes framework (https://scholar.google.com/scholar?hl=fr&as_sdt=0%2C5&q=hierarchical+bayesian+optimization&btnG=), or experience replay (https://scholar.google.com/scholar?hl=fr&as_sdt=0%2C5&q=replay+machine+learning&btnG=).	weakness
2020-759	Therefore, it is difficult to ascertain the research contribution.	weakness
2020-759	As such, I stand by my evaluation that this submission is not ready for publication at *CONF*.	decision
2020-759	=========================== Before rebuttal: The submission presents a hierarchical Bayesian optimization (HiBO) approach to solving a postural control task expressed as a proportional-derivative (PD) controller.	abstract
2020-759	Strengths: - The HiBO approach outperforms the non-hierarchical BO approach on the task of postural control.	strength
2020-759	Weaknesses: - The paper does not make use of representation learning (no, e.g., neural networks are employed) and is therefore out-of-place at *CONF*.	weakness
2020-759	The employed features in Table 3 are handcrafted.	weakness
2020-759	- The task (simulating human postural control) is not well-situated in the context of prior work using HiBO for robotics, so the contribution remains unclear.	weakness
2020-759	- It is not clear why this problem should be formulated as contextual policy search (i.e., to what the context variable refers).	weakness
2020-759	- Only one baseline (Bayesian optimization (BO)) is reported.	weakness
2020-759	This baseline corresponds to the ablation of the HiBO method (i.e., the omission of the context variable), and so does not represent, more broadly, an alternative approach.	weakness
2020-759	- The concept of "mental replay" is briefly introduced, but no reference is made to prior work in imagined rollouts, and no ablation study on the impact of this component is performed.	weakness
2020-759	Minor points: - It is unclear why the problem setting should be labeled as "psychological" postural control.	weakness
2020-759	- There are several missing references ("?") in the text.	weakness

2020-792	This paper considers the problem of text classification, especially the settings in which the number of labeled sentences is very small.	abstract
2020-792	However, authors assume, annotations of rationales behind the label, i.e. highlighting tokens in a sentence which are important in deciding its label.	weakness
2020-792	As per my understanding, this is a big limitation.	weakness
2020-792	Second, the proposed model makes inference of class labels just based upon occurrence of words in a sentence, rather than making more sophisticated inferences relying upon sub-sequence patterns at least.	weakness
2020-792	The idea proposed in the paper is to learn prototype vectors which have high similarity w.r.t. tokens in sentences, especially the highlighted one.	weakness
2020-792	I didn't understand the justification for learning such prototypes in the first place.	weakness
2020-792	This works build upon a workshop paper.	weakness
2020-792	The idea proposed in the paper, even in the specific problem context considered, are incremental.	weakness
2020-792	I don't think that this kind of work aligns with the theme of learning representations.	weakness
2020-792	This paper may be suitable for publication in an NLP workshop as the baseline model.	decision
2020-792	The authors propose PARCUS ("Pattern Representations on Continuous Spaces"), a model which computes a soft-matching probability for all words in an input sequence with so-called prototypes in order to predict a label for the input.	abstract
2020-792	Furthermore, for training, PARCUS makes use of rationales.	abstract
2020-792	Those are indicators of input importance, and help to boost the loss for relevant tokens.	abstract
2020-792	The main motivation to use PARCUS is that it works better in a low-resource setting than recent state-of-the-art models for the high-resource case.	abstract
2020-792	This is due to it having relatively few parameters and to it having a strong inductive bias.	abstract
2020-792	However, the fact that models with less parameters perform better than BERT-based models in the low-resource case is not very surprising.	weakness
2020-792	Looking at the experiments, the results on HATESPEECH show less differences between models than for SPOUSE or MOVIEREVIEW.	weakness
2020-792	Another selling point of PARCUS is that it's interpretable.	weakness
2020-792	While neural networks can also be analyzed in different ways, I agree with the authors that this is nice to have.	strength
2020-792	Overall, the paper seems solid.	strength
2020-792	========== Update: After reading the other reviews and the responses by the authors, I lowered my score from 6 to 3.	rebuttal_process
2020-792	After responses: I read the authors response and decided to stick to my original score mostly because: 1 - I understand that interpretability is hard to define.	rebuttal_process
2020-792	I also agree with the authors response.	rebuttal_process
2020-792	However, this is still not reflected in the paper in any way.	rebuttal_process
2020-792	I expect a discussion on what is the relevant definition used in the paper and how does it fit to that definition.	rebuttal_process
2020-792	Currently, it is very confusing to the reader.	rebuttal_process
2020-792	2 - I understand the authors' response that few-shot learning is a different empirical setting.	rebuttal_process
2020-792	However, authors also agree that settings are some-what relevant.	rebuttal_process
2020-792	I really do not see any gain by NOT discussing the few-shot learning literature.	rebuttal_process
2020-792	At the end, a reader is interested in this work if they have limited data.	rebuttal_process
2020-792	Moreover, other ways to address limited data issue should be discussed.	rebuttal_process
2020-792	----- The manuscript is proposing a few-shot classification setting in which training set includes only few examples.	weakness
2020-792	The main contribution is using prototype embeddings and representing each word as cosine distances to these prototype embeddings.	weakness
2020-792	Moreover, the final classification is weighted summation of the per-token decisions followed by a soft-max.	weakness
2020-792	Per-token classifiers are obtained with an MLP using the cosine distances as features.	abstract
2020-792	When the relevance labels are available, they are used in training to boost gradients.	suggestion
2020-792	PRO(s) The proposed method is interesting and addressing an important problem.	strength
2020-792	There are many few-shot scenarios and finding good models for them is impactful.	strength
2020-792	The results are promising and the proposed method is more interpretable than the existing NLP classifiers.	strength
2020-792	I disagree with the claim that the model is interpretable.	weakness
2020-792	However, I appreciate the effort to interpret the model.	misc
2020-792	CON(s) The model is not interpretable because 1) it starts with embeddings and they are not interpretable, 2) model is full of non-linearities and decision boundaries are not possible to find.	weakness
2020-792	In other words, it is not possible to answer "what would make this model predict some other classifier".	weakness
2020-792	The authors should discuss the existing few-shot learning mechanisms.	suggestion
2020-792	Especially, "Prototypical Networks for Few-shot Learning" is very relevant.	suggestion
2020-792	I also think it can be included as a baseline with very minimal modifications.	suggestion
2020-792	The writing is not complete.	weakness
2020-792	The authors do not even discuss how the prototypes are learned.	weakness
2020-792	I am assuming it is done using full gradient-descent over all parameters.	weakness
2020-792	However, this is not clearly discussed.	weakness
2020-792	Implementation details should be discussed more clearly.	weakness
2020-792	SUMMARY I believe the manuscript is definitely interesting and has a potential.	strength
2020-792	In the mean time, It is not ready for publication.	decision
2020-792	It needs a through review of few-shot learning.	decision
2020-792	Authors should also discuss can any of the few-shot learning methods be included in the experimental study.	suggestion
2020-792	If the answer is yes, it should be.	rebuttal_process
2020-792	If the answer is no, it should be explained clearly.	rebuttal_process
2020-792	Although my recommendation is weak-reject, I am happy to bump it up if these issues are addressed.	decision

2020-793	The paper makes the following two contributions: 1) a new metric to measure the realism of uncertainty estimates for regression problems which uses a Mahalanobis distance-based statistical test.	abstract
2020-793	2) a new probabilistic architecture for semantic segmentation.	abstract
2020-793	Overall I do not think that the paper is qualifies for acceptance, because a) both contributions are only loosely connected and b) some parts are confusingly written or poorly motivated, making the paper hard to follow.	decision
2020-793	After reading the paper it still remains unclear to me why the proposed statistical test is superior to other popular metrics, such as the log-likelihood or the metrics proposed by Mukhoti and Gal.	weakness
2020-793	I think the paper would benefit from a more detailed discussion that highlights the differences between the proposed metric and other commonly used metrics.	suggestion
2020-793	Furthermore, in the experiments, the paper only shows that MC dropout doesn't achieve realistic uncertainty estimates.	weakness
2020-793	I think concluding that variational approaches underestimate the variance is a bit of stretch (see section 4.1) , i e.	weakness
2020-793	it would be more convincing if other approaches (e.g Blundell et al. Hernandes-Lobato and Adams) are also considered.	weakness
2020-793	The paper also just states that uncertainty estimates obtained by MC dropout are unrealistic but doesn't elaborates how to improve them.	weakness
2020-793	The second contribution, a probabilistic architecture for semantic segmentation, is not introduced in the main paper.	weakness
2020-793	Instead details are only provided in the appendix.	weakness
2020-793	In my opinion the paper would be easier to follow if it would contain a section that motivates and described the proposed architecture before jumping directly to the experiments.	weakness
2020-793	Minor comments: - the acronym FRRN is not defined	weakness
2020-793	- Section 4.2 last paragraph: I don't understand why samples obtain by MC dropout and from the latent space are considered to be from the same distribution?	weakness
2020-793	While both methods approximate the weight posterior they use different approximations for that.	weakness
2020-793	- In the introduction the paper states that the proposed segmentation network is a U-net like FRRN architecture , however in section 3 it says instead of a U-net based architecture a FRRN based architecture is used.	weakness
2020-793	This is somewhat confusing. - Section 4.1: how are the variances scaled for Figure 3 middle?	weakness
2020-793	- Section 4.1 It would be also interesting if other metrics, such as log-likelihood or RMSE, to see how well the model is able to fit the data.	suggestion
2020-793	- I am also surprised that CVAE + MC underperforms to just using CVAE?	weakness
2020-793	- Section 4.1: how are the variances scaled for Figure 3 middle?	weakness
2020-793	References: Evaluating Bayesian Deep Learning Methods for Semantic Segmentation	misc
2020-793	Jishnu Mukhoti, Yarin Gal arXiv:1811.12709 [cs.CV]	misc
2020-793	Weight Uncertainty in Neural Networks	misc
2020-793	Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, Daan Wierstra	misc
2020-793	ICML 2015 Hernández-Lobato J. M. and Adams R.	misc
2020-793	Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks,	misc
2020-793	ICML 2015 The paper a new method for evaluating prediction uncertainties for regression and classification tasks.	abstract
2020-793	I argue this work should be rejected.	decision
2020-793	For regression the method is based on Gaussian assumption, which has no reason to be correct (especially for BayesianNN), and for classification the method is not clear at all.	weakness
2020-793	Detailed remarks: - For a BNN, there is no reason why p(y|x) is Gaussian, so even if the residual is rejected as chi-square this doesn't mean anything.	weakness
2020-793	- I am unclear as to how the classifier uncertainty is measured.	weakness
2020-793	- The paper claims that "it is preferable to assess the variances separately." which I agree with, but a mistake in the mean would effect your chi-square test, so it is not separated.	weakness
2020-793	- I am unclear as to what statistical test you perform to accept/reject the chi-square hypothesis.	weakness
2020-793	This paper considers the important open question of how to ensure that uncertainty estimates of neural network predictions actually reflect real world error distributions.	abstract
2020-793	The paper introduces an uncertainty quality metric along with a statistical test based off this metric that enables a binary decision of whether to accept a model's uncertainties as realistic.	abstract
2020-793	The paper also introduces a new model for supervised image-to-image tasks that combines two existing uncertainty mechanisms, and achieves reasonable uncertainty estimates, in particular, demonstrating robustness to out-of-sample data.	abstract
2020-793	I am tending to reject, because although each of the two distinct contributions are good starts on interesting approaches, neither provides a convincing solutions for the main question, and the two contributions are quite distinct, so that the paper lacks a consistent thread.	decision
2020-793	First, the Mahalanobis-based uncertainty evaluation makes sense, but it is not clear what it adds beyond the standard average negative log-likelihood (NLL) metric.	weakness
2020-793	Mahalanobis distance increases monotonically with negative log-likelihood, so is there any reason to expect it is a better way to compare models based on their uncertainty?	weakness
2020-793	Is there some experiment that could show that the new metric is better than NLL at evaluating uncertainty realism?	weakness
2020-793	The statistical test could potentially be a nice real world tool for deciding whether to trust neural network uncertainties.	strength
2020-793	However, the paper only applies the test in one case, where the MC dropout model is shown to have unrealistic uncertainties.	weakness
2020-793	To show that this test is useful, there should also be experiments where uncertainty estimates are shown to be realistic.	suggestion
2020-793	Is there some alternative to MC dropout for regression or some improvements to the algorithm that could yield realistic uncertainties under this statistical test?	suggestion
2020-793	E.g., would the U-Net-based model in the paper pass the test if it were adapted to regression problems?	weakness
2020-793	Second, the new U-Net-based classification model looks like a reasonable approach, but it is disjoint from the new statistical test, and it is not clear that the method yields improvements to uncertainty realism, since there are no comparisons to external results.	weakness
2020-793	Since only a new architecture is used, it is not clear that the deficiencies in uncertainty realism are not architecture-specific.	weakness
2020-793	Is it that there are no existing architectures that can be applied to this problem?	weakness
2020-793	Also, is there some more realistic setting where the CVAE approach would improve in-sample scores, i.e., where out-of-sample data is not generated synthetically?	suggestion
2020-793	Can the statistical test be adapted to the classification setting?	weakness
2020-793	Similar, to the case of regression, the uncertainty realism metrics used for classification are tightly coupled with the prediction accuracy; is there a way to decouple these, would one want to?	weakness
2020-793	The conclusion that CVAE is better than MC for this problem is solid, but is there a more general conclusion to be drawn?	weakness
2020-793	E.g., could a CVAE model yield realistic estimates in the regression setting?	weakness

2020-907	Theorem 2 and its proof are plagiarised: they are rephrased and reorganized formulation and proof of Theorem 1 of [1], while being presented as authors' own work.	weakness
2020-907	Although the assumptions are slightly different (random forest kernels vs general kernels), core of the proof is the same, including notation and its split into Lemmas and helper Theorems.	weakness
2020-907	In particular: - formulation is the same (even use of MMD_u is copied, while not being defined before),	weakness
2020-907	- main proof of Theorem 2 (p.25-26) is the proof of Corollary 3 of [1] followed by the proof of Theorem 5 of [1],	weakness
2020-907	- Lemma 13 is Lemma 3 of [1],	weakness
2020-907	- Definition 3 in Appendix B.2 is the same as Assumption D of [1] (Appendix C.2),	weakness
2020-907	- Proposition 4 and it's proof (p.	weakness
2020-907	21) are the same as Lemma 2 of [1].	weakness
2020-907	[1] Mikołaj Bińkowski, Dougal J.	misc
2020-907	Sutherland, Michael Arbel, and Arthur Gretton.	misc
2020-907	Demystifying MMD GANs. International Conference on Learning Representations, 2018.	misc
2020-907	This paper proposed to utilize the random-forest kernel into MMD GAN.	abstract
2020-907	The experiments are conducted on CIFAR-10, CelebA and LSUN datasets.	abstract
2020-907	The method is not novel.	weakness
2020-907	Both MMD GAN and the random-forest kernel have been well explored.	weakness
2020-907	Combining them together is considered as an extension.	weakness
2020-907	For the theory, the paper only provides the unbiasedness analysis.	weakness
2020-907	It is not clear to me whether this kernel is better than other MMD GAN variations.	weakness
2020-907	It is not clear how the claimed flexibility comes from.	weakness
2020-907	Regarding the experiments, it only compares with very basic baselines and the results are not significantly better.	weakness
2020-907	It would be better to include stronger baselines (Wang et al., 2019, Binkowski et al., 2018).	suggestion
2020-907	The writing of the paper is poor.	weakness
2020-907	with several typos. Moreover, as mentioned by reviewer #1,  theorem 2 and its proof are plagiarised.	weakness
2020-907	Overall, I think the paper is a clear reject.	decision
2020-907	Overview: The paper propose an MMD GAN extension via using Random forest Kernel.	abstract
2020-907	Instead of using Gaussian kernel on the top of the learned embeddings from the discriminator, it combines existing deep forests kernels.	abstract
2020-907	The theory of being differentiable is carefully studied (to prove zero measure) and the experiments are well conducted.	abstract
2020-907	1.  Some important  references are missing.	weakness
2020-907	One very related paper is	misc
2020-907	* Li et al., Implicit Kernel Learning,  AISTATS 2019.	misc
2020-907	That paper is using the same idea to learn to manipulate the random features on the top of the learned embedding.	misc
2020-907	The main difference between it and the proposed algorithm is they use MLP parameterization instead of the tree-based model.	weakness
2020-907	Also, the deep forest model can be treated as a sparse neural network, does it have more advantage over Li et al., (2019)?	weakness
2020-907	given they use simple dense MLP.	weakness
2020-907	Please at least discuss the similarity and difference in the rebuttal and update the draft correspondingly.	suggestion
2020-907	I would even encourage the author to empirically compare with it in the camera ready version.	suggestion
2020-907	It would be interesting to see which parameterization is better in this space.	suggestion
2020-907	There are also other recent MMD GAN extensions should be cited in the discussion, such as	suggestion
2020-907	* On gradient regularizers for MMD GANs. 2.	suggestion
2020-907	For the theory part, based on Binkowski (2018), the gradients for the generator parameters should be biased.	rebuttal_process
2020-907	Could you discuss it with Theorem 2?	suggestion
2020-907	3. For most MMD GAN results, one important property in Li et al., (2017),  Arbel et al., (2018) and Li et al., (2019) is weak* topology.	weakness
2020-907	Does the proposed Random Forest MMD GAN also has that property?	suggestion
2020-907	In Li et al., (2019), they need some condition to ensure that, how's case in the proposed algorithm?	weakness

2020-913	This proposes two techniques to replace mixed-precision arithmetic with half-precision training for a large part of the training process.	abstract
2020-913	In the first approach, the authors simply switch all mixed-precision operations with half-precision operations, and can achieve performances slightly lower than SOTA.	abstract
2020-913	In the second approach, the authors propose to dynamically switch between mixed-operations and half-precision operations during training.	abstract
2020-913	The authors claim that this second approach can match SOTA results while using half-precision arithmetic for more than 94% of training.	abstract
2020-913	Overall the paper is fairly well written, and easy to follow.	strength
2020-913	The proposed techniques seem to empirically work well.	strength
2020-913	However, I have a number of concerns about the paper, which explains my score.	strength
2020-913	I list these concerns below.	misc
2020-913	1. The proposed approach has a number of additional hyperparameters, which makes it less likely for the algorithm to be widely used if the algorithm is very sensitive to the values of this.	weakness
2020-913	For very extreme values of these hyperparameters, I would expect the algorithm to start behaving quite poorly.	weakness
2020-913	But it would help a lot to provide some sensitivity analysis to these hyperparameters for reasonable values of these hyperparameters.	suggestion
2020-913	2. How much do the optimal hyperparameters (like numBatchesMP, numBatchesBF16, emaT) vary across problems?	suggestion
2020-913	3. How much do the above-mentioned optimal hyperparameters vary with mini batch size?	suggestion
2020-913	4. How are the other hyperparameters like learning rates selected?	suggestion
2020-913	Is the learning rate tuned?	suggestion
2020-913	5. Are the experiments repeated multiple times?	weakness
2020-913	6. It seems a bit weird to call a modification that simply uses half-precision arithmetic for most FMA operations a significant contribution of the paper, especially since it can't reach SOTA performance.	weakness
2020-913	7. Algorithm 1 should be written out in a better way that shows the training loop.	weakness
2020-913	It is slightly confusing the way it is written up right now.	weakness
2020-913	Overall I think the paper would significantly benefit from a more thorough empirical evaluation.	weakness
2020-913	============================= Edit after rebuttal: I thank the reviewers for their response and for running the additional experiments.	misc
2020-913	However, I find the updated version of the paper to be inadequate in fully answering my concerns.	rebuttal_process
2020-913	While the authors have included a hyperparameter sensititivity analysis, I find the experiment to be unconvincing.	weakness
2020-913	Only two of the three hyperparameters are swept over a very small range of values, and the results presented are only for the first 12 epochs, while the actual model is typically trained for 90 epochs.	weakness
2020-913	While I appreciate the added experiment and realize that 10 days is too short a time to put in a proper sensitivity analysis, based on the current draft of the paper, I cannot recommend accepting this paper.	decision
2020-913	I am however raising my score to a weak reject.	rating_summary
2020-913	The author(s) propose to accelerate the training of deep neural networks while also maintain the performance of the trained model by switching between fully half-precision computation and mixed-precision computation.	abstract
2020-913	Compared to the commonly-used mixed-precision training strategy, the proposed method can accelerate the training speed.	abstract
2020-913	Besides, on an image classification task, models trained by the proposed method achieve comparable performance with those trained by mix-precision training or full-precision training.	abstract
2020-913	Strength: 1. Section 3 provides useful information for the workloads of deep neural networks.	strength
2020-913	Weakness: 1. The overall idea is not novel.	weakness
2020-913	The proposed method simply switches between two existing training strategies, i.e., the mixed-precision training and half-precision training.	weakness
2020-913	The claim that "this paper is the first in demonstrating that  half-precision can be used for a very large portion of DNNs training and still reach state-of-the-art accuracy" may not correct, in fact, Nvidia's apex has already supported using mixed-precision or entirely half-precision to train DNNs, and there is no clear evidence that the proposed method is better than theirs due to the lack of experiments on more tasks and datasets.	weakness
2020-913	2. From Table 1, the Dynamic strategy outperforms BF16 in terms of classification accuracy.	weakness
2020-913	However, from the experiments, it's unable to tell that the gains actually come from this Dynamic strategy.	weakness
2020-913	Maybe similar gains can be obtained once the same amount of MP iterations are executed at any period of the training process.	suggestion
2020-913	For example, consider a simpler strategy: first train the model with BF16 for K% of the total training iterations, then for the last (100-K)% iterations, train it with MP.	suggestion
2020-913	K can be tuned so that the proportion of BF16FMA is close to those in Table 1.	suggestion
2020-913	Models trained with this strategy might achieve similar performance with the proposed Dynamic strategy.	suggestion
2020-913	3. It's hard to apply the proposed method in real applications, since BF16 is only supported by very few kinds of hardware.	weakness
2020-913	4. To demonstrate the effectiveness of the proposed method more clearly, it could be better to provide the exact proportion of reductions in terms of memory/computation/bandwidth in the experiments.	suggestion
2020-913	5. From Table 1, there still exists a large performance gap in terms of accuracy (1.56% for ResNet-50) between the model trained by the proposed method and the model trained by state-of-the-art MP.	weakness
2020-913	6. The organization of this paper can be improved.	weakness
2020-913	For example, Section 5.2 spends too much space introducing the emulation of BF16, which I think is not very relevant to the topic of this paper.	weakness
2020-913	And Figure 3 takes too much space.	weakness
2020-913	In this paper, the authors propose approaches to accelerate deep neural network training with mixed-precision arithmetic.	abstract
2020-913	Observed that relying purely on half-precision arithmetic results in lower accuracy, the authors developed a method to dynamically switch between mixed-precision arithmetic (MP) and half-precision arithmetic (BF16 FMA).	abstract
2020-913	Empirical results show that the dynamic approach can achieve similar accuracy as MP and FP32 algorithms.	abstract
2020-913	Although this paper shows the possibility to accelerate DNN training without great loss in performance, there are many issues with the paper itself.	weakness
2020-913	First, the title is ambiguous.	weakness
2020-913	The dynamic approach could mean a lot of things while training	weakness
2020-913	DNNs and one cannot tell what the paper is about simply relying on the title.	weakness
2020-913	Also, the dynamic algorithm itself is not well presented.	weakness
2020-913	For example, how to choose the hyperparameters?	weakness
2020-913	What is the overhead to switch between MP and BF16FMA?	weakness
2020-913	Apart from the algorithm itself, I also have questions regarding the experimental results.	weakness
2020-913	Is there a reason why the performance of the half-precision arithmetic varies across different neural networks (Inception > Resnet)?	weakness
2020-913	Specifically, what is the key factor that influences the sensitivity of a neural network towards precision?	weakness
2020-913	Overall I think this paper should be improved in its experiments and presentation.	weakness

2020-922	This paper asks whether it works to remove task-specific heads and treat classification and regression problems as span extraction, by formatting problems in such a way that a single span extraction model can be used.	abstract
2020-922	This is a reasonable question to ask, and the authors performed a very large number of experiments attempting to answer this question.	abstract
2020-922	The authors claim that using span extractive models instead of task-specific heads yields improved performance over separate heads.	abstract
2020-922	My main concern with this work is actually with something that would otherwise be a strength - the very large number of experiments.	weakness
2020-922	Looking at the results tables, I come to a different conclusion from the authors: there does not appear to be a significant difference between using a single head or using multiple heads (this is still an interesting conclusion).	weakness
2020-922	The numbers presented all appear to be within the bounds of random fluctuations, which are not controlled for at all with standard statistical testing methodologies.	weakness
2020-922	And with the very large number of experiments, there are bound to be some that stand out.	weakness
2020-922	This is especially true given the methodology used for small datasets - even if it was used by prior work, it is still not statistically sound to take the max of 20 samples from a training distribution and report the difference without any other statistical testing.	weakness
2020-922	As an example, look at table 3b.	weakness
2020-922	This is claimed as a big win for SpExBERT when comparing the MNLI fine-tuned version.	weakness
2020-922	But if you look at the other rows in the table, SpExBERT is worse than BERT by a *larger margin* than it is better in the MNLI case (contradicting the claimed result from table 2).	weakness
2020-922	And this general trend is seen across the tables - the differences are small and inconsistent, making it look very much like we are just seeing random fluctuations.	weakness
2020-922	This must be controlled for statistically in order to make any valid conclusions.	weakness
2020-922	The one possible exception here seems to be SST.	weakness
2020-922	Those results on the dev set do indeed seem to be more consistent, which is interesting, and hints at the utility of using "positive" and "negative" as natural language descriptions, as the authors claim.	strength
2020-922	It's not very convincing, however, as the test set difference is very small, and SpExBERT had more opportunities to find a good dev set number, as it had more experiments.	weakness
2020-922	My second major concern is with the experimental set up.	weakness
2020-922	The authors want to claim that using a unified span extraction format yields superior performance to having separate heads.	weakness
2020-922	But there are baselines missing to really demonstrate this claim.	weakness
2020-922	The multiple head setup isn't really evaluated as a baseline in most of the experiments (e.g., using SQuAD / other QA datasets as an intermediate task in table 2, using BERT for any of the QA datasets in table 3).	weakness
2020-922	So, even if the above issue of statistical testing were solved, it would still be very hard to evaluate the claim, as the proper comparisons are not present in the majority of cases.	weakness
2020-922	My main conclusion from reading this paper is that it does not appear to matter what head you use for these particular datasets.	weakness
2020-922	This is an interesting result, though it is not the one that is claimed in the paper.	weakness
2020-922	I think it would be very challenging to extend this approach to a broader set of tasks, however, as the authors suggest towards the end of the paper.	suggestion
2020-922	How do the authors propose handling cases where it is not feasible to put all possible outputs in the context?	suggestion
2020-922	This includes any generative task (including generative QA) and any kind of structured output (like parsing, tagging, etc.), or a regression task that does not lend itself well to bucketing.	suggestion
2020-922	Minor issues: I would be careful about claiming that you've successfully captured regression in a span extraction format.	suggestion
2020-922	You have one regression task, and it's one where the original labels were already bucketed, so the bucketing makes sense.	suggestion
2020-922	I am very skeptical that this would actually work for more general regression.	weakness
2020-922	Re the paragraph titled "SpEx-BERT improves on STILTs": Note that SpExBERT requires additional data preprocessing and hand-written templates when switching between tasks, which is not necessary in the method of Phang et al. There are always tradeoffs.	weakness
2020-922	Neither using separate heads nor doing your additional processing are very hard, so I wouldn't make as big a deal out of this as you do.	ac_disagreement
2020-922	If you want to talk about one of the methods using more "human inductive bias", or whatever, the hand-written templates in yours might actually be _more_ "incidental supervision" than a very small difference in model architecture.	suggestion
2020-922	But again, the difference here is very small, not worth noting in the paper.	weakness
2020-922	This paper introduces a method for converting sentence pair classification tasks and sentence regression tasks into span into span extraction tasks, by listing all the possible classes (entailment, contradiction, neural) or the discretized scores (0.0, 0.25 ...) and concatenating them with the source text.	abstract
2020-922	With this formulation, one can train a BERT-based span-extraction model (SpEx-BERT) on classification, regression, and QA tasks without introducing any task-specific parameters.	abstract
2020-922	The purposed SpEx-BERT model achieves moderate improvement (0.3 points) over the BERT-large baseline on the GLUE test set when fine-tuned on intermediate STILTs tasks (Phang et al., 2018).	abstract
2020-922	Strengths: - Extensive finetuning/intermediate-finetuning experiments on a range of NLP tasks.	strength
2020-922	- The paper is mostly well-written and easy to follow.	strength
2020-922	Weaknesses: - This paper presents a lot of experiments.	weakness
2020-922	But it seems that the most useful / head-to-head comparison against the BERT model are the last 2 rows in Table 2 with the GLEU results, where the improvement is moderate.	weakness
2020-922	- The idea of expressing various NLP tasks (including textual entailment and text classification) as question-answer has been well-explored in decaNLP (McCann et al., 2018).	weakness
2020-922	It would be nice if the authors could elaborate more on how the proposed method differs from theirs.	suggestion
2020-922	Other comments/suggestions: - Likely typo in abstract: "fixed-class, classification layers for text classification" This submission proposes a span-extraction approach to unify QA, text classification and regression tasks.	weakness
2020-922	The extensive empirical studies presented in this paper demonstrate that the proposed method can improve the performance by a small margin across multiple datasets and tasks.	weakness
2020-922	Overall, I find that the idea of unifying QA, text classification and regression is interesting by itself, but the experiments cannot justify their claims well mainly due to the mixed results.	weakness
2020-922	I have the following concerns: 0. Compared to decalNLP (https://github.com/salesforce/decaNLP), this new approach seems unable to handle as many types of tasks as decalNLP.	weakness
2020-922	It is not clear to me what is the main advantage.	weakness
2020-922	As discussed in the Related Work Section, decalNLP needs to fix the classifier a-priori, but this submission's method needs a natural language description, which seems more difficult to implement in practice.	weakness
2020-922	1. The results are mixed.	weakness
2020-922	For example, SpEx-BERT underperforms BERT on RTE and QNLI in Table 2 and Span-extractive multi-task learning results in weaker single-task models as shown in Table 4a.	weakness
2020-922	Furthermore, an error analysis would be helpful here.	weakness

2020-979	# Response to rebuttal I would like to thank their authors for their rebuttal.	rebuttal_process
2020-979	After reading the other reviews, the author response and the revised manuscript, I have decided to keep my score of weak reject for the time being.	decision
2020-979	In short, while I appreciate the effort the authors put in partly addressing some of the most important comments raised during the review process, I think the paper would greatly benefit from some additional work.	suggestion
2020-979	In particular: (1) Given the emphasis on scalability, I still believe the authors should carry out more thorough experiments to characterize the runtime of their approach with respect to different characteristics of the graphs.	rebuttal_process
2020-979	While the result provided in the response to Reviewer #3 is a first step, I recommend the authors to extend it by (1) varying graph size (in terms of nodes and edges); (2) varying graph type and (3) reporting the speedup with respect to other baselines.	suggestion
2020-979	(2) To the best of my knowledge, the ablation experiment in Section A.7.4 does not provide results for the setting in which no graph attention mechanism is used at all, neither for the case where the graph attention mechanism used is identical to GAT (restricted to 1-step neighbourhoods).	weakness
2020-979	(3) While NSPDK might be a reasonable choice, I still am of the opinion that the choice of graph kernel for this purpose is highly arbitrary and, thus, should be investigated further.	weakness
2020-979	Given that such a choice is being used to define a performance metric, which moreover is being highlighted as a contribution, the authors should study the robustness of the metric to the choice of graph kernel, as well as its sensitivity to known perturbations.	weakness
2020-979	(4) Finally, I did not see any error bars added to the main results in the paper.	weakness
2020-979	Despite these shortcomings, I would like to reiterate that I believe the proposed approach is promising and, with some additional work, would be a contribution definitely worth publishing.	decision
2020-979	Therefore, I would like to encourage the authors to further revise the manuscript.	suggestion
2020-979	# Summary In this paper, the authors propose an auto-regressive deep generative model for graph-structured data, motivated by the goal of scalability with respect to graph size, graph density and sample size.	abstract
2020-979	In a nutshell, the approach follows closely the ideas in [1, 2], which model graph generation as an auto-regressive process after fixing or sampling an ordering for the nodes.	abstract
2020-979	Unlike [1, 2], however, the proposed method makes use of graph convolutions and a graph attention mechanism, closely related to GAT [3], to parametrize the conditional distributions of node/edges given the previously generated graph elements.	abstract
2020-979	The performance of the proposed approach is evaluated in comparison to [1, 2] in several synthetic and real-world datasets, using MMD [4] between generated and held-out test graphs as metric.	abstract
2020-979	Unlike [2], which applies MMD on three graph statistics (degree, clustering coefficient and average orbit counts), this manuscript proposes to evaluate MMD using a graph kernel as well [5].	abstract
2020-979	# High-level assessment The main contribution in this paper is to combine a graph attention mechanism, which can be seen  as a simplification of GAT [3], with deep autoregressive graph models, such as DeepGMG [1] or GraphRNN [2].	strength
2020-979	In this way, the manuscript has a large conceptual overlap with the method in [6], which can be nevertheless be regarded as concurrent rather than prior work.	strength
2020-979	From a methodological perspective, I believe the contribution is sound and sufficiently novel, although perhaps slightly on the incremental side.	strength
2020-979	However, the current version of the manuscript has shortcomings regarding (i) lack of clarity in the exposition of the method's relation to prior work, low-level implementation details and experimental setup and (ii) insufficient experimental results to back up some of the authors' claims.	weakness
2020-979	Nonetheless, I believe the proposed approach is promising, and encourage the authors to address or clarify these issues during the author discussion phase.	suggestion
2020-979	# Major points / suggestions	misc
2020-979	1. The manuscript presents the proposed approach in a way that does not clearly differentiate between prior work and original contributions.	weakness
2020-979	In particular, I believe that the ideas in Section 3.1 and 3.2 are almost identical to those in [1, 2], the graph attention mechanism in Section 3.3 can be seen as a minor modification of GAT [3], and Section 3.4 also has a strong conceptual overlap with [1, 2].	weakness
2020-979	I would encourage the authors to be more clear with respect to what is novel and what is borrowed from prior work.	suggestion
2020-979	Moreover, when slightly departing from prior work (e.g. the modifications applied to the graph attention mechanism in Section	suggestion
2020-979	3), I would also encourage the authors to focus on explaining what specifically has changed and what is the rationale behind those design choices, rather than explaining the entire mechanism "from scratch", leaving up to the reader to figure out what is novel.	suggestion
2020-979	2. The paper's clarity could be improved, with some parts presented in an unnecessarily complicated manner (e.g. the graph attention mechanism) and others without sufficient detail (e.g. the edge estimator module, the zero-ing heuristic for attention or the generation of graphs based on "seed graphs", which is only mentioned in the appendix).	weakness
2020-979	For example, regarding the graph attention mechanism, I would recommend: (i) explaining more clearly what the "feature vector of node vi" is exactly in relation to the notation of Section 3.1;	suggestion
2020-979	(ii) if the query, key and value matrices are identical, as the text seems to imply, I would rewrite the equations directly in terms of X which would simplify the notation significantly;	suggestion
2020-979	(iii) perhaps most importantly, the bias functions bQ, bK and bV should be defined mathematically and discussed in greater detail and	weakness
2020-979	(iv) the output FNN should also be described mathematically.	weakness
2020-979	Finally, as mentioned above, I would emphasise the differences between the proposed attention mechanism and GAT.	suggestion
2020-979	The edge estimator mechanism is described too imprecisely in Section 3.4.4.	weakness
2020-979	While Section A.4 definitely helps, I would recommend defining the entire operation mathematically in Section 3.4.4 as well.	suggestion
2020-979	Likewise, a precise mathematical definition of GRAM-A in Section 3.5.2 would also be helpful.	suggestion
2020-979	Finally, as mentioned in this forum by Prof.	misc
2020-979	Ranu prior to this review's writing, the graph generation procedure described in Section A.7.2 seems unconventional.	weakness
2020-979	I would encourage the authors to both clarify what they mean by "for the convenience of implementation" and to investigate whether the experimental conclusions are affected by this departure from prior practices.	suggestion
2020-979	3. Key details about the experimental setup, such as the hyperparameter selection protocol for the proposed approach and baselines, as well as the resulting architectures, seems to be missing, making it difficult to assess if the experimental setup is "fair".	weakness
2020-979	In particular, all methods should be allowed to use a similar number of parameters or, alternatively, have their hyperparameters tuned equally carefully for each dataset separately.	weakness
2020-979	4. Most importantly, I believe the experimental results are insufficient to back up some of the claims made in the introduction.	weakness
2020-979	4.1. Despite the focus on scalability throughout the motivation, there are no experiments systematically exploring how the runtime at train and test time of the proposed approach and the main baselines scales with respect to sample size, number of nodes per graph and graph density.	weakness
2020-979	Moreover, no results are provided for large graphs (e.g. ~5k nodes as in [6]).	weakness
2020-979	4.2. The graph attention mechanism was claimed to be an original contribution.	weakness
2020-979	However, no results are provided to evaluate its advantages with respect to the different GAT variants nor ablation studies to see its usefulness relative to a variant of the proposed approach using only graph convolutions.	weakness
2020-979	4.3 The idea of using MMD in conjunction with graph kernels as a performance metric is interesting.	weakness
2020-979	However, there is no investigation of key aspects such as (i) its relation to other metrics and (ii) the impact that the choice of graph kernel, among the many available, and/or of graph kernel hyperparameters has on the resulting metric (see [7] for a comprehensive review on graph kernels).	weakness
2020-979	4.4. Finally, the results have been reported without error bars, making it difficult to quantify the statistical significance of the observed performance differences between approaches.	weakness
2020-979	# Minor points / suggestions	misc
2020-979	1. I strongly believe the authors should adapt the manuscript to mention [6] and related/concurrent work.	suggestion
2020-979	Ideally, including it as an additional baseline would be even better, but not necessary given the limited rebuttal time.	suggestion
2020-979	Nevertheless, this point was not taken into consideration when scoring the manuscript, given how recent [6] is.	suggestion
2020-979	# References [1] Li, Yujia, et al. "Learning deep generative models of graphs." *International Conference on Machine Learning.* 2018.	misc
2020-979	[2] You, Jiaxuan, et al. "Graphrnn: Generating realistic graphs with deep auto-regressive models." *International Conference on Machine Learning.* 2018.	misc
2020-979	[3] Veličković, Petar, et al. "Graph attention networks." *International Conference on Learning Representations*.	misc
2020-979	2018. [4] Gretton, Arthur, et al. "A kernel method for the two-sample-problem." Advances in Neural Information Processing Systems.	misc
2020-979	2007. [5] Costa, Fabrizio, and Kurt De Grave.	misc
2020-979	"Fast neighborhood subgraph pairwise distance kernel." Proceedings of the 26th International Conference on Machine Learning.	misc
2020-979	Omnipress; Madison, WI, USA, 2010.	misc
2020-979	[6] Liao, Renjie, et al. "Efficient Graph Generation with Graph Recurrent Attention Networks." *Advances in Neural Information Processing Systems.* 2019.	misc
2020-979	[7] Kriege, Nils M., Fredrik D.	misc
2020-979	Johansson, and Christopher Morris. "A Survey on Graph Kernels." *arXiv preprint arXiv:1903.11835* (2019).	misc
2020-979	This paper presents a formulation of graph generative models based on graph attention aimed at scalability of these methods.	abstract
2020-979	The paper is generally written well and I like the overall theme of the paper, however, there are a few key issues with this work and I don't think the paper as it stands is ready for publication: 1) The main motivation expressed in the paper is that graph generative models are generally not scalable and they identify three main areas: (a) graph size (i.e. num nodes); (b) data scalability (i.e. num training samples); (c) label scalability (i.e. num of node or edge types).	decision
2020-979	However, the paper doesn't follow on why the proposed method actually addresses these issues.	weakness
2020-979	The derivation doesn't talk about scale until we reach section 3.5 and then we find out that actually the proposed model is O(n^3) in reality.	weakness
2020-979	Then there are approximations to make it scale.	weakness
2020-979	So for me there is a massive disconnect between the main motivation of the paper and the suggested model.	weakness
2020-979	Why not study approximation methods for already existing graph generator models?	weakness
2020-979	2) Following on the theme of scale, the only experimental result discussing this is the time column reported for the training time.	weakness
2020-979	So that partially addresses the data scalability.	weakness
2020-979	Other baselines as well have reasonable training times specially when it comes to large datasets (e.g. ZINC is that the largest dataset studied with 250K samples and GraphRNN is 2x slower and GraphRNN-S only about 20%).	weakness
2020-979	What I was looking for was when you really can train on real-world datasets that other methods basically can't be trained.	weakness
2020-979	The datasets chosen all are small hence there's not much issue with scale there.	weakness
2020-979	The question about the scalability w.r.t. other aspects (i.e. num nodes and num labels) has not been studied or reported.	weakness
2020-979	3) The approximations suggested in section 3.5 also don't seem to have much impact on the training time.	weakness
2020-979	These approximations were motivated by the scale while looking at the training times they barely make any difference.	weakness
2020-979	However, they make a big difference in performance metrics specially in smaller datasets.	weakness
2020-979	So the question that comes to mind is that what is the role of these approximations w.r.t. the quality of the models?	weakness
2020-979	Again this question needs further study.	weakness
2020-979	4) Comparing GraphRNN and GraphRNN-S's modifications with the results from the original paper, it seems they are performing much worse (e.g. deg for the original GraphRNN-S is 0.057 while the reported num here is 0.523 for Protein dataset).	weakness
2020-979	The same is true for other metrics.	weakness
2020-979	Why is that? 5) As pointed out by an observer, it seems that there are nuances to generation of the graph needing seeds of arbitrary size to be provided, explained deep down in the appendix.	weakness
2020-979	If this is the case for generation then it should be discussed in the main part of the paper and contrasted with methods that can start from scratch.	weakness
2020-979	6) In the training configuration part of the appendix, A.7.2 it seems there are discrepancies in number of GPUs as well kinds of GPUs used for each method.	weakness
2020-979	When reporting training times in the main section, do you normalise against these?	weakness
2020-979	7) It seems that many hyperparameters mentioned in A.7.2 are chosen in an ad-hoc manner without proper model selection and seem to vary across each different versions of GRAM for each different dataset.	weakness
2020-979	How sensitive is the model to these hyperparameters?	weakness
2020-979	I suspect if the model was insensitive, you could've fixed them for many of these experiments, but seems that is not the case.	weakness
2020-979	So without proper model selection routines, the results may not be representative of what the model discussed.	weakness
2020-979	Minor comment: The model suggested has some similarities to DEFactor model from Assouel et al 2019 in terms of formulation of the problem for labelled graphs (nodes as a matrix and adj as a tensor), though the underlying models are very different, that paper as well targets arbitrary size graph generation and efficiency w.r.t.	weakness
2020-979	model parameters. This paper presents new graph generative model (GRAM) which claims to tackle the scalability issue found is most of the published models.	abstract
2020-979	The propose architecture can scale on graphs from three perspective - number of graphs, number of nodes/edges and number of node/edge labels.	abstract
2020-979	This is achieved by sequentially generating the subgraph using graph attention and graph convolutional layers.	abstract
2020-979	While training, each of these subgraph can be trained in parallel.	abstract
2020-979	Further, paper applies couple of heuristics to reduce computational time and introduces a new non-domain specific evaluation metric for the generation of node/edge labeled graphs.	abstract
2020-979	Although the paper claims to propose simplified mechanism, I find the generation task to be relatively very complex in comparison to GraphRNN and GRAN (published at NeurIPS'19).	weakness
2020-979	As mentioned below, the use of certain module seems ad-hoc.	weakness
2020-979	Further, the results on the new metric is at times inconsistent with other prior metrics.	weakness
2020-979	In lieu of this, currently the paper leans towards rejection.	decision
2020-979	I would be happy to improve my score if some of the below-mentioned concerns are addressed.	suggestion
2020-979	Clarification: 1. What is the unit for time in Table 1 ?	suggestion
2020-979	Is it inference time or training time ?	weakness
2020-979	2. In my experience, the change in quantitative number do not necessarily reflect improvement in qualitative output.	weakness
2020-979	The metric GK is inconsistent.	weakness
2020-979	For example, on grid - GraphRNN is better on three metrics while GRAM gives the best results on GK.	weakness
2020-979	On community, there is a wide discrepancies between GraphRNN and GraphRNN-S model for most metrics but for GK.	weakness
2020-979	3. Can you guide me on qualitative results of community and B-A graphs data ?	suggestion
2020-979	Currently, nothing could be interpreted from these plots.	weakness
2020-979	Moreover, why the training set of community graph fails to show 4 commnities ?	weakness
2020-979	May be you should modify the data generation process.	weakness
2020-979	Concern and Additional Experiments: 1. Please use standard Grid graph dataset as used in the literature - max |V| = 361.	suggestion
2020-979	Moreover, I was wondering how do one generate 500 grid graphs with just max 100 nodes ?	suggestion
2020-979	Since these graphs are not random.	suggestion
2020-979	2. Node scalability - GRAM has been employed only on graphs of maximum size 500 nodes.	weakness
2020-979	This does not confirm scalability.	weakness
2020-979	The advantage of parallel training of GRAM as against sequential GraphRNN should be showcased on large graphs of atleast 5000 nodes.	weakness
2020-979	3. Please include results on newer models pub lished at NeurIPS'2019 - Graph Recurrent Attention Network (GRAN) and Graph Normalizing flows (GNF).	suggestion
2020-979	4. No one model among GRAM is projecting out to be best.	weakness
2020-979	On couple of data, GRAM is best, while on others GRAM-A or GRAM-B is better.	weakness
2020-979	5. During inference, GRAM needs to compute the shortest path length among different nodes.	weakness
2020-979	This will surely not scale up with increasing nodes.	weakness
2020-979	Moreover, from Table 6 it is inconclusive whether that bias term is useful.	weakness
2020-979	How does the results look if both the biases are removed ?	weakness
2020-979	6. I note that each input node vector stacks degree and clustering coefficient information.	weakness
2020-979	How one obtains this information during inference ?	weakness
2020-979	Yet again, it will face scalability issue as above.	weakness
2020-979	7. The above concern also highlight the fact that the statistics of measured metrics (degree and clustering coefficients) are utilized during training.	weakness
2020-979	It seems more like a hack to me.	weakness
2020-979	No wonder this leads to performance boost of GRAM.	weakness
2020-979	Please share ablation study on this.	suggestion
2020-979	8. Please explain how Graph convolutional complements the processing in graph attention.	suggestion
2020-979	Is both required ? Can you share ablation study on this ?	suggestion
2020-979	Minor: 1. The models categorized as unsupervised indeed trains using supervision of edge connectivity.	weakness
2020-979	2. Frist -> First	weakness

2020-994	This work proposes a method to transfer information from PET imaging data from the medical domain, where data is highly available, to the industrial one, where data is scarce, in the context of non-destructive material quality evaluation.	abstract
2020-994	The basic idea seems interesting, but unfortunately in the present form he paper is very difficult to appreciate, as it lacks of important details concerning methodology, experimental results, and comparison with respect to the state-of-the-art.	weakness
2020-994	Moreover, the manuscript still appears in a draft form.	weakness
2020-994	Sentences are often broken, the text presents many typos and grammar mistakes, and the citations are not understandable.	weakness
2020-994	Missing methodological details are grouped in the following parts of this review.	weakness
2020-994	Section 3.2 Encoder Paragraph 2: The authors claim that they introduce the knowledge of migration learning without explaining it.	weakness
2020-994	Where does this concept come from?	weakness
2020-994	Is there a literature about it or is this a new concept?	weakness
2020-994	Medical images are fitted though a variational auto encoder (VAE) (citation missing).	weakness
2020-994	The encoder description is minimal and lacks of implementation details (see Eq. 3), while the decoder description is missing throughout the paper.	weakness
2020-994	Eq. (2): the authors write that they obtain a distribution p(x) according to Eq.	weakness
2020-994	(2), but this equation is just the formula for the sample mean, where p(x) is sampled and not computed.	weakness
2020-994	Eq. (3): f1 and f2 are never made explicit in the paper so we do not know if they are linear or non-linear functions.	weakness
2020-994	The prior p(Z) is decomposed as a summation of posteriors p(Z|X) and the choice to have these posteriors equal to N(0,1) (1-dimensional, which is unusual) regardless of the data point X is not explained.	weakness
2020-994	Section 3.3 Feature extraction memory module	weakness
2020-994	Feature extraction from industrial images is done through principal component analysis (PCA).	weakness
2020-994	In the same paragraph is written that features are extracted through convolution neural networks (CNN).	weakness
2020-994	So it is not clear if there is an arbitrary choice to use PCA or CNN, and what are the conditions when this happens.	weakness
2020-994	Eq. (6): the score between z_t (medical image distribution) and y_s (industrial image feature vector) is computed as scalar product dot(z_t , W_a * y_s).	weakness
2020-994	The key link is the linear mapping W_a, which is never made explicit in the paper.	weakness
2020-994	How do the authors compute W_a ?	weakness
2020-994	Section 4.1 Implementation details the networks called "identification network" and "front-end network" are not well defined.	weakness
2020-994	They may refer to the  VAE, the CNN, the Adversarial Nets.	weakness
2020-994	There is too much ambiguity.	weakness
2020-994	A captioned figure can help in resolving the ambiguities.	weakness
2020-994	Section 4.2 Dataset In the first paragraph the authors cite a dataset of CT images, while the main focus of the paper is on PET images.	weakness
2020-994	How the CT images comes into play?	weakness
2020-994	Section 4.3 Evaluation The authors compare their method with respect to other three methods, namely VAE, DCGAN, and WGAN.	weakness
2020-994	The implementation details of the competing methods are not described so we cannot be sure about the fairness of the comparison.	weakness
2020-994	Other considerations Introduction, 4th paragraph: "imaging quality is higher" With respect to what?	weakness
2020-994	Usually PET images have the worst quality in the medical domain.	weakness
2020-994	Introduction, 3rd-to-last paragraph: "We use the medical CT image ...".	weakness
2020-994	Should be PET images Related work: This section is a list of works and the relation with the current paper is not highlighted.	weakness
2020-994	"lung cancer cakes" what are they?	weakness
2020-994	Paragraph 3.2: "excessive pursuit of quality" why is it bad?	weakness
2020-994	"migration learning" do they mean transfer learning?	weakness
2020-994	Equation 2 and 3 in relation to a clustering problem never pointed out before in the paper.	weakness
2020-994	Paragraph 4.1. What is the meaning of "Adam algorithm(=0.5)" ?	weakness
2020-994	Figures 1 and 2 have very minimal captions.	weakness
2020-994	What do they represent? Citation formatting problem: name and surname are switched.	weakness
2020-994	Journal/conferences often omitted. This paper applies GAN to the field of nondestructive testing for specific industries.	weakness
2020-994	This paper is more like a technical report rather than a formal paper.	weakness
2020-994	It seems to me that this paper should be submitted to other computer vision conferences of even specific areas while not in *CONF*.	decision
2020-994	Issues: * Bad format or organization.	weakness
2020-994	The authors are suggested that they should give a subtitle of each categories of work in the related work section.	suggestion
2020-994	The table and picture in this paper are arbitrarily designed and take too much space.	weakness
2020-994	In some equations, you need to put commas to separate different equations.	weakness
2020-994	* Acknowledgements reveal personal information in the paper.	weakness
2020-994	It's not allowed in *CONF* submission that would review the identity of the authors.	weakness
2020-994	This is a highly critical issue.	misc
2020-994	* Bad writing. I can barely understand what the authors are talking about.	weakness
2020-994	For example, "In this paper, we propose adversarial networks of positron image memory module based on attention mechanism".	weakness
2020-994	Are you referring you proposed a new GAN model in the paper?	weakness
2020-994	Or you proposed a positron image memory module?	weakness
2020-994	... * What are the functions of the metrics used in the experimental part?	weakness
2020-994	The higher, the better? Or the lower, the better?	weakness
2020-994	Besides, you need some analysis to illustrate the significance of your results.	weakness
2020-994	Considering these issues demonstrated in the paper, I recommend rejection.	decision
2020-994	The topic of the paper is a GAN framework to enhance PET images in industrial inspection, as far as I understand by transfer learning from a medical PET database.	abstract
2020-994	Unfortunately, I am unable assess the paper due to serious language problems.	misc
2020-994	The text is incoherent and not understandable, it is impossible to decipher what is actually proposed.	weakness
2020-994	Additional Comments: The text reads like a machine translation gone wrong, including weird terms like "migration learning" (transfer learning?), "antagonistic generation network" / "countermeasure generation network" / "confrontation network" (GAN?).	weakness
2020-994	References are also mangled and undecipherable.	weakness
2020-994	And seemingly also not always well-chosen - even if I cannot map it to a paper due to bibtex problems, it appears implausible to reference a 2015 paper for something as basic as principal component analysis.	weakness
2020-994	It seems that the only experiments are on simulated PET data.	weakness
2020-994	In may view that would be insufficient for a largely empirical application paper.	weakness
2020-994	The paper claims to be quantitatively better than the baselines, but has, by far, the highest Frechet Inception distance.	weakness
2020-994	To my understanding, FID is a distance, lower is better.	weakness

2020-995	POST-REBUTTAL FEEDBACK I share the same concerns as that of reviewer 2 in the response to the rebuttal.	rebuttal_process
2020-995	Hence, my score remains unchanged.	rebuttal_process
2020-995	SUMMARY OF REVIEW This paper motivates the need to "contextualize" responses based on the query to bring about stable training in NRG and consequently proposes localGAN to realize this.	abstract
2020-995	On the overall, I like the motivation and the proposed approach of this paper.	strength
2020-995	The experimental results also look convincing.	strength
2020-995	On the flip side, the technical formulation and theoretical results are not presented rigorously and important technical details are missing, as discussed below.	weakness
2020-995	As a result, clarifications from the authors are needed to ensure the correctness of their formulation.	rebuttal_process
2020-995	The authors also need to improve the presentation and proof of the theoretical results; the correctness has to be checked again.	weakness
2020-995	In my opinion, these theoretical results do not improve my current assessment of the paper and can be removed to cut down to 8 pages.	weakness
2020-995	If the authors like to keep them, they need to revise them based on my concerns above.	suggestion
2020-995	It would be good to show some sample queries and corresponding "meaningful" responses produced by their proposed LocalGAN that are not considered safe responses which are produced by the other tested methods.	suggestion
2020-995	DETAILED COMMENTS For Lemmas 1 and 2 and Theorem 1, the authors need to present them rigorously by specifying the exact math expressions since they have not defined what it means by sufficient, approximates, small enough, and estimate properly.	suggestion
2020-995	This will also eliminate any discrepancy in their interpretations.	suggestion
2020-995	For example, the authors have used Taylor series expansion to approximate the expectation of F(q,r) in equation 19 (instead of bounding it).	suggestion
2020-995	Hence, one can claim that Lemma 2 does not hold and hence Theorem 1 does not hold as well.	weakness
2020-995	In Section 4.3, the described mechanism is confusing to me: (a) Are the authors saying that it is performed sequentially from foundation to phase-1, followed by phase-2?	weakness
2020-995	Or are the authors saying that these three phases are expected behaviors occurring during the optimization in equation 17?	weakness
2020-995	(b) For the foundation phase, is the DBM pre-trained, that is, prior to optimization in equation 17?	weakness
2020-995	(c) Are there multiple response clusters, that is, one for each q?	weakness
2020-995	If so, the second RELU term in the minimizing criterion in equation 17 does not seem to properly reflect this.	weakness
2020-995	(d) How are the response cluster centers r_c exactly determined?	weakness
2020-995	The authors vaguely say that they are modeled from training data.	weakness
2020-995	Is it one center per response cluster?	weakness
2020-995	Are the cluster centers also optimized in equation 17, besides the generator's weights?	weakness
2020-995	Can the authors provide the argument under the min operator in equation 17?	weakness
2020-995	It is confusing to leave out r_c from the subscript of alpha.	weakness
2020-995	I would have preferred that the authors specify the expression of the evaluation metrics to be self-contained.	weakness
2020-995	In Fig. 2, how exactly do the authors measure stability?	weakness
2020-995	If the entropy rapidly increases like that of LocalGAN and Adver-REGS, are they considered stable?	weakness
2020-995	Minor issues Page 1: Despite of? Page 3: inequation?	weakness
2020-995	Page 3: Equation 4 and 5?	weakness
2020-995	Equation 6: The first summation should just be over q, unless there are multiple sets of R_q per q.	weakness
2020-995	tilde{R}_q is not used in equation 6.	weakness
2020-995	Page 4: a limited samples?	weakness
2020-995	Page 5: defined in 3.2?	weakness
2020-995	Page 5: To be consistent, mathbb should be applied to E.	weakness
2020-995	Page 9: valid this aspect?	weakness
2020-995	Page 9: from the the?	weakness
2020-995	Contributions: The main contribution of this paper lies in the proposed LocalGAN for neural response generation.	strength
2020-995	The key observation is that for a given query, there always exists a group of diverse responses that are reasonable, rather than a single ground-truth response.	weakness
2020-995	Therefore, the local semantic distribution of responses given a query should be modeled.	weakness
2020-995	Besides the original GAN loss, the proposed LocalGAN adds an additional local-distribution-oriented objective, resulting in a hybrid loss for training, which claims to achieve better performance on response generation datasets.	weakness
2020-995	Strengths: I think the proposed model contains some good intuitions, that is, the generated responses should be modeled as a local distribution, rather than a single ground-truth output during training.	strength
2020-995	The motivation of this paper is therefore clear.	strength
2020-995	Experimental results in Table 1 seems encouraging.	strength
2020-995	However, I would have to say that the current draft is poorly presented.	weakness
2020-995	There are a lot of unclear parts that should be more carefully clarified, with details below.	weakness
2020-995	Weaknesses: (1) Writing: I think the language in this paper is repetitive, and can be much more precise and concise.	weakness
2020-995	Also, there are typos here and there throughout the whole draft.	weakness
2020-995	I would suggest the authors doing a careful proofreading before next submission.	suggestion
2020-995	Minor: in the line before Eqn.	weakness
2020-995	(4), change "SIMPLY" to "simply".	suggestion
2020-995	(2) Clarity: Overall, the presented method is unclear.	weakness
2020-995	a) It is not entirely clear what the authors mean by saying "this paper has given the theoretical proof of the upper-bound of the adversarial training ...".	weakness
2020-995	I am not sure whether Eqn.	weakness
2020-995	(6) is totally correct, or at least how useful it is.	strength
2020-995	b) The notations throughout the paper is a little bit confusing.	weakness
2020-995	The authors should normalize all the notations to be consistent.	weakness
2020-995	c) It is not clear what Eqn.	weakness
2020-995	(3) truly means. What is the value for s?	weakness
2020-995	The KL divergence should take two distributions as input, but here, the input are two triplets.	weakness
2020-995	d) In the line below Eqn.	weakness
2020-995	(6), what is \\tilde{R}_q? This is not defined.	weakness
2020-995	e) The proposed method relies on the use of R_q.	weakness
2020-995	However, how to define, or learn R_q is not clear.	weakness
2020-995	In the dataset, given a given query q, how do we find R_q?	weakness
2020-995	f) It is not clear why Deep Boltzmann Machines are needed here.	weakness
2020-995	I'd like the authors to more clearly clarify this design.	suggestion
2020-995	Further, since DBM is used, then how the final model is trained together?	weakness
2020-995	Now, the models contains both adversarial learning, and contrastive-divergence-based algorithms for DBM training.	weakness
2020-995	This seems make the whole model training more unstable.	weakness
2020-995	g) Generally, I think Section 3 and Section 4 are hard to follow.	weakness
2020-995	Further, I did not see how useful Lemma 1 & 2 and Theorem 1 are.	weakness
2020-995	The final objective Eqn. (17) is also confusing.	weakness
2020-995	(3) Experiments: My biggest concern about the experiments is that human evaluation should be conducted, given the subjective nature of the task.	weakness
2020-995	This is lacked in the current draft.	weakness
2020-995	Only reporting numbers like Table 1 is not convincing.	weakness
2020-995	** This paper provides a link that actually links to a github repo.	weakness
2020-995	I am not sure whether this violates the policy of *CONF* submissions or not.	weakness
2020-995	But at least from my point of review, this link should be anonymized.	weakness
2020-995	** In this paper, the author proposed a model to address the training instability of a GAN model on the NRG task.	abstract
2020-995	The authors take advantage of an energy based model to measure the distance between a predicted response and the center of all qualified responses.	abstract
2020-995	The training process becomes a hybrid one with the original loss function in the beginning followed by the loss that pulls the response to the center of the response cluster later.	abstract
2020-995	In general the paper is well written, with experiments clearly showcased improved training stabilities.	strength
2020-995	However, one major flaw in the experiments in that the authors almost only compared diversity measures such as Dist-1, Dist-2 and Ent4.	weakness
2020-995	These measures did not take into consideration the matches between the predicted one and the ground truth.	weakness
2020-995	The only relevance measure used in this paper is the  Rel., which the authors defined as the average of embedding distances.	weakness
2020-995	Such a measure is by no means an objective measure and can't really demonstrate the effectiveness of the model in terms of generating responses that are close to the ground truth.	weakness
2020-995	The authors would need to submit results on one of the widely adopted benchmark metrics (e.g., BLEU, ROGUE) or their equivalents in order to demonstrate the quality of the generated response.	suggestion
2020-995	And this is the main reason of my rating recommendation.	misc

2020-1011	This paper presents a VAE architecture that separates a fixed content representation and time varying features of an image, that can be used to learn a representation of image transformations in a temporal setting.	abstract
2020-1011	The paper is well written and the ideas presented are interesting, but in my opinion not novel enough or thoroughly demonstrated to justify acceptance: - there is a very relevant work that is not mentioned by the authors and that can be seen as a generalization of the model presented in this paper: "Disentangled Sequential Autoencoder" by Li and Mandt (ICML 2018), which introduces a model that is also disentangling a content and a temporal representation of sequential data.	decision
2020-1011	This is basically the more general model introduced by the authors of this submission in the beginning of section 2, without all the assumptions made in the rest of section 2.	weakness
2020-1011	A comparison with this related work would help assess the differences in terms of modelling power and in performances.	suggestion
2020-1011	- The assumptions made in this work are fairly strong for most interesting applications, in particular the fact that the content cannot change across time steps.	strength
2020-1011	- To me, the issue with the novelty of this model would not be a big problem if the authors focused more on showing its usefulness in different applications (e.g. medical domain or RL as mentioned in the conclusions).	ac_disagreement
2020-1011	However, the authors only demonstrate the TEVAE on relatively simple experiments that are only tailored to simple image transformations.	weakness
2020-1011	Review of "Unsupervised-Learning of time-varying features"	misc
2020-1011	This work looks at using a conditional VAE-based approach to model transformations of sequential data (transformations can be spatial, such as rotation of MNIST, or temporal, i.e. screenshots of a car racing game).	abstract
2020-1011	Like how our own visual system encodes differences in time and space [1], they show that in generative modelling with VAEs, "there is an advantage of only learning features describing change of state between images, over learning the states of the images at each frame."	abstract
2020-1011	Such an encoding allows the model to ignore features that are constant over time, and also makes it easier to represent data in a rotating curved manifold.	abstract
2020-1011	They demonstrate this using data collected from CarRacing-v0 task (a task where agents have to learn to drive from pixel observation of a top-down track), and also on MNIST where the digits are rotated around the center of an image.	abstract
2020-1011	They provide interesting analysis of the latent space learned and show that indeed this approach can handle both stationary and non-stationary features well (in CarRacing-v0).	abstract
2020-1011	For MNIST, they compare the latent space learned from transformations (z_dot) and show that this approach can encode image geometric transformations quite well.	abstract
2020-1011	While this paper is interesting and highlights advantages of modeling transformations of sequential data, I don't think the contributions are currently sufficient for *CONF* conference (right now it is a good workshop paper IMHO).	decision
2020-1011	For it to be at the conference level, I can make a few suggestions of things that will bring it there, hopefully the authors can take these points as feedback to help improve the work: 1) Would be great to see how this approach can compare to existing proposed algorithms (i.e. TD-VAE as cited)?	suggestion
2020-1011	Are there problems where this approach will perform really well that current methods are inadequate?	suggestion
2020-1011	2) As the method is based on an RL-task, would the latent representation learned be useful for an RL agent that relies on the latent code across several representative RL tasks (in both sample efficiency, and/or terminal performance)?	suggestion
2020-1011	I don't mean to discourage the authors (esp as an Anon Reviewer #2...), as I like the direction of the work, and also appreciate that a lot of effort has gone into this work.	misc
2020-1011	I hope to see the authors take the criticism to make their work better.	suggestion
2020-1011	Good luck! [1] Concetta1988, Feature detection in human vision: A phase-dependent energy model This paper presents a VAE model.	misc
2020-1011	The authors consider time series data and claim that in this situation it is better to model the transformations in the latents instead of each datum independently.	abstract
2020-1011	The setup is reasonable and seems novel, but since it stops at image registration, which is a well-known existing model I cannot qualify the paper as novel.	weakness
2020-1011	The paper is mostly clear, some claims are not backed up by experiments and the experiments are lacking.	weakness
2020-1011	As I motivate below I find the current content more at a workshop level than a conference paper.	decision
2020-1011	Major issues: * This paper can become a conference paper in two ways in my opinion.	weakness
2020-1011	1) It either needs to show that richer modeling has benefits (if anything it would seem from fig 5 that this is not the case).	weakness
2020-1011	A way towards that would be to take data where there are no simple transformations that we can introduce and show that it discovers reasonable ones.	suggestion
2020-1011	And 2) show on some highly varying temporal domain that this is better than differences of z.	suggestion
2020-1011	* on page 2 " the initial assumption that the time-series must be stationary can be fulfilled" -- The data doesn't have to comply with our standards of stationarity.	weakness
2020-1011	A more sensible formulation is we add these additional constraints to our model which are correct if the data is stationary.	suggestion
2020-1011	* On page 3 "to make sure that the latent space can be interpreted".	suggestion
2020-1011	This is a very strong claim, it implies that if we do this the latent space will always be interpretable, which I think is false and definitely not backed up by experiments.	weakness
2020-1011	* The conditions on \\dot{z} are interesting and potentially useful and they should be explored in experiments.	weakness
2020-1011	Putting them in or not does it really make the sense that we think it should make ?	suggestion
2020-1011	Ideally in a setup where the data is not trivial.	weakness
2020-1011	* I am not sure what insight a reader can possibly get from figure 3.	weakness
2020-1011	* Given the final image-registration setup I find that the following citations are necessary: jaderberg et al. Spatial transformer networks, Shu et al. Deforming auto-encoders: unsupervised disentangling of shape and appearance.	suggestion
2020-1011	Minor issues: * the authors should number all equations.	weakness
2020-1011	* In their first equation (not numbered) the indices go beyond N+1.	weakness

2020-1036	This paper proposes a new understanding of dropout on top of variational dropout, which shows that training with dropout equals to maximizing an empirical variational lower bound on the log-likelihood.	abstract
2020-1036	This paper shows that the log posterior have the same lower bound when the inference model p(y|x) is defined by different methods, i.e., the arithmetic mean of predictions with different dropout masks, the geometric mean, and a power-mean family as an interpolation between these two cases.	abstract
2020-1036	This indicates that with the same training objective, different inference methods have different gaps to the posterior lower bound.	abstract
2020-1036	Intuitively, a smaller gap might lead to better performance.	abstract
2020-1036	The paper then uses an existing result from Liao & Berg (2017) to show that the gap can be bounded by the variance of prediction probability.	abstract
2020-1036	With empirical observations, the paper gives an unrigorous conclusion that the deterministic inference with dropout rate 0 achieves the smallest gap.	abstract
2020-1036	However, this does not hold theoretically due to the extra bias on expectation.	abstract
2020-1036	The optimality of deterministic inference does not hold empirically due to class imbalance or discrepancy between training and test sets.	abstract
2020-1036	The paper then proposes two practical solutions for better inference: 1) tuning dropout rate, softmax temperature, and the power mean parameter; and 2) deterministic inference with tuned softmax temperature.	abstract
2020-1036	By using the first inference solution, the performance on PTB and Wikitext2 LM can be improved by 2-3 on perplexity but is still slightly worse than the SOTA achieved by the mixture of softmaxes.	abstract
2020-1036	The idea of analyzing the gap to variational posterior lower bound for different dropout inference model is interesting.	strength
2020-1036	The derivations are correct. The organization is not perfect and readers might find it hard to follow here and there, but the main idea is understandable.	strength
2020-1036	Experiments show that the suggested tuning of inference hyperparameters can bring improvements to LM tasks, which is convincing.	strength
2020-1036	However, there are still major gaps between the theoretical analysis, the conclusion and the empirical solution (please see the detailed comments).	weakness
2020-1036	Such gaps make the main contribution questionable and make it as a pure empirical paper on its value.	weakness
2020-1036	Detailed comments: 1) Reducing the variance of output prediction can reduce the gap on variational posterior, but how does the gap relate to the generalization error?	weakness
2020-1036	The current paper only indicates that a small gap gives more consistency between the true objective and the optimized objective defined on the training set: they can be still far away from the expected posterior over data distribution.	weakness
2020-1036	Hence, it is hard to directly relate "reducing the gap" and "improve the test-set performance".	weakness
2020-1036	2) As the author mentioned in Section 3.4, reducing the dropout rate causes a bias issue on the expectation.	weakness
2020-1036	So it is not clear whether deterministic inference with zero dropout rate can achieve the smallest gap or not.	weakness
2020-1036	In this way, the conclusion is only supported by the empirical observations but not the presented theoretical analysis.	weakness
2020-1036	3) One main contribution of this paper is the power-mean family of dropout.	weakness
2020-1036	However, only one member (alpha=0.5) from the family has been evaluated in the experiments, and it does not achieve the best performance in most experiments.	weakness
2020-1036	So this contribution seems not practically useful according to the empirical result.	weakness
2020-1036	4) It is not clear how the prediction variance is reduced gradually in order to generate the results in Figure 1(b).	weakness
2020-1036	I guess reducing dropout rate is not the correct way to do so since it causes the bias issue and the tightness will be influenced.	weakness
2020-1036	Authors consider dropout as MAP for conditional model and consider different types of averaging to obtain predictive distribution p(y|x, theta) during inference stage.	abstract
2020-1036	The paper proposes power mean family and shows that well-known types of MC averaging (arithmetic and geometric) are particular cases of proposed family.	abstract
2020-1036	Authors show that power mean family objective is lower-bounded by the original dropout lower-bound.	abstract
2020-1036	Therefore it is consistent to use original dropout on the training stage and do any kind of averaging from power mean family during inference stage.	abstract
2020-1036	Concerns: 1) In general, paper is hard to follow and main motivation of the accomplished work is not clearly stated in the paper.	weakness
2020-1036	2) One of the most confusing things about this paper is the analysis of the lower bound tightness.	weakness
2020-1036	The authors state that the quality of fit for models in the power mean family depends on the Jensen gap ln(E[L]) - E[ln(L)] where L = p(y|x, w).	weakness
2020-1036	This gap reflects the difference between the training objective and the objective which is used at the evaluation stage.	weakness
2020-1036	From this perspective the expectation for the second term E[ln(L)] (which corresponds to the training objective and is the same in all settings) is fixed because we change the dropout scheme only in the inference.	weakness
2020-1036	Therefore, the Eq. 10 for the gap from this paper is misleading.	weakness
2020-1036	From this equality the authors derive that reducing the variance leads to decreasing the gap.	weakness
2020-1036	However, from the Bayes inference it is known that the zero gap between the training objective and the one at evaluation will be reached when we use expectation with respect to the true posterior distribution on the model weights given training data.	weakness
2020-1036	The authors however claim that the gap is zero when deterministic dropout (that is weight scaling rule) is used.	weakness
2020-1036	This would be true if we used the same deterministic objective during training stage (that would correspond to no dropout).	weakness
2020-1036	But we use expectation wrt non-degenerate noise distribution during training and at evaluation stage we take expectation wrt degenerate distribution (i.e. apply deterministic mode).	weakness
2020-1036	Since the distributions are different we cannot conclude that the gap is zero.	weakness
2020-1036	Moreover it can be even negative.	weakness
2020-1036	Hence the statement about zero gap and justification of deterministic mode seems to be wrong.	weakness
2020-1036	3) Experiments results are also hard to follow.	weakness
2020-1036	In Tables 2, 3, 4 the differences in metric values are insignificant and there are no error bars.	weakness
2020-1036	From such empirical results it is difficult to draw any conclusions.	weakness
2020-1036	Overall, the motivation of the paper is not clear, the analysis for the lower bound tightness and following conclusions are misguided and experiments results are unconvincing.	weakness
2020-1036	Therefore, I would suggest rejecting the current version.	decision
2020-1036	Summary: The paper aims to develop a more principled framework for choosing between different inference procedures in neural network models employing dropout as a stochastic regularizer.	abstract
2020-1036	In particular, they posit a family of conditional models and show that the learning objectives of all these models are lower bounded by the usual dropout training objective with L2 regularization on weights.	abstract
2020-1036	They proceed to show empirically that the deterministic inference procedure (multiplying the node's output by the droput rate) achieves the tightest lower bound.	abstract
2020-1036	From this observation the authors conclude that deterministic inference should be seen as the best available approximation to the true dropout objective rather than an approximation to Monte Carlo averaging.	abstract
2020-1036	Strengths: The paper builds on recent works viewing dropout as a Bayesian approximation to the predictive posterior distribution.	strength
2020-1036	Introducing a conditional model and showing that the dropout objective is akin to MAP estimation of the parameters of this model is interesting.	strength
2020-1036	The result that dropout simultaneously optimizes a lower bound to an entire family of conditional distributions is novel.	strength
2020-1036	Weaknesses: The writing is often not clear, ambiguous or misleading and needs improvement.	weakness
2020-1036	For instance: In Section 2.1, comments on weaknesses of variational dropout seems out of place.	weakness
2020-1036	It should either be ommitted or shifted to the previous section where variational dropout is introduced.	weakness
2020-1036	In Section 2.1, "Consider a conditional model p(Y |X, Θ) as a crippled generative model with p(X) constant, X and Θ independent." Assuming p(X), the input features, to be constant is a very strong assumption.	weakness
2020-1036	The variational lower bound is still true if p(X) is assumed arbitrary independent of Θ.	weakness
2020-1036	In Section 3.3, last paragraph, "Suppose we pick a base model from the power mean family and have a continuum of subvariants with gradually reduced variance in their predictions but the same expectation." It is not clear what the authors mean by continuum of subvariants?	weakness
2020-1036	Is it the dropout rate?	weakness
2020-1036	Several statements are made without any citations or explanations.	weakness
2020-1036	In Section 3. "While it is easy to argue in general that objectives of more than one model may share any given lower bound" How?	weakness
2020-1036	More explanation needed. In Section 3.1, "Notice how with SGD and multiple epochs, for each data point several dropout masks are encountered, and the approximating quantity is the geometric mean of the predicted probabilities".	weakness
2020-1036	Citation needed. In Section 3.2, "because M_α is monotonically increasing in α".	weakness
2020-1036	Proof (in appendix) or citation needed.	weakness
2020-1036	In Section 5, "The construction of a conditional model family with a common lower bound on their objectives is applicable to other latent variable models with similar structure and inference method." What general structure and inference method are the authors referring to?	weakness
2020-1036	Technical Concerns: Section 3.3, last paragraph.	weakness
2020-1036	The entire paragraph is extremely convoluted.	weakness
2020-1036	It is not clear how one achieves deterministic dropout inference by reducing variance of the prediction y keeping its expectation constant.	weakness
2020-1036	Section 3.3, "A similar argument based ...	weakness
2020-1036	shows that Z monotonically increases...	weakness
2020-1036	" How? The authors should deliberate more on this statement since, the Z term is also important in the difference between the true objective of each conditional model and the droput training objective.	weakness
2020-1036	In Section 5, "The gains reported in those works might be explained by reducing the bias of deterministic evaluation and also by encouraging small variance in the predictions and thus getting tighter bounds." Isn't this contradictory to Section 3.3, where from Eq. 10 and Eq. 11?	weakness
2020-1036	If the bias is reduced and variance increases, according to Eq. 10, the lower bound would become looser.	weakness
2020-1036	How is Fig. 1a and 1b computed?	weakness
2020-1036	Conclusions drawn from experiments not convincing.	weakness
2020-1036	Section 3.4, last line. "Having trained a model with dropout, the best ﬁt is achieved by the deterministic model with no dropout.	weakness
2020-1036	This result isolates the regularisation effects from the biases of the lower bound and the dropout family." How does this isolate the regularization effects?	weakness
2020-1036	What biases of the lower bound?	weakness
2020-1036	Do you mean the difference between the model's true objective and the dropout training objective?	weakness
2020-1036	Table 4 indicates that not only AMC, also power with alpha=0.5 is better than deterministic in some cases.	weakness
2020-1036	Did the authors try other values of alphas?	weakness
2020-1036	Deterministic seems to be good just for MNIST.	weakness
2020-1036	This strongly refutes the most important claim of this paper, written in the abstract, "Together, these results suggest that the predominant view of deterministic dropout as a good approximation to MC averaging is misleading.	weakness
2020-1036	Rather, deterministic dropout is the best available approximation to the true objective."	weakness
2020-1036	Changing the dropout multiplier and adjusting the softmax temperature of the network output layer, to achieve comparable performance to AMC on several datasets seems to support the existing hypothesis that deterministic dropout is a good approximation to MC average, and not the other way around!	weakness
2020-1036	Summary: The paper introduces some interesting ideas about dropout but suffers from bad writing and presentation of results.	weakness
2020-1036	One of the most important claims made in this paper, "dropout trains a deterministic model ﬁrst and foremost and a continuum of stochastic ones to various extents", is not well-motivated theoretically in Section 3.3.	weakness
2020-1036	Consequently, this seems to be purely an empirical observation, which is contradicted by further experiments on linguistic datasets.	weakness
2020-1036	Several conclusions made from experiments seem adhoc.	weakness

2020-1073	The authors propose a model for Click-Through Rate Prediction using a model consisting of an embedding layer, a Transformer stack, a Factorization Machine, and a DNN.	abstract
2020-1073	I have several major concerns about the submission: 2. Relevance: This work is extremely application specific, the application is not relevant to this community.	weakness
2020-1073	1. Clarity and writing: The contributions which are relevant to the *CONF* community are not explained well and the paper needs copy-editing for English grammar	weakness
2020-1073	4. Novelty: While seemingly showing good results on some benchmarks, the model is a mix of many components and it's not clear which components actually improve performance and would be worth further study.	weakness
2020-1073	Minor comments: Applying the DNN directly on top of the embeddings, and having a parallel stack of Encoder-FM, is not well explained.	weakness
2020-1073	What does it mean that "DNN aims at bit-wise level" if the DNN receives the same embedding features as the encoder, which supposedly "learn[s] at vector wise level"?	weakness
2020-1073	References to datasets are missing	weakness
2020-1073	Ablation study is limited, and has surprising results.	weakness
2020-1073	E.g. even completely removing self-attention barely makes a dent in how well the method compares to other published work, moving it from rank 1 to rank 2.	weakness
2020-1073	Otherwise only small tweaks with even more minor effects are made.	weakness
2020-1073	What about removing e.g. the FM, other major components?	weakness
2020-1073	The biggest architectural innovations here are the bi-linear attention mechanism and max-pooling self attention.	weakness
2020-1073	They are hard to interpret in this context.	weakness
2020-1073	It's not clear how they would perform in a simpler architecture (e.g. vanilla BERT or Transformer) and in the context of a more standard benchmark.	weakness
2020-1073	That study would have a lot more relevance to this community than the present one.	weakness
2020-1073	The paper applies Multi-Head Self-Attention (MHSA) to a CTR prediction model with some small changes.	abstract
2020-1073	The empirical results on two public datasets show it improves performance over some baselines.	abstract
2020-1073	First of all, the novelty of the proposed algorithm is limited in that it mainly applies existing mulit-head self-attention.	weakness
2020-1073	The paper does include some small modifications to MHSA and achieves better performance, such as bi-linear similarity and max-pooling.	weakness
2020-1073	However, the nature of these changes seems more incremental.	weakness
2020-1073	The experiment section is very detailed and the paper conducts several ablation studies to understand which components contribute the most, which is nice.	strength
2020-1073	However, the paper is missing several important baselines, for example, Deep & Cross [1], which makes the results less convincing.	weakness
2020-1073	Another issue with the paper is that it does not control the model capacity when comparing performance.	weakness
2020-1073	It is usually the case that increasing model capacity leads to better performance.	weakness
2020-1073	Given that MHSA and bi-linear similarity have increased a lot of model parameters, it is more fair to compare performance across models with similar capacity.	weakness
2020-1073	In fact, in [1], they show the logloss on Criteo dataset can be as low as 0.4423 when using large enough parameters.	weakness
2020-1073	Minor: in the ablation study, it shows head = 1 has the best performance.	weakness
2020-1073	In this case, why max-pooling is needed?	weakness
2020-1073	Reference: [1] Wang, R., Fu, B., Fu, G.	misc
2020-1073	and Wang, M., 2017, August.	misc
2020-1073	Deep & cross network for ad click predictions.	misc
2020-1073	In Proceedings of the ADKDD'17 (p.	misc
2020-1073	12). ACM. This papers proposes DeepEnFM approach for CTR prediction task.	abstract
2020-1073	In detail, Transformer encoder is applied on top of embeddings to generate new projected embeddings.	abstract
2020-1073	Such transformer encoder is composed of self-attention with bilinear (to replace dot) and multi-head, which is followed by a mx pooling layer and then a FC layer.	abstract
2020-1073	Position encoding is utilized then.	abstract
2020-1073	Besides, some resnet-style trick in placed in the middle.	abstract
2020-1073	Such encoder output is fed into FM and raw embeddings are feed into DNN part.	abstract
2020-1073	These two parts are then used for final prediction.	abstract
2020-1073	Some experimental results show the improvement of the proposed method over other methods.	abstract
2020-1073	The major questions are: *  The assumption of "The field embedding size is very low in CTR" is not reasonable.	weakness
2020-1073	Do we have any study to verify this hypothesis?	weakness
2020-1073	* Regarding to above hypothesis, i think it doesn't hold for all the CTR prediction tasks.	weakness
2020-1073	Computation cost will be dramatically increased when embedding size increases because of bilinear between key and query and the FC on top of self-attention.	weakness
2020-1073	* The novelty of the proposed method needs to justified to reach the bar of *CONF*.	decision
2020-1073	The major reason is that 1) the proposed method just replaces MHSA with two changes, i.e., bilinear + max pooling, 2) other tricks such as resnet-style connection, layer norm and position encoding have been adopted everywhere.	weakness
2020-1073	* The gain of proposed method is not so clear though the author test to remove each component from the architecture.	weakness
2020-1073	As the change of encoder part is on top of MHSA, but there is no experiment to show the gain compared to using original MHSA instead of newly proposed bilinear + max pooling.	weakness
2020-1073	I suggest to do this for better understanding the gain of changes.	suggestion

2020-1109	The authors propose a new univariate time series analysis framework called RISE, which unifies the existing work on adapting RNNs to irregular time series.	abstract
2020-1109	Building on top of the RISE, they propose a modification called DISE in which the algorithm skips the intervals without any observations.	abstract
2020-1109	In that sense, DISE can be considered a marked point process analysis algorithm.	abstract
2020-1109	They quantify the performance of the RISE and DISE on two datasets.	abstract
2020-1109	Table 1 is a valuable summary of the existing efforts on adapting RNNs to irregular time series.	abstract
2020-1109	However, the paper overstates its scope.	weakness
2020-1109	This work only studies RNNs. There are many alternatives for analysis of irregular time series, including Gaussian processes [1], ordinary differential equations [2], convolutional neural networks [3], neural point processes and spiking neural networks [4].	weakness
2020-1109	These references are only notable examples from each category and there are many more.	weakness
2020-1109	A major limitation of this paper is that it only applies to the univariate time series.	weakness
2020-1109	Usually in domains such as healthcare, almost always different variables have different missing rates.	weakness
2020-1109	Multiple works address the multivariate case, see [5] for example.	weakness
2020-1109	The main dataset used for evaluation is the Glucose dataset.	weakness
2020-1109	However, this dataset is a peculiar and very specific dataset because its goal is to predict glucose level for type-1 diabetics only base on the past glucose measurements.	weakness
2020-1109	While this task is meaningful, human biology states that forecasting glucose levels without knowledge of insulin injection or carbohydrate consumption is an extremely difficult task.	weakness
2020-1109	In this setting, the most useful data is the latest data point.	weakness
2020-1109	This dataset is an extreme forecasting task in absence of major predictors and I do not think it should be the primary dataset for evaluation of a new algorithm.	weakness
2020-1109	Finally, the main idea of skipping the intervals without measurements is not very novel given the existing literature on neural point processes.	weakness
2020-1109	Also, it is not enough contribution for a full conference paper.	weakness
2020-1109	[1] Shukla, Marlin (2019) Interpolation-Prediction Networks for Irregularly Sampled Time Series.	misc
2020-1109	In *CONF*. [2] Chen, T. Q., Rubanova, Y., Bettencourt, J., & Duvenaud, D.	misc
2020-1109	K. (2018). Neural ordinary differential equations. In NeurIPS.	misc
2020-1109	[3] Nguyen, P., Tran, T., Wickramasinghe, N., & Venkatesh, S.	misc
2020-1109	(2016). Deepr: a convolutional net for medical records.	misc
2020-1109	IEEE BHI. [4] Islam, K. T., Shelton, C. R., Casse, J. I., & Wetzel, R. (2017).	misc
2020-1109	Marked point process for severity of illness assessment.	misc
2020-1109	In Machine Learning for Healthcare Conference.	misc
2020-1109	[5] Che, Z., Purushotham, S., Li, G., Jiang, B., & Liu, Y.	misc
2020-1109	(2018). Hierarchical deep generative models for multi-rate multivariate time series.	misc
2020-1109	In ICML. Overall: Provides a nice summary of different methods for dealing with missing values in neural net time series models and proposes a new technique that does not involve running a series of possibly diverging predictions but rather jumps ahead to reason about arbitrary points in the future in a "single hop", avoiding the risks associated with compounding errors.	strength
2020-1109	Also proposes a new method for encoding values that's quite unusual but appears to work very well.	strength
2020-1109	Overall, the paper is mostly clear, the technique is reasonable, and the best model does indeed appear to work well.	strength
2020-1109	I have only one serious reservation about this paper - and it is an extremely serious concern about the experimental setup, and I would ask that the authors clarify this point for me in a response.	weakness
2020-1109	DISE works poorly or only comparably well to the baselines in all tasks unless the GRU-based input encoding is used.	weakness
2020-1109	Obviously any RISE model likewise depends on an input encoding, so the question is whether the baseline RISE models were given the benefit of the GRU-based input encoding.	weakness
2020-1109	If not, please provide this comparison.	weakness
2020-1109	Minor comments: "replace the standard input with a transformed input ˆx" -> I find this wording awkward.	weakness
2020-1109	If the input is missing, it cannot be transformed, it can be predicted using a conditional model over data given a representation of past (and/or future) observations, or it can be a (probably learned) dummy value, but please clarify this wording- it's essential.	weakness
2020-1109	Similarity of DISE to prior work: There are a number of processes that build representations based on measurements that happen at random times without "rolling forward" a single step model, for instance, the neural Hawkes process (Mei and Eisner, 2017 or so), which has also been applied to impute missing values.	weakness
2020-1109	Some discussion of the relationship to work like this is recommended.	suggestion
2020-1109	Additionally, the idea of learning representations based on predicting values at several time scales into the future comes up in contrastive predictive coding (van Oord et al, 2018).	suggestion
2020-1109	The paper studies missing value imputation in univariate time series.	abstract
2020-1109	The paper introduces a framework called RISE which provides a unified framework for existing methods in the domain.	abstract
2020-1109	The authors further propose DISE which generalizes RISE.	abstract
2020-1109	Experiments on time series forecasting demonstrate improved performance.	abstract
2020-1109	+ It is quite interesting that the unified framework RISE can encompass the existing missing value imputation methods as special cases.	strength
2020-1109	+ The idea of using learnable factors for relative and absolute time information in DISE makes sense.	strength
2020-1109	- The alternative notations for the proposed framework and the existing framework are very confusing.	weakness
2020-1109	It is not clear why such alternative notations for the same setting are necessary.	weakness
2020-1109	- The modeling novelty is quite limited.	weakness
2020-1109	Other than learnable factors for absolute and relative time information, there is very little motivation or theory regarding the modeling choice.	weakness
2020-1109	- The experiments are not well motivated.	weakness
2020-1109	The paper compares with a lot of missing value imputation baselines but the experimental setup is actually for extrapolation.	weakness
2020-1109	In this case, a more proper set of baselines should be time series forecasting methods for irregularly sampled data such as Phased LSTM.	suggestion

2020-1130	The novelty of this paper is adding an extra regularization term to the objective of beta-TCVAE (a VAE that regularizes total correlation), based on the discovery that low TC(z) does not necessarily mean low TC(mu).	abstract
2020-1130	The added term enforces sample and mean representations stay close.	abstract
2020-1130	The authors' idea is understandable at a coarse resolution.	strength
2020-1130	However, the authors explain the mathematics poorly.	weakness
2020-1130	Explanations of lots of variables and notions are missing.	weakness
2020-1130	For example in Theorem 1, what is "j"?	weakness
2020-1130	what is \\sigma_j? In Section 4, the simplification of notations lead to more difficulties to understand the formulas.	weakness
2020-1130	In "x_n", is n the index of a sample or a dimension?	weakness
2020-1130	The notations of variables are also confusing.	weakness
2020-1130	Boldface lowercase letters should be used for vectors, and plain letter should be used for scalars.	weakness
2020-1130	In Equation 4, what are D and k?	weakness
2020-1130	It is nice to see, in the given experimental results,  that latent representations of RTCVAE are less correlated in comparison with FactorVAE in Figures 6 and 7.	weakness
2020-1130	However, the authors should show some generated examples through latent variable traversal to qualitatively demonstrate the potential advantages of the proposed improvement.	suggestion
2020-1130	Minors: Section. X -> Section X The paper proposes a method to address a known problem for unsupervised disentangling methods that penalises total correlation, namely that while the total correlation of the samples from q(z) (denoted TC(z)) are encouraged to be small, the total correlation of the means of q(z|x) (denoted TC(mu)), used as the disentangled representation in practice, is not necessarily small and can increase with regularisation strength.	abstract
2020-1130	In the introduction, I think that the statement "they concluded pessimistically that it is fundamentally impossible to learn a disentangled representation in an unsupervised setting" is a wrong interpretation of Locatello et al. They show that optimising marginal likelihood in a generative model (such as a VAE) cannot achieve disentangling without any inductive biases in the model.	weakness
2020-1130	But there inductive biases in the models used by disentangling methods, along with the loss (that is a variant of the ELBO and not the marginal likelihood), that allow disentangling in practice.	weakness
2020-1130	There are also theoretical works such as [1] that explain this behaviour.	weakness
2020-1130	The theoretical contribution of the paper is Theorem 1, that claims to show the existence of distributions with arbitrarily large TC(mu) but with small, bounded TC(z).	weakness
2020-1130	Indeed the proof shows that TC(z) is bounded by C, but looking at Appendix A it seems as though C is a function of c1,c2 and R that is used to define p(z|mu), and is lower bounded by (2pi)^{-D/2} (a constant, which confusingly, is also denoted by C in the appendix).	weakness
2020-1130	It appears necessary to have another line that mentions how small C can be chosen to be via choice of c1,c2,R.	weakness
2020-1130	Also it seems as though the proof can be largely simplified by having sigma'_j(mu)=c_1 if |mu|<R and sigma'_j(mu)=c_4/|mu| if |mu|>R, removing free parameters l,c_2,c_3.	weakness
2020-1130	The methodological contribution of the paper is to propose an extra regularisation term that penalises the variances of q(z|x).	weakness
2020-1130	While this does introduce another hyperparameter to tune, it has the advantage of being simple to implement and having an intuitive explanation of how it can address the problem;	strength
2020-1130	if q(z|x) is encouraged to have smaller variance, the distribution of z will be encouraged to be closer to the distribution of mu, hence helping to address the disparity between TC(z) TC(mu).	strength
2020-1130	I like the simplicity of the idea, however the analysis is lacking in rigour.	weakness
2020-1130	First of all, when comparing the different methods of estimating TC(z), it's not clear what the mathematical difference of MSS_0 and MSS_1 is.	weakness
2020-1130	This should be explicitly stated so that one can understand the results in Figure 1.	suggestion
2020-1130	Regarding the following analysis, it's not clear why the off diagonal elements of the cube (i.e. q(z^(i)_k|n^(j)) when i != j ) should be very small compared to the diagonal elements.	suggestion
2020-1130	For example, it could be the case that z^(i) and z^(j) are close to one another, in which case the (i,j)th entries will be non-negligible compared to the diagonal.	weakness
2020-1130	Hence the analysis is difficult to accept.	weakness
2020-1130	Also the claim that MSS and MWS prefer to shut down latent dims should be verified by experiments.	weakness
2020-1130	Further, it's unclear why this is undesirable from a disentangling point of view.	weakness
2020-1130	Of course we don't want to use fewer number of latent dimensions than the number of ground truth factors, but also we don't want to use more latent dimensions.	weakness
2020-1130	Also the at the bottom of page 5 is a Gaussian with a correlated covariance matrix, and it's claimed that its TC can be arbitrarily large, but surely this is fixed?	weakness
2020-1130	Finally the authors list lots of reasons why not to use MSS, but there is no discussion about the density-ratio trick method for estimating TC.	weakness
2020-1130	For example, it is known that this method suffers underestimates of TC (c.f. Kim & Mnih) - it has its own issues, that can be arguably more severe than MSS.	weakness
2020-1130	This analysis needs a lot more explanation and rigour.	weakness
2020-1130	The experimental results are very weak and sparse, that is nowhere near enough to give a convincing case for the newly proposed method.	weakness
2020-1130	The method has only been trained on dsprites and 3d shapes, with three choices of beta and a single value of eta, and only estimates of TC(mu) and TC(z) are reported, with no evaluation of disentanglement performance.	weakness
2020-1130	There is some evidence in the paper that the regularisation makes both TC(mu) and TC(z) close to 0 with eta=10, but it's unclear how this affects disentangling performance, and whether smaller values of eta can give a sweetspot.	weakness
2020-1130	The experiments should cover a larger range of datasets, with evaluation on how different disentanglement metrics, TC(mu) and TC(z) change for different values of beta and eta, along with a comparison with other disentangling methods, especially DIP-VAE-1, that directly penalises correlation in mu (for an open source library that facilitates this, see e.g. github.com/google-research/disentanglement_lib).	suggestion
2020-1130	Even the authors acknowledge that "the scale of our experiments is limited", and it is clear that the paper is not yet ready for publication.	rebuttal_process
2020-1130	Overall, the proposed idea is simple and easy to implement, which is the main advantage of the paper, but it is evident that the analysis and evaluation lacks rigour, hence the paper will need to undergo significant revision to be in a publishable state.	decision
2020-1130	[1] Rolinek, M., Zietlow, D.	misc
2020-1130	and Martius, G., Variational Autoencoders Pursue PCA Directions (by Accident).	misc
2020-1130	CVPR 2019. Minor typos/comments: Eqn(4): the ||.||_1 should be replaced by trace, since the term inside ||.||_1 is a covariance matrix (although it's diagonal).	weakness
2020-1130	If A is a matrix, ||A||_1 is the maximum absolute column sum, which is different to what is meant by the paper, the trace (sum of diagonals).	weakness
2020-1130	p3: Can MWS also be stated in the paper (or at least in the appendix) to make it self-contained?	weakness
2020-1130	p4: followed <- follow, n_{m+1} <- n_{M+1}	weakness
2020-1130	p6-7: Section 6.1 should be in a related work section, and not under the Experiment section.	weakness
2020-1130	The point about modularity is a fair but known issue, closely related to the issue of axis alignment/unidentifiability (see e.g. Rolinek et al) This paper considers the extensions of variational autoencoders (VAEs), which take into account the total correlation of sampled distribution of latent variables.	abstract
2020-1130	Proving a theorem that a family of distributions of sample representations with a bounded total correlation can have a mean representation of arbitrarily large total correlation, the authors propose RTC-VAE, which additionally penalizes total covariance of sampled latent variables.	abstract
2020-1130	The authors demonstrate that RTC-VAE produces less correlated distributions of mean representation compared with baselines.	abstract
2020-1130	The proposed method, RTC-VAE, is based on a simple idea and its performance in experiments is promising.	strength
2020-1130	However, its derivation is somewhat ad-hoc and the experiments are not so comprehensive enough to provide the evidence for its good performance.	weakness
2020-1130	The covariance term in RTC-VAE of Eq.	weakness
2020-1130	(4), is indirectly related to mean representation.	weakness
2020-1130	Is it difficult to penalize TC(\\mu), directly?	weakness
2020-1130	The arguments in Section 5 are somewhat superficial.	weakness
2020-1130	It isn't explained how Eq. (5) is derived. Without the explicit definition of D(z), Eq.	weakness
2020-1130	(8) is not so informative.	weakness
2020-1130	Section 6: It is not discussed why the regularization parameter \\eta is fixed to 10 and how RTC-VAE is sensitive to \\eta.	weakness
2020-1130	Are there any other performance measures to indicate the good overall performance of RTC-VAE other than the training ELBO in Fig. 5?	suggestion
2020-1130	Minor comments: p.3, l.21 from the bottom: [z] should not be in the subscript.	weakness
2020-1130	p.4, l.3: n_{m+1} -> n_{M+1}	weakness
2020-1130	p.6, l.17 from the bottom: ``"that Factor VAE does" -> ``"than Factor VAE does"	weakness
2020-1130	The authors' responses answered my questions.	rebuttal_process
2020-1130	However, I still think that the paper  has room for improvement in justifying the method, explaining the choice of hyperparameter and so on.	weakness

2020-1131	NOTE: This paper is 10-pages long which requires a higher bar according to the guidelines.	weakness
2020-1131	Summarize what the paper claims to do/contribute.	weakness
2020-1131	* This paper claims to propose the first method to translate an environment representation to a different representation when that changes.	abstract
2020-1131	Clearly state your decision (accept or reject) with one or two key reasons for this choice.	suggestion
2020-1131	Reject. * The results were not adequate.	weakness
2020-1131	I suggest exploring more environments and more complex ones than MountainCar.	suggestion
2020-1131	* I do not believe this is the first attempt in translating an environment represention to a different one.	ac_disagreement
2020-1131	Other techniques in domain adaptation have been working on this for quite some time.	suggestion
2020-1131	It might be the case that the technique proposed here is better eg to pixel-based adaptation or adaptation of features, but it would need to be shown experimentally.	weakness
2020-1131	* Given the higher number of pages, i would have expected more thorough experimentation.	weakness
2020-1131	The authors propose a means to adapt to new state representations during reinforcement learning.	abstract
2020-1131	The method works by learning a translation model that translates new state representations to old state representations.	abstract
2020-1131	The authors evaluate the method on the MountainCar environment and show that the adaptation model is more efficient than training a new policy from scratch.	abstract
2020-1131	My concerns with this work are as follows: - I don't find the type of changes to state representations very useful (e.g. Section 6, velocity *=2, position /= 2) nor practical.	weakness
2020-1131	Moreover, learning a translation model to recover the old representation seems easy given this type of simple perturbations.	weakness
2020-1131	This perturbation is fundamentally different than those used to motivate the problem (e.g. "a robot whose sensors break down" or "whose sensor outputs degrade", in the introduction).	weakness
2020-1131	- The authors only evaluate with one type of simple perturbation on one environment, hence I am skeptical regarding the generalizability of this work.	weakness
2020-1131	- The premise of this work is to not store old transitions (Section 1, the paragraph "the most simplistic idea is to..."), however this model does store old transitions because it uses prioritized experience replay.	weakness
2020-1131	In this case there is no argument against using this data to train the translation model.	weakness
2020-1131	- A comparison that is missing from the paper is to fine-tune the existing model.	weakness
2020-1131	I believe this is a more fair comparison in terms of sample-efficiency than training from scratch.	weakness
2020-1131	Other comments: - For the title, to call the adaptation to slightly different state representations "policy adaptation" is a stretch.	weakness
2020-1131	- There are a lot of tangential information in the introduction on things like sample efficiency and model-free vs.	weakness
2020-1131	model-based RL. This is distracting. - The paper is excessively long.	weakness
2020-1131	The paper investigates a setting in which the observation function changes while the underlying environmental dynamic stays the same.	abstract
2020-1131	In order to re-use the policy which was trained on the old observation function, they propose to learn a mapping function to map the new observations to the old ones.	abstract
2020-1131	I believe the work is interesting as generalization and reducing the sample complexity of learning policies, for example through re-use of old policies, is of high current interest.	strength
2020-1131	However, I believe this paper requires more work to show the feasibility of the proposed approach.	weakness
2020-1131	In particular: - The proposed method has the problem that matching is done 'locally' and without any guarantee that the mapping function will converge to the correct mapping.	weakness
2020-1131	This is not a problem of the method itself but of the challenging problem setup.	weakness
2020-1131	The authors discuss this and propose two approaches to alleviate this.	weakness
2020-1131	However, no experimental evidence is shown whether and to what extend this prevents wrong local minima, as I don't believe the mountain car has such problems?	weakness
2020-1131	- Evaluation is only done on the mountain-car experiment, which is not sufficient to show feasibility in general	weakness
2020-1131	- The learning curves in the experiment seem highly volatile and unstable.	weakness
2020-1131	I'm not sure why this is the case, maybe wrong hyperparameters or a bug in the code?	weakness
2020-1131	- Lastly, the paper is over the recommended limit of 8 pages and could, in my opinion, made more concise at many points to shorten it and also make it easier to read.	weakness
2020-1131	In summary: I believe this interesting work, but requires more experiments in different environments and additional ablation studies to show the feasibility of the proposed method.	weakness
2020-1131	Making the writing more concise would, in my opinion, not only shorten the paper but also make it easier to read.	suggestion

2020-1190	This paper proposes a quasi-multitask learning (Q-MTL) for supervised learning.	abstract
2020-1190	The network architecture in Q-MTL borrows the idea of multi-task neural networks by sharing the latent representation among different classifiers which are designed for a single task.	abstract
2020-1190	What is the difference among multiple classifiers for the single task?	abstract
2020-1190	Can they become identical? The rationale behind Q-MTL is unclear to me.	weakness
2020-1190	Authors need to conduct more analyses to show why Q-MTL is superior to supervised learning.	suggestion
2020-1190	Authors claim that Q-MTL is equivalent to performing some regularization.	abstract
2020-1190	However, I did not see any analysis on this aspect.	weakness
2020-1190	In experiments, the performance of Q-MTL is not so good when compared with ensemble learning.	weakness
2020-1190	This paper considers a regularization technique, derived from multi-task learning, where multiple models with some shared parameters are jointly trained to solve copies of the same task.	abstract
2020-1190	The technique is well-motivated as an efficient alternative to ensemble learning.	abstract
2020-1190	The method is validated for a BiLSTM NLP model, which is applied to several POS tagging and named entity recognition tasks.	abstract
2020-1190	The power of the technique as a regularizer is also demonstrated in the case of highly noisy labels, surprisingly, even outperforming ensemble learning in this setting.	abstract
2020-1190	Despite this, my inclination is to reject the paper because of the substantial overlap with previous work and the limited scope of experiments.	decision
2020-1190	My primary concern is that the proposed technique was previously introduced in [1].	weakness
2020-1190	This prior work is not acknowledged in the current paper.	weakness
2020-1190	Perhaps it was overlooked because it is situated tightly in Multi-task Learning, whereas the present work is motivated mainly with respect to Ensembling.	weakness
2020-1190	Although the general method was introduced previously, the paper does have some key experimental differences that would be interesting to see explored further.	strength
2020-1190	(1) The paper uses a hidden layer in the separate classification heads, whereas previous work only used a linear classifier.	strength
2020-1190	The intuition that more complex heads will yield more diverse models is clear, but it would be great to see experimental evidence that this complexity helps.	suggestion
2020-1190	The conclusion states that the computational overhead is "infinitesimal"; does increasing the complexity of the classifier trade cost for performance?	suggestion
2020-1190	(2) This paper uses Eq. 3 to make predictions, whereas previous work found that this did not improve over simply using the best single prediction model, which makes prediction somewhat more efficient.	weakness
2020-1190	Is there some experimental evidence that Eq. 3 leads to improvements?	weakness
2020-1190	(3) This paper considers the comparison to ensembling, whereas previous work only considered comparisons to single task and standard multitask learning.	weakness
2020-1190	Additional experiments showing the advantages over ensembling could make this extension a significant contribution.	suggestion
2020-1190	(4) This paper presents novel investigation of the regularization effects of the method, i.e., the resilience to noisy labels and the analysis of learned weight matrices.	suggestion
2020-1190	Is there a real problem where this resilience to noise will improve over ensembles, i.e., without randomly replacing labels?	weakness
2020-1190	Such an experiment would make this point more compelling.	weakness
2020-1190	Also, is there some underlying reason why the method outperforms ensembles in this case?	weakness
2020-1190	Is it simply because the method is less expressive so cannot overfit?	weakness
2020-1190	In effect, if the paper could clearly show that (1) or other practical extensions lead to improvements over ensembling in settings where ensembling is commonly used, or enable ensembling in settings where vanilla ensembling fails (i.e., the case of noisy labels), then it could be a substantial contribution.	suggestion
2020-1190	The current scope of the experiments is too limited to conclusively show these points.	weakness
2020-1190	For example, the technique can be applied to any architecture, but the experiments in the paper are limited to a single architecture; and additional experiments with architectures and tasks that commonly use ensembling would make the experiments more compelling, ideally with comparisons to external results.	weakness
2020-1190	Other minor comments: - It would be good to see the number of model parameters for easy comparison, especially in table 2 with different value of k.	suggestion
2020-1190	- It looks like the x and y axis labels are swapped in Figure 3; from the Figure it looks like STL gets higher accuracies.	weakness
2020-1190	- Figure 2 should say epochs instead of iterations.	weakness
2020-1190	[1] Meyerson, E. & Miikkulainen R.	misc
2020-1190	"Pseudo-task Augmentation: From Deep Multitask Learning to Intratask Sharing---and Back", ICML 2018.	misc

2020-1203	In this paper, a method for re-ranking beam search results for semantic parsing is introduced and experimentally evaluated.	abstract
2020-1203	The general idea is to train a paraphrase critic.	abstract
2020-1203	Then, the critic is applied to the each pair (input sentence, logic form) in the beam to determine if they are close.	abstract
2020-1203	The main problem with the proposed method is that the critic does not receive high quality negative examples.	weakness
2020-1203	The generator is never trained to adapt to the critic.	abstract
2020-1203	Second big problem is that the critic trained on two sources of data: the original dataset and the Quora paraphrasing dataset.	weakness
2020-1203	It is very unclear what is the impact of each of the data sources.	weakness
2020-1203	Also, it is unclear how the critic works in this case.	weakness
2020-1203	It seems to be an easy task to distinguish a logical form from a natural sentence.	weakness
2020-1203	In general, the paper is well written.	strength
2020-1203	I would suggest to reduce the size of the introduction and dedicate this space to more detailed explanation how reranking works and the experimental details.	suggestion
2020-1203	Figures don't add much to understanding.	weakness
2020-1203	The experimental part is rather weak.	weakness
2020-1203	The error analysis part is great, but not very methodical.	weakness
2020-1203	It is not clear is these examples are cherry picked or it is frequent mistake of the baseline.	weakness
2020-1203	I would like to the accuracy of the critic and the analysis of its performance.	weakness
2020-1203	The critic is the main contribution of this paper and it is strange that so little attention is dedicated to it.	weakness
2020-1203	Other aspects that need to be highlighted in the experimental section: - how the Quora pretraining helps	weakness
2020-1203	- do other strategies for negative sample work	weakness
2020-1203	- how important is not to rerank in certain cases (Sec 3.3)	weakness
2020-1203	In conclusion, I encourage the authors to develop the idea further.	weakness
2020-1203	Taking in into account the issues with the method (or its presentation) and the experimental weaknesses I recommend reject for now.	decision
2020-1203	Typos: - [CLS] is not defined in text	weakness
2020-1203	- Shaw et al. should be in Previous methods in Table 3 This paper proposes a framework for semantic parsing, which includes a neural generator that synthesizes the logical forms from natural language utterances, and a neural reranker that re-ranks the top predictions generated by beam search decoding using the neural generator.	weakness
2020-1203	While the neural generator is the same as prior work, the main novelty is the reranker design, which is a binary classifier that takes a pair of natural language utterance/logical form, and predicts the similarity between them.	weakness
2020-1203	This reranker could also be pre-trained using auxiliary data sources, e.g., Quora question pairs benchmark for paraphrasing.	weakness
2020-1203	They evaluate their approach on 3 semantic parsing datasets (GEO, ATIS, and OVERNIGHT), and show that their reranker can further improve the performance of the base generator.	weakness
2020-1203	I think the general motivation of the framework is sound.	strength
2020-1203	Although the idea of reranking is not new in the semantic parsing community, with the most recent work [1] already shows the promise of this direction, the concrete approach described in this paper is different, seems simple yet effective.	strength
2020-1203	The most interesting part is to transform the generated logical form into a pseudo-natural language text, so that it becomes a paraphrase of the input natural language utterance in some sense, which enables the re-ranker to be pre-trained with auxiliary data sources, and to use the wordpiece tokenizer that is effective in understanding natural language.	strength
2020-1203	In their evaluation, they indeed show that this transformation helps improve the performance of the reranker.	strength
2020-1203	My main concern of  this paper is about evaluation.	weakness
2020-1203	First, although they already evaluate on 3 datasets, all of them are not among the most challenging benchmarks in semantic parsing.	weakness
2020-1203	In [1], they also evaluate on Django and Conala, which are 2 benchmarks to translate natural language to Python, and also are more complicated than the benchmarks in this paper.	weakness
2020-1203	It would be helpful for the authors to show results on such datasets that the results of baseline neural generators are less satisfactory, which may also make more room for the possible improvement using a re-ranker.	suggestion
2020-1203	On the other hand, they also lack a comparison with existing re-ranking approaches.	weakness
2020-1203	For example, it will be helpful to compare with [1], given that they also evaluate on GEO and ATIS.	suggestion
2020-1203	Right now the results are not directly comparable because: (1) the base generators are different; and (2) the beam size used in this paper (10) is larger than the beam size (5) in [1].	weakness
2020-1203	It will be helpful if the authors can at least provide results with a smaller beam size, and would be better if they can provide results that are directly comparable to [1].	weakness
2020-1203	[1] Yin and Neubig, Reranking for Neural Semantic Parsing, ACL 2019.	misc
2020-1203	------------ Post-rebuttal comments I thank the authors for the response.	misc
2020-1203	However, I don't think my concerns are addressed; e.g., without a comparison with previous re-ranking methods, it is hard to justify their proposed approach, given that other re-ranking methods are also able to improve over an existing well-performed generator.	ac_disagreement
2020-1203	Therefore, I keep my original assessment.	ac_disagreement
2020-1203	------------ This paper proposes a reranking architecture with a LogicForm-to-NaturalLanguage preprocessing step for semantic parsing.	abstract
2020-1203	The authors experiment their method on three datasets and get the state of the art results.	abstract
2020-1203	The proposed method is natural.	strength
2020-1203	But using neural models to rank (or rerank) is a long-existing technique, regardless of the chosen parametrization of the reranking model.	weakness
2020-1203	This paper chose BERT. See section-2.6 of this tutorial for more details about using neural models to rank: https://www.microsoft.com/en-us/research/uploads/prod/2017/06/INR-061-Mitra-neuralir-intro.pdf.	misc
2020-1203	Overall, I think the paper is not ready to publish for the following reasons.	decision
2020-1203	1. The method relies much upon manual designs that seem hard to generalize.	weakness
2020-1203	By converting the logic forms to natural languages, the authors can leverage paraphrase datasets and pre-train the critic as a paraphrase model.	weakness
2020-1203	However, the way they convert the logic forms is different for each dataset and they have to manually design rules for each logic form.	weakness
2020-1203	2. It is not clear how certain experimental designs were made.	weakness
2020-1203	The authors chose to not rerank if the candidates' scores are too low or high but close.	weakness
2020-1203	Such choice and associated thresholds seem arbitrary: how were they actually found out?	weakness
2020-1203	Were they tuned on a development set?	weakness
2020-1203	How does the method work if the candidate with the highest score is always picked: in the end, this is what the model is supposed to learn, correct?	weakness
2020-1203	Other designs include beam size, whether or not to use a pretrained model, etc.	weakness
2020-1203	How were such decisions made?	weakness
2020-1203	Tuned on a development set?	weakness
2020-1203	3. The results are not sound enough.	weakness
2020-1203	Given the issued pointed out in 1 and 2, I am not sure if the results are really sound as the authors claimed.	weakness
2020-1203	For example, what if the authors don't use a LogicForm-to-NaturalLanguage conversion?	weakness
2020-1203	What is the result if we directly learn to match input and logic forms?	weakness
2020-1203	Moreover, the authors better answer questions in 2 so I can gauge if their hyper-parameters were chosen in the principled ways.	weakness
2020-1203	Once those are answered, a significant test had better be done since the improvement seems small.	weakness
2020-1203	4. Claiming Shaw et al. 2019 in table-3 as ``our methods'' is wrong.	weakness
2020-1203	It is clear that Shaw et al. (2019) didn't experiment on OVERNIGHT dataset, but setting up the baseline on a dataset should not be classified as ``our method''.	weakness
2020-1203	Moreover, I have some comments on the model and experiments.	misc
2020-1203	These are not weakness, but I think some work in this direction may help improve the paper.	misc
2020-1203	1. The model architecture should be better justified.	weakness
2020-1203	In its current form, the two arguments (input query and output sequence translated from a logic form) are interchangeable.	weakness
2020-1203	Why so? Why isn't an asymmetric architecture more natural?	weakness
2020-1203	How can the authors use a pair of logic forms as negative examples (in figure-2)?	weakness
2020-1203	Why do the authors use the Quora dataset in particular?	weakness
2020-1203	2. The error analysis might be better to be a bit more quantitative.	weakness
2020-1203	Its current form doesn't seem to give insight on how the proposed method really helps.	weakness
2020-1203	What the authors can do is: you can sample some sentences from the test/development set and count how many comparative words are misused in the original model, among which how many are corrected by reranking.	suggestion

2020-1209	This paper describes a structure to approach the federated machine learning problem for hospitals.	abstract
2020-1209	The approach does not seem very novel and it is hard to see what the representation learning challenges are.	weakness
2020-1209	There is no open benchmark that the community can work on.	weakness
2020-1209	I suggest that the paper focus on the method and not the private dataset used.	suggestion
2020-1209	If you cannot release a public dataset then maybe a synthetic dataset that presents known challenges you observe in private data.	suggestion
2020-1209	This can be used as a benchmark for the community to improve these methods.	suggestion
2020-1209	Typos: "Step 1..Claims" Some of the citations seem to be listing every author of the paper which is very hard to read the paper.	weakness
2020-1209	The authors propose a learning strategy to fit predictive models on data separated across nodes, and for which different set of features are available within each node.	abstract
2020-1209	This concept is developed by introducing the concept of two degree separation across horizontal (nodes) and vertical (feature) axis.	abstract
2020-1209	The proposed approach consists in an iterative scheme where i)  models at independentently trained at each site, and ii) models' parameters are subsequently averaged and redistributed for the next optimisation round.	abstract
2020-1209	The problem tackled in this work is interesting, with an important application on medical records from > 100,000 individuals followed  over time.	strength
2020-1209	Unfortunately the paper is not clear in several aspects, and presents methodological issues.	weakness
2020-1209	Here my main comments on this work: - The authors should definitely refer to the concept of meta-learning [1], which addresses modelling problems very close to the one presented in this work: training a meta-model by aggregating information from different learning tasks.	weakness
2020-1209	The paper should definitely compare the proposed methodology with respect to this paradigm.	weakness
2020-1209	- The fact that the parameters can be averaged across nodes implies that they must be of same dimension.	weakness
2020-1209	This is counterintuitive, as the dimension of the data represented at each site may significantly differ depending on the kind of considered feature.	weakness
2020-1209	This aspect points to some methodological inconsistency.	weakness
2020-1209	- There is no comparison with any other federated method, neither with any classification method besides a NN, at least with the aggregated data.	weakness
2020-1209	Also it could have been possible to reduce the number of input features using simple dimensionality reduction previous to the NN, such as PCA.	weakness
2020-1209	- Vertical separation importance: At the end it looks like diagnosis is the main driver for the classification, showing results that are comparable to the ones obtained with the aggregated data.	weakness
2020-1209	It is therefore not clear whether the proposed application allows to clearly illustrate the benefit of using this method with regard to vertical separation.	weakness
2020-1209	- All in all, the paper appears in a draft form, and the text is often inconsistent.	weakness
2020-1209	For example, there is often inconsistency in the number of branches, or types of data considered, figures are not self-explanatory and present notation and symbols not defined anywhere.	weakness
2020-1209	The bibliography is given in a non-standard format.	weakness
2020-1209	[1] Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.	misc
2020-1209	Finn, C., Abbeel, P., & Levine, S.	misc
2020-1209	Proceedings of the 34th International Conference on Machine Learning-Volume 70 (pp.	misc
2020-1209	1126-1135). This paper considers the problem of learning from medical data that is separated both horiontally (across different practices and centers) and vertically (by data type).	abstract
2020-1209	The contribution is a "confederated" machine learning method that learns across these divides.	abstract
2020-1209	The particular application considered here as means of illustration is that of fall prediction in the elderly.	abstract
2020-1209	Specifically the authors investigate an ML approach to risk-stratifying elderly patients with respect their likelihood of falling in the next two years.	abstract
2020-1209	The basic challenge addressed here is learning in the setting in which different data elements are available only at specific sites, and it is assumed that they do not share data.	abstract
2020-1209	In addition, it is assumed there are multiple distinct sites that have data corresponding to the respective elementes.	abstract
2020-1209	However, it is assumed that labels (target vectors) are shared across all sites.	abstract
2020-1209	This setup is simulated using available data.	abstract
2020-1209	A simple distributed training scheme is outlined.	abstract
2020-1209	This is a potentially important problem worthy of study.	strength
2020-1209	I some major concerns with the present work, however.	misc
2020-1209	First, I do not think that *CONF* is really the best venue for this work.	misc
2020-1209	The machine learning component of this is quite straightforward; basically SGD is performed iteratively on parameters associated with the data types "owned" by the respective (simulated) sites.	abstract
2020-1209	Updates are then averaged over these parameter subsets.	abstract
2020-1209	This is perfectly reasonable, but not terribly novel.	weakness
2020-1209	The presentation of this is also much longer than it needs to be for the *CONF* audience.	weakness
2020-1209	I think this paper, in its current form, would be better suited for an audience more interested in clinical applications specifically (and I say this as someone quite appreciative of work on applied ML; it's just that the audience here will be more interested in methodological innovations.)	decision
2020-1209	With respect to clinical utility: Do we really need ML to tell us about risk of falls?	rebuttal_process
2020-1209	I mean, if we were to ask the MD who had seen these patients to perform a simple stratification (perhaps on an ordinal scale), would they not likely be able to do so reasonably well?	rebuttal_process
2020-1209	The authors mention something like this, discussing the 'clinical screening process' which involves asking about prior falls.	rebuttal_process
2020-1209	This seems like a really strong baseline.	strength
2020-1209	The authors argue that this is time-consuming,	rebuttal_process
2020-1209	In any case, is AUCPR an appropriate or useful metric here?	rebuttal_process
2020-1209	In practice one would need to pick a threshold on which to act; perhaps a simulation that investigated doing so would provide a more meaningful evaluation.	rebuttal_process
2020-1209	Although again a strong baseline here would probably be to ask physicians to risk stratify patients for interventions direclty (I appreciate that this would be a non-trivial experiment to run, but still).	suggestion
2020-1209	I also have a question regarding the simulation.	weakness
2020-1209	I *think* the authors have randomly assigned patients to the respective simulated sites; is that right?	weakness
2020-1209	This seems problematic because in practice patients would not be IID distributed in this way; sites would have their own patient populations which would affect the losses.	weakness
2020-1209	This should be somehow taken into account in the simulation.	weakness
2020-1209	Other comments --- - I think I am missing something in the notation here.	weakness
2020-1209	Ysi is a 'binary label' but seems to vary across 'states' for an individual, is that right?	weakness
2020-1209	Shouldn't this be constant for an individual?	weakness
2020-1209	The paper states below that "The output of the classifier is a binary variable indicating whether the beneficiary had a fall during the follow up period."	weakness
2020-1209	- Labels were derived from ICD codes; was there any effort to spot check these?	weakness
2020-1209	I am always a bit concerned about deriving labels from ICD and trusting them.	weakness
2020-1209	- As far as I understand from 2.1, the authors have not included features extracted from notes in the patient history; is that right?	weakness
2020-1209	Why not? Smaller issues --- - I would strongly suggest numbering your equations.	suggestion
2020-1209	Also, suggest using \\text while in mathmode for superscripts like `diag'.	suggestion
2020-1209	- "Step 1.." --> "Step 1." (p3)"	suggestion
2020-1209	- "The parameter Θof f is randomly initialized" --> missing space before "of"	weakness
2020-1209	- On page 4: L(Xdiag, Xmed, Xlab, Θ) is written incorrectly.	weakness
2020-1209	- page 4: "Tstands"  missing space.	weakness
2020-1209	- page 5: " fallst." --> "falls."	weakness
2020-1209	- Appendix Tables 2 and 3 both contain the typo "varaible" (should be "variable")	weakness
2020-1209	- In Appendex Table 2, I suggest reporting results with a consistent amount of precision, e.g., 0.002 --> 0.0020 here.	suggestion

2020-1231	This paper proposes an interesting optimization algorithm called first-order preconditioning (FOP).	abstract
2020-1231	The basic idea of FOP is updating the preconditioned matrix by its gradient, which avoid calculating or approximating the Hessian directly.	abstract
2020-1231	To make the algorithms more practical, the authors also conduct the low-rank FOP and the momentum-type version.	abstract
2020-1231	The empirical studies on CIFAR-10 and ImageNet validate the effectives of the proposed algorithms.	abstract
2020-1231	Major comments: 1. Section 2.1 says "we follow the example of Almeida et al. (1998) and assume that J does not dramatically".	weakness
2020-1231	However, the goal of FOP is to encourage J reduce faster.	weakness
2020-1231	Is there any conflict? 2. In low-rank FOP, the initial preconditioner P contains the term I_m which does not exist in standard FOP (section 2.1).	weakness
2020-1231	How does this term affect the update procedure?	weakness
2020-1231	Can you provide some details?	weakness
2020-1231	3. Theorem 2 provide a linear convergence of FOP under convex, Lipschitz and PL condition.	weakness
2020-1231	The proof relaxes the preconditioner P into its minimum and maximum eigenvalues.	weakness
2020-1231	Since P changes over the course of training, it is difficult to check weather the result of Theorem 2 is stronger than gradient descent method.	weakness
2020-1231	4. Why the experimental results not include the other second order optimization algorithms such as K-FAC and KFC?	weakness
2020-1231	Minor comment: The notations M in (1) (2) and (5) are ambiguous.	weakness
2020-1231	It is prefer to use another letter to present the preconditioner in (1).	weakness
2020-1231	This paper studies hypergradient descent for precondition matrices.	abstract
2020-1231	The goal is to learn an adaptable preconditioning for the task while training.	abstract
2020-1231	Specifically, they take the gradient of the loss wrt the precondition matrix and update the precondition matrix to decrease the loss.	abstract
2020-1231	They reparametrize the precondition matrix to ensure it is positive-definite and provide low-rank approximations and they provide cheap approximations for CNNs. Pros: - Figure 3 and 4 show promising results on cifar10 with a 9-layer cnn.	strength
2020-1231	- Figure 4 shows FOP can improve the accuracy for particular hyper-parameters.	strength
2020-1231	In cases improving by 2%.	strength
2020-1231	Cons: - Results on imagnet are not particularly good.	weakness
2020-1231	The improvement is not significant.	weakness
2020-1231	- Why positive-definite precondition matrix rather than positive-semi-definite?	weakness
2020-1231	- Section 5: why is a degenerate precondition matrix bad?	weakness
2020-1231	Fisher and Hessian for deep networks can be highly ill-conditioned.	weakness
2020-1231	- Theo 1 seems to have errors.	weakness
2020-1231	The term M_t in the update rule should show up in the bound on P as an exponential term in the first upper bound.	weakness
2020-1231	- Figure 2: On mnist after 20 epochs the model has not reached 1% test error.	weakness
2020-1231	Not clear if we can make any conclusions from this figure.	weakness
2020-1231	After rebuttal: I keep my rating as weak reject.	rebuttal_process
2020-1231	I reiterate that results look promising.	strength
2020-1231	However, the quality and accuracy of the writing are not acceptable for a paper on optimization.	weakness
2020-1231	In my original review I only named a few problematic statements.	misc
2020-1231	I have to clarify that I do not think fixing only those few is enough.	misc
2020-1231	I am also not convinced about the proof of Theorem 1.	weakness
2020-1231	Basically, section 6 looks very much like section 5 from Baydin et al. 2018.	weakness
2020-1231	Even the wording is mostly the same.	weakness
2020-1231	Theorem 5.1 in Baydin et al. 2018 is based on their update rule in Eq 6 in the form of alpha_t = alpha_{t-1} - beta nabla^T nabla, where alpha does not appear in the second term.	weakness
2020-1231	However, in this paper, the update rule on line 7 in Algorithm 1 is M_t = M_{t-1} + rho * eps *(.) M_{t-1}, where M_t appears in the second term.	weakness
2020-1231	Hence, the first bound in Theorem 1 in this paper cannot simply be the same as in Baydin et al. 2018.	weakness
2020-1231	This paper presents a first-order preconditioning (FOP) method to generalize previous work on hypergradient descent to learn a preconditioning matrix that only makes use of first-order information.	abstract
2020-1231	Pros: This paper extends the idea of hypergradient descent in [Almeida et al., 1998; Maclaurin et al., 2015; Baydin et al., 2017] with a preconditioning method.	strength
2020-1231	A low-rank FOP is further proposed to lighten the computation burden for the preconditioning matrix.	strength
2020-1231	Cons: 1- The novelty and contribution is not clear.	weakness
2020-1231	2- The ideas of approximating the preconditioning matrix or factorized approximate inverse have been well studied in the literature, which are not sufficiently cited in the paper, such as Adagrad (Duchi et al. 2011), review in Bottou et al. 2016, etc.	weakness
2020-1231	3- Derivation of Eq.(4) seems to be missing.	weakness
2020-1231	4- Typo errors such as "is can" in page 5.	weakness
2020-1231	5- A mistaken derivation in A.1 Eq.(20).	weakness
2020-1231	"k" should be "k+1". Therefore, I tend to give this paper a Weak Reject score.	decision

2020-1282	This paper proposes a method for generating dialogue responses that are not generic.	abstract
2020-1282	The authors propose maximizing correlation between latent representations of responses and prompts, such that the response is encouraged to contain information relevant to the prompt.	abstract
2020-1282	The method consists of two parts, the first part predicts a latent representation of the response while the second part decodes a response from the latent representation.	abstract
2020-1282	The idea is conceptually intuitive, however I have some questions regarding the details: - It's surprising that this works at all, since the inference representations seem to come from an entirely different distribution than in training (e.g. Figure 2)	weakness
2020-1282	- Given that this works, I'd like to see an ablation in which Y is removed (e.g. we go from X and Yu to Gy), so as to evaluate the utility of the "correlated response encoder".	suggestion
2020-1282	This is effectively what's happening during inference anyway.	suggestion
2020-1282	- I am skeptical about the early stopping criteria, which involve human evaluation.	weakness
2020-1282	I also don't find the justification convincing ("there is no obvious automatic metric") --- why don't we just use the automatic metrics listed in 4.3?	weakness
2020-1282	- Can the authors please comment on the choice of evaluation?	weakness
2020-1282	It seems like the evaluation metrics are different from what's typically used (e.g. see http://convai.io for PersonaChat).	weakness
2020-1282	Why don't the authors use these metrics instead?	weakness
2020-1282	This, combined with the early stopping criterion, make it difficult to evaluate the effectiveness of the proposed method in light of prior work.	weakness
2020-1282	In terms of the writing, I think the authors could do with more polish: - there are many generic claims which can be more detailed (e.g. abstract: enables our model to view semantically related responses collectively; achieving [...] better coherence)	weakness
2020-1282	- some terms are not clearly defined (e.g. semantics, one-to-many task vs.	weakness
2020-1282	one-to-one task, canonical correlated feature extractor)	weakness
2020-1282	- the introduction is overly verbose, much of it should be in the methodology section.	weakness
2020-1282	there should be an overview of experimental results and analysis in the intro.	weakness
2020-1282	- In 3.3, it doesn't seem like you "enforce" a normal distribution.	weakness
2020-1282	If I understand correctly, you use KL to encourage a normal distribution.	weakness
2020-1282	1. Summary: The authors proposed to alleviate the generic response problem in open-domain dialog generation by generating a response to a prompt from a semantic latent vector.	abstract
2020-1282	This vector needs to be located close to the latent vector of the corresponding prompt.	abstract
2020-1282	To this end, they employ canonical correlation analysis and auto-encoder to learn the mapping from a sequence of text to a semantic latent vector.	abstract
2020-1282	To model the variations and topic shifts that may happen in responses, they also use a separate intermediate vector in the auto-encoder of generating responses.	abstract
2020-1282	2. Overall assessment: While this paper is quite fun to read, it is not innovative enough and it lacks some critical experiments and error analysis to be accepted this time.	decision
2020-1282	I'll elaborate on these problems in my comments below.	misc
2020-1282	3. Strengths: 3.1 This paper is well written.	strength
2020-1282	The motivation and the main idea are well explained and pretty easy to understand.	strength
2020-1282	Although there are some details missing, it doesn't prevent readers from understanding and enjoying this paper.	strength
2020-1282	3.2 The use of human evaluation is a great plus.	strength
2020-1282	Subtle characteristics of text, such as readability, coherence, and specificity cannot be well justified by automatic evaluation.	weakness
2020-1282	Human evaluation is a must for these aspects.	weakness
2020-1282	It's great to see the authors include this in this paper.	weakness
2020-1282	4. Weakness and questions: 4.1 It seems the model in this paper can be connected to adversarial learning from some angles.	weakness
2020-1282	It would be great to see such analysis in this paper.	suggestion
2020-1282	4.2 The experiments in this paper do not look thorough enough.	weakness
2020-1282	There are many more things should be included, such as error analysis, comparisons over different variations of the proposed model and so on.	suggestion
2020-1282	What if we remove Yu in both training and inference but keep the overall model the same?	suggestion
2020-1282	How important is Yu and what's its effect?	suggestion
2020-1282	Many such questions haven't been answered in this paper.	suggestion
2020-1282	4.3 Embedding average cosine similarity seems to be too simple to be used for evaluation as it omits the contextual information and semantic meaning of a sentence.	weakness
2020-1282	4.4 It would be interesting to see the Dist-1 and Dist-2 scores of the gold standard responses.	suggestion
2020-1282	It's a good reference to let us know ho diversified the real responses are.	suggestion
2020-1282	4.5 I'd like to see some explanation of how the raters rate specificity and coherence.	weakness
2020-1282	What are the standards they use?	weakness
2020-1282	What are the instructions the author give to them?	suggestion
2020-1282	4.6 Are improvements significant in Table 1?	weakness
2020-1282	It seems the proposed model is not performing very stably over different metrics.	weakness
2020-1282	Some anlysis on this would be great.	suggestion
2020-1282	[Summary] This paper proposes a dialogue generation model that learns a semantic latent space.	abstract
2020-1282	In this paper, the authors tackle the generic response issue.	abstract
2020-1282	The proposed model consists of three (prompt/correlated response/uncorrelated response) encoders and a decoder.	abstract
2020-1282	The authors add an objective that maximizes the correlation between prompt and response features to the existing autoencoder structure, which prevents the generation of generic responses.	abstract
2020-1282	[Comments] The paper is well-organized and clearly written but has some weakness: - There seems to be a need for more detail on comparisons of papers that previously tackle the generic response problem.	weakness
2020-1282	- In addition to the proposed main architecture, there are so many things combined (ex.	weakness
2020-1282	denoising, attention). It seems like it's doing well with additional things rather than the model structure.	weakness
2020-1282	In fact, the results of the model without denoising in the ablation study show poor performance.	weakness
2020-1282	- The test pool for human-evaluation is too small (only 3 workers).	weakness
2020-1282	It seems necessary to perform the human-evaluation on a larger number of participants.	weakness
2020-1282	I think that it is a very important issue since the generic response addressed as the main problem in this paper can only be evaluated by human-evaluation.	weakness
2020-1282	[Questions] - What are the criteria for specificity and coherence used in human-evaluation?	weakness
2020-1282	If there are some criteria provided to the participants, it would be better to include a description together.	weakness
2020-1282	- Can you provide an intuitive or theoretical explanation of denoising (to add a <unk>)?	weakness

2020-1317	This paper proposes an autocompletion model for UI layout based on adaptations of Transformers for tree structures and evaluates the models based on a few metrics on a public UI dataset.	abstract
2020-1317	I like the area of research the authors are looking into and I think it's an important application.	strength
2020-1317	However, the paper doesn't answer key questions about both the application and the models: 1) There is no clear rationale on why we need a new model based on Transformers for this task.	weakness
2020-1317	What was wrong with LSTMs/GRUs as they've been used extensively for recursive problems including operations on trees?	weakness
2020-1317	Similarly, I'd have expected baselines that included those models in the evaluation section showing the differences in performance between the newly proposed Transformer model for trees and previously used methods.	suggestion
2020-1317	2) The evaluation metrics used while borrowed from the language or IR fields doesn't seem to translate to UI design.	weakness
2020-1317	UI layout is about visual and functional representation of an application so if one is seeking to evaluate different models, they need to relate to those.	weakness
2020-1317	Summary: This paper introduces the task of using deep learning for auto-completion in UI design.	abstract
2020-1317	The basic idea is that given a partially completed tree (representing the design state of the UI), the goal is to predict or "autocomplete" the final tree.	abstract
2020-1317	The authors propose a transformer-based solution to the task, considering three variants: a vanilla approach where the tree is flattened to a sequence, a pointer-network style approach, and a recursive transformer.	abstract
2020-1317	Preliminary experiments indicate that the recursive model performs best and that the task is reasonable difficulty.	abstract
2020-1317	Assessment: Overall, this is a borderline paper, as the task is interesting and novel, but the presentation is lacking in technical detail and there is a lack of novelty on the modeling side.	weakness
2020-1317	In particular, the authors spend a bulk of the paper describing the three different baselines they implement.	weakness
2020-1317	However, despite the fact that most of the paper is dedicated to the explanation of these baselines.	weakness
2020-1317	There is not sufficient detail to reproduce the models based on the paper alone.	weakness
2020-1317	Indeed, without referencing the original Pointer Network and (and especially the) Transformer papers, it would not be possible to understand this paper at all.	weakness
2020-1317	Further technical background and detail would drastically improve the paper.	weakness
2020-1317	Moreover, it seems strange that significant space was used to give equations describing simple embedding lookups (i.e., matrix multiplications with one-hot vectors), but the basic technical foundations of Transformers were not adequately explained.	weakness
2020-1317	In addition, only the transformer baselines were considered, and it would seem natural to consider LSTM-based baselines, or some other related techniques.	weakness
2020-1317	In general, the space that was used to explain the Transformer baselines---which are essentially straightforward ways to adapt transformers to this task---could have been used to give more detail on the dataset.	weakness
2020-1317	For example, one question is how often a single partial tree has multiple possible completions in the data.	weakness
2020-1317	A major issue---mainly due to the lack of technical details and the lack of promise to provide code/data (unless I missed this)---is that the paper does not appear to be reproducible.	weakness
2020-1317	Given the intent to have this be a new benchmark, ensuring reproducibility seems critical.	weakness
2020-1317	Reasons to accept: - Interesting new application of GNNs	strength
2020-1317	Reasons to reject: - Incremental modeling contribution	strength
2020-1317	- Lack of sufficient technical detail on models and dataset	weakness
2020-1317	- Does not appear to be reproducible The paper presents an auto completion for UI layout design.	weakness
2020-1317	The authors formulate the problem as partial tree completion, and investigate a range of variations of layout decoders based on Transformer.	weakness
2020-1317	The paper proposes two models: Pointer and Recursive Transformer.	abstract
2020-1317	The paper designs three sets of metrics to measure the quality of layout prediction based on the literature and the domain specifics of user interface interaction.	abstract
2020-1317	The writing quality is readable.	strength
2020-1317	The presentation is nice. The task of auto completion for UI layout design is relatively new.	strength
2020-1317	The paper misses the key baseline in Bayesian optimisation using tree structure [1] which can perform the prediction under the tree-structure dependencies.	weakness
2020-1317	[1] Jenatton, Rodolphe, et al. "Bayesian optimization with tree-structured dependencies." Proceedings of the 34th International Conference on Machine Learning-Volume 70.	misc
2020-1317	JMLR. org, 2017. NB: the reviewer has low confidence in evaluating this paper.	weakness

2020-1342	This paper empirically demonstrates that DNNs can be trained to be identity mappings for small quantities of samples.	abstract
2020-1342	It also demonstrates that for many parameterizations, these identity DNNs also have a small number of attractors, iterative fixed points, and can also learn short circular sequences of examples.	abstract
2020-1342	The paper is well written and easy to understand, although the presentation could be improved a bit (see comments).	strength
2020-1342	Its contents aren't particularly novel in terms of ideas, but they investigate memorization and attractors much further than previous studies.	strength
2020-1342	In a way, the memorization results are unsurprising.	weakness
2020-1342	We know that DNNs can memorize perfectly, including sequences, so it is natural that by increasing capacity, at some point they should be able to memorize entire images (in fact this is what Zhang et al. (2019)'s Figure 1 appears to be showing).	strength
2020-1342	The more novel and surprising aspect of this is that DNNs would learn such strong (and so few) attractor basins.	strength
2020-1342	The fact that deep autoencoders could have attractors centered on the training points has been postulated before (see [1]), but this work makes a stronger case for it.	strength
2020-1342	A crucial aspect that is missing from this paper in order for me to give in an accept is that there is very little about how this paper positions itself in the current literature.	decision
2020-1342	There could be much more discussion about related work, and much more discussion about the impacts of these findings.	weakness
2020-1342	I have given this paper a 'weak reject' mark but I think with some work this paper could be of interest to many.	decision
2020-1342	To reiterate, I am unable to see anything wrong with this paper, but at the same time I am unable to see how impactful these findings are.	weakness
2020-1342	Detailed comments: - It's interesting that DNNs can implement associative memory, but what is the cost of doing that?	weakness
2020-1342	Should we be using that in practice?	suggestion
2020-1342	Since there is no sense of how costly the presented experiments are, it is hard to tell.	weakness
2020-1342	- Again, these results are interesting, but after some time pondering about it, I can't really convince myself that knowing the results of this paper will be beneficial to future research.	weakness
2020-1342	That being said, there are many areas of Machine Learning that I am unfamiliar with.	misc
2020-1342	It should be part of the paper to familiarize readers with areas where these results could be impactful.	suggestion
2020-1342	- "the function interpolates the training images" not sure what this means.	weakness
2020-1342	Interpolation means making a prediction for a point `u` that is "between" two points `x,y` with known values	weakness
2020-1342	- "black and white" should be "grayscale" if values are in [0,1]	weakness
2020-1342	- Figure 2b is interesting, but I wonder what happens if e.g. a perturbed version of e.g. Example 6 is fed.	weakness
2020-1342	Presumably since Example 6 is not an attractor (Jacbian with an eigeinvalue > 1), it should converge to another example.	weakness
2020-1342	- Figure 2b's caption numbers, which say you use 1k example, to not correspond to numbers earlier in the text, which say you use 10k examples.	weakness
2020-1342	- "Since overparameterized autoencoders interpolate the training data", again this is a fairly important assumption and it needs to be defined very clearly, because it could mean many things.	weakness
2020-1342	- "it is essential that we interpolate to numerical precision", I don't think you are using the word "interpolate" correctly, do you mean "inference"?	weakness
2020-1342	"train"? - Adam citation should be "Adam: A Method for Stochastic Optimization, Diederik P.	weakness
2020-1342	Kingma, Jimmy Ba", not Goodfellow et al., RMSprop should also have a citation, Hinton et al. 2012 - ReLU citation should be "Rectified linear units improve restricted Boltzmann machines, Nair & Hinton", Leaky ReLU should be Maas et al 2013, SELU should be Klambauer et al. 2017.	weakness
2020-1342	- The combination of section 3.1 and Figure 3 doesn't make it clear if models trained with Adam and RMSprop have weight decay or not.	weakness
2020-1342	Can you clarify? - "Note that a minimum width of 100 is needed to allow for interpolation." Again I think you mean "learning" rather than "interpolation".	weakness
2020-1342	- You say that you trained black and white images, but all the images of CIFAR10 in the figures are colored, including the inputs and outputs.	weakness
2020-1342	Can you clarify why? - You might be interested in [2], which is much older work about perceptrons, but still relevant to what is studied here.	weakness
2020-1342	- The linked supplemental material gives a 404 for me.	weakness
2020-1342	I replicated the MNIST Figure 6 experiment.	weakness
2020-1342	I was unable to replicate exactly your results but they were similar enough.	weakness
2020-1342	In particular, the activation function choice seems to be critical.	weakness
2020-1342	[1] The Potential Energy of an Autoencoder, Hanna Kamyshanska, Roland Memisevic	misc
2020-1342	[2] Basins of Attraction in a Perceptron-like Neural Network, Werner Krauth, Marc Mezard, Jean-Pierre Nadal The paper studies a phenomenon of unusual memorisation in deep overparametrized neural networks.	abstract
2020-1342	Authors observe that, if an auto-encoder overfits to machine precision on a number of images, they can be reliably decoded from random noise and that it is even possible to memorise this way a sequence of images.	abstract
2020-1342	Essentially, images from such a training set become attractors for the mapping defined by the auto-encoder.	abstract
2020-1342	The impact of network size, nonlinearity and initialization is studied and, quite surprisingly, very unusual trigonometric non-linearities performed the best.	abstract
2020-1342	I find the studied phenomenon rather interesting and the analysis well-performed, but I am not sure how practically important is this work.	weakness
2020-1342	First, I would argue that to call the overfit auto-encoder a function associative memory, it must be able to retrieve stored images not just from random noise, but from a somehow distorted or partially known version.	weakness
2020-1342	Otherwise we are just left with a ridiculously large network that can only recall a handful of images we could store in the raw format using much less numbers.	weakness
2020-1342	Second, training until convergence takes prohibitively long time.	weakness
2020-1342	I would be also interested to at least an interesting discussion, if not an answer, to the question of why and how exactly trained images become attractors.	suggestion
2020-1342	In terms of novelty, it feels like Zhang et al, 2019 already studied a very similar phenomenon and the submitted paper does not add much to understanding of memorisation in neural networks.	weakness
2020-1342	However, memorization of sequences was indeed a surprise.	strength
2020-1342	Overall, I do not have a strong opinion on rejecting the paper, it just feels like more work in this direction will make the paper significantly better.	decision
2020-1342	Summary: This paper explores the properties of an auto-encoder to behave as an associative memory retrieval mechanism.	abstract
2020-1342	The authors show really interesting results where they are able to retrieve a small subset of encoded images (mnist) by giving the autoencoder random noise.	abstract
2020-1342	They also show they can retrieve full videos by giving the autoencoder the output frame from the previous timestep.	abstract
2020-1342	The overall problem is a really interesting one which is to try to develop associative memory, retrieval models.	strength
2020-1342	Decision: Reject Reasons: 1. Although the work is interesting, the only related work the authors cover is hopfield networks.	weakness
2020-1342	A cursory search indicates that this has been done before (k.	weakness
2020-1342	Niki IEEE, Trischler 2016, M.A.Kramer 1992).	misc
2020-1342	Improvement: 1. A more thorough discussion of related work would be helpful.	weakness
2020-1342	2. A direct qualitative comparison to related work would also be helpful.	weakness

2020-1357	This paper proposes to integrate Neural ODEs into image segmentation using level sets.	abstract
2020-1357	I think the paper makes a good methodological contribution, however I don't think that *CONF* is the best conference to publish this as the topic (image rather semantic segmentation) is too narrow and in my humble opinion, it won't attract the interest of *CONF* audience.	decision
2020-1357	Moreover, it seems to me that the saliency object detection experiment is not a very convincing one as the methods compared are a bit old (mainly from 2015-2016).	weakness
2020-1357	I strongly recommend the authors try to publish this at MICCAI focusing on kidney segmentation or any other related medical imaging application.	suggestion
2020-1357	This paper proposes to apply the Neural ODE framework (Chen et al 2018) for image segmentation.	abstract
2020-1357	The method relies on contour delineation through Level Sets.	abstract
2020-1357	Since contour estimation requires to solve an ODE, this naturally allows to apply the work presented in (Chen et al 2018).	abstract
2020-1357	The method is here applied in two segmentation tasks: kidney segmentation and salient object detection.	abstract
2020-1357	The concept underlying the paper is interesting, and leverages on very recent advances in the field.	strength
2020-1357	The idea of learning the dynamics required to evolve segmentation contours is original and certainly appealing.	strength
2020-1357	Unfortunately the content of this work seems quite preliminary in terms of presentation and experiments.	weakness
2020-1357	First, the methodology is only sketched, while the motivation underlying the modelling rationale is often missing.	weakness
2020-1357	For example, it is not clear what is the difference between "image evolution" and "contour evolution" models, besides the implementation details, and what motivates the definition of these two different modelling approaches in parallel.	weakness
2020-1357	Second, the experimental paradigm is controversial.	weakness
2020-1357	The application on medical imaging is overly simplistic, as the authors do not consider the original 3D image stack, but rather the set of corresponding 2D slices modelled independently.	weakness
2020-1357	The paper seems to ignore the large variety of body organ segmentation methods already available to the community, most of them working in 3D (e.g. [1-4]).	weakness
2020-1357	The paper should necessarily compare with respect to these approaches and, even more importantly, with respect to standard level sets methods.	weakness
2020-1357	From the practical perspective, the proposed method builds upon the results obtained with the UNet, and therefore is characterised by an additional computational burden.	weakness
2020-1357	Given that the the training of neural ODE is not straightforward and computational expensive, the use of this model for achieving a tiny accuracy improvement seems overkill for this kind of application.	weakness
2020-1357	Moreover, the segmentation accuracy is still computed slice-by-slice in the 2D images, and no information is available for the consistency of the reconstruction in 3D (regularity over the vertical axis).	weakness
2020-1357	Finally, the results reported in Table 3 are not clear, why the metrics of the competing methods are approximated (e.g. ~ 0.7), while for the proposed methods are given up to the 3rd decimal term?	weakness
2020-1357	[1] 3D Kidney Segmentation from Abdominal Images Using Spatial-Appearance Models.	misc
2020-1357	Fahmi Khalifa, Ahmed Soliman, Adel Elmaghraby, Georgy Gimel'farb, and Ayman El-Baz 1.	misc
2020-1357	[2] Automatic Detection and Segmentation of Kidneys in 3D CT Images Using Random Forests.	misc
2020-1357	Rémi Cuingnet, Raphael Prevost, David Lesage, Laurent D.	misc
2020-1357	Cohen, Benoit Mory, Roberto Ardon.	misc
2020-1357	Medical Image Computing and Computer-Assisted Intervention – MICCAI 2012: 15th International Conference, Nice, France, October 1-5, 2012, Proceedings, Part III	misc
2020-1357	[3] Multi-organ localization with cascaded global-to-local regression and shape prior.	misc
2020-1357	Medical image analysis. Gauriau, R., Cuingnet, R., Lesage, D., & Bloch, I.	misc
2020-1357	(2015), 23(1), 70-83. [4] Joint Classification-Regression Forests for Spatially Structured Multi-object Segmentation.	misc
2020-1357	Ben Glocker, Olivier Pauly, Ender Konukoglu, Antonio Criminisi.	misc
2020-1357	ECCV 2012 pp 870-881 This paper proposes to utilize Neural ODEs (NODEs) and the Level Set Method (LSM) for the task of image segmentation.	abstract
2020-1357	The argument is that the NODE can be used to learn the force function in an LSM and solve the contour evolution process.	abstract
2020-1357	The authors propose two architectures and demonstrate promising performance on a few image segmentation benchmarks.	abstract
2020-1357	While I like the attempt to combine deep learning with traditional CV algorithms, I do not think this submission is suitable for acceptance.	decision
2020-1357	My major critique is that both the two proposed models (Figure 2) are essentially two fully differentially NODE based architecture trained in a purely supervised way (by minimizing MSE).	weakness
2020-1357	This makes the flavor of the proposed methods drastically different from what an LSM does, whereas the latter heavily rely on rich priors embedded in the design of the force function.	weakness
2020-1357	To be more specific, the image evolution method (Figure 2(b)) essentially has nothing to do LSM.	weakness
2020-1357	The contour evolution method bares more similarity to LSM but only in the sense that it learns to iteratively refine a contour estimation with an NODE.	weakness
2020-1357	In the experimental evaluations, it seems that the image evolution model works favorably compared to the contour evolution method.	strength
2020-1357	This suggests that the main benefit of the proposed method comes from applying an NODE based architecture to a supervised learning task, rather than the inductive prior brought by LSM.	weakness
2020-1357	Given this, I think a much more proper way of presenting this work should be from the view of applying an NODE to the supervised image segmentation task.	weakness
2020-1357	This reduces the novelty but increases clarity, and may still make the work a useful empirical reference for these benchmarks.	strength
2020-1357	Some more detailed comments: 1. Equation 3&4 are not super easy to follow.	weakness
2020-1357	For example, \\gamma^{(1)} is not defined or explained in main text.	weakness
2020-1357	2. A related work section will be useful, especially for readers who are not familiar with LSM and NODE related literature.	weakness
2020-1357	3. Experiments with more careful control needed.	weakness
2020-1357	For example, from Table 1, it seems that the baseline Unet 15M performs inferior to the 5M model (explanation needed too), while Table 2 only compares against the 15M model.	weakness
2020-1357	This makes it difficult to interpret the results.	weakness

2020-1364	Overall the paper is well written and organized and is an application of various paradigms to extract most relevant features for Arrhythmia Subtype classification.	strength
2020-1364	Plan to release the largest (claimed) public ECG data set of continuous raw signals for representation learning containing 11 thousand patients and 2 billion labelled beats.	strength
2020-1364	Our goal is to enable semi-supervised ECG models to be made as well as to discover unknown sub types of arrhythmia and anomalous ECG signal events.	strength
2020-1364	The stated intended goal though is the discovery of new  Arrhythmia Sub types (title), "automated arrhythmia detection" (1.1 Objective).	weakness
2020-1364	A definition/example of a regular ECG signal, one presenting arrhythmia, various types of arrhythmia signal forms, would be welcome for the paper to fit this audience and be self-contained.	suggestion
2020-1364	This work suffers from many drawbacks: - A definition/example of a regular ECG signal, one presenting arrhythmia, various types of arrhythmia signal forms, would be welcome for the paper to fit this audience and be self-contained.	weakness
2020-1364	- Given the intended audience in *CONF*, the application domains specificities are not well explained.	weakness
2020-1364	Many concepts are not introduced clearly: o ECG models, sub types of arrhythmia, anomalous ECG signal events.	weakness
2020-1364	o In related work section:  Paragraph 2: more "leads", RR interval, PR interval, QRS duration, induced myocardial ischemia.	weakness
2020-1364	 Paragraph 3: single-lead wearable devices.	misc
2020-1364	o In 3 privacy concerns: heartbeats as biometrics section/ Paragraph 2:  alternative ways to sense "cardiac motion".	weakness
2020-1364	o In 4 {companyname} 11k data set section:  Paragraph 2: "third line exam".	weakness
2020-1364	 Paragraph 3: "beats and rhythms", these are fundamental to understanding graphical results provided.	weakness
2020-1364	o In 5.1 quantitative evaluation section:  Paragraph 3: " ..	weakness
2020-1364	irregular RR intervals, no distinct P waves and usually variable intervals between two atrial activations.	weakness
2020-1364	 Page 6:  " ..	misc
2020-1364	high-level abnormality labels" o 5.2 qualitative evaluation section	weakness
2020-1364	 Paragraph 1:  " ..	misc
2020-1364	has a dominant S wave in V1 lead."	weakness
2020-1364	o In 6 conclusion section:  " Single-lead heart monitors" .	misc
2020-1364	- Figures are barely decipherable o In Figure 6:  What are ESSV and ESV, btype and rtype.	weakness
2020-1364	Could you give a list of known subtypes?	weakness
2020-1364	 Is this for PVC data only?	weakness
2020-1364	- Many paragraphs are not clear to us: o Introduction/Paragraph 2:  "While cardiologists are able to see these differences, it is hard to conclude that they are 'real' by finding the same anomalous signal across multiple time points and patients without a data driven approach."	weakness
2020-1364	o In 3 privacy concerns: heartbeats as biometrics section/ Paragraph 3:  Contrary to 1), 3) & 4), is (2) "..	weakness
2020-1364	the expression of environmental variables on the heartbeat data is unique to the individual", a limitation to ECG to being considered a biometric measure?	weakness
2020-1364	o In 4 {companyname} 11k dataset section:  Paragraph 4:  "we segment each patient record into segments of 220 +1 signal samples ( ~70 minutes).	weakness
2020-1364	Care to explain the rationale?	weakness
2020-1364	 Last paragraph: " ..	misc
2020-1364	we believe that processing the data with these levels of hierarchy results in some grouping information that could be leveraged to attain better results.".	suggestion
2020-1364	This is a multi-scale approach.	weakness
2020-1364	But do you have any medical (application domain) knowledge that would justify/hint to using such approach?	weakness
2020-1364	o Figure 5:  Only Beats are labelled.	weakness
2020-1364	No Rhythm labelling? o Table 2:  "Only 2 types of labels are provided".	weakness
2020-1364	Are these beats and Rhythms?	weakness
2020-1364	What are anomalies considered in the study then?	weakness
2020-1364	o In 5.1 quantitative evaluation section:  Paragraph 2: "..PAC is an abnormal beat only because it appears too soon and disrupts the rhythm (frequency).	weakness
2020-1364	Furthermore, a PAC beat has the same shape as a normal beat, so taken alone, you can nearly not make the difference with a normal beat.".	weakness
2020-1364	A graphical representation would be welcome.	suggestion
2020-1364	 Paragraph 3: "..Both require a representation that will compose a representation showing the difference between beats over time.".	suggestion
2020-1364	o qualitative evaluation section  Paragraph 2: "We note that these are easy to see because of the different colors we use to highlight the points, but there seems to be remaining clusters that have not been analysed.".	weakness
2020-1364	The clusters are not evident to us even after purposefully colored.	weakness
2020-1364	This paper describes a large-scale ECG dataset that the authors intend to publish.	abstract
2020-1364	Along with the to-be-released dataset, the authors also provide some unsupervised analysis and visualization of the dataset.	abstract
2020-1364	The data is collected using the author's company's single lead ECG devices.	abstract
2020-1364	The dataset is collected from 11,000 patients and contains over 2.7 billion peaks.	abstract
2020-1364	According to the cited works in section 2, the scale of this proposed dataset is unprecedented and will be beneficial to the ECG community.	strength
2020-1364	I think this is an interesting dataset for the ECG machine learning community.	strength
2020-1364	Some recent advances in this field are based on non-public dataset.	strength
2020-1364	However, this dataset seems to require additional curation before it is ready.	strength
2020-1364	Questions. In section 3, the authors discuss the potential concerns regarding privacy, what are the measures taken by the authors when collecting & distributing this dataset?	strength
2020-1364	I didn't find this question addressed in section 3.	strength
2020-1364	Like the authors stated in 2nd paragraph under section 4, this dataset is biased in the sense that it is collected from patients.	weakness
2020-1364	The subjects are in the age group of 62.2 +/- 17.4.	weakness
2020-1364	Do the authors recognized various chronicle conditions that often appear in that age group?	weakness
2020-1364	Is that information part of the to-be-released dataset?	weakness
2020-1364	Since this work focuses on releasing  a dataset, I find the current experiment section unnecessary & somewhat unrelated.	weakness
2020-1364	What would be interesting to see is whether the authors use ML techniques to facilitate the curation of the dataset.	suggestion
2020-1364	For example, in paragraph 3 under section 4, it says each segment data is labeled by 3 technologists.	suggestion
2020-1364	How many technologist are involved in total?	suggestion
2020-1364	and what measure are taken to address the variances among different technologists?	suggestion

2020-1377	# Summary The paper replaces the entropy term in the objective of SAC with a KL(\\pi(a|s) || p(a)) where p(a) is the marginal distribution p(a) = \\int \\pi(a|s) \\mu(s) ds.	abstract
2020-1377	It derives the gradient of this modified objective and then proceeds to evaluate the resulting "SAC with mutual information" to demonstrate (i) better sample efficiency and (ii) generalization to environment change.	abstract
2020-1377	# Decision The paper proposes an interesting approach but a more thorough evaluation is needed before it can be recommended for publication.	decision
2020-1377	# Comments The theoretical contribution is quite small since the connection to RD theory is well established by now, e.g., see papers by Daniel Alexander Braun from Ulm and his students.	weakness
2020-1377	Therefore, the main contribution is incorporation of the mutual information into SAC.	weakness
2020-1377	Then the question is what properties/advantages/disadvantages such approach brings.	weakness
2020-1377	And on this front, the paper is quite weak.	weakness
2020-1377	The chain environment is quite toy-ish and may only serve to indicate that the implementation is correct.	weakness
2020-1377	The continuous control environments are more interesting, but the learning curves look very unreliable.	weakness
2020-1377	Just a quick Google search for SAC results on Roboschool reveals much smoother and higher learning curves (e.g., https://medium.com/@kengz/soft-actor-critic-for-continuous-and-discrete-actions-eeff6f651954).	suggestion
2020-1377	It would be paramount to make sure that the baselines are fairly represented in the evaluations.	suggestion
2020-1377	The generalization in continuous control is only evaluated on the pendulum by varying length and mass.	suggestion
2020-1377	It is insufficient to make a decisive judgement.	misc
2020-1377	Moreover, length and mass are coupled, such that different combinations of length and mass may yield similar dynamics.	weakness
2020-1377	=> If better sample efficiency and better generalization are claimed, then a more thorough evaluation is required.	weakness
2020-1377	In general, writing can be improved, figure made nicer and smaller, introduction and connections section made shorter, and the main derivation moved from the Appendix into the main body and explained better.	weakness
2020-1377	The paper presents a reinforcement learning method that regularizes the objective using the mutual information term.	abstract
2020-1377	The idea is simple and the paper is easy to follow.	strength
2020-1377	However, the novelty is limited since the difference between the proposed method and Soft Actor Critic (SAC) is just adding the entropy term of \\pi(a) to the objective function if I understand the method correctly.	weakness
2020-1377	In addition, the intuition of adding the entropy term of \\pi(a) to the objective is not clearly described.	weakness
2020-1377	The proposed method is evaluated on continuous control tasks.The results shown in the paper is mixed, and I cannot conclude that the proposed method outperforms SAC.	weakness
2020-1377	Thus, the benefit of the proposed method is not clearly supported by the experimental results.	weakness
2020-1377	For the current form of the paper, I give "weak reject" due to the weak support of the experimental results and the unclear motivation of the method.	decision
2020-1377	One of my concerns is that the way of estimating the \\pi(a) which is the marginal distribution of the action.	weakness
2020-1377	From the current manuscript, I did not fully understand how it is estimated in the proposed method.	weakness
2020-1377	I think that the accuracy of the estimation of \\pi(a) is crucial in the proposed method since it is the difference from SAC.	weakness
2020-1377	A comment on the paper structure is that the connection to the "capacity-limited" objective should be described more explicitly in Section 2.1.	weakness
2020-1377	Although the "capacity-limited" reminds me of the objective something like \\mathcal{L} + | C - I(X;Y)  | as in [Dupont, 2018],	weakness
2020-1377	the objective in the proposed method shown in page 2 is \\mathcal{L} + \\beta I(X;Y).	weakness
2020-1377	I did not understand why the proposed method is "capacity-limited" until Section 5.	weakness
2020-1377	I think authors should explicitly mention in Section 2.1 that \\beta is adjusted so as to limit the information capacity.	suggestion
2020-1377	To improve the manuscript, I request authors the following things: - The proposed method can be interpreted as adding the penalizing the entropy of \\pi(a) to the entropy-regularized RL.	suggestion
2020-1377	I do not fully understand the intuition of penalizing the entropy of \\pi(a) in the context of RL.	weakness
2020-1377	Please explain it. - I think some tasks should be performed with longer training.	weakness
2020-1377	For example, agent should be trained for 1-2 millions steps on Humanoid and Ant tasks.	weakness
2020-1377	In addition, evaluation with 10 trials are preferable.	suggestion
2020-1377	- Please cite papers that estimate the marginal distribution \\pi(a) in the same manner.	suggestion
2020-1377	If there is no previous work, please explain the details of estimating \\pi(a) and how \\pi(a) is approximated from samples.	suggestion
2020-1377	The authors propose capacity-limited reinforcement learning and apply an actor-critic method (CLAC) in some continuous control domains.	abstract
2020-1377	The authors claim that CLAC gives improvements in generalization from training to modified test environments, and that it shows high sample efficiency and requires minimal hyper-parameter tuning.	abstract
2020-1377	The introduction started off making me think about this area in a new way, but as the paper continued I started to find some issues.	misc
2020-1377	To begin with, I think the motivation in the introduction could be improved.	weakness
2020-1377	Why would I choose to limit capacity?	weakness
2020-1377	This is not sufficiently motivated.	weakness
2020-1377	I suspect that the author(s) want to argue that it *should* give better generalization, but this argument is not made very clearly in the introduction.	weakness
2020-1377	Perhaps this is because it would be difficult to make this argument formally, and so it is merely suggested at?	weakness
2020-1377	Are there connections between this and things like variational intrinsic control (VIC, Gregor et al. 2016) and diversity is all you need (DIAYN, Eysenbach et al., 2019)?	weakness
2020-1377	These works aim to maximize the mutual information between latent variable policies and states/trajectories, whereas this work is really doing the opposite.	weakness
2020-1377	I would be interested in understanding the author's take on how the two are related conceptually.	suggestion
2020-1377	Moving to the connections with past work, this paper seriously abuses notation in a way that actually hinders comprehension.	suggestion
2020-1377	Some of the parts that really bothered me, and should be fixed to be correct: Mutual information is a function of two random variables, whereas it is repeatedly expressed as a function of the policy.	weakness
2020-1377	Being explicit about the random variables / distribution here is pretty important.	weakness
2020-1377	In Equation 2 (and subsequent paragraph) the marginal distributions p_a(a) and p_s(s) are not well defined, marginalizing over what, what are these distributions?	weakness
2020-1377	I might guess that p_s(s) is the steady state distribution under a policy pi, and that p_a(a) is marginalizing over the same distribution, essentially capturing the prior probability of each action under the policy.	weakness
2020-1377	But these sort of things need to be said explicitly.	weakness
2020-1377	In KL-RL section there is a sentence with "This allows us to define KL-RL to be the case where p_0(a, s) = \\pi_0(a_t | s_t)." What does this actually mean?	weakness
2020-1377	One of these is a joint probability for state and action, and one is an action probability conditional on a state.	weakness
2020-1377	What does \\pi_\\mu(a_t) \\sim \\mathcal{D} mean?	weakness
2020-1377	In the block just before Algorithm 1, many of these symbols are never defined.	weakness
2020-1377	This needs a significant amount of care (by the authors) and right now relies on the reader to simply make a best guess at what the authors probably intend.	weakness
2020-1377	Overall in the first three sections the message I would like the authors to understand is that, in striving for a concise explanation they have significantly overshot.	weakness
2020-1377	These sections require some significant work to be considered publishable.	decision
2020-1377	The experiment in section 4.1 is intended to give a clean intuitive understanding of the method, but falls a bit short here.	weakness
2020-1377	It is clean, but I needed more explanation to really drive the intuition home.	weakness
2020-1377	I see that CLAC finds a solution more sensitive to the beta distribution, but help me understand why this is the right solution in this particular case.	weakness
2020-1377	I really disagree with the conclusions around the experiments in section 4.2.	weakness
2020-1377	I do not think these results show that for the CLAC model increasing the mutual information coefficient increases performance on the perturbed environments.	weakness
2020-1377	First, the obvious, how many seeds and where are the standard deviations?	weakness
2020-1377	Second, the trend is extremely small and the gap between CLAC and SAC is just as minor.	weakness
2020-1377	Finally, CLAC has better performance on the training distribution which means that it actually lost *more* performance than SAC when transferring to the testing and extreme testing distributions.	weakness
2020-1377	The results for section 4.3 are just not significant enough to draw any real conclusions.	weakness
2020-1377	The massive temporal variability makes me very suspicious of those super tight error bands, but even without that question, the gap is just not very large.	weakness
2020-1377	Finally, in section 4.4 we see the first somewhat convincing experimental results.	weakness
2020-1377	These look reasonable, but even here I have a fairly pointed question: compared with the results in Packer et al (2018) the amount of regression from training to testing is extremely large (whereas they found vanilla algorithms transfer surprisingly well).	weakness
2020-1377	Can you explain why there is such a big discrepancy between those results and these?	weakness
2020-1377	But again, this section's results are in my opinion the most convincing that something interesting is happening here.	strength
2020-1377	Lastly, in section 8.1 the range of hyper-parameters for the mutual information coefficient is very broad, which really makes it hard to buy the claim of requiring minimal hyper-parameter tuning.	weakness
2020-1377	All in all there is something truly interesting in this work, but in the present state I am unable to recommend acceptance, and the amount of work required along with questions raised lead me to be fairly confident in this assessment.	decision

2020-1390	The paper studies the role of over-parametrization in the student-teacher multilayer ReLU networks.	abstract
2020-1390	It presents a theoretical part about properties of SGD critical points for the teacher-student setting.	abstract
2020-1390	And a heuristic and empirical part on dynamics of the SDG algorithm as a function of properties of the teacher networks.	abstract
2020-1390	Overall, given previous literature, I do not find the presented results novel nor fundamentally very interesting and some parts are hard to understand due to missing details.	weakness
2020-1390	I tend to vote for rejection at this point.	decision
2020-1390	More detailed questions, comments follow.	misc
2020-1390	In related works: ** Paragraph on "Teacher-student/realizable setting": The recent line of works is interesting, but the authors should be clearer about this being a very classical setting dating back several decades.	weakness
2020-1390	The first paper I know where the teacher student setting appeared is by Garder, Derrida'83 (model B, https://iopscience.iop.org/article/10.1088/0305-4470/22/12/004/pdf).	weakness
2020-1390	In the classical textbook on neural networks Engel, Andreas, and Christian Van den Broeck.	misc
2020-1390	Statistical mechanics of learning. Cambridge University Press, 2001, there is a very detailed account of many results on the setting from 80s and 90s.	misc
2020-1390	** "A line of works (Saad & Solla, 1996;	misc
2020-1390	1995; Goldt et al., 2019; Freeman & Saad, 1997;	misc
2020-1390	Mace & Coolen, 1998) studied the dynamics from a statistical mechanics point of view, focusing on local analysis near to some critical points."	misc
2020-1390	and "(Goldt et al., 2019) assumes Gaussian input and symmetric parameterization to analyze local structure around critical points," The statements that these works focus on local analysis is not correct.	weakness
2020-1390	While some formal analysis in these works required an infinitesimally informed start toward the teacher the experiments (in particular all those in Goldt et al., 2019) are run from random initialization and these works show empirically that randomly initialized training converges exactly to the fixed points described in the analysis.	weakness
2020-1390	** "Local minima is Global" paragraph: This paragraph seems to neglect the empirically observed fact (e.g. https://arxiv.org/pdf/1906.02613.pdf) that there can be global minima that generalize bad.	weakness
2020-1390	Hence being global does not ensure good generalization.	weakness
2020-1390	Body of the paper: ** The authors cite: "Previous works (Ge et al., 2017; Livni et al., 2014) show that empirically SGD does not recover the parameters of a teacher network up to permutation." but they fail to mention that separate line of work, e.g. (Saad & Solla, 1996; 1995; Goldt et al., 2019) observed empirically the opposite.The different exiting works have to be reconciles and understood and that may be beyond the scope of the present work.	weakness
2020-1390	But presenting only one side of the results is not helping.	weakness
2020-1390	** The part on the dynamics with strong and weak directions reminds me on the results on so called "INCREMENTAL LEARNING" e.g. in the work: Andrew M Saxe, James L McClelland, and Surya Ganguli.	weakness
2020-1390	Exact solutions to the nonlinear dynamics of learning in deep linear neural networks.	weakness
2020-1390	arXiv preprint arXiv:1312.6120, 2013. also later: https://arxiv.org/pdf/1809.10374.pdf and others.	weakness
2020-1390	It would be useful to understand what is the relation in more detail and comment on it.	suggestion
2020-1390	** The experimental part of the paper has numerous flaws that make it hard to be understood.	weakness
2020-1390	For instance the authors do not specify the distribution of the input data.	weakness
2020-1390	Some experiments are run with CIFAR and others with "random" data, but random in which sense?	weakness
2020-1390	While generalization is the main focus of the paper the experimental results focus on the alignments of the teacher and students without really being clear how specifically the speed or the generalization error improves when neural networks are overparametrised.	weakness
2020-1390	I found this information only in Fig. 8 for the test error.	weakness
2020-1390	In Fig. 11 I do not know what are the different panels.	weakness
2020-1390	What is the parameter p?	weakness
2020-1390	So I do not know what to conclude from this figure ....	weakness
2020-1390	in the first pannel the non-overparametrized loss (blue) decreases fastest.	weakness
2020-1390	In the last pannel all curves are comparable.	weakness
2020-1390	But this would suggest that over-parametrizatoin is not really helping which seems to go agains the rest of the conclusion in the paper.	weakness
2020-1390	** A side remark: I note that the paper is on 10 pages and hence according to the paper call higher standards should be applied in the review process.	weakness
2020-1390	The paper is well written, but I am not entirely sure of the interest of the results.	weakness
2020-1390	I might accept, but would not be too disappointed if it didn't pass.	decision
2020-1390	A first comment is that the  alignment between student and teacher nodes is a very old problem, discussed at length in, for instance Saad&Solla, under the name "specialisation".	weakness
2020-1390	Since the phenomenon is known, and already has a name, it should at least be also refereed to as such.	weakness
2020-1390	The result on the overlap and the "specialisation" of the teacher to the student presented in the paper is rigorous (though I did not completely checked the proof), and seems general enough, but it seems a bit trivial: of course if I have no or little error on all my data-points, I have overlap with the teacher, and since I'm over-parameterised and it's a ReLU network, then the alignment will be many-to-one.	weakness
2020-1390	More interesting would be to study alignment in the deeper case, but the authors prove it only for the lowest layer of a deep network.	weakness
2020-1390	The paper is mainly mathematical, and they are number of things I would find more interesting than the proof (though of course, this is a personal bias): - plot the overlaps layer-wise (i.e. student layer 1 vs teacher layer 1, student layer 2 vs teacher layer 2, etc.) What do they look like?	strength
2020-1390	That's something I would actually quite like to know!	misc
2020-1390	- the result on larger nodes being learnt first is known for online learning already in the 1990s (This is a celebrated results of Saad&Solla, though not an entirely rigorous one, and only for model data), so here the contribution is to show this for ReLU networks in particular.	weakness
2020-1390	- Since ReLU networks are somewhat linear, it would be interesting to compare the results on the dynamics to plain linear networks, as in Saxe et al (e.g. https://arxiv.org/abs/1710.03667 ).	weakness
2020-1390	Discuss similarities / differences? - The absence of "specialisation" in linear model is also a well known feature, see for instance https://arxiv.org/abs/1312.6120 https://arxiv.org/abs/1710.03667.	weakness
2020-1390	Finally, I am a bit confused by the experiments : I did not understand which experiment is done for which data in fig.	weakness
2020-1390	5.6.7 (8 is for CIFAR of course) and 11.	weakness
2020-1390	This paper studies the learning of over-parameterized neural networks in the student-teacher setting.	abstract
2020-1390	More specifically, this paper assumes that there is a fixed teacher network providing the output for student network to learn, where the student network is typically over-parameterized (i.e., wider than teacher network).	abstract
2020-1390	This paper first investigates the properties of critical points of student networks in the ideal case, i.e., assuming we have infinite number of training examples.	abstract
2020-1390	Then the results have been generalized to a practical case (the gradient is smaller than some small quantity).	abstract
2020-1390	Moreover, this paper further studies the training dynamics via gradient flow, and proves some convergence results of GD.	abstract
2020-1390	Overall, this paper is somewhat difficult to follow and understand.	weakness
2020-1390	The notation system is kind of complicated and some assumptions seem to be unrealistic.	weakness
2020-1390	Detailed comments are as follows: It is a little bit difficult to get insightful understandings towards the critical points of deep neural networks from the theorems provided in this paper.	weakness
2020-1390	I would like to see clearer properties of the critical points learned by student network rather than some intermediate results.	weakness
2020-1390	The title is not consistent with the content of the paper.	weakness
2020-1390	From the title of this paper looks like a characterization on the student network trained by SGD.	weakness
2020-1390	However, throughout the paper, the authors somehow investigate the critical points under a stronger condition, i.e., all stochastic gradient is zero, rather than the widely used one, the expectation of stochastic gradient is zero.	weakness
2020-1390	I don't think the critical points considered in this paper can be guaranteed to be found by SGD.	weakness
2020-1390	Besides, when analyzing the training dynamics, as provided in Section 5, the authors resort to gradient descent, because in (5) the dynamics of Wk rely on the expectation of stochastic gradients.	weakness
2020-1390	Many statements should be elaborated in detail.	weakness
2020-1390	For example, in the paragraph before Corollary 1, why Rl is a convex polytope?	weakness
2020-1390	In Theorem 2, what's αkj?	weakness
2020-1390	What's the meaning of alignment?	weakness
2020-1390	In the paragraph after Theorem 4, why Theorem 4 suggests a picture of bottom-up training?	weakness
2020-1390	I believe the authors should provide a more detailed explanation.	weakness
2020-1390	This paper studies the over-parameterized student network, is there any condition on its width?	weakness
2020-1390	In Theorem 5, the assumption ∥g1∥∞<ϵ seems rather unrealistic, typically this bound can only hold in expectation or with high probability.	weakness
2020-1390	Besides, why there is no condition on the sample size n in Theorem 5?	weakness
2020-1390	It looks like Theorem 5 aims to tackle the case of finite number of training samples.	weakness
2020-1390	----------------------------------- Thanks for your response and revision.	misc
2020-1390	The current title is clearer and the definition of SGD critical points is more accurate.	strength
2020-1390	The observations regarding the alignment between teacher and student networks are indeed interesting.	strength
2020-1390	However, I still feel that this result is somehow difficult to parse, as I am not clear why this can be interpreted as the learning of the teacher network.	weakness
2020-1390	Therefore I would like to keep my score.	weakness

2020-1416	This paper proposes a method for fixing exposure bias (ie.	abstract
2020-1416	training vs generated distribution mismatch) in seq2seq modeling with attention, particularly for the application of speech synthesis where reference alignments are available.	abstract
2020-1416	Related Work is missing: - Another paper that studies fixing exposure bias in seq2seq learning: Wiseman & Rush.	weakness
2020-1416	Sequence-to-Sequence Learning as Beam-Search Optimization https://arxiv.org/pdf/1606.02960.pdf	misc
2020-1416	- Other papers that try to enforce attention to attend to specific locations: Bao et al. Deriving Machine Attention from Human Rationales.	weakness
2020-1416	https://arxiv.org/abs/1808.09367 Liu et al. Neural Machine Translation with Supervised Attention.	misc
2020-1416	https://www.aclweb.org/anthology/C16-1291/ Yu et al. Supervising Neural Attention Models for Video Captioning by Human Gaze Data.	misc
2020-1416	https://arxiv.org/abs/1707.06029 Without the comparison against other related papers that also aim to supervise attention mechanisms (there are other beyond the ones I cited above)s, it is unclear how much is novel about this paper.	weakness
2020-1416	- Furthermore, it is conceptually clear to me that attention-forcing fully matches the training vs generated distributions.	weakness
2020-1416	The authors should describe in greater detail why this happens this, or whether these distributions are not required to fully match in attention-forcing (and in this case, why this would be desirable).	suggestion
2020-1416	- The experiments are not very convincing (only 30 human evaluators for Speech synthesis with no other quantitative evaluation, NMT results that are not particularly promising).	weakness
2020-1416	- Use of non-anonymous github link is questionable for blinded submissions.	weakness
2020-1416	This paper proposes a novel training scheme for seq2seq models where attention or reference alignment is used in combination with free-running mode for improving training.	abstract
2020-1416	The positives of this paper are that it is well written and very clear.	strength
2020-1416	It also is very relevant as seq2seq models can be hard to train and techniques like scheduled sampling and x-forcing algorithms are good heuristics but heuristics none-the-less.	strength
2020-1416	The downside of this paper is in the experimental results and also complexity.	weakness
2020-1416	It would've been good to see a broader set of experiments to really benchmark attention-forcing from other self-attention models.	suggestion
2020-1416	Attention forcing also requires a reference or ground-truth alignment, which is often not available.	suggestion
2020-1416	Hence the authors propose to simultaneously train another teacher-forcing model to estimate the reference alignment.	weakness
2020-1416	However, this would incur twice the computation complexity.	weakness
2020-1416	Attention forcing could also be used in conjunction with scheduled sampling.	weakness
2020-1416	How does that compare with the reported results for attention forcing?	suggestion
2020-1416	This paper proposes an alternative mechanism of training the attention values of a sequence to sequence learning model as applied to tasks like speech synthesis and translation.	abstract
2020-1416	During training they compute two forms of attention: (1) the standard soft-attention from a decoder fed with teacher forced output, and (2) the inference-time attention from a decoder fed with predicted outputs.	abstract
2020-1416	Their training objective consists of two terms: The first is the token-wise cross entropy loss but by conditioning on the predicted output  but with teacher-forced attention.	abstract
2020-1416	The second is a KL distance between the above two types of attention distributions.	abstract
2020-1416	Experiments with mechanical  turks indicate that their attention forcing mechanism is strongly preferred over the existing teacher forced output and attention model.	abstract
2020-1416	On translation their method provides little or no improvement.	abstract
2020-1416	I am inclined towards rejecting the paper because the experiment and related work section still requires a lot of work before 1.	decision
2020-1416	The claimed utility of the idea is established, and 2.	abstract
2020-1416	The novelty over the many existing attention architectures is established.	strength
2020-1416	I elaborate on each of these next.	strength
2020-1416	Related work: Recently, many papers have directly or indirectly handled the problem of exposure bias that this paper attempts to address.	strength
2020-1416	The paper does not discuss most of these.	weakness
2020-1416	Here are some that are missed from the paper: 1.   Sequence level training with recurrent neural networks	weakness
2020-1416	MA Ranzato, S Chopra, M Auli, W Zaremba, 2015.	misc
2020-1416	This paper shows that the scheduled sampling method (discussed in the paper) is much worse than a reinforce-based training mechanism of handling exposure bias.	abstract
2020-1416	2. An actor-critic algorithm for sequence prediction	misc
2020-1416	D Bahdanau, P Brakel, K Xu, A Goyal, R Lowe	misc
2020-1416	3.  Posterior Attention Models for Sequence to Sequence Learning	misc
2020-1416	S Shankar, S Sarawagi - 2019	misc
2020-1416	4. Latent Alignment and Variational Attention	misc
2020-1416	Yuntian Deng, Yoon Kim, Justin Chiu, Demi Guo, Alexander M.	misc
2020-1416	Rush 2018 5. Attention Focusing for Neural Machine Translation by Bridging Source and Target Embeddings	misc
2020-1416	Shaohui Kuang, Junhui Li, António Branco, Weihua Luo, Deyi Xiong	misc
2020-1416	Experiments:  Their experiments are rather sketchy and limited.	weakness
2020-1416	The TTS experiments are only on one dataset.	weakness
2020-1416	Their method is compared only with the standard seq2seq learning approach.	weakness
2020-1416	Even the scheduled sampling or professor forcing methods are not compared with.	weakness
2020-1416	In addition, state of the art TTS methods have gained significantly from hierarchical attention.	weakness
2020-1416	As such as far as the TTS task is concerned the significance of the improved quality over a baseline seq2seq method is limited.	weakness
2020-1416	For translation they consider only the English-Vietnamese task whereas there are tens of other translation tasks that are used in recent literature.	weakness
2020-1416	Overall, the idea proposed seems quite incremental, experiments are limited, and related work discussion incomplete.	weakness
2020-1416	********* I read the author response but I do not think the paper is ready for publication yet without the thorough comparison with related work.	decision

2020-1461	This paper examines the problem of warm-starting the training of neural networks.	abstract
2020-1461	In particular, a generalization gap arises when the network is trained on the full training set from the start versus being warm-started, where the network is initially (partially) trained on a subset of the training set, then switched to the full training set.	abstract
2020-1461	This problem is practical, as it is often preferable to train online while data is collected to make up-to-date predictions for tasks (such as in online advertising or recommendation systems), but it has been found that retraining is necessary in order to obtain optimal performance.	abstract
2020-1461	The paper also mentions active learning, domain shift, and transfer learning as two other relevant and important problems.	abstract
2020-1461	The paper attempts to investigate this phenomena from a few different avenues: (1) simple experiments segmenting the training set into two different subsets, then training to completion or partial training on the first subset before switching to training on the full set;	abstract
2020-1461	(2) looking at the gradients of warm-started models;	abstract
2020-1461	(3) adding regularization; (4) warm-starting all layers, then training only last layer;	abstract
2020-1461	(5) perturbing the warm-started parameters.	abstract
2020-1461	Strengths: I believe very strongly in the practical impact of the problems presented in this paper.	strength
2020-1461	These indeed are challenging problems that are relevant to industry that have not been given sufficient attention in the academic literature.	strength
2020-1461	I appreciate the initial experimentation on this subject, and the clear demonstration of the problem through simple experiments.	rebuttal_process
2020-1461	The paper is also well-written.	strength
2020-1461	Weaknesses: Some questions I had include: - Why is the Pearson correlation between parameters of the neural network a good way of measuring the correlation to their initialization?	weakness
2020-1461	- Why is it surprising that the magnitude of the gradients of the "new" data is higher than at a random initialization?	weakness
2020-1461	- Why does this phenomena occur even though the data is sampled from the same distribution?	weakness
2020-1461	- Does this work have any relationship with work on generalization such as: [1] Recht, Benjamin, et al. "Do CIFAR-10 classifiers generalize to CIFAR-10?." arXiv preprint arXiv:1806.00451 (2018).	weakness
2020-1461	[2] Recht, Benjamin, et al. "Do ImageNet Classifiers Generalize to ImageNet?." arXiv preprint arXiv:1902.10811 (2019).	misc
2020-1461	etc. Although I like the topic of this paper, the investigation seems too preliminary at this point.	weakness
2020-1461	There is no clear hypothesis towards answering the problems proposed in the paper.	weakness
2020-1461	There is also no analysis, which places the burden on the numerical experiments to demonstrate something interesting, and the experiments seem sparse and small-scale.	weakness
2020-1461	For these reasons, I am inclined to reject this paper at this time, but I strongly encourage further exploration into the topic.	decision
2020-1461	Some potential questions or directions could include: 1. What if only a single epoch of training is used on 50% of the data?	weakness
2020-1461	Does the gap appear in that setting?	suggestion
2020-1461	I ask because one would expect that a single epoch of training on 50% of the data, then training on new data would be equivalent to training on the full dataset from the start.	weakness
2020-1461	2. How does this gap change with respect to the (relative) amount of new data introduced into the problem?	suggestion
2020-1461	For example, if one were to only add a single datapoint to the training set, would one still observe this behavior?	weakness
2020-1461	Could one potentially add data more incrementally (rather than half of the training set) and potentially mitigate this drastic change in the problem?	suggestion
2020-1461	3. There are optimization algorithms specifically designed for stochastic optimization (with a fixed distribution) versus for online optimization (online gradient, Adagrad).	suggestion
2020-1461	Is the online optimization framework perhaps more "realistic" than the stochastic optimization framework in these streaming/warm-starting settings?	weakness
2020-1461	This paper conducted an empirical study on why training with warm starting has worse generalization ability than learning from scratch.	abstract
2020-1461	The paper is interesting, however, it has something unclear to me, as explained below.	weakness
2020-1461	1) The scale and diversity of the study can be improved.	weakness
2020-1461	Only three models and three datasets were examined, which might not be representative enough.	weakness
2020-1461	For example, the popular Transformer model, the large-scale datasets like ImageNet, the language understanding and machine translation tasks, etc.	weakness
2020-1461	were not included in the study.	weakness
2020-1461	This may make the study less relevant to many important tasks and domains.	weakness
2020-1461	2) The interesting and highlight part of the paper is that it studies many different factors and aspects, including the influence of batch size, learning rate, regularization, moment, denoising, etc.	strength
2020-1461	However, I kind of feel that the experimental setting has some fatal problems, which makes the experimental results not convincing.	weakness
2020-1461	The authors partitioned the dataset into two halves, using the first half for pre-training, and then use the whole datasets for continued training.	weakness
2020-1461	Although the partitioning is random, given the limited size of the datasets, such a treatment will change the underlying distribution (frequency of the samples during training).	weakness
2020-1461	The first half of the dataset plays a more important role in training: it was used during pre-training, and also used in training.	weakness
2020-1461	So somehow the first half was used twice, or at least used more than once,  depending on the numbers of epochs in pre-training and training.	weakness
2020-1461	This distribution change may make the training a little biased, and at least it is not a fair comparison with learning from scratch (the latter will not have such bias in data).	weakness
2020-1461	So for a fair comparison, one needs to add some baselines to understand the influence of data frequency change.	weakness
2020-1461	Without the understanding from this angle, the study may be mis-leading.	weakness
2020-1461	**I read the author rebuttal, however, I still think the experiments are not comprehensive and the use of data partitions in the experiments are problematic (nothing to do with realistic or not, just for fair comparison with learning from scratch).	rebuttal_process
2020-1461	So I would not change my assessment.	rebuttal_process
2020-1461	The author proposes different approaches to the problem of  "warm-started" neural networks.	abstract
2020-1461	Models trained from scratch on the whole dataset have better performance than "warm-started" models, which are trained with weights initialized from training using part of the available data.	abstract
2020-1461	The authors change hyperparameters like batch size and learning rate and demonstrate a tradeoff between generalization performance of the model and time, required for its training.	abstract
2020-1461	We can also see that the choice of hyperparameters, necessary for the best performance, levels benefit in time from "warm starting."	abstract
2020-1461	The core idea of the paper is the investigation of various possible causes of difficulty of "warm start" to reduce training time without damaging a generalization performance.	abstract
2020-1461	The authors investigate the dependence of this effect with gradient values, regularization, part of "warm started" layers, noising weights, catastrophic forgetting, and so on.	abstract
2020-1461	The authors describe different problems where this research can be useful and tries to shed light on the causes of this problem, but the solution is not found.	weakness
2020-1461	This article can be helpful for future researchers as they continue research in this direction from a warm start.	strength
2020-1461	However, it is hard to judge how valuable this contribution is.	weakness
2020-1461	Also, see a few minor comments: 1. Maybe it should be useful to include in Table 1 results for models trained using only 50% of data.	suggestion
2020-1461	2. Typo: NVIDA -> NVIDIA (p.	misc
2020-1461	6) 3. It seems that the problem lies in the area of the complex learning landscape for optimization of Neural Networks as we end up in the worse local optimum if we use a warm start.	weakness
2020-1461	Maybe one should attack the problem with this direction, as there are several papers that investigate how the loss function landscape looks like e.g. [1]	suggestion
2020-1461	4. It seems that the behavior becomes worse if we increase the complexity of the model.	weakness
2020-1461	Investigation of the dependence of severity of warm start effect on e.g. number of layers in the network can be useful.	weakness
2020-1461	Also, it can be possible to gain some theoretical insights and provable results while dealing with simpler models.	weakness
2020-1461	[1.] H. Li, Zh. Xu et. al. Visua	misc
2020-1461	5. It might be useful to research the dependence of "warm start" effect from the portion of data on which the model was pre-trained.	suggestion
2020-1461	As I understand situations, where 80-90% of data are used in the first round of training, are more common.	suggestion
2020-1461	6. The authors provide us with graphics of accuracy on training dataset for "warm started" and trained from the scratch models.	strength
2020-1461	We can see that both models reach 100% train accuracy, and the authors state that it is impossible to spot the "warm start" problem on the training dataset because the metrics are equal.	weakness
2020-1461	Maybe it could be useful to show graphics of loss function.	suggestion
2020-1461	Despite of similar 100% train accuracy, final losses might be different("warm start" loss > from scratch loss).	suggestion
2020-1461	It may mean that in case of warm start we reach a local minimum, but not the best one.	weakness
2020-1461	7. It might be a good idea to add to Table 2 results for not-regularized model in order to compare results with and without regularization and figure out what effect on "warm started" models regularization have.	suggestion

2020-1490	The paper considers generative models and proposes to change the VAE approach in the following way.	abstract
2020-1490	While VAEs assume a generative model (prior on the latent space + stochastic generator) and aim at learning its parameters so as to maximize the likelihood of the (training) data distribution, the authors propose to derive the learning objective from a different view.	abstract
2020-1490	In my understanding, they consider the two composed mappings generator(encoder) and encoder(generator) and require the first one to have the data distribution as a fixpoint and the second one to have the latent prior as a fixpoint.	weakness
2020-1490	Starting from this idea they derive an objective function for the case that the mappings are deterministic and then further enrich the objective by either likelihood based terms or VAE based terms.	abstract
2020-1490	The new approach is analysed experimentally on MNIST, CIFAR and CelebA datasets.	abstract
2020-1490	The authors report quantitative improvements in terms of Frechet inception distance (FID) as well as sharper samples (when compared to standard VAEs).	abstract
2020-1490	I find the main idea of the paper highly interesting and compelling.	strength
2020-1490	Nevertheless, I would not recommend to publish the paper in its present state .	decision
2020-1490	The technical part is in my view very hard to comprehend.	weakness
2020-1490	This is partially due to the disadvantageous notation chosen by the authors.	weakness
2020-1490	Furthermore, the derivation of the individual terms in the objective is hard to understand and the arguments given in the text are not convincing: - The two terms in the objective related to the fixpoint of the encoder(generator) mapping seem to enforce a fixpoint that is a mixture of the latent Gaussian prior and the encoder image of the data distribution.	weakness
2020-1490	It remains unclear to me, why this is a good choice.	weakness
2020-1490	- The derivation of the additional likelihood based terms and VAE based terms is in my view hard to understand.	weakness
2020-1490	It should be possible (and I believe, is possible) to derive a simpler objective ab initio, starting from the main idea of the authors.	suggestion
2020-1490	Side note: A close visual inspection of the presented generated samples seems to confirm the known doubts about the appropriateness of the FID measure for evaluation of generative models.	weakness
2020-1490	This paper presents a set of losses to train auto-encoders using a stochastic latent code (PGA).	abstract
2020-1490	The authors relate it to VAE and propose a variational variant of their framework (VPGA), but the initial intuition is distinct from VAEs.	abstract
2020-1490	Results are presented on MNIST, CIFAR10 and CelebA and show both qualitative and quantitative improvements over VAEs.	abstract
2020-1490	The intuitions behind this framework seem sound and the authors added theoretical justifications when possible.	rebuttal_process
2020-1490	This paper seem to present a good idea that should be published, but is currently not clear enough.	decision
2020-1490	The writing of Section 3, especially section 3.1, need more work.	weakness
2020-1490	The wording needs to be improved, maybe some notations are not needed, such as z^=h(z).	weakness
2020-1490	There should be a clear description of what each loss is aiming to achieve.	weakness
2020-1490	Currently, this is not clear.	weakness
2020-1490	For instance, there are several mentions that h must map N(0, 1) to H^, but loss (2) makes it map N(0, 1) to N(0, 1) (and I don't see other losses that would make it happen).	weakness
2020-1490	It is likely I didn't understand it fully and a clearer section would help.	weakness
2020-1490	Another example of possible improvement would be calling the encoder and decoder with consistent names (for instance, Enc and Dec) could help, too.	suggestion
2020-1490	Currently, they are called encoder and decoder or generator in the text, f and g in the math, and theta and phi on figure 1.	weakness
2020-1490	I am ready to change my rating after the rebuttal if the authors address clarity of section 3.	misc
2020-1490	The main contribution of the paper is in the novel training procedure in which the target distribution and the generated distributions are mapped to a latent space where their divergence is minimised.	abstract
2020-1490	Training procedures for the same based on MLE and VAE are presented as well.	abstract
2020-1490	The idea is quite interesting but there are certain problems in clarity regarding the loss terms and the precise need for them.	weakness
2020-1490	It appears that the work is proposing a novel framework for training VAEs where instead of comparing the target and generated distribution in the data space (the standard Lr), the loss is minimised by minimizing the divergence between these distributions after mapping them onto a latent space.	abstract
2020-1490	To achieve this objective the author's design two loss terms in addition to the standard reconstruction error.	abstract
2020-1490	Authors provided two approaches for their training method based on MLE and VAE.	abstract
2020-1490	Their framework is then experimentally evaluated on the standard dataset and demonstrate superior results; better-generated images and lower FID score) and provide ablation results.	abstract
2020-1490	The explanation of the Equation 2 is confusing, where the Figure-1a and the equation seem to agree but the subsequent description says that h(.) should map N(0,I) to H^ but Equation-2 will bring h(z) closer to N(0,I).	weakness
2020-1490	Is there something missing here?	weakness
2020-1490	The notation and the derivation of the MLE approach in Section 3.3 are not clear.	weakness
2020-1490	This section would need rewriting with clearer and compact notation for better readability.	weakness
2020-1490	The main idea is quite clear but how this training procedure achieves that is not coming out clearly in this version.	weakness
2020-1490	Thus I feel the paper, though has good content, is not publishable in the current format.	decision

2020-1515	# 1403 General The paper proposes a method to achieve the no-harm fair model that will lie on the Pareto-optimal front, but has the minimum risk discrimination gap.	abstract
2020-1515	While the problem formulation is interesting, the paper is not very easy to follow and there are some aspects that the paper needs to get improved to get published, in my opinion.	decision
2020-1515	Con & Questions: The notations for the mathematical expressions are not very clearly explained.	weakness
2020-1515	I think it causes unnecessary confusions.	weakness
2020-1515	Deferring the main algorithm to the Supplementary seems weird.	weakness
2020-1515	I think the algorithm pseudo-code should be included in the main paper so that the full method can be appreciated properly.	suggestion
2020-1515	The quality of the figures is very poor.	weakness
2020-1515	Fonts are too small and hard to read.	weakness
2020-1515	Table 1 is  confusing. The numbers it presenting is not clearly described.	weakness
2020-1515	In the caption, it says they are cross-entropy risk / accuracies, but the caption also says Pareto-Fair achieves the lowest mean risk and risk disparity.	weakness
2020-1515	Where is the information about the risk disparity?	weakness
2020-1515	What exactly are the number for the row Discrimination?	weakness
2020-1515	This paper considers the notion of "no-harm" group fairness, i.e. trying to reduce the risk gap between minority and majority groups without excessive reduction in performance on the majority groups.	abstract
2020-1515	Authors formalize the problem by defining a Pareto fair classifier, i.e. one that minimizes the risk gaps between groups and belongs to the family of Pareto classifiers containing the classifier minimizing the empirical risk.	abstract
2020-1515	Authors suggest an optimization procedure for finding the Pareto fair classifier and demonstrate its performance on multiple datasets.	abstract
2020-1515	Pros: I think that studying "no-harm" classifiers is an important topic given the alarming tendency of some of the recent group fairness approaches to achieve fairness by essentially driving down the performance on the majority group without improving on the minority group.	strength
2020-1515	Decision making in medical applications is one of the prominent examples where "no-harm" is absolutely needed, as authors suggested.	abstract
2020-1515	The mathematical formulation of the problem around the notion of Pareto optimality also seems reasonable.	strength
2020-1515	Cons: My concerns are related to counter-intuitive experimental results and lack of clarity in parts of the presentation.	weakness
2020-1515	Figure 1 seems important for understanding the ideas in the paper, but is not explained in much detail.	weakness
2020-1515	Analogous to it Figure 2 is lacking important details.	weakness
2020-1515	In the upper left plot, what are the decision boundaries of the baselines?	weakness
2020-1515	What are the baselines risks in the center top figure, particularly for the equal risk classifier?	weakness
2020-1515	It is hard to see from the right figure if the proposed classifier achieves the "no-harm" fairness over the equal risk classifier - numerical summary in a table could help.	weakness
2020-1515	Finally, why is it necessary to use a neural network (which seems to be the case based on the supplement A.3) for the toy problem?	weakness
2020-1515	I would recommend working through a toy example in more detail using a linear classifier to verify the correctness of the proposed technique and improve the overall clarity.	suggestion
2020-1515	Further, absence of a toy problem with linear classifier is alarming given there is not much discussion of the algorithm and its convergence properties.	weakness
2020-1515	Regarding the real data experiments, none seem to showcase the "no-harm" versus "zero-gap" fairness tradeoff motivating this paper.	weakness
2020-1515	MIMIC-III results seem to contradict the main story of the paper.	weakness
2020-1515	The minority group appears to be "D/A/NW", then there should be a "harming" group fairness classifier achieving close to 0 discrimination at the cost of lowering performance on other subgroups.	weakness
2020-1515	The "no-harm" classifier should then achieve a similar or slightly lower performance on "D/A/NW", but much better results on other sub-groups.	weakness
2020-1515	Despite, the "no-harm" classifiers seems to outperform other approaches on "D/A/NW" by a good margin.	strength
2020-1515	Next, it appears that "Naive+Zafar" (it also would be helpful to have a brief discussion of the baselines considered) approach was not configured to eliminate A/S disparity as suggested by poor results on the D/A/NW and D/A/W, while it performs very well on other subpopulations.	weakness
2020-1515	Skin Lesion classification experiment departs from the problem of fairness and considers the problem of classification with unbalanced classes instead.	weakness
2020-1515	Results are again counterintuitive. "Rebalanced Naive" only mildly improves over the "Naive" approach, while proposed algorithm seems to achieve a quite significant mean accuracy improvement.	weakness
2020-1515	This again does not show the motivating "harm" vs "zero gap" tradeoff, but it could be interesting as the imbalanced classification is an important problem by itself.	weakness
2020-1515	Could you please compare to more advanced imbalanced classification algorithms?	weakness
2020-1515	Results on the Adult and German Credit datasets are very similar across competing methods.	weakness
2020-1515	Acknowledgement and references to the individual fairness line of works are missing when presenting the problem of fairness in machine learning.	weakness
2020-1515	Font size in tables and Figure 2 legends is too small.	weakness
2020-1515	Typo in the last sentence on page 8: "have highly impactful" -> "are highly impactful".	weakness
2020-1515	This paper introduces a new kind of algorithmic fairness framework where the focus is on first finding a fair classifier that does "no harm" and then in a subsequent step potentially allow doing harm in order to achieve even fairer outcomes.	abstract
2020-1515	Fairness is here understood as risk disparity: how different are the risks achieved by our model in the various subgroups.	abstract
2020-1515	The risk is task-dependent and can be something like a cross-entropy loss for classification problems.	weakness
2020-1515	The goal is to have similar risks in the subgroups that correspond to sensitive attributes.	weakness
2020-1515	It is often impossible to have equal risks without doing some harm because some subgroups might have higher noise-levels or fewer samples so that it is fundamentally not possible to achieve low risks in these subgroups.	abstract
2020-1515	The only way then to make risks equal is by *increasing* the risk in all the other subgroups.	suggestion
2020-1515	This is not always desirable, so this paper presents a method for finding a model that is as fair as possible without doing harm.	weakness
2020-1515	--- The basic idea of this paper is solid, but the mathematical definitions don't seem to capture that idea.	weakness
2020-1515	Definitions 3.1, 3.2 and 3.3 define together the "optimal Pareto-fair classifier".	weakness
2020-1515	But this doesn't seem to correspond to what was described before.	weakness
2020-1515	Here is an example to show what I mean: Say, we have two subgroups: a=0 and a=1 and the risk is a binary classification loss.	weakness
2020-1515	Furthermore, we have two classifiers h1 and h2.	weakness
2020-1515	Now, say the achieved risk is such that h1 achieves 80% accuracy on a=0 and 30% accuracy on a=1 (to make it precise it should be classification loss instead of accuracy but those two should be basically equivalent); classifier h2 achieves 60% on a=0 and 31% on a=1.	weakness
2020-1515	According to definition 3.1, neither of them dominates the other.	weakness
2020-1515	So they could both be in the Pareto front.	weakness
2020-1515	But classifier h2 clearly does harm to a=0.	weakness
2020-1515	And furthermore, definition 3.3 will choose h2 over h1 as the optimal classifier as the gap is smaller with h2.	weakness
2020-1515	So how can you claim that the optimal Pareto-fair classifier does no harm?	weakness
2020-1515	Now, the classifier that you train in the end is actually from a much smaller subset that happens to be in the Pareto front: it is one that minimizes the overall risk (Lemma 3.2) and this subset might really do no harm, but that is still not obvious to me.	weakness
2020-1515	Another problem that I see is that the proof for Lemma 3.1 is not constructive, so while there might exist a classifier hp that dominates h, you might not be able to find it; and just using h might turn out to be a reasonable choice.	weakness
2020-1515	Minor comments: - the plots don't seem to be vector graphics	weakness

2020-1518	This paper presents an algorithm to generate images for training a student network through distillation.	abstract
2020-1518	The paper claims the use of the same training data is not necessarily beneficial when it comes to improving the accuracy of the student being trained.	weakness
2020-1518	The paper sits on the empirically driven side with sufficient experiments in the context of random forest and CNN.	weakness
2020-1518	As a second contribution, the paper proposes a scoring process to evaluate the quality of datasets generated by GAN methods.	abstract
2020-1518	There are little experiments on this side.	weakness
2020-1518	Pros: - I like the paper and the idea behind being able to improve or even train a student network when the original data is not present.	strength
2020-1518	- Metrics tailored to the problem are relevant.	strength
2020-1518	Negs: - While there are plenty of experiments, there is a lack of detailed descriptions.	weakness
2020-1518	- The scoring for GANS seems to be barely tested.	weakness
2020-1518	In the scoring GAN, The fact that TSCS drops is enough to be a valid metric (or better than existing?).	weakness
2020-1518	In the TSC vs inception, it is hard for me to see the unrealistic artifacts and, according to the text, that is not what TSCS is measuring, right?	weakness
2020-1518	What is the influence of using different student-teacher configuration?	weakness
2020-1518	(on the time to produce the scores the paper claims NiN and LeNet, is there any difference if using other architectures (ResNet family for instance)?	weakness
2020-1518	At least, in that case, the time changes.	weakness
2020-1518	It would be nice to see the stability of this metric to demonstrate that the need for training an inexpensive model is correct.	suggestion
2020-1518	For the TSC vs Inception, the GANs are subjectively assessed, isn't it (as to select well-trained to Inferior).	suggestion
2020-1518	Would it be possible to see exactly the same images between the two of them?	suggestion
2020-1518	Seems like the difference in quality for IS is significantly larger than for the proposed metric (even in the last gan there is a slight increase in the metric).	weakness
2020-1518	It seems to me that IS is just a quality metric based on how a single image looks like.	weakness
2020-1518	Would it be possible to disentangle the training and the scoring in the proposed metric?	weakness
2020-1518	What if my hyperparameters for doing the single epoch are totally wrong?	weakness
2020-1518	In the general idea of the GAN, while I like it, there is little about how the GAN is actually trained.	weakness
2020-1518	I guess this GAN is trained using some sort of real data and therefore, the comparison is not totally fair.	weakness
2020-1518	How many images were used to train this GAN?	weakness
2020-1518	What would happen if those images are used directly in the distillation framework?	weakness
2020-1518	How many images are generated in section 4?	weakness
2020-1518	Is the influence of pfake related to the dataset?	weakness
2020-1518	If I have to train using another dataset, how do i set that parameter?	weakness
2020-1518	In this manuscript, authors adopt GAN for data augmentation to improve the performance of knowledge distillation.	abstract
2020-1518	My concerns are as follows.	misc
2020-1518	1. The novelty is limited.	weakness
2020-1518	Using GAN for data augmentation is not new and authors only introduce it for KD, which didn't address the essential problem of KD itself.	weakness
2020-1518	2. The experiments are not sufficient.	weakness
2020-1518	For DNNs, authors only compare the performance on CIFAR-10 with the conventional KD.	weakness
2020-1518	More data sets and benchmark algorithms are helpful to illustrate the effectiveness of GAN data.	weakness
2020-1518	This paper proposes an approach for improving teacher-student compression by introducing the assistant of GANs. A conditional GAN is trained for generating synthetic data.	abstract
2020-1518	Then, the generated data combined with training data is used for knowledge distillation.	abstract
2020-1518	Experiments on large random forests and deep neural networks demonstrate the effectiveness of the proposed method on data-augmentation.	abstract
2020-1518	Moreover, an evaluation metric is proposed to evaluate s across-class diversity and intra-class diversity for generative models.	abstract
2020-1518	Pros: + While using synthetic data of GANs to assist supervised learning has been shown to be failed in pervious works (e.g. [1] and also shown in this paper, this paper presents a new perspective to utilize GAN as a successful data-augmentation technique in teacher student paradigm.	strength
2020-1518	+ Experiments are conducted in several settings including different models (random forests, deep neural networks) and different datasets (images and tabular) to show the effectiveness of proposed method in various settings.	strength
2020-1518	+ The proposed GAN-TSC can be combined with standard augmentation to achieve higher performance as shown in the experiments.	strength
2020-1518	+ This paper is well written and easy to follow.	strength
2020-1518	Cons: - Knowledge distillation, as a classical model compression technique, has been applied in deep convolutional models for several years.	weakness
2020-1518	The CIFAR-10 dataset is too simple to evaluate this kind of methods.	weakness
2020-1518	The author should try to conduct experiments on large scale datasets such as ImageNet, unless the reliability of the proposed algorithm would be very limited.	suggestion
2020-1518	- The proposed TSCScore seems to be similar with [1], especially when its novelty mainly lies in intra-class diversity compared with IS.	suggestion
2020-1518	It's necessary to discuss difference between TSCScore and [1].	weakness
2020-1518	[1] Konstantin Shmelkov, Cordelia Schmid, and Karteek Alahari.	misc
2020-1518	How good is my GAN?	misc
2020-1518	ECCV 2018.	misc

2020-1527	The paper is about a method for estimation of parameters of a collection of HMMs and the main contribution is the  combination of classical EM with a neural net.	abstract
2020-1527	+ I like the idea of generally approximating gradients in more specific layers that are usually not easy to compute.	strength
2020-1527	They clearly formulate their message here and the technical parts of adapting work from prior literature looks solid.	strength
2020-1527	- At the same time I don't know how much the computational constraints that are formulated are really constraints in practice.	weakness
2020-1527	A couple of the related works that are cited don't seem to have these issues.	weakness
2020-1527	Naively O(T^2) doesn't really sound like too much of a problem unless the sequences are really long.	weakness
2020-1527	(In their practical example that isn't applied to more general recommender systems, this doesn't really seem to be the case.	weakness
2020-1527	So it's unclear ) + The technical contribution of the gradient estimation seems sound.	strength
2020-1527	While I didn't really go through the proof of convergence, it at least looks rigorous.	strength
2020-1527	But I would have to spend a lot more time here to form a well informed opinion.	misc
2020-1527	+ The experiments on synthetic data are clear and further empirically motivate the authors' work.	strength
2020-1527	The paper is very well written in some parts and in other parts is difficult to understand.	weakness
2020-1527	- I am not sure what the benefit of the "e-commerce" application is to the community.	weakness
2020-1527	The dataset seems to be neither open-source, nor referenced and is insufficiently described.	weakness
2020-1527	The comparison and conclusion with respect to e.g. GraphSage is hard to interpret as GraphSage is neither explained nor referenced properly (unless I missed it somehow).	weakness
2020-1527	The authors repeatedly emphasize that their approach works well here but not in the "more general recommender systems scenario".	weakness
2020-1527	It would be good if the authors showed something that the rest of the community can directly relate to instead of something that is closed-source and by definition not reproducible.	suggestion
2020-1527	- I suppose "We apply DENNL in a clearly defined and fast-growing sector on OUR e-Commerce platform, namely Home Decoration" is technically a violation of the blind review if the authors were to now include a reference/link etc.	weakness
2020-1527	to the dataset. On the other hand, if the dataset remains closed-source then blind review isn't violated but results aren't reproducible and hard to follow by the community with the current level of description.	weakness
2020-1527	If the authors can comment about the last few points above (especially about open dataset, reproducibility) then I will reconsider raising the rating.	suggestion
2020-1527	The authors propose to use numerical differentiation (using random perturbation) to approximate the Jacobian of a particular update (essentially equations 5~7) which plays an important role in the estimation of HMMs.	abstract
2020-1527	To do so, the authors provide first a concise intro to HMM models (well known stuff in S2), presenting the iteration in detail, jump into their model (cryptically presented in my opinion in S3) and then propose a numerical approximation scheme using SPSA (building upon literature from the 90's, with Theo 1 being the main contribution), before moving onto experiments.	abstract
2020-1527	I have found the paper poorly presented.	weakness
2020-1527	Its general motivation stands on a shaky ground (as illustrated by the choice of words by the authors, see below).	weakness
2020-1527	In terms of presentation, reminders on HMM are welcome, but unfortunately the authors have not kept the same standard for clarity of notation in Section 3, which makes reading and understanding what the authors are doing quite difficult.	weakness
2020-1527	Not being a specialist in this field, I have struggled a bit to understand the model itself, and the practical motivation of adding a DNN in the middle of what is otherwise an unrolled back-and-forth between k steps of EM estimation of transition parameters and the addition of a DNN layer.	weakness
2020-1527	Despite the complexity in the story, what the authors propose is essentially to apply a numerical approximation scheme for Jacobians of these EM updates instead of backprop.	weakness
2020-1527	Since this is the crux of the contribution,  I feel some more numerical evidence that their approach works compared to baselines (e.g. Hinton et al 2018) is needed.	suggestion
2020-1527	For these reasons my assessment is a bit on the lower side.	misc
2020-1527	- parenthesis bug in b_j(...	weakness
2020-1527	in Eq.4 - in Eq. 5, index i appears both in numerator (as regular index) and denominator (as sum index)	weakness
2020-1527	- what is \\Psi in Eq.8 ?	weakness
2020-1527	- "While HMM is arguably less prevalent in the era of deep learning": odd way to start an intro.	weakness
2020-1527	All papers cited date back to more than 2011, 2 in 2006, all the rest in 20th century.	weakness
2020-1527	This is particularly strange given the few citations to papers >2015 in Section 5.	weakness
2020-1527	- the observation sequence o_{t,1:T(u)} is "weakly" indexed by u (since T(u) is just a length)	weakness
2020-1527	- What is the \\forall u notation below Eq. 9?	weakness
2020-1527	- "the number of nodes required to build the forward and backward probability in the computation graph of an automatic differentiation engine is on the order of O(T^2).	weakness
2020-1527	Empirically we found this leads to intractable computation cost." since this is critical, where is this empirical evidence?	weakness
2020-1527	this seems to be a storage problem and cannot be a complexity issue.	ac_disagreement
2020-1527	There are ways to mitigate this problem by only storing partially information, I feel this comparison would add a lot of value to the authors' claim.	suggestion
2020-1527	- Where is J^{(k)} defined (as opposed to \\hat{J}^{(k)}) defined in Eq.14?	weakness

2020-1572	The paper is an empirical study that looks into the effect of neural network pruning on both the model accuracy as well as the generalization risk (defined as the difference between the training error and the test error).	abstract
2020-1572	It concludes that while some pruning methods work, others fail.	abstract
2020-1572	The authors argue that such discrepancy can be explained if we look into the impact of pruning on "stability".	abstract
2020-1572	The first major issue I have with the paper is in their definition of stability.	weakness
2020-1572	I don't believe that this definition adds any value.	weakness
2020-1572	Basically, the authors define stability by the difference between the test accuracy pre-pruning and post-pruning.	weakness
2020-1572	This makes the results nearly tautological (not very much different from claiming that the test accuracy changes if the test accuracy is going to change!).	weakness
2020-1572	One part where this issue is particularly important is when the authors conclude that "instability" leads to an improved performance.	weakness
2020-1572	However, if we combine both the definition of test accuracy and the definition of "instability" used the paper, what the authors basically say is that pruning improves performance.	weakness
2020-1572	To see this, note that a large instability is equivalent to the statement that the test accuracy changes in any direction (there is an absolute sign).	weakness
2020-1572	So, the authors are saying that the test accuracy after pruning improves if it changes, which is another way of saying that pruning helps.	weakness
2020-1572	The second major issue is that some of the stated contributions in the paper are not discussed in the main body of the paper, but rather in the appendix.	weakness
2020-1572	For example, the authors mention that one of their contributions is a new pruning method but that method is not described in the paper at all, only in the appendix.	weakness
2020-1572	If it is a contribution, the authors should include it in the main body of the paper.	suggestion
2020-1572	Third, there are major statements in the paper that are not well-founded.	weakness
2020-1572	Take, for example, the experiment in Section 4.4, where they apply zeroing noise multiple times.	suggestion
2020-1572	The authors claim that since the weights are only forced to zero every few epochs, the network should have the same capacity as the full network (i.e. VC capacity).	weakness
2020-1572	I disagree with this. The capacity should reduce since those weights are not allowed to be optimized and they keep getting reset to zero every few epochs.	ac_disagreement
2020-1572	They are effectively as if they were removed permanently.	strength
2020-1572	This paper studies a puzzling question: if larger parameter counts (over-parameterization) leads to better generalization (less overfitting), how does pruning parameters improve generalization?	abstract
2020-1572	To answer this question, the authors analyzed the behaviour of pruning over training and finally attribute the pruning's effect on generalization to the instability it introduces.	abstract
2020-1572	I tend to vote for a rejection because	decision
2020-1572	(1) The explanation of instability and noise injection is not new.	weakness
2020-1572	Pruning algorithms have long been interpreted from Bayesian perspective.	weakness
2020-1572	Some parameters with large magnitude or large importance contribute to large KL divergence with the prior (or equivalently large description length), therefore it's not surprising that removing those weights would improve generalization.	weakness
2020-1572	(2) To my knowledge, the reason why over-parameterization improves generalization (or reduces overfitting) is because over-parameterized networks can find good solution which is close to the initialization (the distance to the initialization here can be thought of as a complexity measure).	weakness
2020-1572	In this sense, the effect of over-parameterization is on neural network training.	weakness
2020-1572	However, pruning is typically conducted after training, so I don't think the fact that pruning parameters improves generalization contradicts the recent generalization theory of over-parameterized networks.	ac_disagreement
2020-1572	Particularly, these two phenomena can both be explained from Bayesian perspective.	abstract
2020-1572	This paper mainly studies the relationship between the generalization error and mean/variance of the test accuracy.	abstract
2020-1572	The authors first propose a new score for pruning called E[BN].	abstract
2020-1572	Then, the authors observe the generalization error and the test accuracy mean/variance for pruning large score weights and small score weights for VGG11, ResNet18, and Conv4 models.	abstract
2020-1572	From these experiments, the authors observe that pruning large score weights generates instable but high test accuracy and smaller generalization gap compared to pruning small score weights.	abstract
2020-1572	The authors additionally study some other aspects of pruning (e.g., pruning as a noise injection) and conclude the paper.	abstract
2020-1572	Overall, I am not sure whether the observation holds in general due to the below reasons.	abstract
2020-1572	- The authors proposed a new score E[BN] and all experiments are performed on this.	weakness
2020-1572	However, how it differs from the usual magnitude-based pruning in practice is unclear.	weakness
2020-1572	I would like to know whether similar behavior is observed for the naïve magnitude-based pruning.	suggestion
2020-1572	- I think that the author's observation is quite restricted and cannot extend to a general statement since the experiments are only done for pruning small score/large score weights.	weakness
2020-1572	To verify the generalization and instability trade-off, I believe that it is necessary to examine several (artificial) pruning methods controlling the instability of test accuracies and check whether the proposed trade-off holds.	suggestion
2020-1572	For example, one can design pruning methods that disconnect (or almost disconnect) the network connection from the bottom to the top (i.e., pruned network always outputs constant) with some probability to extremely increase the instability.	suggestion
2020-1572	- The authors did not report the results for high sparsity.	weakness
2020-1572	Besides, I am not sure the meaning of the instability since when the test accuracy of the pruned model is higher than that of the unpruned model, the instability could be large.	weakness
2020-1572	Other comments: - The first paragraph mentions that the generalization gap might be a function of the number of parameters.	weakness
2020-1572	However, I think that it is quite trivial that the generalization gap is not a function of the number of parameters while it only provides the upper bound.	weakness
2020-1572	---------------------------------------------------------- I have read the authors' response.	misc
2020-1572	Thanks for clarifying the definition of instability and additional experiments with high sparsity.	strength
2020-1572	However, I will maintain my score due to the following concern.	misc
2020-1572	The remaining concern is that the current evidence for verifying generalization-stability tradeoff is not convincing as the authors presented only some examples having small and large instability (e.g., pruning smallest/largest weights) under the same pruning algorithm.	rebuttal_process
2020-1572	I think that the results would be more convincing if the authors add a test accuracy plots given a fixed prune ratio, whose x-axis is controlled instabilities (e.g., from 10% to 90%) among various pruning algorithms (other than magnitude-based ones, e.g., Hessian based methods).	suggestion
2020-1572	It would be much more interesting if the same instability results same test accuracy even for different pruning algorithms.	suggestion

2020-1573	This paper starts with a conceptual claim that incorporating a notion of "empathy" in language emergency would help agents learn faster.	abstract
2020-1573	The paper then proposes a learning mechanism for implementing this, and looks at its empirical effect for the case of a Speaker-Listener game.	abstract
2020-1573	The concept at the core of the paper is thought-provoking, somewhat grounded in human communication, and it's interesting to see how this can be translated into a learning mechanism for the multi-agent setting.	strength
2020-1573	The specific implementation proposed seems reasonable at a high level, however there are many technical details missing which really hamper the paper's message & potential scientific impact.	weakness
2020-1573	The results are limited to a single game, with just a pairwise comparison (with and without "empathy"), and provide a narrow view into the effectiveness of the proposed technique.	weakness
2020-1573	My main problem with the paper is the clarity & organization problems.	weakness
2020-1573	Usually I tend to be lenient on this, thinking poor writing is much easier to fix than poor science.	ac_disagreement
2020-1573	But in this case the problems are large enough that the paper is just too far from the standard for *CONF* publication.	decision
2020-1573	It also fits in 5 pages, so the authors had lots of space to write a much better paper.	decision
2020-1573	I encourage them to do this for a future submission, in addition to more extensive results, because I think the ideas are worthwhile.	decision
2020-1573	Specific comments: Design of the empathy mechanism.	weakness
2020-1573	Can you motivate why it's reasonable to "achieve a high relation between the hidden states of both agents"?	suggestion
2020-1573	Is this necessary / sufficient for empathy?	weakness
2020-1573	What are alternate framings of this?	weakness
2020-1573	What are properties and pros/cons of this framing?	suggestion
2020-1573	Sec.4 needs a lot more detail!	weakness
2020-1573	Sections Agent setup, Learning and Empathy Extension in Sec.5 should be moved to Sec.4, since they describe the method, rather than the experiments.	weakness
2020-1573	Sec.5 needs better clarity. o What are m^l_t and M^{<l}_t in Eqn 5?	weakness
2020-1573	Define how h_S and h_L are parameterized, and how each is trained.	weakness
2020-1573	o Fig.2 gives a high-level view of the approach, but lacks important details.	weakness
2020-1573	Do you apply a loss at both the Speaker's Decoder output, and the Listener's Decoder output?	weakness
2020-1573	Or just the latter? What is the loss specifically?	weakness
2020-1573	I assume combination of Eqn 5 and Eqn 6, but not sure.	weakness
2020-1573	o If you train just on the loss of the Listener's Decoder, does this mean this is backpropagated all the way to train the Speaker?	weakness
2020-1573	How would this be done in a real system?	weakness
2020-1573	It's a very strong assumption to say that the Listener will share gradients with the Speaker.	weakness
2020-1573	It seems more realistic to assume they will each observe a loss and train independently.	weakness
2020-1573	Results are very brief. o How robust are the results to the specification of the \\alpha (the loss weight from Eqn 6)?	weakness
2020-1573	How much data goes to finding a good \\alpha?	weakness
2020-1573	o What is the difference between the left and the right plot?	weakness
2020-1573	Is one for the Speaker and the other for the Listener?	weakness
2020-1573	o How do you measure "learning speed", which is the main metric discussed in the text of Sec.6?	weakness
2020-1573	o How do the results change by number of concepts in the game?	weakness
2020-1573	o Do you do any pre-training of the encoder/decoder networks?	weakness
2020-1573	o Can you show confidence intervals on each curve?	weakness
2020-1573	o Can you show test performance?	weakness
2020-1573	o Are there other related games to consider?	weakness
2020-1573	Many references missing throughout to support statements, e.g. o "Natural language is not as rule-based as…"	weakness
2020-1573	o "These considerations led to the research field of emergent communication…"	misc
2020-1573	o Sec.2:  Earlier refs to RL in general (e.g. work Sutton in the 1980's).	weakness
2020-1573	Earlier refs to RL with neural networks (e.g. work of G.	weakness
2020-1573	Tesauro; work of M. Riedmiller). o Referential game in Fig.1 caption.	weakness
2020-1573	Some minor language issues, e.g. o "The field was then alleviated" -> Do you mean elevated?	weakness
2020-1573	Summary: This paper aims to take insight from human language acquisition and the importance of empathic connection to learn better models for emergent language.	abstract
2020-1573	The authors propose an approach to introduce the notion of empathy to multi-agent deep RL by extending existing approaches on referential games with an auxiliary task for the speaker to predict the listener's empathy/mind.	abstract
2020-1573	Experiments show that this gives some improvement with faster convergence.	abstract
2020-1573	Strengths: - The concept is interesting and grounded in human communication.	strength
2020-1573	Weaknesses: - I like the motivation of predicting empathy, but the paper vastly oversells this part: I don't see how predicting the listener's hidden state is the same as modeling empathy.	weakness
2020-1573	Empathy is a complex human state/emotion that should not be reduced to this.	weakness
2020-1573	- This paper is very preliminary.	weakness
2020-1573	There are multiple typos in the paper.	weakness
2020-1573	Figures are not professionally created.	weakness
2020-1573	There are multiple training details not included such as how the agents are modeled and trained.	weakness
2020-1573	The authors seem to have run out of time given the short length of the paper.	weakness
2020-1573	- The experimental results are not convincing at all.	weakness
2020-1573	The improvement is too small and it would help to run the experiment multiple times to see the improvement with respect to variance in the model.	weakness
2020-1573	There should also be experiments testing the effect of \\alpha on performance.	weakness
2020-1573	There is no analysis of how well the model is able to predict empathy, as well as ablation studies testing for various design decisions.	weakness
2020-1573	The authors should also add an analysis of the learned communication protocols and whether they are different in a meaningful way.	weakness
2020-1573	This paper takes the reference-game setup of Lazaridou et al. (2018), as a means of enabling emergent communication, and adds an auxiliary task to demonstrate that this helps with language emergence.	abstract
2020-1573	The auxiliary task is to enable the speaker to predict the hidden state of the listener, after the message has been received.	abstract
2020-1573	This is (not unreasonably) likened to providing the speaker with some empathy, in that it enables the speaker to try and predict what the effect of the message will be on the listener.	abstract
2020-1573	The main result is that the learning exhibits a speed-up, arriving at roughly the same level of overall reward but in fewer training steps.	abstract
2020-1573	The idea of adding an "empathy" auxiliary task to the reference-game setup is an interesting one, and the approach is well-motivated and described, including a background section.	strength
2020-1573	Unfortunately, however, the contributions of the paper are some way off what would be required for a full *CONF* paper.	decision
2020-1573	Note that the main experimental results section takes up only 1/3 of a page, and the overall paper has only 5 pages of content.	weakness
2020-1573	(As far as I know there is no requirement for an *CONF* paper to take up the whole 8 pages, but a submission with only 5 pages is quite unusual.)	ac_disagreement
2020-1573	So the overall contribution could be summarised as taking an existing emergent-language setup with the same speaker and listener neural architectures;	suggestion
2020-1573	adding a single MLP to the speaker;	suggestion
2020-1573	and showing two graphs of training reward, varying the number of candidates (2 and	strength
2020-1573	5). I hope that the authors can perhaps see that this submission would be better suited to a dedicated workshop on emergent communication (and even then it would need more experiments and analysis).	decision

2020-1605	** Summary ** In this paper, the authors propose a new variant of Transformer called Tied-multi Transformer.	abstract
2020-1605	Given such a model with an N-layer encoder and an M-layer decoder, it is trained with M*N loss functions, where each combination of the nth-layer of the encoder and the mth-layer of the decoder is used to train an NMT model.	abstract
2020-1605	The authors propose a way to dynamically select which layers to be used when a specific sentence comes.	abstract
2020-1605	At last, the authors also try recurrent stack and knowledge to further compress the models.	abstract
2020-1605	** Details ** 1. The first question is "why this work": a. In terms of performance improvement, in Table 2, we can see that dynamic layer selection does not bring any improvement compared to baseline (Tied(6,6)).	weakness
2020-1605	When compared Tied(6,6) to standard Transformer, as shown in Table 1, there is no improvement.	weakness
2020-1605	Both are 35.0. b. In terms of inference speed, in Table 2, the method can achieve at most (2773-2563)/2998 = 0.07s improvement per sentence, which is very limited.	weakness
2020-1605	c. In terms of training speed, compared to standard Transformer, the proposed method takes 9.5 time of the standard Transformer (see section 3.4, training time).	weakness
2020-1605	Therefore, I think that compared to standard Transformer, there is not a significant difference.	weakness
2020-1605	2.  The authors only work on a single dataset, which is not convincing.	weakness
2020-1605	3. In Section 5, what is the baseline of standard RS + knowledge distillation?	weakness
2020-1605	This work proposes a way to reduce the latencies incurred in inference for neural machine translation.	abstract
2020-1605	Basic idea is to train a model with softmax attached to each output of decoder layers, and computes a loss by aggregating the cross entropy losses over the softmaxes.	abstract
2020-1605	During inference, it could either use one of the softmax or train an additional model which dynamically selects softmaxes given an input string.	abstract
2020-1605	Experimental results show that it is possible to reduce latencies by trading off the translation qualities measured by BLEU.	abstract
2020-1605	Dynamically selection did not show any gains in latencies, though, this work empirically shows potential gains in oracle studies.	abstract
2020-1605	This work further shows that the model could be compressed further by knowledge distillation.	abstract
2020-1605	I have several concerns to this work and I'd recommend rejecting this submission.	decision
2020-1605	- One of the problems of this paper is presentation.	weakness
2020-1605	This work basically combines three work together as a single paper, i.e., section 3 for the basic model, section 4 for dynamic selection and section 5 for distillation, with each section describing a separate experiment.	weakness
2020-1605	I'd strongly suggest the author to focus on the main point, e.g., dynamic selection, and present the basic model and dynamic selection.	suggestion
2020-1605	Experiments should be presented in a single section for brevity.	suggestion
2020-1605	- Similarly, this work should have been submitted when meaningful gains were observed in the dynamic selection method, given that the proposal is somewhat new.	weakness
2020-1605	Otherwise, I don't find any merits to see this accepted in *CONF*, given the rather negative results in section 4.	decision
2020-1605	- The description in section 4.2 is totally messed up.	weakness
2020-1605	x^i and y^i_k are strings since they are an input sentence and an output sentence, respectively,.	weakness
2020-1605	However, they are treated as scalars in Equation 3 by multiplied with \\delta_k, subtracted from 1 and taking sigmoid through \\sigma.	weakness
2020-1605	I strongly suggest authors to carefully check variables used in the equations and the description in the section.	suggestion
2020-1605	- The authors claim that the use of knowledge distillation is novel.	suggestion
2020-1605	However, it is already widely known in the research community and I don't think it is worthy to keep it as a single section.	strength
2020-1605	It could have been described as a yet another experiment in a single experimental section.	weakness
2020-1605	Other comment: - Although this paper claims that attaching a softmax for each output layer is new, there is a similar work in language modeling, though the motivation is totally different.	weakness
2020-1605	Direct Output Connection for a High-Rank Language Model, Sho Takase, Jun Suzuki and Masaaki Nagata, EMNLP 2019.	misc
2020-1605	- In section 3.4, this paper claims that the training of all 36 models took 25.5 more time, but took 9.5 more time for a tied-model when compared with a basic 6-layer Transformer.	weakness
2020-1605	It is not clear to me whether this comparison is meaningful given that it might be possible to employ multiple machines to train 36 models.	weakness
2020-1605	This paper proposes a novel procedure for training multiple Transformers with tied parameters which compresses multiple models into one enabling the dynamic choice of the number of encoder and decoder layers during decoding.	abstract
2020-1605	The idea is simple and reasonable and the results are promising.	strength
2020-1605	I have several questions about the paper: 1. "This enables a fair comparison, because it ensures that each model sees roughly the same number of training examples." This is not a fair comparison.	weakness
2020-1605	Note that those models are of very different size, and thus they may need different numbers of samples for training.	weakness
2020-1605	For example, a 1-1 model should need much less data for training than a 6-6 model.	weakness
2020-1605	If the number of training samples is ok for the 1-1 model, it might be insufficient for the 6-6 model.	weakness
2020-1605	Therefore, I think development set is necessary for a fair comparison.	weakness
2020-1605	2. I don't understand Eq. (3).	weakness
2020-1605	What do x and y_k mean in this equation?	weakness
2020-1605	Are they corresponding to x^I and y^i_k in Eq (2)?	weakness
2020-1605	However, y^i_k in Eq. (2) is a translation, i.e., a text sentence, while y_k in Eq.	weakness
2020-1605	(3) looks like a number in [0,1].	weakness

2020-1646	Summary: The submission performs empirical analysis on f-VIM (Ke, 2019), a method for imitation learning by f-divergence minimization.	abstract
2020-1646	The paper especially focues on a state-only formulation akin to GAILfO (Torabi et al., 2018b).	abstract
2020-1646	The main contributions are: 1) The paper identifies numerical proplems with the output activations of f-VIM and suggest a scheme to choose them such that the resulting rewards are bounded.	abstract
2020-1646	2) A regularizer that was proposed by Mescheder et al. (2018) for GANs is tested in the adversarial imitation learning setting.	abstract
2020-1646	3) In order to handle state-only demonstrations, the technique of GAILfO is applied to f-VIM (then denoted f-VIMO) which inputs state-nextStates instead of state-actions to the discriminator.	abstract
2020-1646	Contribution / Significance: I think that the contributions of the paper are rather marginal.	weakness
2020-1646	I do think that the choice of output activation may have large impact on the performance and it seems that the activation suggested by Ke et al. (2019) are somewhat arbitrary.	weakness
2020-1646	However, the activations proposed in the current submission are also seem somewhat arbitrary and are not accompanied by any theoretical analysis.	weakness
2020-1646	2) and 3) are marginal combinations of existing work that are only insufficiently evaluated and do not seem particular effective.	weakness
2020-1646	Hence, I think that the current submission is of rather limited interest.	weakness
2020-1646	Soundness: The "reparametrization" of f-VIM is motivated based on exploding policy gradients when using unbounded reward functions, especially when minimizing the (R)KL.	abstract
2020-1646	I am not convinced by this motivation, given that GAIL and AIRL (which approximatly minimizes the RKL) use unbounded reward functions and do not seem to suffer from such problems.	weakness
2020-1646	Evaluation: The effect of the "reparametrization" is only evaluated for total variation.	weakness
2020-1646	The regularization loss is only evaluated with a single fixed coefficient of 10 on all experiment.	weakness
2020-1646	I think that a sweep over the coefficient would be mandatory, especially given that current experiments do not show a clear benefit of the regularization loss (the regularized version performs worse on roughly half of the experiments).	weakness
2020-1646	When learning from observations only, the submission only evaluates the proposed combination of f-VIM and GAILfO.	weakness
2020-1646	However, it seems like it would be perfectly possible to handle state-only observations by simply making the discriminator independent of the actions, i.e. using D(s,a) = D(s).	suggestion
2020-1646	Such technique matches the marginal distributions over states and is commonly applied to GAIL, e.g. by Peng et al. [1].	suggestion
2020-1646	It is not clear whether the reported problems of learning from observations only is really a general problem of the learning setting (as claimed in the submission) or a problem of the proposed method.	weakness
2020-1646	Clarity: The paper is well written and easy to follow.	strength
2020-1646	Using different linestyles to distinguish the learning with regularization versus without regularization would help a lot.	suggestion
2020-1646	Decision: Due to the marginal contribution and the insufficient evaluation I have to recommend rejection.	decision
2020-1646	Question: I am maily interested in the authors response to my critique, especially regarding	rebuttal_process
2020-1646	- the choice not to compare with state-only f-VIM, and	weakness
2020-1646	- the motivation of the proposed output activations.	weakness
2020-1646	[1] Peng, Xue Bin, et al. "Variational discriminator bottleneck: Improving imitation learning, inverse rl, and gans by constraining information flow." arXiv preprint arXiv:1810.00821 (2018).	misc
2020-1646	* Summary: The paper proposes an IL method based on the f-divergence.	abstract
2020-1646	Specifically, the paper extends f-VIM (Ke et al., 2019), which uses the f-divergence for IL, by using a sigmoid function for discriminator output's activation function.	abstract
2020-1646	This choice of activation function yields an alternative objective function, where the reward function for an RL agent does not directly depend on the convex conjugate of the function f; the paper claims that this independency improves stability of policy learning.	abstract
2020-1646	This proposed method is named f-VIM-sigmoid.	abstract
2020-1646	The paper extends f-VIM-sigmoid to the setting of IL with observation and proposes f-VIMO-sigmoid.	abstract
2020-1646	Experiments on Mujoco locomotion tasks show that f-VIM-sigmoid and f-VIMO-sigmoid perform better than existing methods.	abstract
2020-1646	* Rating: The paper proposes a simple but interesting approach to improve stability of adversarial IL.	strength
2020-1646	However, the paper has issues regarding baseline methods, motivation, supports of the claim, and experiments (see below).	weakness
2020-1646	These issues should be addressed.	suggestion
2020-1646	At the present, I vote for rejection.	decision
2020-1646	* Major comments: - Discussion and comparing against a simple baseline method based on swapping distributions: To make the reward function be independent of the convex conjugate f*, it is possible to simply swapping the distributions P and Q in the definition of the f-divergence.	rebuttal_process
2020-1646	More specifically, instead of minimizing D_f(P||Q), we can minimize D_f(Q||P), where P is a data distribution and Q is a generator.	rebuttal_process
2020-1646	In this case, pi* and pi_theta in Eq.	rebuttal_process
2020-1646	(7) swap, and the RL agent minimizes the cost function g_f(V_w(s,a)).	rebuttal_process
2020-1646	This cost function does not directly depend on f*, similarly to the reward function r(V_w(s,a)) in Eq. (8).	rebuttal_process
2020-1646	This swapping is simpler and more flexible than re-parameterizing, while achieving the same goal as f-VIM-sigmoid.	rebuttal_process
2020-1646	This swapping method should be discussed and compared against the proposed methods.	rebuttal_process
2020-1646	- Need stronger baseline methods for ILfO: The paper should evaluate f-VIMO-sigmoid against stronger baselines, e.g., forward adversarial IL (Sun et al., 2019) which outperforms GAIL-based methods in the ILfO setting.	suggestion
2020-1646	[1] Wen Sun, Anirudh Vemula, Byron Boots, and J Andrew Bagnell.	misc
2020-1646	Provably efficient imitation learning from observation alone.	misc
2020-1646	ICML, 2019. - Using the f-divergence for ILfO is not well motivated: The paper does not provide good motivations for using f-divergence in ILfO.	weakness
2020-1646	This makes the paper quite difficult to follow, since there is no connection between f-divergence and ILfO.	weakness
2020-1646	- The experiments focus on evaluating existing methods rather than the proposed methods: Specifically, the proposed methods are evaluated with only one choice of the divergence (TV) in Figure 2.	weakness
2020-1646	Meanwhile, most of Section 6 and results (Figure 3 and 4, and additional results in the appendix) focus on evaluating the existing methods (f-VIM and f-VIMO) with different choices of divergence.	weakness
2020-1646	- The experiments in Figure 2 do not support the claim regarding stability: The paper claims to improve stability of IL by using the proposed re-parameterization.	weakness
2020-1646	However, the experimental results do not support this claim, and the questions asked in Section 5 are not related to this claimed.	weakness
2020-1646	Instead, it seems that re-parameterization helps avoiding local optima (possibly due to a biased reward function, see below), while stability is improved by regularizing the discriminator.	weakness
2020-1646	I could not see how the re-parameterization improves the policy stability as claimed.	weakness
2020-1646	- The experiments in Figure 2 seem unfair, since TV-VIM-sigmoid incorporates priors about survival bonuses: Specifically, TV-VIM-sigmoid uses sigmoid which yields strictly positive rewards, while TV-VIM uses tanh which yields positive and negative rewards.	weakness
2020-1646	As discussed by Kostrikov et al., 2019, using strictly positive rewards incorporate strong priors about the survival bonuses, which exist in the locomotion task used in the experiments.	weakness
2020-1646	Therefore, TV-VIM-sigmoid uses strong priors while TV-VIM does not.	weakness
2020-1646	In order to make the comparison fairer, I suggest the authors to evaluate TV-VIM with sigmoid reward output, or include environments that do not have survival bonuses.	suggestion
2020-1646	[2] Ilya Kostrikov, Kumar Krishna Agrawal, Debidatta Dwibedi, Sergey Levine, and Jonathan Tompson.	misc
2020-1646	Discriminator-actor-critic: Addressing sample inefficiency and reward bias in adversarial imitation learning.	misc
2020-1646	*CONF*, 2019 * Minor comments: - The abstract is long and could be shorten.	weakness
2020-1646	- Figures are too small and difficult to see, especially the legends.	weakness
2020-1646	- Table 1 should describe the form of f in addition to its conjugate.	weakness
2020-1646	- The title of the Algorithm 1 should be f-VIMO-sigmoid instead of f-VIMO.	weakness
2020-1646	** Update after response. I read the response.	misc
2020-1646	I thank the authors for clarifying the claims as well as the new experiments with the swap formulation.	rebuttal_process
2020-1646	However, improving clarity of the claims is considered a major revision.	weakness
2020-1646	I still keep the vote of rejection.	weakness
2020-1646	Regarding reward bias. As the authors acknowledge, the improvement achieved by using reparameterization+sigmoid can be explained by two equally-plausible reasons: 1) reparameterization+sigmoid improves stability (as claimed) and 2) sigmoid gives biased rewards.	abstract
2020-1646	The issue here is that we do not know which is the actual reason, given the current experiments in the paper.	weakness
2020-1646	As I commented, evaluating TV-VIM with sigmoid but without reparameterization will help address this issue.	suggestion
2020-1646	This paper proposes the application of the f-VIM framework (Ke et.	abstract
2020-1646	al., 2019) to the problem of imitation learning from observations (no expert actions).	abstract
2020-1646	The authors first identify a potential source of numerical instability in the application of f-VIM to imitation learning – the rewards for the policy-gradient RL are given by a combination of a convex conjugate and an activation function.	abstract
2020-1646	To alleviate this, f-VIM is reparameterized by curating the activation using conjugate inverse (Equation 8), yielding a potentially more stable reward for deep-RL.	abstract
2020-1646	I have the following concerns about the paper: 1. Lack of novelty – Although I appreciate the reparameterization applied to f-VIM to make it potentially more stable for imitation learning in large state- and action-spaces, I don't think that by itself meets the bar for *CONF*.	weakness
2020-1646	Algorithm 1 is basically the GAILFO algorithm (Torabi et al. 2018) written in the f-Vim framework, with the proposed reparameterization.	weakness
2020-1646	The discriminator regularization (Section 4.4) has been used before.	weakness
2020-1646	2. Experiments – Figure 2 shows the improvement with TV when using the reparameterization, and the authors mention in text about the difficulty with KL and reverse-KL.	weakness
2020-1646	What about the JS divergence (GAIL)?	weakness
2020-1646	Does reparameterization help or affect that?	weakness
2020-1646	3. In Figure 3, is GAIL from the original paper, or does it use the sigmoid rewards?	weakness
2020-1646	Figure 3 does not offer any evidence that the proposed methods in the paper lead to algorithms that should be preferred over the current state-of-the-art in imitation learning with divergence minimization such GAIL and WAIL.	weakness
2020-1646	Minor comment: In Table 1: GAN is not a divergence.	weakness
2020-1646	Please use Jensen-Shannon, with the corresponding tweaks to the columns.	suggestion

2020-1662	This paper studies the curriculum learning approach that can more effectively utilize the data to train DNNs. It formulates DIH as a curriculum learning problem, and derives theory on the approximation bound.	abstract
2020-1662	The method is verified by a set of experiments.	abstract
2020-1662	There are  several concerns raised by the reviewer.	misc
2020-1662	I found the presentation of this paper is rather bad.	weakness
2020-1662	The structure of the paper is quite strange.	weakness
2020-1662	The Introduction section contains a lot of stuffs that I believe should be moved to the preliminary or method sections.	weakness
2020-1662	Also, there are a lot of confusions in the descriptions.	weakness
2020-1662	For example, when defining the curriculum learning problem in eq.2 and eq.3, are the f's the same?	weakness
2020-1662	If so, why do they have different input arguments?	weakness
2020-1662	"In step t, after the model gets trained on S_t, the feedback a_t(i) for i \\in S_t is already available": I don't get this.	weakness
2020-1662	I am not sure what Theorem 1 tries to tell.	weakness
2020-1662	If one chooses k large enough, the inequality satisfies trivially.	weakness
2020-1662	BTW, what is A_{1:T}? To sump up, there are some interesting ideas in this paper.	weakness
2020-1662	However, with the current stage of writing, I cannot recommend acceptance.	decision
2020-1662	This paper presents a technique for curriculum learning using Dynamic Instance Hardness (DIH).	abstract
2020-1662	DIH is defined as value for each training instance that characterizes how hard that instance is and is updated throughout the training process.	abstract
2020-1662	The DIH value is used to select the best set of instances to learn.	abstract
2020-1662	It is shown that instances with high  (low)  DIH values maintain the high (low) value throughout the training process.	abstract
2020-1662	The main contributions and pros of the paper are	strength
2020-1662	1. A notion of instance hardness that is persisted and updated throughout the training procedure.	strength
2020-1662	2. An objective function for characterizing instance hardness as a dynamic subset selection problem.	strength
2020-1662	Presenting a greedy algorithm for online maximization of this function.	strength
2020-1662	3. Experimental results that show how the property of instance hardness is maintained throughout training and showing how DIH-driven curriculum learning techniques that use random sampling outperforms non-curriculum learning techniques.	strength
2020-1662	Cons 1. The writing of this paper is difficult and in many of the core parts of the paper, the important definitions are not clear.	weakness
2020-1662	E..g a) the role of the function 'f' that is being maximized in section 3.2 is not clear.	weakness
2020-1662	To elaborate, it is not obvious what this function is or why should one care about it?	weakness
2020-1662	2. The greedy algorithm has a bound in equation 7 that appears to be quite loose as the value of k is as high as the order of the size of the entire training set (in the experiments, 0.2n <= k < n).	weakness
2020-1662	Am I misinterpreting it? Furthermore, the greedy algorithm -- while being focused on the core of the technical contributions -- is not used in experimental comparisons and instead all the results presented use random sampling.	weakness
2020-1662	At least the result of DIH-greedy should be presented.	weakness
2020-1662	3. This is more of a suggestion: one of the claimed advantages of the algorithm (over non curriculum learning and MCL) is that it requires less training examples to train.	weakness
2020-1662	Given this, the authors should present training time improvements over large datasets.	suggestion
2020-1662	*Revision after author response* I thank the authors for the comments on my questions.	misc
2020-1662	Unfortunately, I do not feel that these comments addressed my main concerns.	misc
2020-1662	For all my experimental analysis questions, the authors promised some analyses for future versions, but I was hoping to see at least a minor preliminary analysis at this point, to see if indeed my concerns are valid or not.	rebuttal_process
2020-1662	Moreover, for my question number 1 about the optimization problem, the authors referred me to Corollary 1 from the paper, but that didn't really help me because, as the other reviewers also point out, the writing is quite hard to follow.	rebuttal_process
2020-1662	Because of all these, I have decided to revise my score to a weak reject.	rebuttal_process
2020-1662	While I believe the paper has merit, it requires revisions at many points in order for a reader to truly understand the method and trust the experimental results.	suggestion
2020-1662	-------------------------------------------------------------------------------------------------------------- The paper proposes a curriculum learning approach that relies on a new metric, the dynamic instance hardness (DIH).	abstract
2020-1662	DIH is used to measure the difficulty of each sample while training (in an online fashion), and to decide which samples to train on next.	abstract
2020-1662	The authors provide extensive experiments on 11 datasets as well as some theoretical motivation for the use of this approach.	abstract
2020-1662	---- Overall opinion ---- Overall I believe this paper is an interesting take on curriculum learning that is able to achieve good results.	strength
2020-1662	I believe this approach is a combination of core ideas from multiple sources, such as boosting, self-paced learning, continual learning and other curriculum learning approaches, but overall it seems different enough from each one of them individually.	strength
2020-1662	Because of the resemblance with these many different methods, the method itself does not surprise through the novelty of a new idea, but the authors seemed to have found something that was missing from these methods and that leads to very good results.	weakness
2020-1662	The experimental results look great, but I believe the paper is missing some ablation studies to assess the importance of certain components (see details below).	weakness
2020-1662	I also had some trouble understanding certain arguments, which I hope the authors can clarify.	weakness
2020-1662	---- Major issues ---- 1. I find the arguments section 2.1 quite difficult to follow.	weakness
2020-1662	In particular, under the assumption stated in the paper that r_t(i) = f(i|S_{1:t−1}) =  f(e_i + S_{1:t−1}) − f(S_{1:t−1}) , why does it follow that r_t(i) can be used instead of f in the minimization problem (2).	weakness
2020-1662	2. Based on the method itself, it seems to me that the parameter k_t could would have a lot of influence on how well the method doing.	weakness
2020-1662	The authors mention in the experimental section what values they use, but there is no indication on how one would choose this value.	weakness
2020-1662	Moreover, it would be good to see an analysis of how sensitive the results are to this choice.	weakness
2020-1662	3. In Figure 1, it is not clear whether the figure on the right shows the actual loss, or the smooth loss using Equation (1) with instantaneous instance (A).	weakness
2020-1662	If it is the former, then if the loss is so smooth, why do we need DIH?	weakness
2020-1662	If it is the latter, then what does the instantaneous loss look like?	weakness
2020-1662	This actually raises the question of how important the smoothing component is -- could we achieve the same results with an instantaneous loss (i.e. set gamma to 1 in Eq. 1)?	weakness
2020-1662	---- Minor issues ---- 1. How do you choose T0, gamma and gamma_k?	weakness
2020-1662	2. In the conclusions, the authors state that " The reason [why  MCL and SPL are less stable] is that, compared to the methods that use DIH, both MCL and SPL deploy instantaneous instance hardness (i.e., current loss) as the score to select sample".	weakness
2020-1662	Since there are so many other differences in the way training progresses, I think we don't have enough evidence to attribute this to merely the "instantaneousness" of the loss.	weakness
2020-1662	In fact, it would be interesting to see how SPL does if you use DIH as a metric (just smoothing the loss over time), but their approach of scheduling samples (easy to hard, and not the opposite and in DIHCL).	weakness
2020-1662	3. Appendix C shows some interesting results regarding wall time comparison.	weakness
2020-1662	I was surprised to see that, despite the extra computations, DHCL is comparable to random mini-batches.	strength
2020-1662	This makes me wonder what the stop criteria was, because when you stop matters a lot for run time comparisons.	weakness
2020-1662	It would also be interesting to see a more ample discussion on this in the main text.	suggestion
2020-1662	4. In Figure 1, the axes are barely readable.	suggestion
2020-1662	5. The authors oftentimes reverse the use of \\citet and \\citep, for example "has been called the "instance hardness" Smith et al. (2014) corresponding to" should have a bracket, whereas "Our paper is also related to (Zhang et al., 2017)" should not have brackets.	weakness
2020-1662	6. This is not an issue, but I just wanted to say I appreciated Appendix B.	ac_disagreement
2020-1662	---- Suggestions ---- 1. It would be interesting to make a connection between the DIH and what other papers have discovered about example forgetting (e.g. Toneva et.	suggestion
2020-1662	al, that was mentioned in the paper).	suggestion
2020-1662	2. Major issues 3 -> a study on the effect of k and how to choose it.	weakness
2020-1662	3. While I understand that the models chosen in the experiments are expensive to train, it would be good to report standard deviations in Table 1.	suggestion
2020-1662	4. Based on Table 1 and Figure 3, there is no concrete winner among the DIHCL methods.	weakness
2020-1662	It would be good to include some recommendations in your conclusion on which one to choose and when.	suggestion
2020-1662	---- Questions ---- 1. "On average, the dynamics on the hard samples is more consistent with the learning rate schedule, which implies that doing well on these samples can only be achieved at a shared sharp local minima." -> can you please explain why this is so?	weakness
2020-1662	2. See Major issues 3.	misc
2020-1662	3. In Table 1, on some datasets, the authors apply lazier-than-lazy-greedy, and on some not.Why, and how does one decide this for a new dataset?	misc
2020-1662	4. How did you choose T0, gamma and gamma_k, as well as the schedules in Appendix C (page 17)?	weakness

2020-1677	The paper propose a noisy autoencoder that considers the jacobian between data and latent spaces to match the corresponding densities.	abstract
2020-1677	This idea has already been proposed elsewhere, and here it is applied to autoencoders.	abstract
2020-1677	Overall I had hard time understanding the paper, the motivation, the main contribution or the claim, the model definition and the jacobian method.	weakness
2020-1677	The paper is poorly written, with lots of issues in math notation and poor motivation and explication of what the sections are introducing, and what parts of the presentation is novel and what is already known.	weakness
2020-1677	Lots of the math machinery is too vague to follow.	weakness
2020-1677	The distribution p(z) is unclear, and whether z is random variable or not.	weakness
2020-1677	It seems that "z" is a non-random variable, and then adding noise \\eps makes it stochastic.	weakness
2020-1677	However, then p(z) without \\eps does not make any sense since z is not random.	weakness
2020-1677	It seems that p(z) is maybe a prior distribution instead (or maybe the variational posterior?), but then adding \\eps noise to an already stochastic variable is strange.	weakness
2020-1677	Overall I have hard time understanding the motivation of the two discrepancies in eq 4, what is the point of adding more noise to "z"?	weakness
2020-1677	This seems some kind of noisy or perhaps robust AE variant, but the paper does not explicate this.	weakness
2020-1677	I have hard time following the eqs 8-15.	weakness
2020-1677	I am not convinced of the orthogonality argument, and I fail to see what this section tries to show or demonstrate.	weakness
2020-1677	It seems that eq 14 is the final result, but its difficult to follow due to most terms in eq 14 being undefined.	weakness
2020-1677	Optimizing eq 14 seems trivial since we can always match pz and pz_\\varphi easily with neural networks, or similarly the two x-distributions.	weakness
2020-1677	In the experiment 4.1. the proposed method seems to achieve matching densities, although the distributions are wrongly normalized.	weakness
2020-1677	How does the density matching improve?	weakness
2020-1677	All three methods seem to have equally good scatters.	weakness
2020-1677	The benchmarks on table 1 show clear improvement with the method.	weakness
2020-1677	The face experiment is unconvincing since the VAE spreads variance across all latent dimensions while RADO seems to compress them to just first 20 or so.	weakness
2020-1677	If one would visualise the z_100 there would be no variance in RADO and possibly some variance in VAE.	weakness
2020-1677	The paper also should compare their model to simple MNIST/VAE to highlight what problems are there in standard approaches (such as VAE), and how does the proposed method alleviate them.	weakness
2020-1677	Overall the paper is poorly presented and difficult to follow.	weakness
2020-1677	Despite this the method does seem to work remarkably well, and the Jacobian idea is clearly very promising.	strength
2020-1677	Nevertheless in its current form the paper is badly premature for *CONF*, and needs a lot more work and polish to be made understandable for wider ML audience.	decision
2020-1677	Minor comments o Px(x), x1, x2 are probably missing subscripts o The point of eq 5 is unclear, it seems unnecessary.	weakness
2020-1677	It also does not contain h(), which is claimed after eq6	weakness
2020-1677	o The log pz(z) in eq 4 is not entropy o eq 8 is unclear, is the dx a derivative, distance or change?	weakness
2020-1677	o the t prefix notation is confusing, what does it mean?	weakness
2020-1677	o what is the \\sim and line notation in eq 5?	weakness
2020-1677	o what are the products in eq9, are these inner products?	weakness
2020-1677	o in eq 13 pz, pxd or hat(pxd) have not been introduced or defined This paper aims to obtain latent representation of data such that probability density for the real space can be calculated correctly from that in the latent space.	abstract
2020-1677	The authors optimize a loss function that has components related to parametric probabilistic distribution and auto encoder simultaneously.	abstract
2020-1677	While this might be an important problem (I am not sure), the paper is not written and organized well which makes a through evaluation very difficult.	weakness
2020-1677	I provide below some of the problems with this the paper: Why the introduced method is better than VAE as a generative model for capturing the latest representation is not explained well.	weakness
2020-1677	It is not also used as a baseline in most of the experiments.	weakness
2020-1677	The motivation for having the third term in Equation (4) needs to be explained.	weakness
2020-1677	Also what is h() in the second term.	weakness
2020-1677	The authors only describe briefly both terms together after they used it here but failed to describe what each term is.	weakness
2020-1677	Why there is an h for the second term but not for the third term.	weakness
2020-1677	h() becomes more clear much later in the paper but when it is used the first time, it not defined.	weakness
2020-1677	I believe A in Equation (5) should be also positive-definite.	weakness
2020-1677	What is L(x) in Equation (8).	weakness
2020-1677	It needs to be defined.	weakness
2020-1677	Experiments: 1- It is useful to also plot the original data in space s to see how the results in Figure 2 make sense.	strength
2020-1677	2- Figure 3 is not clear.	weakness
2020-1677	3- In the Anomaly detection experiments, the authors make two assumptions that usually do not exist in real-worlds: (1) they assume that they have access to training set that only contains normal cases.	weakness
2020-1677	(2) They assume that they know the correct rate of anomaly.	weakness
2020-1677	I think both these assumptions are very restrictive and unreal.	weakness
2020-1677	While these assumptions are used for all the comparing methods, it is not obvious how different algorithms behave in real scenario.	weakness
2020-1677	4- Figure 4 and what it represents is not clear.	weakness
2020-1677	Writing Problems: 1- In the text of paragraph before Figure 1, Eq. (5) in "in the second term of Eq. (5)" is a typo and should be Eq. (4). 2- In the paragraph before Figure 1, the following sentence is not complete: "Then, averaging Eq.	weakness
2020-1677	(4) according to distribution, x~P_x(x) and epsilon~ P(epsilon)."	weakness
2020-1677	3- Section 4.2.1: "there is a difference is PDF → "there is a difference in PDF Summary of the paper: The authors propose a latent variable model RaDOGAGA, a generative autoencoding model.	weakness
2020-1677	The model is trained via a tradeoff between distortion (the reconstruction error) and the rate (the capacity of the latent space, measured by entropy).	weakness
2020-1677	The paper provides an analysis of theoretical properties of their approach, and presents supporting experimental results.	weakness
2020-1677	Review tl;dr: weak reject, for three main reasons: (i) While the existing literature around VAEs, beta-VAEs,  and Rate-Distortion theory is mentioned in the related work, the connections are not nearly discussed sufficiently.	weakness
2020-1677	(ii) On top of (i), the derivation of their loss function and architecture is not sufficiently motivated.	weakness
2020-1677	This is in astonishing contrast to 1.5 pages of main text and 8 pages of (much appreciated!) analysis of properties.	weakness
2020-1677	(iii) Given the paper is clearly related to existing approaches in the literature, the experiments would require a much more careful comparison to existing models.	weakness
2020-1677	It remains unclear why an interested user should favor your model over conceptually simpler generative models with fewer hyperparameters.	weakness
2020-1677	Detailed review: Nota bene: This review is a late reassignment.	weakness
2020-1677	While I reviewed the paper to the best of my ability, time constraints did not allow me to review parts of the paper in depth.	misc
2020-1677	I am open to reassess my review during the second stage.	misc
2020-1677	Connection to prior art: As a probabilistic, neural autoencoding model, the connections to the family of VAE models are obvious.	weakness
2020-1677	The loss function (eq. (4)) still looks very much like the ELBO, where the typical conditional log-likelihood was split into two distortion terms.	weakness
2020-1677	How is this different from e.g. a beta-VAE?	weakness
2020-1677	Particularly, what is the connection between the rate-distortion analysis of beta-VAE by Alemi et al. and yours?	weakness
2020-1677	These things need to be discussed explicitly, with more than a sentence or two in the related work section.	weakness
2020-1677	A lesser, but still important omission in your discussion of prior work: The Jacobian of the generator has also been studied, even for the VAE, cf.	weakness
2020-1677	e.g. [1]. I believe this deserves more attention in your assessment of prior art.	weakness
2020-1677	Motivation: You use two distortion terms: actual sample vs.	weakness
2020-1677	undistorted reconstruction. Why is that? What is the interpretation of the multipliers?	weakness
2020-1677	How do I choose them?	weakness
2020-1677	Why is a large part of your architecture (the pipeline from x to \\hat(x)) actually deterministic?	weakness
2020-1677	Why are you using the entropy of the prior over the latents, rather than the KL divergence between encoder and a prior?	weakness
2020-1677	I think an interested reader could learn much more from your paper if you discussed your model embedded in th related work rather than in isolation.	suggestion
2020-1677	Theory: Due to aforementioned time constraints, I was not able to review the extensive theoretical analysis in depth.	weakness
2020-1677	Still, I would strongly recommend structuring the respective sections more clearly.	suggestion
2020-1677	Separate model and architecture description from the theoretical analysis; precisely formulate your claims.	suggestion
2020-1677	In particular, state your assumptions clearly.	suggestion
2020-1677	For instance, you assume "that each function's parameter is rich enough to fit ideally" (and similar e.g. in Appendix A).	suggestion
2020-1677	Does this only mean that the true distributions are part of the parametric family?	suggestion
2020-1677	What if this is not the case?	weakness
2020-1677	Do your parameters need to be in the optimum for your analysis to hold true?	suggestion
2020-1677	Given that the full 20-page manuscript spends 10 pages on theory, I think this contribution is not given appropriate space in the main text.	weakness
2020-1677	Experiments: There are three experiments: a simple 3D proof of concept; anomaly detection; analysis of the latent state in CelebA.	weakness
2020-1677	As mentioned in my review of the methods section, I believe the approach to be very similar to established models.	weakness
2020-1677	None of the experiments provides convincing evidence why I should prefer the new, arguably more complex model.	weakness
2020-1677	For instance, I would have much preferred that you investigate properties of your model against alternatives over the anomaly detection experiments, which did not further my understanding of the proposed model.	weakness
2020-1677	Summary: The paper tackles an important problem, namely the lack of control over the latent embedding in autoencoding generative models.	abstract
2020-1677	I believe the author's contribution can be valuable, and I particularly appreciate the effort to investigate theoretical properties.	strength
2020-1677	As is, the case is not sufficiently convincing to be accepted, but I encourage the authors to improve the paper.	decision
2020-1677	Minor comments: 1. While I appreciate a pun, I would recommend to rename the model along with the acronym to a more concise name.	suggestion
2020-1677	2. Please revise your notation and typsetting.	suggestion
2020-1677	Examples: x1 instead of x_1, f of f(\\cdot) instead of f(), \\log instead of log.	suggestion
2020-1677	3. Introduce acronyms before using them (e.g. VAE, MSE, SSIM), even when they seem obvious to you.	suggestion
2020-1677	4. Please carefully check the manuscript for typos, missing articles, missing spaces etc.	suggestion
2020-1677	5. Your citations are inconsistent, in that they sometimes use first names, sometimes first name initials, and sometimes no first names.	weakness
2020-1677	6. To my knowledge, the term scale function does not have an obvious definition.	weakness
2020-1677	I think you are simply referring to monotonically increasing functions.	weakness
2020-1677	Please clarify! 7. Your figures should be understandable without too much context, they need more detailed captions.	weakness
2020-1677	[1] http://proceedings.mlr.press/v84/chen18e.html	misc

2020-1678	Text normalization or the transformation of words from the written to the spoken form is an important and realistic question in natural language processing.	strength
2020-1678	This paper aims to use sequence-to-sequence models to perform text normalization.	abstract
2020-1678	However, this paper does not use the official template and the content is too short to be a conference paper.	weakness
2020-1678	I suggested resubmitting to another (NLP) conference after extending the content with detailed description for the model and the method, and conducting more experiments on public acceptable benchmarks.	decision
2020-1678	This paper addresses the text normalization problem, where  the special processing is required for different kinds of non-standard words (NSW's).	abstract
2020-1678	Dataset:  a new dataset is collected, including many types of non-standard words from different Amharic news Media and websites, FBC more than eighty percent, VOA and BBC.	abstract
2020-1678	Model: Bidirectional GRU with the size of 250 hidden units both are used for encoding and decoding layers.	abstract
2020-1678	This paper is not ready to publish.	decision
2020-1678	Please consider to complete the project, polish the writing, and submit to a different venue.	decision
2020-1678	The paper describes a method for word normalization of Amharic text using a word classification system followed by a character-based GRU attentive encoder-decoder model.	abstract
2020-1678	The paper is very short and lacks many important details, such as where the data is collected from, how it is processed and split into training and evaluation sets, and how the initial token classification is performed.	weakness
2020-1678	The paper also doesn't adhere to the conference paper template, which is grounds for desk rejection.	decision
2020-1678	The authors should revise the paper with this information and consider submitting to a different venue, as the task considered, while interesting, seems far from the core focus of *CONF*.	decision

2020-1694	The paper introduces a new approach to generate adversarial examples for deep classifiers.	abstract
2020-1694	As opposed to the majority of work on adversarial attack models, which generally limit the attacker on pixel-space distortions measured with respect to an Lp norm, the authors here consider a slightly more general attack model that is a combination of an affine transformation and additive L2 perturbation of the input example.	abstract
2020-1694	Finding optimal attacks for this model can be non-trivial (standard due to the highly nonlinear coupling between the affine parameters and the additive perturbation), so the authors instead propose training a surrogate neural network that generates the attack affine-transformation and distortion- parameters sequentially.	abstract
2020-1694	This can, in principle, be done in a traditional supervised training setup; however, to force the adversarial images to look perceptually close to natural looking images, the authors throw a discriminator loss on top, and train the attack generator network adversarially.	abstract
2020-1694	The paper is well-written in general, the idea is intuitive, and the experiments are well-described.	strength
2020-1694	However, I have a few concerns that lead to me to give a low score (at least in the first round of reviews).	rating_summary
2020-1694	- Novelty. Leveraging spatial distortions (or other visually meaningful transformations) to generate adversarial attacks is not a new idea, but the authors seem to have been unaware of this very large body of work.	weakness
2020-1694	See, for example: ** Engstrom et al, "Exploring the landscape of spatial robustness", ICML 2019	misc
2020-1694	** Poovendran et al, "Semantic adversarial examples", CVPR 2018	misc
2020-1694	** Ho et al, "Catastrophic Child's Play", CVPR 2019	misc
2020-1694	** Joshi et al, "Semantic adversarial attacks", ICCV 2019	misc
2020-1694	among many others. Using GAN-like transformation models to generate attacks is also not a new idea.	weakness
2020-1694	A few of the above papers use this approach, and the authors refer to a few other such papers as well.	weakness
2020-1694	So as such, the conceptual novelty of the contribution seems to be low (beyond the specific choice of combining affine and L2 perturbations).	weakness
2020-1694	- Experimental evaluation. The authors do a commendable job thoroughly laying out the experimental setup.	strength
2020-1694	However, a couple of red flags emerge in the experiments.	misc
2020-1694	First, why not look at L-infty perturbations (as opposed to L2)?	weakness
2020-1694	Second, why not test on more challenging datasets (CIFAR, CelebA, etc) as opposed to simple black/white datasets such as MNIST/Fashion-MNIST?	weakness
2020-1694	One would imagine that the smaller, simpler datasets are easier to optimize for, and therefore the "amortized" attack generator networks are not necessary here.	weakness
2020-1694	- Weakness of theoretical part.	weakness
2020-1694	I am not sure the theorem is saying anything strong or useful (since the underlying transformer neural network is assumed to possess infinite capacity).	weakness
2020-1694	I would suggest just removing it.	suggestion
2020-1694	This paper builds upon the work of AdvGAN and proposes to add spatial transformations on top of it.	abstract
2020-1694	The resulting attacking framework is demonstrated to outperform AdvGAN on attacking several defense approaches, such as Defense-GAN, AdvCritic and adversarial training.	abstract
2020-1694	Compared to previous approaches on generating spatially transformed adversarial examples, this approaches amortizes the attacking procedure and can produce spatially transformed adversarial examples much faster.	abstract
2020-1694	This approach also simultaneously combine spatial transformations and perturbations to make the attack stronger.	abstract
2020-1694	I cannot recommend acceptance of this paper because of several reasons: - The idea is not novel enough.	decision
2020-1694	It is simply an A + B paper where A = AdvGAN and B = spatial transformer networks.	weakness
2020-1694	The idea of adversarial attacks with spatial distortion is not the innovation of this paper and has been proposed and extensively studied by many previous papers.	weakness
2020-1694	This paper does not have additional innovation and does not lead to additional insight that can warrant an acceptance at *CONF*.	decision
2020-1694	- The general narrative of this paper is misleading.	weakness
2020-1694	The title seems to indicate this paper is the first to discover the importance of considering spatial perturbations, which is misleading.	weakness
2020-1694	There is no mention of previous work on spatial transformation attacks in either the abstract nor the introduction (except at the very last).	weakness
2020-1694	The introduction simply analyzes some well-known phenomenon in the literature, does not place this work well in the literature (even true in the related work section as well), and can mislead readers in believing that this work was the first to realize the importance of spatial transformation attacks.	weakness
2020-1694	- Theorem 1 is a vacuous statement.	weakness
2020-1694	It is automatically true based on the universal approximation assumption of neural networks.	weakness
2020-1694	Including the statement of Theorem 1 is decorative and a waste of space.	weakness
2020-1694	- The experiments are not convincing.	weakness
2020-1694	For example, there is no \\gamma value reported in the tables.	weakness
2020-1694	Since \\gamma is as important as \\epsilon in the proposed attacking method, the missing of this important variate is suspicious.	weakness
2020-1694	Also the adversarial training only uses FGSM not PGD.	weakness
2020-1694	The Defense-GAN is already shown not robust by Athalye et al. and cannot be considered as one of the state-of-the-art defenses.	weakness
2020-1694	This paper proposes a new adversarial attack method by combining spatial transformations with perturbation-based noises.	abstract
2020-1694	The proposed method uses two networks to generate the parameters of spatial transformation and the perturbation noise.	abstract
2020-1694	The whole architecture is trained by a variant of GAN-loss to make the adversarial examples realistic to humans.	abstract
2020-1694	Experiments on MNIST prove that the proposed attack method can improve the success rate of white-box attacks against several models.	abstract
2020-1694	Overall, this paper considers an important problem of adversarial robustness of classifiers, and present a new approach to craft adversarial examples.	strength
2020-1694	The writing is clear. However, I have some concerns about this paper.	strength
2020-1694	1. This paper seems to integrate multiple ideas studied before into a single attack method.	weakness
2020-1694	Perturbation-based adversarial examples, spatial transformation-based adversarial examples, generating adversarial examples based on the GAN loss are all studied before.	weakness
2020-1694	And the proposed method integrates them together to form a new attack.	weakness
2020-1694	2. The experiments are only conducted on MNIST and Fashion MNIST.	weakness
2020-1694	More experiments on CIFAR-10 and ImageNet can further prove the effectiveness of the proposed method.	weakness
2020-1694	3. More robust defense models should be incorporated in experiments, at least the PGD-based adversarial training model (Madry et al., 2018).	weakness

2020-1701	### Summary This paper described a model-based RL method which uses learned dynamics models to augment the replay buffer used when training a PPO agent.	abstract
2020-1701	Specifically, the agent learns an ensemble of dynamics models, and then performs a PPO updates using a mixture of trajectories sampled from the true environment and trajectories sampled from teh learned dynamics models.	abstract
2020-1701	The fictitious trajectories are sampled from different dynamics models in the ensemble, which helps prevent the policy from exploiting the errors of a single model.	abstract
2020-1701	The proportion of real/fake trajectories are adapted using the ratio of the real vs.	abstract
2020-1701	predicted rewards: if the average returns are similar, then the proportions will be approximately equal, but if they are very different then more trajectories from the real environment will be used.	abstract
2020-1701	Overall, I think there are some interesting elements to this paper but it is currently not ready for publication.	decision
2020-1701	I recommend weak reject for three reasons: limited novelty, the experiments as they stand are not very convincing and the writing needs work.	decision
2020-1701	#### Novelty The two stated contributions are: 1. the use of principled uncertainty estimates in model-based RL (an anchored ensemble)	abstract
2020-1701	2. the routine which adjusts the proportion of real vs.	abstract
2020-1701	simulated trajectories for learning the policy.	abstract
2020-1701	In my opinion, 1. is not much of a contribution since a number of works have already made use of different types of model uncertainty in the context of model-based RL.	weakness
2020-1701	Here they use a slightly different version (the anchored ensemble, which is similar to the randomized priors used in DQNs) but this is more of a choice of implementation than a contribution in itself (a number of methods for estimating uncertainty exist, such as regular ensembles, dropout masks, BNNs, etc).	weakness
2020-1701	The manner in which they use the uncertainty is to perform simulations with several different models to avoid overfitting to one, and this was already proposed in the ME-TRPO paper.	weakness
2020-1701	The idea of 2. is interesting and in general, adapting between model-based and model-free RL regimes during execution seems to have potential.	strength
2020-1701	However the current method seems currently under-explored and heuristic.	weakness
2020-1701	The fact that it is sensitive to the \\alpha hyperparameter (Figure 2) is a bit troubling.	weakness
2020-1701	Is there a principled way which does not require tuning this hyperparameter?	weakness
2020-1701	Or reformulating things so that it is less sensitive?	weakness
2020-1701	#### Experiments Although the experiments show some improvement, they are not that convincing.	weakness
2020-1701	The improvements do not seem statistically significant for Swimmer and Walker, and the asymptotic performance is worse than PPO for Hopper.	weakness
2020-1701	There is only half-cheetah where the algorithm shows a clear improvment.	weakness
2020-1701	Since one of the claimed contributions is the use of the anchored ensemble, there should be an ablation experiment showing this gives an improvement over a standard ensemble, but this is not included.	weakness
2020-1701	#### Writing: One issue with the paper is that it spends *much* too long discussing related work and preliminaries.	weakness
2020-1701	The first 5 pages are devoted to this and the proposed method is only introduced on page 6!	weakness
2020-1701	Some detailed comments: - Paragraph 1 in the intro should be drastically cut.	weakness
2020-1701	The sentence "Recently...challenging tasks" could be followed by references and then a sentence discussing the sample inefficiency and then moving on to the next paragraph.	weakness
2020-1701	Most readers will be familiar with DQN, actor critic etc.	weakness
2020-1701	- Same for paragraphs 2 and 3.	weakness
2020-1701	A short discussion of the general idea behind model-based RL and its improved sample efficiency, the issue of the policy exploiting model errors, and some references are sufficient.	weakness
2020-1701	- Similarly, section 2.1 is mostly unnecessary.	weakness
2020-1701	It isn't necessary to detail the updates for standard algorithms such as PPO/TRPO unless they are useful for the proposed algorithm.	weakness
2020-1701	- Section 2.2 is also too long.	weakness
2020-1701	They main idea is very simple and is summarized in Equation 13.	weakness
2020-1701	This paper presents a new model-free + model-based algorithm, MBPGE, that trains a policy using a policy gradient algorithm on top of the learned models.	abstract
2020-1701	Contrary to previous approaches, they use a true Bayesian distribution by means of the randomized anchorized MAP.	abstract
2020-1701	Furthermore, they combine rollouts from the real environment and from the learned dynamics directly for the policy training, instead of relying just on the ones of learned dynamics, which induces a larger distributional shift.	abstract
2020-1701	The paper readability could be improved.	weakness
2020-1701	First of all, the introduction spans over 2 pages.	weakness
2020-1701	The readability could be significantly improved by splitting the introduction into introduction (containing the motivation) and related work.	weakness
2020-1701	Secondly, the preliminary section spans more than their approach, which hints that the original contribution is too incremental.	weakness
2020-1701	All of the actual method is just combining section 2.1 and 2.2.	weakness
2020-1701	Lastly, section 3.1 is hard to parse.	weakness
2020-1701	The authors extend the paper to 9 pages when there was no need for it.	weakness
2020-1701	In terms of contribution, it seems that the main contribution is to use the method presented [1] and replace the ensemble with the ensemble of [2] and use PPO [3] instead of TRPO [4].	weakness
2020-1701	There is no further insight in the paper, but the fact that the ensemble of [2] works better than the classical ensemble (fact shown in [2]) and that PPO works better than TRPO (fact shown in [3]).	weakness
2020-1701	The other contribution is to combine samples from the real environment and the from the learned models to train the policy.	weakness
2020-1701	This however has actually been done in the context of model-based reinforcement learning, see [5].	weakness
2020-1701	It would be interesting that the authors compared against different heuristics to choose the ratio between imagined and real rollouts (i.e., constant, annealed, fraction of improvement [1], etc…).	suggestion
2020-1701	Overall, I don't think that the contributions of this paper are enough for publication.	decision
2020-1701	Regarding the experiment section I strongly believe that the comparison is flawed.	weakness
2020-1701	The results they report on MB-MPO do not match with the ones in [6, 7].	weakness
2020-1701	For instance, half-cheetah does not learn at all while it is an easier environment than Walker and Hopper (and there's learning in those).	weakness
2020-1701	Furthermore, given this they should also compare against ME-TRPO and ME-TRPO switching the TRPO with PPO, since this would be a fairer comparison.	weakness
2020-1701	This section lacks also of a proper ablation analysis to identify how much each element of the proposed algorithm affects the performance the choice of Bayesian ensemble and heuristic to determine the amount of real samples and imagined ones.	weakness
2020-1701	At this stage, there is not enough contribution in terms of novelty nor delta in performance.	weakness
2020-1701	[1] Thanard Kurutach, Ignasi Clavera, Yan Duan, Aviv Tamar, Pieter Abbeel.	misc
2020-1701	Model-Ensemble Trust-Region Policy Optimization. [2] Tim Pearce, Felix Leibfried, Alexandra Brintrup, Mohamed Zaki, Andy Neely.	misc
2020-1701	Uncertainty in Neural Networks: Approximately Bayesian Ensembling.	misc
2020-1701	[3] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov.	misc
2020-1701	Proximal Policy Optimization Algorithms. [4] John Schulman, Sergey Levine, Philipp Moritz, Michael I.	misc
2020-1701	Jordan, Pieter Abbeel. Trust Region Policy Optimization	misc
2020-1701	[5] Michael Janner, Justin Fu, Marvin Zhang, Sergey Levine.	misc
2020-1701	When to Trust Your Model: Model-Based Policy Optimization	misc
2020-1701	[6] Ignasi Clavera, Jonas Rothfuss, John Schulman, Yasuhiro Fujita, Tamim Asfour, Pieter Abbeel.	misc
2020-1701	Model-Based Reinforcement Learning via Meta-Policy Optimization	misc
2020-1701	[7] Tingwu Wang, Xuchan Bao, Ignasi Clavera, Jerrick Hoang, Yeming Wen, Eric Langlois, Shunshi Zhang, Guodong Zhang, Pieter Abbeel, Jimmy Ba. Benchmarking Model-Based Reinforcement Learning.	misc
2020-1701	### Summary ### This paper focuses on model based reinforcement learning (RL).	abstract
2020-1701	Specifically, the authors consider the setting of combining model based and model free RL algorithms by using the learned dynamics model to generate new data for training the model free algorithm.	abstract
2020-1701	In order to capture the uncertainty of the environment and the model, the author applied Baysian neural network to learn the dynamics of the environment.	abstract
2020-1701	The authors approximated the true Bayesian inference process by keeping an anchored ensemble of neural networks, where the prior and posterior of network weights are approximately Gaussian.	abstract
2020-1701	The ensemble of dynamics model is then used to generate data to train a PPO[1] based agent.	abstract
2020-1701	In order to prevent the agent from exploiting the learned dynamics model, the authors propose a heuristic way of balancing the amount of real data and model generated data by comparing the rewards.	abstract
2020-1701	The authors evaluate the proposed algorithm on simulated robotic locomotion environments in MuJoCo, and the results show that the proposed method has better same efficiency compared to baseline methods in some environments.	abstract
2020-1701	### Review ### Overall I think this paper presents an interesting idea in combing model based and model free RL algorithms.	strength
2020-1701	The idea is very well presented and authors include empirical evidence to support the proposed method.	strength
2020-1701	However I do find a number of shortcomings that need to be addressed.	misc
2020-1701	Pro: 1. The idea for this paper is really well presented.	strength
2020-1701	The structure of the paper is well organized and the experiment results are easy to interpret.	strength
2020-1701	2.  The authors provide a detailed description of the configurations and the hyperparameters for each experiments.	strength
2020-1701	Such description would be very helpful if the results in this paper are to be reproduced.	strength
2020-1701	Con: 1. I'm not convinced about the magnitude of novelty in this paper.	weakness
2020-1701	The proposed method seems very similar to ME-TRPO[2] and it seems to me that the novelty comes from the application of Bayesian ensemble techniques and the generated data ratio tuning heuristics.	weakness
2020-1701	While these variations might be important for the final performance of the proposed method, the paper does not include any ablation study to further justify the importance of these variations.	weakness
2020-1701	2. I'm not convinced about some of the performance of some of the baseline methods presented in this paper.	weakness
2020-1701	In this paper, MB-MPO[3] does not improve at all during training on Half-Cheetah environment.	weakness
2020-1701	However, in the original MB-MPO paper, the algorithm does improve and the performance seems to be comparable to that of the proposed method in this paper.	weakness
2020-1701	3. The experiment results are not very strong for the proposed method.	weakness
2020-1701	In 3 of 4 environments, the proposed algorithm does not show much advantage over the baseline algorithms.	weakness
2020-1701	The only environment in which the proposed method shows significant improvement is Half-Cheetah, and I believe that the baseline algorithms might not be properly tuned in this environment.	weakness
2020-1701	4. The paper lacks certain baseline comparisons.	weakness
2020-1701	There are many other model based RL algorithms developed recently, and it would be important to compare to these methods.	weakness
2020-1701	Some examples would be ME-TRPO[2], SLBO[4] and MBPO[5].	weakness
2020-1701	The idea in the paper is well presented and carefully investigated.	strength
2020-1701	However, I am still not convinced about the novelty of the proposed idea and the magnitude of performance improvement.	weakness
2020-1701	Therefore, I would not recommend acceptance before these problems are addressed.	decision
2020-1701	References [1] Schulman, John, et al. "Proximal policy optimization algorithms." arXiv preprint arXiv:1707.06347 (2017).	misc
2020-1701	[2] Kurutach, Thanard, et al. "Model-ensemble trust-region policy optimization." arXiv preprint arXiv:1802.10592 (2018).	misc
2020-1701	[3] Clavera, Ignasi, et al. "Model-based reinforcement learning via meta-policy optimization." arXiv preprint arXiv:1809.05214 (2018).	misc
2020-1701	[4] Luo, Yuping, et al. "Algorithmic framework for model-based deep reinforcement learning with theoretical guarantees." arXiv preprint arXiv:1807.03858 (2018).	misc
2020-1701	[5] Janner, Michael, et al. "When to Trust Your Model: Model-Based Policy Optimization." arXiv preprint arXiv:1906.08253 (2019).	misc

2020-1787	After Responses: I understand the differences that authors pointed to the relevant literature.	misc
2020-1787	However, it is still lacking comparisons to these relevant methods.	weakness
2020-1787	The proposed method has not been compared with any of the existing literature.	weakness
2020-1787	Hence, we do not have any idea how does it stand against the existing approaches.	weakness
2020-1787	Hence, I believe the empirical study is still significantly lacking.	weakness
2020-1787	I will stick to my decision.	misc
2020-1787	Main reason is as follows; I believe the idea is interesting but it needs a significant empirical work to be published.	weakness
2020-1787	I recommend authors to improve empirical study and re-submit.	decision
2020-1787	------- The submission is proposing a method for multi-objective RL such that the preference of tasks learned on the fly with the policy learning.	abstract
2020-1787	The main idea is converting the multi-objective problem into single objective by scalar weighting.	abstract
2020-1787	The weights are learned in a structured learning fashion by enforcing them to approximate the Pareto dominance relations.	abstract
2020-1787	The submission is interesting; however, its novelty is not even clear since authors did not discuss majority of the existing related work.	weakness
2020-1787	Authors can consult the AAMAS 2018 tutorial "Multi-Objective Planning and Reinforcement Learning" by Whiteson&Roijers for relevant papers.	suggestion
2020-1787	It is also important to note that there are other methods which learn weighting.	weakness
2020-1787	Optimistic linear support is one of such methods.	weakness
2020-1787	Hence, this is not the first of such approaches.	weakness
2020-1787	Beyond RL, it is also studied extensively in supervised learning.	weakness
2020-1787	For example, authors can see "Multi-Task Learning as Multi-Objective Optimization" from NeurIPS 2018.	suggestion
2020-1787	The manuscript is also very hard to parse and understand.	weakness
2020-1787	For example, Definition 2 uses but not define "p" in condition (2).	weakness
2020-1787	Similarly, Lemma 1 states sth is "far greater" than something else.	weakness
2020-1787	However, "far greater" is not really defined.	weakness
2020-1787	I am also puzzled to understand the relevance of Theorem 1.	weakness
2020-1787	It is beyond the scope of the manuscript, and also not really new.	weakness
2020-1787	Authors suggest a method to solve multi-objective optimization.	abstract
2020-1787	However, there is no correctness proof.	weakness
2020-1787	We do not know would the algorithm result in Pareto optimal solution even asymptotically.	weakness
2020-1787	Arbitrary weights do not result in Pareto optimality.	weakness
2020-1787	Proposing a new toy problem is well-received.	strength
2020-1787	However, not providing any experiment beyond the proposed problem is problematic.	weakness
2020-1787	Authors motivate their method using DOOM example.	weakness
2020-1787	Why not provide experimental results on a challenging problem like DOOM?	weakness
2020-1787	In summary, I definitely appreciate the idea.	strength
2020-1787	However, it needs better literature search.	weakness
2020-1787	Authors should position their paper properly with respect to existing literature.	suggestion
2020-1787	The theory should be revised and extended with convergence to Pareto optimality.	suggestion
2020-1787	Finally, more extensive experiments on existing problems comparing with existing baselines is needed.	weakness
2020-1787	Thank the authors for the response.	rebuttal_process
2020-1787	I agree with R2 that the paper lacks comparisons with previous works.	weakness
2020-1787	I will stick to my previous decision.	misc
2020-1787	---------------------------------------- Summary This paper presents a new approach for single-objective reinforcement learning by preferencing multi-objective reinforcement learning.	abstract
2020-1787	The general idea is to first figure out a few important objectives, add some helper-objectives to the original problem, and learn the weights for each individual objective by trying to keep the same order as Pareto dominance.	abstract
2020-1787	This paper has potential, but I lean to vote for rejecting this paper now, since it is still not ready.	decision
2020-1787	I might change my score based on the reviews from other reviewers.	misc
2020-1787	Strengths - The idea is novel.	strength
2020-1787	Learning weights for each objective by keeping the order as Pareto dominance is an interesting idea to me.	strength
2020-1787	Weaknesses - The lack of experiments.	weakness
2020-1787	The authors tested their method in only one scenario, which makes me feel unsafe.	weakness
2020-1787	Only testing on one simple scenario does not demonstrate the effectiveness.	weakness
2020-1787	The authors are supposed to test their method on more (complex) scenarios to show the effectiveness of their method.	suggestion
2020-1787	Possible Improvements As mentioned before, the proposed method can be tested on more scenarios (e.g., Deep Sea Treasure, SuperMario, etc.).	suggestion

2020-1788	This paper studied the problem of universal adversarial attack which is an input-agnostic perturbation.	abstract
2020-1788	The authors proposed to use the top singular vector of input-dependent adversarial attack directions to perform universal adversarial attacks.	abstract
2020-1788	The authors evaluated the error rates and fooling rates for three attacks on standard benchmark datasets.	abstract
2020-1788	- The paper is generally well-written and easy to follow.	strength
2020-1788	My main concern towards this paper is about the experiments part from several aspects.	weakness
2020-1788	First, the proposed method needs quite large L2 norm (50 on ImageNet) to work, while common adversarial attack experiments on ImageNet are usually conducted with L2 perturbation strength of 5 or less.	weakness
2020-1788	I totally understand that performing universal attack would be much more difficult, yet having such loose L2 norm constraint still seems impractical.	weakness
2020-1788	Second, the authors did not compare with any other baselines such as  (Moosavi-Dezfooli et al. 2017a) arguing that their universal attack is different for different perturbation strength and pixels are normalized.	weakness
2020-1788	I do not think normalized pixel will be a problem as you can simply scale the perturbation strength accordingly.	ac_disagreement
2020-1788	And because (Moosavi-Dezfooli et al. 2017a) uses different attack vectors for different perturbation strength, some comparison between these two types of universal attacks should be presented in order to mark the difference and demonstrate your advantages.	suggestion
2020-1788	I would suggest the authors to compare with several mentioned baselines in the paper to show the superiority of the proposed method.	suggestion
2020-1788	- Theorem 1 seems interesting, yet it needs a special assumption.	weakness
2020-1788	The authors argue that this is a reasonable assumption in a small neighborhood of x.	weakness
2020-1788	I wonder if the authors could conduct some demonstrative experiments to verify this?	suggestion
2020-1788	Because the definition of S_x depends on the attack function, does it mean that the assumption need to be held for any attack function?	suggestion
2020-1788	Also regarding the choice of \\delta, it seems that \\delta is different for different x?	weakness
2020-1788	If so, since u is also depend on \\delta, this attack vector seems not universal?	weakness
2020-1788	Detailed comments: - In proof of Theorem 1, all S should be G?	weakness
2020-1788	- In proof of Theorem 2, how to get \\|v - \\hat v\\|_2 \\leq \\epsilon/(\\gamma - \\epsilon)?	weakness
2020-1788	Directly applying the Theorems seems to get \\epsilon / (\\gamma) only?	weakness
2020-1788	Depending on whether the authors can address my concerns, I may change the final rating.	misc
2020-1788	====================== after the rebuttal I thank the authors for their response but I still feel that the assumption is not well-justified and there is still a lot to improve in terms of experiments.	rebuttal_process
2020-1788	Therefore I decided to keep my score unchanged.	rebuttal_process
2020-1788	This paper presents a universal adversarial attack, which firstly conducts existing gradient-based attacks on the sample images and then applies SVD on the perturbations from those attacks.	abstract
2020-1788	The universal attacks are the right singular vectors of the SVD.	abstract
2020-1788	The experiments are conducted on attacking VGG and ResNet. In addition, theoretical analysis is also provided in the paper.	abstract
2020-1788	Compared with instance-wise attacks, universal attacks are relatively rare.	abstract
2020-1788	The idea of this paper is intuitive but I feel that it is highly related to the one in Khrulkov & Oseledets (2018).	weakness
2020-1788	The latter finds singular vectors with the gradients of the hidden layers of the targeted classifier.	weakness
2020-1788	In general, the instance-wise attacks such as FGSM and Gradient are essentially based on gradients of the classifiers, as well.	weakness
2020-1788	Therefore, given Khrulkov & Oseledets (2018), I would consider the novelty of this paper is not large enough, although I can see that the proposed may be more efficient.	weakness
2020-1788	In addition to attacking raw classifiers, I would also expect the comparisons with defence methods against universal attacks, such as the one in [1].	suggestion
2020-1788	Minors: It is a bit hard to compare the performance across different methods in Figure 1.	weakness
2020-1788	I would suggest using tables to give a clearer comparison.	suggestion
2020-1788	Overall, I think the paper stands on the borderline.	misc
2020-1788	[1] Akhtar, Naveed, Jian Liu, and Ajmal Mian.	misc
2020-1788	"Defense against universal adversarial perturbations." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.	misc
2020-1788	2018. This paper presents an observation that one can use the top singular vector of a matrix consisting of adversarial perturbation (Gradient attack, FGSM attack, or DeepFool) vectors of a subset of data as a universal attack (applying the same perturbation to all inputs and fools a large fraction of inputs).	abstract
2020-1788	The paper gives a theoretical justification of their method using matrix concentration inequalities and spectral perturbation bounds.	abstract
2020-1788	Strengths: - A simple and effective technique to fool a large fraction of examples leveraging the observation that only a small number of dominant principal components exist for input-dependent attack directions.	strength
2020-1788	- Clean theoretical justification of the performance of the proposed methodology.	strength
2020-1788	- I also like the observation and the generality, simplicity, and theoretical proof of the proposed universal attack algorithm SVD-Universal.	strength
2020-1788	Weaknesses: - Performance seems to be inferior to previous methods e.g. Khrulkov & Oseledets 2018.	weakness
2020-1788	The paper does not give a comparison between SVD-Universal and (p,q)-SVD.	weakness
2020-1788	- Although the author gives a justification of why they do not compare with (p,q)-SVD, I still like to see a comparison between the two methods such that we can have a better idea about what is the potential performance loss by using the SVD-Universal when compared with (p,q)-SVD.	weakness
2020-1788	- It is not clear to me how the authors build the matrix corresponding to the universal invariant perturbations in sec 6.	weakness

2020-1895	This paper proposed a new model for change point detection, using autoencoders with temporal regularization, in order to impose temporal smoothness in the latent codes.	abstract
2020-1895	To motivate this new model, the authors also provided a toy example to show how the abnormality in a time series is removed in the reconstructed signal using this additional regularization term.	abstract
2020-1895	Experimental results were provided to support the proposed new model.	abstract
2020-1895	I have a few concerns about some technical details of the paper, as explained below: 1) The paper motivated the new model with difficulty in detecting change points in seasonal time series.	weakness
2020-1895	However, the proposed model with the temporal regularization is not directly related to the seasonality or periodicity of the input data.	weakness
2020-1895	It is more related to the smoothness of the latent code.	weakness
2020-1895	Hence it seems to me that there is a slight disconnection between the motivation and the actually proposed model.	weakness
2020-1895	It would be nice if the authors can provide more intuitive explanation on why the temporal regularization can handle well change point detection in seasonal temporal series.	suggestion
2020-1895	2) The temporal regularization proposed in this paper is very similar to the total variation penalty used extensively in statistics and image processing.	weakness
2020-1895	It would be nice if the authors can make a connection between the two.	suggestion
2020-1895	For example: Harchaoui, Z., & Lévy-Leduc, C.	suggestion
2020-1895	(2010). Multiple change-point estimation with a total variation penalty.	misc
2020-1895	Journal of the American Statistical Association, 105(492), 1480-1493.	misc
2020-1895	Beck, A., & Teboulle, M.	misc
2020-1895	(2009). Fast gradient-based algorithms for constrained total variation image denoising and deblurring problems.	misc
2020-1895	IEEE transactions on image processing, 18(11), 2419-2434.	misc
2020-1895	3) In the experimental section 4.3, the authors mentioned that "In Table 2, ...	weakness
2020-1895	we can see that our algorithm outperforms the baseline model".	strength
2020-1895	However, in Table 2 the precision of the proposed model (67%) is lower than the baseline model (68%).	weakness
2020-1895	Hence it is not obvious to the reader that the proposed model outperforms the baseline.	weakness
2020-1895	4) In the appendix B, the authors explained the architecture of the autoencoder used in the paper.	weakness
2020-1895	I wonder why the authors chose an asymmetric structure between the encoder and decoder, as most autoencoders have a symmetric structure.	weakness
2020-1895	Summary: The paper raises an alarm that state-of-the art change-point detection methods in the ML literature do not handle important practical aspects arising in time-series modeling, namely seasonality.	abstract
2020-1895	Indeed, methods designed to detect changing distribution under an i.i.d. setting can fail dramatically when the assumption is violated, when the change happens in the seasonal component.	abstract
2020-1895	The paper proposes to use an auto-encoder to find the "main pattern" within each seasonal window, and to use total variation penalty (l1-norm on the change) of the hidden state in the auto-encoder to encourage a smooth state-sequence which allow breaks.	abstract
2020-1895	They use k-means clustering to partition data-points, and detect a change-point if two consequent hidden states don't end up in the same cluster.	abstract
2020-1895	While the proposal is sensible and the paper is reasonably readable, I find the paper lacking in several respects, and recommend to reject it.	decision
2020-1895	My main concerns are (a) novelty: despite the claims in the paper -- the importance of seasonality is well known and appreciated in time-series literature, and the proposal to look for changes in seasonality is fairly obvious when dealing with practical time-series.	weakness
2020-1895	I would suggest to do a comprehensive literature search and re-evaluate the novelty of the paper.	suggestion
2020-1895	I believe that recent ML papers e.g. kernel two-sample tests and such, focus on the i.i.d. setting and ignore seasonality (and other messy aspects of practical TS) -- as it is the more challenging statistical problem.	suggestion
2020-1895	(b) The paper considers a setting where the time-series consists of a seasonal component and an i.i.d. component (combined additively or multiplicatively).	abstract
2020-1895	It doesn't attempt to model any kind of stochastic dynamics -- e.g. at least a simple auto-regressive model instead of iid, and non-stationarity (trends) in the time-series.	weakness
2020-1895	So despite aiming to look at practical time-series, the paper still considers a simplified model.	weakness
2020-1895	(c) The paper's presentation is often sloppy in language use, assumptions, mathematical details, and simulations and needs to be significantly improved to be considered for *CONF* (or related ML conferences).	weakness
2020-1895	Detailed comments: a) The references are severely lacking.	weakness
2020-1895	There is an extensive literature in modeling time-series with seasonality and classical methods such as SARIMA (seasonal ARIMA), or exponential smoothing can track the evolution and changes in seasonal components.	weakness
2020-1895	Various nonlinear DL-approaches to TS with seasonality have also started to appear.	weakness
2020-1895	Once time-series is decomposed into trend, seasonal and stochastic part (using any linear or nonlinear or deep model), it is straightforward to apply anomaly detection algorithms to each component separately.	weakness
2020-1895	Please take a look at e.g. https://anomaly.io/blog/index.html (from salesforce.com), to see practical change-point or anomaly detection in time-series in practice which does pay attention to seasonality.	suggestion
2020-1895	Also papers by Rob Hyndman pay close attention to seasonality, see e.g. https://otexts.com/fpp2/.	suggestion
2020-1895	"Changepoint Detection in Periodic and Autocorrelated Time Series", https://journals.ametsoc.org/doi/full/10.1175/JCLI4291.1	misc
2020-1895	https://cran.r-project.org/web/packages/trend/vignettes/trend.pdf  (which has a section on seasonal change-point detection)	misc
2020-1895	Harvey, Koopman, Penzer, "Messy Time Series: A Unified approach", Adv. in Econometrics, Vol. 13, pp.	misc
2020-1895	103-143., https://www.stat.berkeley.edu/~brill/Stat248/messyts.pdf Perhaps there's relatively less focus on these practical details of change-point detection in recent ML literature and the focus is on the stochastic component, as it is the most challenging for prediction.	weakness
2020-1895	The use of l1-norm of differences in time-series to detect changes is a natural idea, and has been suggested many papers e.g.in: http://eeweb.poly.edu/iselesni/lecture_notes/TV_filtering.pdf,	suggestion
2020-1895	"Time Series Clustering using the Total Variation Distance",	misc
2020-1895	Stephen Boyd's trend filtering, https://web.stanford.edu/~boyd/papers/pdf/l1_trend_filter.pdf .	misc
2020-1895	While I am not aware of a specific prior work on auto-encoder with temporal smoothness for CPD, most of the main ideas are well known, and in my view the contribution is very limited in novelty.	weakness
2020-1895	b) You're ignoring any memory or dynamics in the stochastic component of the time-series -- e.g. allowing something like a simple AR model rather than iid would be a good step.	weakness
2020-1895	Detecting changes in the dynamics or correlation structure (temporal or cross-sectional) would make the paper more interesting.	suggestion
2020-1895	Something closer to switching linear dynamical systems, see for example https://arxiv.org/abs/1610.08466.	suggestion
2020-1895	c) The presentation has many issues in language / math / simulations and needs to be improved: 1. The setting is not described clearly / formally -- are you trying to detect change-points online or offline, what assumptions are you making on the segments after removing seasonality -- are these just iid / stationary, can they include trends, outliers, e.t.c. 2.	weakness
2020-1895	Baseline methods for detecting seasonal patterns are naive -- clearly applying methods that are not aware of seasonality will fail when there is strong seasonal components.	weakness
2020-1895	There is one basic attempt at removing the seasonal component by averaging, and applying iid kernel CPD methods -- where it does help.	weakness
2020-1895	I believe doing something a bit more realistic (like doing a seasonal decomposition) will make the baselines much stronger.	suggestion
2020-1895	3. Citation format is inconsistent with *CONF*.	weakness
2020-1895	4. ATR-CSPD is undefined in the abstract.	weakness
2020-1895	5. Intro:  i, j, k notation inconsistent -- you seem to use i both for i = j*p + k, and also to refer to window id.	weakness
2020-1895	6. What is a "generative function" of time-series?	weakness
2020-1895	Do you mean the pdf / cdf?	weakness
2020-1895	What do you mean by a product of generative functions (which is additive or multiplicative), do you mean adding / taking products of random variables coming from independent distributions?	weakness
2020-1895	What do you mean that you do not differentiate between additive / multiplicative?	weakness
2020-1895	Do you claim to handle both within the same model?	weakness
2020-1895	7. Definition 2 -- do you look for x_jo,k ~ Gk',  or x_j for j> j0 ~ Gk'?	weakness
2020-1895	8. You claim a multi-variate extension is easy -- but is it?	weakness
2020-1895	How would you tackle e.g. changes in correlation structure?	weakness
2020-1895	9. "Autoencoders attempt to copy input to output" - isn't this trivial by using an identity function?	weakness
2020-1895	You should mention some compression / bottleneck as well.	weakness
2020-1895	10. How do you optimize the total-variation (l1-norm) penalty in your formulation?	weakness
2020-1895	Just throw it into SGD in keras?	weakness
2020-1895	11. The discussion in 3.2. is confusing -- you talk about weekly series, but use daily-seasonality, however you then describe detecting weekdays vs.	weakness
2020-1895	weekends? How can you associate separate weekends without a weakly seasonal model?	weakness
2020-1895	12. London electricity data-set -- why do you average all weeks within the time-series to find average customer week?	weakness
2020-1895	This was very surprising. Don't you loose most of the interesting anomaly data this way?	weakness
2020-1895	13. Figures are not explained well.	weakness
2020-1895	While there's nice use of color -- it's often hard to understand what is the description pointing at.	weakness
2020-1895	typos: Person -> Pearson,  Autencoder -> Autoencoder, and many others.	weakness
2020-1895	I am quite disappointed with the presentation and technical quality of the paper.	weakness
2020-1895	There are numerous grammatical errors that make the reading unpleasant.	weakness
2020-1895	The mathematical notations are also inconsistent throughout different places in the paper.	weakness
2020-1895	The extensive literature of modelling time series with seasonality trends, both in the statistics and the machine learning community, is severely under-represented in the motivations and related works.	weakness
2020-1895	Models like SARIMA have no mention in the paper.	weakness
2020-1895	The temporal regularization imposed in section 3.2, coupled with an autoencoder, does not seem very different from the state-space models and their more complex and recent variants that use multi-layered networks (a google search will provide plenty references).	weakness
2020-1895	The experiments, with many of the useful baselines missing, are equally unimpressive.	weakness
2020-1895	The paper investigates the important problem of detecting changes in seasonal patterns, and proposes ATR-CSPD to learn a low-dimensional representation of the seasonal pattern and then detects changes with clustering-based approaches.	abstract
2020-1895	ATR-CSPD achieves improved results on part of synthetic and real-world datasets.	abstract
2020-1895	The paper may not have enough contribution to be accepted due to the following key concerns: - The proposed model is not quite novel, and the design needs more justification.	decision
2020-1895	- The empirical results are not strong enough to show the effectiveness of ATR-CSPD.	weakness
2020-1895	# Model design The idea of using auto-encoder with temporal smoothing to learn a low-dimensional representation of time-series need more justification.	weakness
2020-1895	- What are the main intuitions of using an auto-encoder?	weakness
2020-1895	e.g., removing anomaly or denoising.	weakness
2020-1895	Why will it be easier for the model to detect the changes on the reconstructed time-series?	weakness
2020-1895	- The temporal smoothing makes adjacent periods similar to each other.	weakness
2020-1895	However, this may have side effects like low recall.	weakness
2020-1895	For example, in Figure 2(a), the pattern in Aug 17th (Sat) and that in Aug 18th(Sun) can possibly be different (i.e., a change in seasonal pattern), while the difference is smoothed out by the temporal regularization.	weakness
2020-1895	Is the model sensitive to the regularization, e.g., λ?	weakness
2020-1895	Why L1 regularization instead of L2 is used?	weakness
2020-1895	It will be helpful to provide more justification/intuition of the model design.	suggestion
2020-1895	- Why only the smoothness regularization between adjacent seasons is used?	weakness
2020-1895	Other potential regularization includes penalizing the difference between the same phase in different seasons.	suggestion
2020-1895	# Assumption and limitation The proposed method requires the seasonal period being provided, and also requires a large number of hyperparameters being specified, e.g., 1) the threshold of silhouette score, 2) the hidden representation dimension q, 3) the regularization coefficient, 4) γ,λ,  5) hyperparameters for constructing the encoder/decoder and 6) training the models.	weakness
2020-1895	Regarding the threshold of the silhouette score in the clustering step, is setting this hyperparameter easier than the number of clusters, i.e., the number of changing points?	weakness
2020-1895	Is ATR-CSPD sensitive to this parameter?	weakness
2020-1895	How this hyperparameter is tuned?	weakness
2020-1895	Having too many hyperparameters (that are potentially non-trivial to set/tune) may make the proposed method less robust.	weakness
2020-1895	# Experimental results: According to the results in Table 1, ATR-CSPD is mainly better at detecting Category C/D/E change points, which are mainly caused by changes of height/position of the spike.	weakness
2020-1895	However, it performs either similarly or worse than the other baselines on other tasks.	weakness
2020-1895	Besides, the lack of ground-truth data on NYC Taxi dataset and the Azure monitor dataset makes it hard to evaluate the effectiveness of the proposed algorithm.	weakness
2020-1895	Moreover, only uni-variate time series tasks are investigated.	weakness
2020-1895	These issues may limit the application domain of the proposed algorithm.	weakness
2020-1895	# Minor notation and presentation issues	weakness
2020-1895	- In Definition 2, does CSPD assume F is the same in Gk and Gk′?	weakness
2020-1895	If not, CPD might be a subset of CSPD.	weakness
2020-1895	- In Equation 1 and 2, n is used to represent the number of observations, while in Definition 1, capital N is used to represent the same concept.	weakness
2020-1895	- In Figure 2, it might be easier to understand if all the weekdays are drawn using the same color (blue or green) and all the weekends are also drawn in the same color (yellow or red).	weakness

2020-1929	This paper attempts to learn a preconditioner for optimization, specifically for the Dual space preconditioned descent (DPGD).	abstract
2020-1929	- The techniques used to learn the preconditioner are heuristic, not scalable and without justification or ablation studies.	weakness
2020-1929	- It does not compare against "standard" optimization techniques that construct data-driven preconditioners such as Adam or Adagrad or even to more Newton, natural gradient methods that use the Hessian or the Fisher information matrix as preconditioners.	weakness
2020-1929	It shows ad-hoc synthetic experiments in dimensions 1 and 50.	weakness
2020-1929	This is clearly not enough.	weakness
2020-1929	Detailed review below: - Section 2: Please explain why Legendre functions are useful in ML.	weakness
2020-1929	For assumption 1, 2; it needs to be explained why these hold for a given f*.	weakness
2020-1929	What constraints do you need on f?	weakness
2020-1929	What functions satisfy these? Please explain this explicitly.	weakness
2020-1929	- Section 3: What is the number of points x_i needed in high dimensions to learn?	weakness
2020-1929	Is it even possible to scale up this method to high dimensions?	weakness
2020-1929	- Constructing \\mu requires computing the determinant of the Jacobian.	weakness
2020-1929	What is the computational complexity?	weakness
2020-1929	Moreover, it seems that we need access to the \\nabla f(x) for all x in D(f)?	weakness
2020-1929	- Please state all the assumptions in the beginning rather than introducing one at a time in the propositions.	weakness
2020-1929	- Remark 1: It is unclear that the cost of an inverse Hessian matrix is more than the procedure proposed in this paper.	weakness
2020-1929	- Section 3.5: Please explain what is the advantage of this learned optimizer compared to other methods?	weakness
2020-1929	Note that there is literature on non-smooth optimization and methods like sub-gradient descent can be used in this case.	weakness
2020-1929	- What is the justification for the selection of the loss function and log-rescaling?	weakness
2020-1929	- The result of Lemma 1 is standard.	weakness
2020-1929	Please acknowledge this. -  Section 4: "The step-size is set to 1".	weakness
2020-1929	It seems that the optimizer has been overfit and engineered to work on this specific problem.	weakness
2020-1929	Either these decisions need to be justified, there needs to be an ablation study or there needs to be a larger set of experiments.	weakness
2020-1929	[Update after rebuttal period] I have read the response,  my confusion in the original reviews cannot be answered satisfactorily.	rebuttal_process
2020-1929	Therefore, I keep my initial scores.	rebuttal_process
2020-1929	[Original reviews] Firstly, the motivation of the proposed method is not convincing for me.	weakness
2020-1929	The authors want to propose a general methodology for learning precondition by supervised learning setting.	abstract
2020-1929	However the method in practice, the x is a complex distribution, it is difficult to handle the map between the gradient and the x.	weakness
2020-1929	This method proposes log-scaling, but it needs to be stored with a precision of approximately 15 decimal places and the regressed model will be a piecewise constant function, which is very computationally time-consuming.	weakness
2020-1929	Secondly, the experimental results are not sufficient for evaluation.	weakness
2020-1929	This paper shows two The experimental result which includes the result of power function and the logistic function.	abstract
2020-1929	But It is not clear that the whole process of dual space preconditioned method with the model of computation of precondition given.	weakness
2020-1929	And without quantitative results given, it is not convincing the "dramatic" speedups" of these methods, because the surprising training process is off-line and time-consuming.	weakness
2020-1929	On the other hand, because of the different forms of the convex objective function, the network will train for the specific convex objective functions.	weakness
2020-1929	In my opinion, it is not a general method to lead to dramatically speed up.	weakness
2020-1929	Finally，the function of x and the gradient is complex, it is difficult to predict the relationship by using a simple network, This paper proposes an optimization method with the preconditioning in the framework of supervised learning.	weakness
2020-1929	The ideal preconditioning is given by the Fenchel conjugate of the optimization function.	suggestion
2020-1929	This paper uses a supervised scenario to find the ideal preconditioning.	abstract
2020-1929	The authors point out the importance of the sampling distribution then and propose a sampling scheme using the uniform distribution on the space of gradient descents.	abstract
2020-1929	The samples are used to train neural networks that imitate the mapping of the Fenchel conjugate.	abstract
2020-1929	The training network is incorporated into the Dual space Preconditioned Gradient Descent (DPGD).	abstract
2020-1929	Some numerical experiments show the effectiveness of the proposed method comparing to the standard gradient descent method.	abstract
2020-1929	The authors proposed an interesting approach to the preconditioning in optimization problems.	abstract
2020-1929	However, the paper is not well-written.	weakness
2020-1929	In particular, the optimization algorithm is not clearly described.	weakness
2020-1929	Numerical experiments with some toy problems are not very convincing to show the benefit of the proposed method.	weakness
2020-1929	Though this paper may have some interesting ideas, more intensive analysis would be required.	weakness
2020-1929	other comments: - The optimization algorithm is not explicitly described.	weakness
2020-1929	Is the neural network trained as the batch learning?	weakness
2020-1929	Is it possible to use the learning of the preconditioning in an online manner?	weakness
2020-1929	- It is not sure whether the ideal distribution \\mu over the domain D(f) presented in Proposition 3 is computationally tractable.	weakness
2020-1929	- In Proposition 3: I think that the uniform property of the sampling does not directly mean the optimality in the sense of the learning accuracy.	weakness
2020-1929	The authors need to investigate the more detailed relationship between the distribution mu and the prediction accuracy of the Fenchel conjugate.	weakness
2020-1929	- The proposed method requires the learning of neural networks, which will be computationally demanding.	weakness
2020-1929	Please report the overall computational cost of the optimization algorithm in numerical experiments.	suggestion

2020-1955	Overview: This work proposes to learn sentence embeddings using both contrastive learning and multiple "views" of sentences.	abstract
2020-1955	This work largely builds off of [1], including using the same objective, but uses a multi-view approach to modeling.	abstract
2020-1955	- They apply the concept of multi-view models, specifically combining tree and linear LSTMs to learning sentence representations.	abstract
2020-1955	- They prepare a new, large-scale book dataset, which is useful because the previously commonly used book dataset was taken down for legal reason.	abstract
2020-1955	- They provide a fairly broad set of analyses on their model, both quantitative and qualitative, performance-driven and analysis-driven.	abstract
2020-1955	- Review: The ideas and models presented in this paper are not new, while the supporting experiments are not very well done or convincing.	weakness
2020-1955	Overall, I recommend rejecting this work.	decision
2020-1955	- The models are contrastively learned in that they are trained to embed "similar" sentences nearby in the embedding space, and "dissimilar" sentence far away, where "similar" sentences are defined as consecutive sentences.	weakness
2020-1955	This method of learning textual representations is well-established in the NLP literature, mostly prominently in recent years with word embedding models like Skip-Gram and in sentence embedding models like in [1], [2], [3] (the next sentence prediction task), and several more.	weakness
2020-1955	- In practice, the multiple views of each sentence that this paper considers boils down to encoding the sentence with a bidirectional LSTM and a TreeLSTM and concatenating the representations from each encoder.	weakness
2020-1955	This idea again has been established in the literature ([4], [5], [6]).	weakness
2020-1955	- The experiments don't seem setup to demonstrate that the multiple views are beneficial over a single view.	weakness
2020-1955	In Table 1, there are rows for just an LSTM or just a TreeLSTM, but they seem to be trained with labeled data whereas the proposed method is trained self-supervised.	weakness
2020-1955	A more informative comparison to demonstrate the value of using multiple views would be to train the LSTM and TreeLSTM with the same objective (and ideally model size).	suggestion
2020-1955	Overall, I don't think the claims in the paper are well-supported by the model proposed or the experiments.	weakness
2020-1955	- I have a number of concerns about the experiments.	weakness
2020-1955	- "Models are trained on a single epoch on the entire corpus without any train-test split": so there is no early stopping?	weakness
2020-1955	Why stop training after one epoch?	weakness
2020-1955	Was there any indication you were overfitting the data?	weakness
2020-1955	- "The training phase was stopped after 33 hours of training": Why stop there?	weakness
2020-1955	Computational constraints? Later comments suggest this is quite premature ("training phase was completed on only 4.6M sentences among the 78M available").	weakness
2020-1955	- The results seem to indicate that this method underperforming recent work significantly.	weakness
2020-1955	Areas of improvement - Some of the language in the introduction and conclusion are a bit of a stretch.	weakness
2020-1955	Using a linear and tree LSTM (based on dependency parses) doesn't really represent a "diversity of linguistic structures".	weakness
2020-1955	- Related work: There's no mention of pretained language models, which could be seen as a form of representation learning for language, and have been hugely impactful in NLP.	weakness
2020-1955	- Method - Missing negative in the log likelihood	weakness
2020-1955	- Why do you use inner product if other works "report excellent results" with other scoring functions?	weakness
2020-1955	- "assumes the underlying structure of the sentence to be a sequence, while allowing for long term dependencies": If anything, the treeLSTM more easily allows for long-term dependencies than the linear LSTM.	weakness
2020-1955	- "Negative examples are obtained using the dependency Tree LSTM": I'm not totally sure how the negatives are obtained here.	weakness
2020-1955	- "The target sequence is encoded using the sequential Tree LSTM, while the positive and negative samples are encoded using the ChildSum Tree LSTM": why are the sentences not all encoded with the same encoder?	weakness
2020-1955	- It looks really odd that most of Table 1 is empty.	weakness
2020-1955	Given your model, I imagine it can't have been that difficult to evaluate more baselines (BiLSTM and TreeLSTM) on the rest of the tasks.	weakness
2020-1955	- It'd be nice if you could clearly indicate in Table 1 which method is yours.	weakness
2020-1955	- Results and Analysis - The standard evaluation setting for sentence embeddings would be GLUE or SuperGLUE.	weakness
2020-1955	- A glaringly missing baseline is BERT (or any of its relatives), which is also self-supervised.	weakness
2020-1955	- The results are underwhelming, and as the author admits, somewhat premature as training didn't seem to finish.	weakness
2020-1955	- 5.2: what are the contrastive LSTM and Tree LSTM?	weakness
2020-1955	Are those the learned encoders from the "Contrastive Tree" in Table 1, or are they trained from scratch?	weakness
2020-1955	- I don't think the analyses in Sections 5.2 and 5.3 or Figure 2 are particularly useful.	weakness
2020-1955	- There are a noticeable number of typos.	weakness
2020-1955	For example, in the abstract: "this linguist[ic] diversity" and "better capture semantic[s]".	weakness
2020-1955	It'd be worthwhile to look over the paper closely for typos.	suggestion
2020-1955	[1] AN EFFICIENT FRAMEWORK FOR LEARNING SENTENCE REPRESENTATIONS.	misc
2020-1955	Lajanugen Logeswaran and Honglak Lee	misc
2020-1955	[2] Discourse-Based Objectives for Fast Unsupervised Sentence Representation Learning.	misc
2020-1955	Yacine Jernite, Samuel R. Bowman, David Sontag	misc
2020-1955	[3] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.	misc
2020-1955	Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova	misc
2020-1955	[4] Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference.	misc
2020-1955	Qian Chen, Xiaodan Zhu, Zhenhua Ling, Si Wei, Hui Jiang.	misc
2020-1955	[5] Enhanced LSTM for Natural Language Inference.	misc
2020-1955	Qian Chen, Xiaodan Zhu, Zhenhua Ling, Si Wei, Hui Jiang, Diana Inkpen.	misc
2020-1955	[6] Improving Sentence Representations with Consensus Maximisation.	misc
2020-1955	Shuai Tang, Virginia R. de Sa. The paper proposes a new sentence embedding method.	abstract
2020-1955	The novelty is to use dependency trees as examples in the self-supervised method based on contrastive learning.	abstract
2020-1955	The idea to use linguistic knowledge in the design of sentence embeddings is attractive.	strength
2020-1955	The sentence representation is computed by a bi-LSTM and dependency tree representations are computed by Tree LSTM.	strength
2020-1955	The softmax classifier is trained using the negative log-likelihood loss.	abstract
2020-1955	In my opinion, the paper could not be accepted.	decision
2020-1955	As said before, the idea is attractive but the paper lacks motivations for the choice of dependency trees as additional linguistic knowledge.	weakness
2020-1955	Indeed, the goal of the proposed algorithm should be made more precise.	weakness
2020-1955	It is, in my opinion, very difficult to do better than existing sentence embedding methods and the proposed method should be used for specific downstream tasks where the structure of sentences is meaningful.	weakness
2020-1955	Moreover, the proposed method do not scale well and empirical results on classical downstream tasks are not convincing.	weakness
2020-1955	Last, in my opinion, the redaction of the paper should be improved and the bibliography should be updated.	weakness
2020-1955	For instance, the best up-to-date sentence embedding methods are not cited (ELMO and BERT).	weakness
2020-1955	Detailed comments. * Abstract and introduction.	weakness
2020-1955	The description of the contribution is not precise enough.	weakness
2020-1955	Please make precise what are "multiple views", "different linguistic views".	weakness
2020-1955	Please explain why you choose dependency trees and explain why their use can improve sentence embeddings.	suggestion
2020-1955	* Related work. Please consider only word embeddings and sentence embeddings because the literature is sufficiently large in the last few years.	suggestion
2020-1955	Please update your related work with methods such as ELMO and BERT and subsequent work.	suggestion
2020-1955	Also recent papers study how BERT embeddings embed structural information and these should be discussed as you consider dependency trees in the construction of sentence embeddings.	suggestion
2020-1955	* The method does not scale well.	weakness
2020-1955	The paper does not propose ideas to solve this problem.	weakness
2020-1955	Why don't you consider the approach used in Logeswaran et al. * The qualitative analysis shows that similar sentences have a similar structure.	weakness
2020-1955	This is not surprising because dependency trees are used for learning.	weakness
2020-1955	But this should give ideas of downstream tasks for which the approach could be fruitful.	weakness
2020-1955	* Many typos. This paper describes a self-supervised sentence embedding approach that incorporates a different view from plain text where some extent of linguistic knowledge is incorporated through the application of tree LSTM.	abstract
2020-1955	The training procedure is standard contrastive framework where the model is encouraged to distinguish between context sentence (sentences appearing close to the target sentence) and negative samples.	abstract
2020-1955	Evaluations are conducted on 1) downstream tasks, but with a simple logistic regression model on top of sentence embeddings; 2) probing tasks that more focus on surface information prediction, syntactic and semantic tasks; and 3) qualitative analysis with nearest 5 sentences.	abstract
2020-1955	Although the experiments are thorough, I am in favor of rejecting this paper with the following reasons: First, the proposed model is trained with 4.6M sentences among 78M available for 33 hours.	decision
2020-1955	It is unclear why authors stop the training at this early stage but the results on all three evaluations seem to be inferior to the state-of-the-art by a big margin.	weakness
2020-1955	I am happy to raise my score if authors can show the results of a well trained proposed model.	ac_disagreement
2020-1955	Second, the paper has some room for improvement in terms of clarity, to name a few: 1) Authors can strengthen the motivation for multi-views learning in related work;	weakness
2020-1955	2) Formula 1 for softmax is wrong;	weakness
2020-1955	3) Contrastive LSTM and contrastive tree LSTM are not clearly defined in the paper, although the former should refer to quick-thoughts and the latter means the proposed method;	weakness
2020-1955	4) In qualitative analysis, for the last example, there is exactly the same candidate with similarity score 0.012.	weakness
2020-1955	According to cosine similarity, wouldn't this be 0 and also show up in the baseline model regardless of the embeddings?	weakness

2020-1960	This paper considers the problem of how the mismatch between distributions of training data and test data would affect the generalization gap in machine learning tasks.	abstract
2020-1960	This phenomenon has been observed many times in previous literature and has gathered significant attention in the machine learning community.	abstract
2020-1960	The paper took a step in relating the change in the performance of the learned function to the Frechet distance (FD), also known as 2-Wasserstein distance, between the input and output distributions and proved that the former is lower bounded by the latter multiplied by a term related to the sensitivity of learning algorithm to distribution shift.	abstract
2020-1960	The paper also provides empirical evidence that the testing error is correlated with the FD between input and output distributions based on tasks including text classification, image classification, and speech separation.	abstract
2020-1960	I find the idea of the paper interesting but the content not convincing enough.	weakness
2020-1960	The theory proved in the paper does not provide additional quantitive insight beyond intuition.	weakness
2020-1960	Specifically, the term about the sensitivity of the algorithm is not justified enough in the paper.	weakness
2020-1960	The experiments provide some evidence but not convincing, especially for the part about image classification.	weakness
2020-1960	I also find the statement about the generalization gap a bit misleading.	weakness
2020-1960	Generally, the generalization gap refers to the gap between the expected error and the empirical error.	weakness
2020-1960	But the experiments are mostly presenting the performance on the test data.	weakness
2020-1960	Overall, I don't think the paper meets the standard for publication at *CONF*.	decision
2020-1960	The authors propose to relate the performance of a classifier under distribution shift using a quantity called Frechet distance.	abstract
2020-1960	It is common belief that the further apart the training and test distributions are, the more difficult it is to transfer a learned classifier.	abstract
2020-1960	They give simple bounds via gradient norm/Lipschitz constants and distribution distance in Theorem 1.	abstract
2020-1960	The authors try to capture it with Frechet distance, but I struggle to understand what is new in this work.	abstract
2020-1960	First, there are a lot of assumptions in the computation of the Frechet distance: 1. The authors use the embeddings given by the neural networks instead of the raw data since density estimation is hard.	weakness
2020-1960	This makes the distance model-dependent	weakness
2020-1960	2. The authors assume the embeddings are normally distributed in their computation, which have not been justified.	weakness
2020-1960	Most importantly, they do not relate the Frechet distance to the lower bound in Theorem 1.	weakness
2020-1960	There is no estimation on how the learned changes across distributions in the gradient norm term.	weakness
2020-1960	This makes the evaluation nothing more than a confirmation of the general idea that the closer the distribution, the better the transfer.	weakness
2020-1960	The lower bound is not used in any quantitative manner.	weakness
2020-1960	The authors should make the connection of the bound and its computation clear, with proper connections to the experiments.	weakness
2020-1960	The current paper looks like separate theoretical and experimental results that do not tie together.	weakness
2020-1960	The authors consider the relation between Frechet distance of training and test distribution and the generalization gap.	weakness
2020-1960	The authors derive the lower bound for the difference of loss function w.r.t. training and test set by the Wasserstein distance between embedding training and test set distribution.	weakness
2020-1960	Empirically, the authors illustrate a strong correlation between test performance and the distance in distributions between training and test set.	weakness
2020-1960	The motivation to find the relation between generalization gap and the Frechet distance of training and test distribution is sound.	strength
2020-1960	However, I am not sure that the lower bound as in Equation (1) is enough.	weakness
2020-1960	I am curious that one can derive the upper bound for the relation or not.	weakness
2020-1960	The finding about choosing a training data distribution should be close to the test data distribution seems quite trivial in some sense.	weakness
2020-1960	I am not clear about its important since it is quite popular that the distribution shift affects the performance and many learning approach assumes same distribution for training and test data.	weakness
2020-1960	Overall I feel that the contribution may be quite weak, and I lean on the negative side.	decision
2020-1960	Below are some of my concerns: 1) About the lower-bound in Equation	weakness
2020-1960	(1), it seems unclear to me that when the W_2(p1, p2) = 0, we can inference any information about the test performance (It seems quite trivial for this case, the left hand side time is greater than or equal 0?)	weakness
2020-1960	In my opinion, the upper-bound is more important which one can inference much information about the difference of generalization gap.	weakness
2020-1960	2) In the proof of Theorem 1, it is quite hard to follow with the current notation, for the integral in (i), (ii) as well as in the proof using the intermediate value theorem, which variables are used?	weakness
2020-1960	I am confused which one is variable, which one is constants in those integrals.	weakness
2020-1960	3) In page 5, at the interpretation (1), for W2(p1, p2) = 0, the learned function fits training distribution perfectly and is not ill-conditioned ==> why one can deduce that the test distribution is fit perfectly?	weakness
2020-1960	What we have in Theorem 1 is the lower-bound only?	weakness

2020-1965	Summarize what the paper claims to do/contribute.	suggestion
2020-1965	- The paper proposes a new method for zero-shot visual transfer for RL, SADALA.	strength
2020-1965	The method first learns a feature extractor with attention (to focus on realted features only) and then learns a policy in the source task and is able to transfer zero-shot int he target domain.	strength
2020-1965	The method is evaluated on two tasks: Cartpole-v1 (Gym) and "Collect Good Objects" (Deepmind Lab).	strength
2020-1965	It is compared against DARLA for both tasks and against Domain Randomization only for Cartpole.	strength
2020-1965	Clearly state your decision (accept or reject) with one or two key reasons for this choice.	suggestion
2020-1965	Reject. - The experiments of the paper were particularly weak.	weakness
2020-1965	--More standard visual adaptation techniques like DANNs,ADDA, PixelDA/SimGAN, CycleGAN were not considered.	weakness
2020-1965	--The results on domain randomization were not convincing: more details are necessary to determine what the experimental protocol was.	weakness
2020-1965	One major question: what is the source domain in the case of domain randomization (for Fig. 6) In any case, I find it very hard to believe that simple domain randomization considered here can not fully solve this task for all visual pertrubations considered.	weakness
2020-1965	-- In Fig. 5 the reconstruction is not correct.	weakness
2020-1965	-- Domain randomization was not tried on the DeepMind Lab example because of compute.	weakness
2020-1965	However, I'd encourage the authors to try this.	suggestion
2020-1965	Converging will surely not be  linear to the number of perturbations considered as it seems to be implied.	suggestion
2020-1965	Also the OpenAI paper cited as an example where domain randomization took 100 years of simulation required for transfer is a problem of rather different scale: the domain gap there is between simulation and reality for an anthropomorfic robotic hand, and not a simple visual gap where the color of an identical environment are changed.	suggestion
2020-1965	-Related work discussion was insufficient	weakness
2020-1965	-- Related work section is missing and work is not adequately placed in the context of existing literature in the Introduction where some related work is indeed discussed.	weakness
2020-1965	-- Related work at the last sentence of the introduction is not discussed correctly.	weakness
2020-1965	It is implied that all these works are on domain randomization which is not true.	weakness
2020-1965	Also one work (Chebotar et al) is not relevant as from what I recall there was no visual gap.	weakness
2020-1965	Finally most of these works deal with much more complex visual gaps so sample complexity is hard to be compared.	weakness
2020-1965	Pros: This paper proposed a new method for zero-shot transfer learning under the reinforcement learning setting.	strength
2020-1965	The use of attention weights to regularize the latent states was fairly interesting.	strength
2020-1965	Cons: Limited applicability of the proposed methods	weakness
2020-1965	- The paper was restricted in a setting where rewards, actions, and true states were identical between source and target environments, and only the observed states differed due to differing renderers.	weakness
2020-1965	Working under such a restricted setting was interesting in its own right, but it might also lead to limited applicability of the proposed method in the real-world setting.	weakness
2020-1965	- The proposed method focused on solving a very specific problem: learning a dis-entangled latent representation for images.	weakness
2020-1965	As a result, the potential impact of the proposed methods could be minimal.	weakness
2020-1965	Limited technical novelty - The proposed method, SADALA, was built on top of Higgins et al., 2017 (DARLA).	weakness
2020-1965	The only difference was an added attention layer to the learning of latent states.	weakness
2020-1965	As a result, the novelty of the proposed method was very incremental and limited from a technology perspective.	weakness
2020-1965	- Even with additional attention layer, the paper could have performed a more thorough study to help the readers understand and appreciate the idea.	weakness
2020-1965	For example, this paper didn't discuss the tradeoff between training SADALA over separate stages, versus training it from end to end.	weakness
2020-1965	For example, why the weights of the pre-trained beta-VAE had to be frozen and used as weights in the state representation stage.	weakness
2020-1965	Insufficient experiments -More thorough discussion of the qualitative results should be helpful to understand whether the attention weights helped the model to focus on the right thing.	weakness
2020-1965	For example, this paper did study the quality of reconstruction in Figure 3-5 of the proposed method.	weakness
2020-1965	When comparing Figure 3 and Figure 5, it appeared to me that the reconstructed the angle of the pole was different from the original one.	weakness
2020-1965	And it seemed like attention weights did successfully ignored the color of the cart and pole, but it ignored the angle of the pole, which should be important to the learning task.	weakness
2020-1965	Unfortunately, the paper didn't further explain the implication of such misrepresentation.	weakness
2020-1965	-Quantitative results * It would be interesting to all compare the proposed methods against model-agonistic methods like MAML	weakness
2020-1965	* It would be useful to include confidence intervals over different tasks.	suggestion
2020-1965	* It would be useful to compare different methods with different parameter settings	suggestion
2020-1965	* The authors mentioned "Visual Pendulum tasks" but didn't include them in the paper	weakness
2020-1965	Reproducibility - It's unclear to me how reproducible the research conducted in this paper was, and it would be useful to open source the code used to conduct the experiments.	weakness
2020-1965	The paper proposes adding an attention mechanism to the DARLA beta-VAE approach to transfer learning.	abstract
2020-1965	The beta-VAE, soft attention and policy are trained on appropriate source tasks and evaluated zero-shot on target tasks, using two more difficult continuous control domains with RGB observations.	abstract
2020-1965	Results indicate some improvements to compared to the immediate relevant baseline which may be statistically significant, but it is not clear whether over 10% in practice.	weakness
2020-1965	I cannot at this stage recommend acceptance for the following reasons: 1) The paper augments an existing method with a well understood attention mechanism, so the novelty of the approach is relatively low.	decision
2020-1965	2) The experimental results are interesting, but I don't find them compelling enough to recommend acceptance based on the results alone.	decision
2020-1965	The paper does not solve a major problem with the approach it is based on.	strength
2020-1965	In fact, the improvement seems to be smaller when the environment is more complex.	weakness
2020-1965	3) Several baselines which are cited in the paper are actually missing in the experiments, so it is hard to determine how important is that roughly 10% improvement compared to SOTA.	weakness

2020-1967	This paper studies the problem of domain adaptation via learning invariant representations.	abstract
2020-1967	The main argument here is that when the total depth of layers in a neural network is fixed, tradeoffs exist between feature alignment and prediction power.	abstract
2020-1967	Furthermore, the authors argue that richer feature extractor can sometimes significantly overfit the source domain, leading to a large risk on the target domain.	abstract
2020-1967	Overall the paper is well-written and easy to follow.	strength
2020-1967	My major concern is that the paper, including the motivation and illustrative example, are too similar to previous work [1-2].	weakness
2020-1967	More detailed discussions are needed to highlight the difference of this work compared with [1-2].	weakness
2020-1967	The main contribution lies in Theorem 4.	strength
2020-1967	However, the upper bound is both loose and misleading.	weakness
2020-1967	Compared with the original generalization upper bound [3], the one proposed in this paper contains a constant λ that contains FOUR optimal error terms.	weakness
2020-1967	Note that the original one in [3] only contains two such terms.	weakness
2020-1967	In fact even a bound containing 2 such terms could potentially be very loose, since it's perfectly fine that a hypothesis can have large risk on the source domain while still attaining a small risk on the target domain.	weakness
2020-1967	The bound is misleading in the sense that this λ term cannot be computed or approximated, hence only the first two terms in (6) could be minimized in practice.	weakness
2020-1967	However, this again can potentially lead to large target risk when the label distributions of source and target domains differ.	weakness
2020-1967	The experiments on using different number of layers of the network as feature extractors are quite interesting.	strength
2020-1967	The main message here is that general tradeoff exists with richer encoding function class.	strength
2020-1967	However, similar phenomenons have already been observed [4, Section 6.4], and it's not clear to me what's new here.	weakness
2020-1967	[1]. On Learning Invariant Representations for Domain Adaptation, ICML 2019.	misc
2020-1967	[2]. Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment, ICML 2019.	misc
2020-1967	[3]. Analysis of representations for domain adaptation, NIPS 2007.	misc
2020-1967	[4]. A DIRT-T APPROACH TO UNSUPERVISED DOMAIN ADAPTATION, *CONF* 2018.	misc
2020-1967	This paper proposes a new theory for domain adaptation considering the complexity of representation extractors.	abstract
2020-1967	This paper gives a new bound for target error in domain adaptation, which contains the classic distribution distance related to the hypothesis space of high-level classifiers and a new distribution distance defined on the embedding space.	abstract
2020-1967	This paper also proposes Multilayer Divergence Minimization algorithm based on the theory and evaluates it on real-world dataset.	abstract
2020-1967	Positive points: (a) This paper proposes an interesting insight that the complexity of embeddings is also important in domain adaptation.	strength
2020-1967	(b) This paper defines a new distribution divergence and build an interesting theory based on it.	strength
2020-1967	(c) The proposed algorithm could automatically reach the best result of trying DANN on each layer.	strength
2020-1967	Negative points: (a) There is no proof that this new bound is better than classic domain adaptation theory (Ben-David et al., 2010).	weakness
2020-1967	Although this bound involves new insight, the novelty is limited if it is looser than existing upper bound.	weakness
2020-1967	Furthermore, there are no creative tools in the mathematical proof part, which is a direct extension of the classic theory.	weakness
2020-1967	(b) There is no analysis about the generalization when estimating this upper bound from finite samples.	weakness
2020-1967	It could be easily seen that the sample complexity of embedding complexity is at least of the same order than classic \\mathcal{H}\\Delta\\mathcal{H}-divergence (Ben-David et al., 2010).	weakness
2020-1967	(c) The analysis on the monotonicity of the divergences across the layers is very limited.	weakness
2020-1967	It will be better if there is a discussion about when the monotonicity is strict.	weakness
2020-1967	(d) What is the role of embedding complexity in the algorithm?	weakness
2020-1967	It seems that only high-level classifier divergence is minimized.	weakness
2020-1967	(e) Why minimizing the sum of divergences computed on all layers can control the proposed upper bound?	weakness
2020-1967	It seems that if the embedding complexity of each layer is a constant, minimize divergence of a single layer can further minimize the minimum.	weakness
2020-1967	Furthermore, there are previous method that minimizes divergences on all layers [A].	weakness
2020-1967	Please give a discussion on this method.	weakness
2020-1967	(f)The empirical evaluation is relatively weak.	weakness
2020-1967	There is no experiment based on convolutional networks, which are widely used on the Digit and Office-31 datasets.	weakness
2020-1967	Although the insight is interesting, the novelty of this paper is not enough for being accepted by *CONF*.	decision
2020-1967	So I vote for rejecting this submission.	decision
2020-1967	[A] Zhang, Weichen, et al. "Collaborative and adversarial network for unsupervised domain adaptation." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.	misc
2020-1967	2018. This paper studies the impact of embedding complexity on domain-invariant representations.	abstract
2020-1967	By incorporating embedding complexity into the previous upper bound explicitly, the authors demonstrate the limitations of previous theories and algorithms.	abstract
2020-1967	Based on their theoretical findings, the authors propose to control the embedding complexity with implicit regularization.	abstract
2020-1967	Specifically, aligning source and target feature distributions in multiple layers controls both embedding complexity and domain discrepancy.	abstract
2020-1967	The proposed algorithm can achieve similar performance as DANN with manual selection of embedding depth.	abstract
2020-1967	By noting that the hypothesis space can be decomposed in to the feature extractor and the classifier, the authors propose to address the domain discrepancy separately.	abstract
2020-1967	D_H\\DeltaH is termed latent divergence, which the algorithm attempts to minimize.	abstract
2020-1967	D_G\\DeltaG is treated as embedding complexity, which is the intrinsic property of the feature extractor.	abstract
2020-1967	Thus, domain-invariant representations should seek a proper tradeoff between those two terms.	abstract
2020-1967	The paper is well-written and the contributions are stated clearly.	strength
2020-1967	The exploration on the layer division is really insightful.	strength
2020-1967	However, I have several concerns: 1. The proposed upper bound is insightful, but it has several limitations.	weakness
2020-1967	Compared to the version applied to the feature space in equation (3), the proposed upper bound is looser.	weakness
2020-1967	The embedding complexity terms includes two encoders, which are deep neural networks in practice, thus it can be excessively large.	weakness
2020-1967	As the authors point out, in equation (3), the embedding complexity is not addressed explicitly, but it is implicit in the adaptability \\lambda in a more reasonable way.	weakness
2020-1967	Previous works [1], [2], [3] have already taken them into consideration.	weakness
2020-1967	Proposition 5 is a direct application of proposition 1 in [1].	weakness
2020-1967	2. On the claim of implicit regularization.	weakness
2020-1967	By applying domain adversarial training to multiple layers, the authors claim that the encoder in higher layers is implicitly restricted.	weakness
2020-1967	However, they do not validate this regularization effect.	weakness
2020-1967	Is the embedding complexity controlled?	weakness
2020-1967	Theoretical analysis or experimental results would be helpful.	weakness
2020-1967	3. The proposed MDM method seems to be incremental.	weakness
2020-1967	[4] has probed into the effect of multi-layer adaptation strategy.	misc
2020-1967	Besides, applying domain adversarial training to many layers leads to more computational cost and may slow down training significantly.	weakness
2020-1967	[1]Fredrik D Johansson, Rajesh Ranganath, and David Sontag.	misc
2020-1967	Support and invertibility in domain- invariant representations.	misc
2020-1967	arXiv preprint arXiv:1903.03448, 2019. [2]Han Zhao, Remi Tachet des Combes, Kun Zhang, and Geoffrey J Gordon.	misc
2020-1967	On learning invariant representation for domain adaptation.	misc
2020-1967	arXiv preprint arXiv:1901.09453, 2019. [3] Hong Liu, Mingsheng Long, Jianmin Wang, and Michael Jordan.	misc
2020-1967	Transferable adversarial training: A general approach to adapting deep classifiers.	misc
2020-1967	In International Conference on Machine Learning, pp.	misc
2020-1967	4013–4022, 2019. [4] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I.	misc
2020-1967	Jordan. Learning transferable features with deep adaptation networks.	misc
2020-1967	In Proceedings of the 32nd International Conference on International Conference on Machine Learning, volume 37, pp.	misc
2020-1967	97–105, 2015.	misc

2020-2012	========================= Update review After reading the authors response I would like to keep my score as is.	rebuttal_process
2020-2012	I still see many unclear statements, and most importantly I feel that more analysis of the proposed method should have been done here.	weakness
2020-2012	========================= This paper proposed a Top-Down method for neural networks training based on the good classifier hypothesis.	abstract
2020-2012	In other words, after obtaining a classifier that performs well on the test set, keep fine-tuning / re-learning the data representation.	abstract
2020-2012	The authors provide character error rate results for the task of Automatic Speech Recognition using WSJ and CHiME-4 datasets.	abstract
2020-2012	Although being an interesting research idea, several issues in this paper make it not yet ready for publication at *CONF*.	decision
2020-2012	First, the paper is poorly written; there are many claims the authors are making without providing experiments/proofs/citations.	weakness
2020-2012	For example: "...since the feature extractor learns more slowly, then potentially the classifier may overfit the feature extractor before the feature extractor is able to learn much about the underlying pattern of the data...".	weakness
2020-2012	Or: "...We suggest that the reason for this is that when all layers are trained on the noisy dataset jointly, the middle layers overfit the bottom-most layers much faster than the bottom-most layers are able to learn input features..."	weakness
2020-2012	Next, since there is no theoretical/mathematical explanation of the proposed approach, I expect the authors to run an analysis on the results to better understand the effect of using such an approach.	suggestion
2020-2012	For instance, under which settings this method is most efficient?	suggestion
2020-2012	In what layer should  I start the fine-tuning?	suggestion
2020-2012	Is it better to reinitialize the bottom layers or fine-tune them?	suggestion
2020-2012	Does the proposed approach applicable to different domains?	suggestion
2020-2012	i.e. vision/nlp/other speech/signal processing tasks?	suggestion
2020-2012	Does the proposed approach applicable to different models or only for the proposed one?	suggestion
2020-2012	Lastly, although it is not the main point in this paper since all results are reported on ASR, did the authors tried to compute WERs too?	weakness
2020-2012	That way, people can compare results with other ASR models.	weakness
2020-2012	The baseline seems relatively weak, at least in Table 1.	weakness
2020-2012	Minor comments: The complexity of the algorithm is written to be O(n).	strength
2020-2012	However, this assumes training the model takes O(1) or did I miss something?	weakness
2020-2012	Can the authors provide more details/insights regarding the delta differences in Table 1?	suggestion
2020-2012	Did the authors use the same initializations?	suggestion
2020-2012	Did the authors try different ones?	suggestion
2020-2012	This work proposed a mechanism to freeze top layers after supervised pre-training, and re-initialize and retrain the bottom layers.	abstract
2020-2012	For a model with n layers, when a separation index i is specified, the approach define layer 1~i as bottom layers and i+1~n as top layers.	abstract
2020-2012	The proposed process enumerate all i from 1 to n-1, compute resulting validation errors respectively, and then pick the i with lowest validation error.	abstract
2020-2012	The algorithm exhibited significant improvement on WSJ and some minor improvement on CHiME-4.	abstract
2020-2012	This work provides some new insight for training ASRs and the observations provide further data points for understanding the training behavior.	abstract
2020-2012	The layer freezing trick however is relatively well-known, and thus leaving the novelty of the proposed idea to be limited at what layers they choose to freeze.	weakness
2020-2012	In algorithm 1 it describes the mechanism as having two loops while it really only needs one loop.	weakness
2020-2012	The author mentioned they used a simplified version later in the text, and I'll suggest to update the algorithm block to make it clearer.	rebuttal_process
2020-2012	This paper studies the common experimental finding that low level features trained end-to-end in a deep model converge (get "locked in place") earlier than higher level features, which may result in problematic undertraining.	abstract
2020-2012	The focus of the study is not on skip connections, but really on getting adequate training in deeper networks.	abstract
2020-2012	They posit a "good classifier hypothesis" where, once a deep network converged, they fix the top layers (the "good classifier") and train only the lower ones.	abstract
2020-2012	They propose a "top-down training strategy" to search where to make the cut for the "top layers" of the "good classifier", based on the validation set.	abstract
2020-2012	(+) The experimental results seem encouraging and supporting the author's claim (consistently improve over baseline on WSJ and CHiME-4).	strength
2020-2012	(-) No WER (not even without a language model) results on WSJ make it harder to (i) compare to other work (is it just that in this case the authors didn't optimize properly in the first place?), (ii) compare the relative gains between with and without the method in WER.	weakness
2020-2012	(-) For an experimental (no theorem) optimization paper, there should be experiments on at least another domain.	weakness
2020-2012	And in particular one would have expected more analysis of the experimental optimization results.	weakness
2020-2012	(-) (minor) There is no discussion of the link with target propagation or other synthetic gradients.	weakness
2020-2012	Overall, I think this could be an interesting paper, but more work is needed to prove the effectiveness of the method, and to analyze experimentally in more details some of the claims from this paper.	weakness

2020-2088	In this paper, the authors focus on alleviating the catastrophic forgetting problem in continual learning.	abstract
2020-2088	The authors propose a discriminative variational autoencoder (DiVA) to solve this problem under the generative replay framework.	abstract
2020-2088	DiVA modifies the objective function of VAE by introducing an additional term that maximizes the mutual information between the latent variables and the class labels.	abstract
2020-2088	The authors do not thoroughly explain the motivation of this paper.	weakness
2020-2088	The authors do not explicitly define continual learning, incremental learning, and catastrophic forgetting problem.	weakness
2020-2088	It is also not clear to me why these problems are important.	weakness
2020-2088	The idea that introduces labels in VAE is not novel.	weakness
2020-2088	For example, Narayanaswamy et al. [1] also propose to utilize labels to VAE.	weakness
2020-2088	I do not understand why making use of labels is important for solving the catastrophic forgetting problem and how the labels are useful in the generative replay process.	weakness
2020-2088	It is also not clear to me how domain translation is relevant to continual learning.	weakness
2020-2088	In terms of modeling, since the input into the prior network has finite possible discrete values, we do not need a fully connected network to generate μ^c and σ^c.	weakness
2020-2088	Instead, we can directly optimize μ^c and σ^c for each c as parameters.	weakness
2020-2088	The paper provides some good experimental results.	strength
2020-2088	But the problem settings are not clear to me.	weakness
2020-2088	I do not understand how the model is trained to solve multiple tasks.	weakness
2020-2088	Do the same model is trained for multiple tasks?	weakness
2020-2088	Is each of the tasks trained sequentially or simultaneously?	weakness
2020-2088	It is also not clear to me why CIFAR datasets involve two domains and how these domains are relevant in each of the tasks.	weakness
2020-2088	In summary, since DiVA gives a good experimental performance, the proposed method might be promising.	strength
2020-2088	However, it looks to me that the authors need to better explain the motivation of DiVA, the differences of DiVA from existing supervised VAE, and the experimental settings, before the acceptance of this paper.	suggestion
2020-2088	References [1]Narayanaswamy, Siddharth, T. Brooks Paige, Jan-Willem Van de Meent, Alban Desmaison, Noah Goodman, Pushmeet Kohli, Frank Wood, and Philip Torr.	misc
2020-2088	"Learning disentangled representations with semi-supervised deep generative models." In Advances in Neural Information Processing Systems, pp.	misc
2020-2088	5925-5935. 2017. The paper devises a pipeline that aims to address catastrophic forgetting in continual learning (CL) by the well-known generative replay (GR) technique.	abstract
2020-2088	The key ingredient of the pipeline is a modern variational auto-encoder (VAE) that is trained with class labels with respect to a mutual information maximization criterion.	abstract
2020-2088	The paper does not follow a smooth story line, where an open research question is presented and a solution to this problem is developed in steps.	weakness
2020-2088	The flowchart in Fig 1 is rather a system design consisting of many components, the functionality of which is not clearly described and existence of which is not justified.	weakness
2020-2088	This complex flowchart does not even describe the complete task.	weakness
2020-2088	It is in the end plugged into a continual learning algorithm which also performs domain transformation.	weakness
2020-2088	All of these pieces are very well-known methods (e.g. VAEs, conditional VAEs, CL, catastrophic forgetting, domain transformation) in the literature and this paper puts them together in a straightforward way.	weakness
2020-2088	Hence, I kindly do not think the outcome is truly a research result.	weakness
2020-2088	It is more system engineering than science.	weakness
2020-2088	The next submission of the paper could choose one or few of these pieces as target research problems and develop a thoroughly analyzed novel technical solution for them.	suggestion
2020-2088	If this solution can be proven to improve a valuable metric (e.g. accuracy, interpretability, theoretical understanding, or computational efficiency) of a setup, it is then worthwhile being published.	suggestion
2020-2088	Minor: The abstract could be improved by providing more clear pointers to the presented novelty.	weakness
2020-2088	-- This paper seeks to combine several ideas together to propose an approach for image classification based continual learning tasks.	weakness
2020-2088	In this effort, the paper combines previously published approaches from generative modeling with VAEs, mutual information regularization and domain adaptation.	abstract
2020-2088	I am a making a recommendation for reject for this paper with the main reason being that I believe the primary derivations for their method appear flawed.	decision
2020-2088	--In the main section describing the approach (Section 4), the authors start with a claim that Equation 1 and 2 are equal; I don't believe 1 and 2 are equal.	weakness
2020-2088	--In Section 4.1, it appears that they are instead making a claim about Equation 2 being a bound for equation 1; but even this derivation appears to have a problem.	weakness
2020-2088	The following is the concern: --In the second line of Equation 5, the KL term appears to be measuring a distance between distributions on two different variables; z|c and c|z.	weakness
2020-2088	If one were to interpret the second one as the unnormalized distribution on z defined via the likelihood for c given z;	weakness
2020-2088	even this has an issue because then the expression for KL where we plug the unnormalized density in place of the normalized need not be positive which is something they need to derive their bound.	weakness
2020-2088	--Another issue is that the regularization lambda should apply to both the terms in the bound but in Equation (7) only appears selectively for one of the two terms.	weakness
2020-2088	It is also not clear how the loss function proposed differs from that of the CDVAE, etc.	weakness
2020-2088	If the novelty is in applying to continual learning and new datasets, it is not clear that this is sufficient.	weakness
2020-2088	Additional feedback for authors (not part of the main decision reasoning): - What is dt in Algorithm 1 description?	weakness
2020-2088	Figure 1: -typo "implmented" -What's the 3d plot supposed to represent?	weakness
2020-2088	Doesn't the classification loss have a dependency on the input condition?	weakness
2020-2088	--What does a "heavy classifier" imply concretely?	weakness
2020-2088	--"Redundant weights" seems like not a very strong constraint especially for a small cardinality label space (like 10, in the case of this paper).	weakness
2020-2088	--The notation for the proposed parameters theta, theta', phi, phi' are not consistent with the notation in the intro section, where phi was used for the encoder and theta for the decoder.	weakness
2020-2088	In later sections they use theta and theta' for encoder/decoder resp.	weakness
2020-2088	-- "When the encoder and decoder networks are sufficiently complex, it is enough to implement each the prior and classification network as one fully-connected layer" → what do the authors mean "when … networks are sufficiently complex" or do they actually mean when the "when the problem is simple enough"?	weakness

2020-2141	<Strengths> + This paper addresses an interesting and practically important problem: detection of piano fingering from videos and MIDI files.	strength
2020-2141	Fingering is a valuable source for piano learners and has to be manually annotated otherwise.	strength
2020-2141	The proposed approach is automatic and low-cost from playing videos.	strength
2020-2141	+ This paper collects a large-scale dataset for piano-fingering named APFD, including 90 finger-tagged pieces with 155K notes.	strength
2020-2141	+ The paper reads very well.	strength
2020-2141	<Weakness> 1. One major weakness of this work is lack of technical novelty.	weakness
2020-2141	- As described in section 3 in detail, the proposed approach consists of a sequence of well-known techniques (e.g. Faster R-CNN for hand detection and CycleGAN for finger pose estimation) and is largely based on lots of heuristics in every step of the procedure.	weakness
2020-2141	- Thus, the method may be practically viable but bear little technical novelty.	weakness
2020-2141	2. Experimental results are rather weak.	weakness
2020-2141	- Only a single baseline is used in the existing PIG dataset, while no baseline method is compared for the new APFD dataset,  for which more baselines may need to be implemented and compared.	weakness
2020-2141	- The proposed approach (64.1) is slightly worse than the previous SOTA (64.5) in the PIG dataset, although it is improved by fine-tuning with the APFD data that are not available for the previous SOTA.	weakness
2020-2141	Thus, no experimental evidence is presented in the paper to convince that the proposed approach is better than existing ones.	weakness
2020-2141	<Conclusion> Although this work is practically promising, my initial decision is 'reject' mainly due to lack of technical novelty and limited experiments.	decision
2020-2141	The paper is a nice piece of works which clearly articulates the objective and the subsequent discussion.	strength
2020-2141	The focus of the paper--i.e. disclose the difficulties of piano fingering data annotation and the proposal of automating this process by automatically extracting fingerings from public videos and MIDI files, using  computer-vision DNN-based algorithms —although not really mainstream, it does provide some practical insights using a couple of experimental settings (piano fingering model and prediction) to help the readers.	strength
2020-2141	I really enjoyed reading this paper.	misc
2020-2141	I think that it can be considered a relevant and interesting piece of work, very well written and clear.	strength
2020-2141	Furthermore, providing new benchmarks/datasets/competitions for the AI community is always refreshing.	strength
2020-2141	Also, the results seem believable and solid, and potentially useful.	strength
2020-2141	My only concern is that, although the rationale and utility of the paper is clear, the rest of the paper is somewhat incremental/engineering piece which depends somehow on previous works (see Nakamura,2019).	weakness
2020-2141	I fail to see much novel scientific contribution to the area of research (apart from the dataset) and I'm not sure whether there are enough scientific technical advancements.	weakness
2020-2141	Furthermore, the experimental setting is somewhat limited, and it is not clear whether results are statistically significant.	weakness
2020-2141	In this paper, the authors proposed an automatic piano fingering algorithm, that accepts YouTube videos and corresponding MIDI files and outputs fingering prediction for each note.	abstract
2020-2141	The claimed contribution is two-fold: First, they proposed the algorithm, and second, they claim that the algorithm can be used to automatically generate large datasets for piano fingering problems.	abstract
2020-2141	The motivation is clearly stated and convincing.	strength
2020-2141	The overall algorithm is mainly described.	strength
2020-2141	However, I would like to reject this paper.	decision
2020-2141	Major issues: * Some key information is missing in Section 3.6, which is the only section that shows technical details: What is X_{n_k}?	weakness
2020-2141	How is that related to the estimated finger poses?	weakness
2020-2141	What is the function f in the definition of function g?	weakness
2020-2141	(Also, it would be helpful to label the equations for clarification.) Are you doing Bayesian inference?	weakness
2020-2141	With the key information missing, it is hard to fully understand the remaining technical details in this section.	weakness
2020-2141	* Their experimental results cannot properly support their claims.	weakness
2020-2141	In Section 4.2, the authors try to show the strength of their proposed piano fingering algorithm by comparing their automatically annotated dataset APFD with an existing manually annotated dataset PIG.	abstract
2020-2141	The authors showed the evaluation results of models trained and fine-tuned with different datasets.	abstract
2020-2141	However, this is not an acceptable comparison for me, due to several reasons.	weakness
2020-2141	First, in order to show the strength of automatic piano fingering prediction, it is much better to directly run the prediction algorithm on datasets with known labels.	suggestion
2020-2141	According to the related work section, there is at least one existing work by Takegawa et al. that uses videos and MIDI files to detect piano fingering.	weakness
2020-2141	Can you compare your algorithm with theirs?	weakness
2020-2141	Second, it is essentially unreliable to compare two datasets by comparing the performance of two prediction models, as there are too many implementation details that are almost impossible to control.	weakness
2020-2141	Third, it is not clear how we should compare the testing errors in Table 2.	weakness
2020-2141	Yes, a model initially trained on PIG and fine-tuned on APFD may perform better than a model trained merely on APFD, but does that suggest anything (and the advantage is just 0.4%)?	weakness
2020-2141	Similarly, the experimental result that an MLP model initially trained on APFD then fine-tuned with PIG works better than an HMM model that is trained with PIG data alone cannot prove anything.	weakness
2020-2141	There are too many possible reasons that may lead to this experimental result.	weakness
2020-2141	* How is this method more attractable than the existing ones?	weakness
2020-2141	There are neither experimental comparisons nor high-level justifications of why the existing algorithms are not applicable to the given scenario.	weakness
2020-2141	In Section 2, although the authors described a good number of existing work on piano-fingering and their drawbacks, they failed to point out the strength of their paper as a comparison.	weakness
2020-2141	As a result, the strength of this paper is still unclear after reading this section.	weakness
2020-2141	How does this paper avoid the drawbacks of these previous papers?	weakness
2020-2141	* The writing of this paper needs to be greatly improved.	weakness
2020-2141	It takes a lot of effort to literally understand this paper: There may be missing parts, misplaced clauses, and broken logic between sentences.	weakness
2020-2141	I have listed several examples in the minor issues part.	misc
2020-2141	Minor issues: * In the first paragraph of Section 1: The sentence before 'In practice ...' is incomplete.	weakness
2020-2141	* In the last paragraph of Section 1: Missing brackets for \\textsection 3.3 and \\textsection 3.4.	weakness
2020-2141	Also, 'on A new dataset we introduce' should be 'on THE new dataset we introduce'.	weakness
2020-2141	* On page 3, the sentence 'In this work, we continue the transition of search-based methods that optimize a set of constraints with learning methods that ...' is not making sense to me.	weakness
2020-2141	Do you mean that your work is an extension of search-based methods, or do you mean that your work is not a search-based method?	weakness
2020-2141	Also, are you optimizing a set of constraints, or optimizing with a set of constraints?	weakness
2020-2141	* On page 3, the last sentence in Section 2: '...	weakness
2020-2141	and adapt their model to compare TO our ...' should be '...	weakness
2020-2141	and adapt their model to compare WITH our ...'.	weakness
2020-2141	The last part of this sentence is also a bit confusing: How do you compare a model with a dataset?	weakness
2020-2141	* On page 4, the paragraph starting with 'MIDI files': The first two sentences are almost the same; the period between them is missing.	weakness
2020-2141	I guess one of them should be deleted.	suggestion
2020-2141	The following sentences in this paragraph are also subject to grammatical errors.	weakness
2020-2141	For example, the sentence 'It consists of a sequence of events ...	weakness
2020-2141	to carry out, WHEN, and allows for ...' is not a complete sentence.	weakness
2020-2141	'We only use videos that come along with a MIDI file' -> 'We only use videos that come along with MIDI files'.	weakness
2020-2141	* On page 5, last paragraph in Section 3.3: 'highest probability defections' -> 'highest probability detections'.	weakness
2020-2141	* The last paragraph on Page 5: 'Using off-the-shelve ...' -> 'Use off-the-shelf ...'.	weakness
2020-2141	* In Section 4.2.1, the corresponding result is Table 2, instead of Table 1.	weakness

2020-2192	Summary ======== This paper proposes a framework for privacy-preserving training of neural networks, by leveraging trusted execution environments and untrusted GPU accelerators.	abstract
2020-2192	The system builds heavily on the prior Slalom system, and uses standard MPC techniques (three non-colluding servers, multiplication triplets) to extend Slalom's inference-only protocol to privacy-preserving training.	abstract
2020-2192	This is a valuable and hard to reach goal.	abstract
2020-2192	Unfortunately, the paper's evaluation fails to deliver on its strong promises, by ignoring the high network communication between the non-colluding servers.	weakness
2020-2192	Specifically, all experiments were conducted with three servers co-located in a public cloud's LAN.	weakness
2020-2192	In this setting, it is hard to argue that non-collusion is a valid security assumption as the cloud provider controls all servers (alternatively, if the cloud provider is trusted, then there is no need for any trusted execution or cryptography).	weakness
2020-2192	If the same experiments were conducted on a WAN, the communication costs would alleviate any savings in computation time.	weakness
2020-2192	For these reasons, I lean strongly towards rejection of this paper.	decision
2020-2192	Detailed comments ================= Extending the ideas in Slalom to support privacy-preserving training is a good research question, and Tramer and Boneh had discussed some of the challenges and limitations towards this in their original paper.	strength
2020-2192	Getting rid of the pre-processing stage for blinding factors by leveraging non-colluding servers is a well-known trick from the MPC literature, but it does not seem easily applicable here.	weakness
2020-2192	The problem is that the servers need to communicate an amount of data proportional to the size of each internal layer of the network, for each forward and backward pass.	weakness
2020-2192	If the servers communicate over a standard WAN, the communication time will be much too high to be competitive with the CaffeScone baseline.	weakness
2020-2192	In a LAN, as in this paper's experiments, the network latency is low enough for the network costs to be dominated by computation.	weakness
2020-2192	But this begs the question of whether servers running in a same LAN (e.g., hosted by a single cloud provider) can really be considered non-colluding.	weakness
2020-2192	In the considered setup, the cloud provider (Google in this case), could just observe the communication between all servers, thereby breaking privacy.	weakness
2020-2192	Another security issue with proposed scheme is the lack of computation integrity.	weakness
2020-2192	This corresponds to the so-called "honest-but-curious" threat model which often appears in the MPC literature, and this should be acknowledged and motivated.	weakness
2020-2192	On the experimental side, the considered baseline, CaffeScone, seems pretty weak.	weakness
2020-2192	In particular, any optimizations that the authors implement for Goten (e.g., better paging) should also be added to their baseline for a fair comparison.	suggestion
2020-2192	The numbers in Figure 3 show that the baseline could be optimized a lot further.	weakness
2020-2192	A gap between hardware/simulation modes of ~6x seems indicative of sub-optimal paging.	weakness
2020-2192	Even the single-core, simulation mode throughput numbers seem low for CIFAR10.	weakness
2020-2192	The experimental setup is quite confusing.	weakness
2020-2192	Running the baseline and Goten in different environments (e.g., different CPUs) and then re-normalizing throughputs is somewhat convoluted and prone to mistakes.	weakness
2020-2192	Why not run all experiments on the same setup?	weakness
2020-2192	Similarly, converting between results in SGX's hardware and simulation modes is also not very indicative.	weakness
2020-2192	The authors note (p. 8) that in SGX's simulation mode "code compilation is almost the same as hardware mode except that the program is not protected by SGX, which is fine for our purpose since the DNN training and prediction algorithms are publicly known".	weakness
2020-2192	This is fundamentally incorrect! SGX's simulation mode provides absolutely no security guarantees.	weakness
2020-2192	It simply compiles the code using the SGX libraries and ensures that the enclaved code performs no untrusted operations, but it does not provide any hardware protections whatsoever.	weakness
2020-2192	In particular, code running in simulation mode will not be affected by the overhead of SGX's paging, as the memory is never encrypted.	weakness
2020-2192	As a result, performance results in simulation mode are usually not indicative of performance in hardware mode.	weakness
2020-2192	Trying to convert runtimes from simulation mode to hardware mode by comparing times of specific layers is also prone to many approximation errors.	weakness
2020-2192	Finally, I had some trouble understanding the way in which Goten quantization works.	weakness
2020-2192	Section 3.3. mentions that values are treated as floats, but then mentions the use of 53 bits of precision.	weakness
2020-2192	Did you mean double-precision floats here?	weakness
2020-2192	But then, aren't modern GPU optimized mainly for single-precision float operations?	weakness
2020-2192	Section 3.3. also says that the quantization ensures that there are nearly no overflows.	weakness
2020-2192	What happens when an overflow occurs?	weakness
2020-2192	I guess that because of the randomized blinding, a single overflow would result in a completely random output.	weakness
2020-2192	How do you deal with this during training?	weakness
2020-2192	Minor ===== - Typo in abstract: Slaom -> Slalom	weakness
2020-2192	- I don't understand the purpose of footnote 3 in Appendix B.2.	weakness
2020-2192	First, the bibliographic entry for (Volos et al. 2018) explicitly says that the paper was published in OSDI 2018, a top-tier peer-reviewed conference.	weakness
2020-2192	Regardless, claiming a date for a first unpublished draft of your paper is a little unusual and somewhat meaningless.	weakness
2020-2192	I'm sure Volos et al. had a draft of their paper ready in late 2017 or even earlier if they submitted to OSDI in XXX 2018.	misc
2020-2192	If you want to timestamp your paper, post in to arXiv or elsewhere online.	suggestion
2020-2192	The paper proposes a method for privacy-preserving training and evaluation of DNNs.	abstract
2020-2192	The method is based on a combination of hardware support from a trusted execution enclave (Intel SGX) and an algorithm for offloading intensive computation to unsecure GPU devices and communicating with the trusted environment without losing security guarantees during communication.	abstract
2020-2192	Compared to related work on a similar system (Slalom), the proposed system enables secure training in addition to inference.	abstract
2020-2192	The approach is based on the use of additive secret sharing to relegate chunks of computation to independent GPU servers.	abstract
2020-2192	The evaluation presents experiments that report timings of the proposed system against a baseline.	abstract
2020-2192	Throughput (images/second) improvements of 8-9x are reported, but the contrast point is unclear (it appears to be CaffeSCONE, but there are several unclear points, summarized below).	weakness
2020-2192	In addition, a set of results reporting a speed up ratio against attained accuracy of a trained VGG11 network, and a set of results reporting speed up against arithmetic intensity of the workload are given.	abstract
2020-2192	I lean towards rejection of this draft, as it has several weaknesses: - The connection between the evaluation (which mostly focuses on the speed benefits) and the claimed contributions is tenuous at best.	decision
2020-2192	This issue is further compounded by clarity issues in the experiments and their description	weakness
2020-2192	- The empirical results are unclear due to differences between simulation of SGX capability vs hardware support of SGX capability.	weakness
2020-2192	It is not clear what part of the results is influenced significantly by this disparity, and more importantly whether all the comparisons are done in an equal footing (for example the reported results comparing CaffeSCONE with Goten are performed in two different regimes).	weakness
2020-2192	As a byproduct, there is a confusing "scaling factor" described by the authors that is applied to the timings.	weakness
2020-2192	- A brief mention is made of the fact that the proposed system does not in fact provide correctness guarantees (unlike CaffeSCONE), but this is dismissed by reference to utilizing the same trick used by Slalom.	weakness
2020-2192	However, this trick is not described or motivated.	weakness
2020-2192	- The writing in the current draft is of relatively low quality, significantly impacting the readability of the paper and making it hard to understand the contributions and whether they are backed by the presented results.	weakness
2020-2192	The paper builds a privacy-preserving training framework within a Trusted Execution Environment (TEE) such as Intel SGX.	abstract
2020-2192	The work is heavily inspired from Slalom, which does privacy-preserving inference in TEEs.	abstract
2020-2192	The main drawbacks of Slalom when extending to training are	weakness
2020-2192	(1) weight quantization needs to be dynamics as they change during training, and	weakness
2020-2192	(2) pre-processing step of Slalom to compare u = f(r) isn't effective as the weights change, and running this within TEE is no better than running the full DNN within TEE.	weakness
2020-2192	In addition, Goten also makes the weights private as opposed to Slalom.	weakness
2020-2192	Overall, this is a very important contribution towards privacy preserving training and the paper takes a strong practical and implementation-focused approach by considering issues arising due to memory limitations in TEE and the performance implications of default Linux paging.	strength
2020-2192	The paper comes up with a novel outsourcing protocol with two non-colluding servers for offloading linear operations in a fully privacy-preserving way and does detailed analysis of the performance implications.	abstract
2020-2192	Similar to a lot of other methods for training with quantization, the weights are stored and updated in floats while the computation is performed using quantized values.	abstract
2020-2192	The experimental results suggest a strong improvement over the CaffeSCONE baseline.	abstract
2020-2192	One drawback with experiments is the lack of comparison with Slalom for inference if Goten is assumed to be a framework for both training and prediction in a privacy-preserving way.	weakness
2020-2192	Another downside of the paper is that a few sections could be improved with their explanation, and there is quite a bit of redundancy in going over the downsides of Slalom and why it can't be used for secure training.	weakness
2020-2192	For instance, - Section 1.1: "Our results (referring to Section 4.2) show that CaffeSCONE's performance greatly suffer from the enclave's memory limit as it needs an inefficient mechanism to handle excessive use of memory not affordable by the enclave".	weakness
2020-2192	Here, it's not clear which mechanism is inefficient.	weakness
2020-2192	Are we talking about mechanisms in CaffeSCONE for reducing memory usage while training and if so, are they somehow inefficient?	weakness
2020-2192	Or does it mean to imply that we can't train a DNN fully within an enclave due to memory limits?	weakness
2020-2192	-  Last paragraph of section 2.2 is unclear.	weakness
2020-2192	"CaffeSCONE guarantees the correctness of both training and prediction.	weakness
2020-2192	Goten does not provide it as we present it due to page limitation, but we can resort to the trick used by Slalom".	weakness
2020-2192	What does the last sentence mean?	weakness
2020-2192	Does Goten guarantee correctness during training and prediction or not?	weakness
2020-2192	And what trick from Slalom are we referring to?	weakness
2020-2192	The blinding trick used for privacy or the Freivalds' algorithm used for correctness?	weakness
2020-2192	Overall a strong contribution with supporting experimental results, but the certain parts need further explanation or rewriting for higher rating.	weakness
2020-2192	Pros: - An important contribution in the direction of fully private DNN training and inference within a TEE.	strength
2020-2192	Draws inspirations from Slalom and mainly addresses the challenges left to extend the approach to training.	strength
2020-2192	- Motivation and reasons for why Slalom can't be used for training is very well laid out.	weakness
2020-2192	- In addition to input and output activations, Goten also preserves the privacy of the weights.	strength
2020-2192	- Good baseline for comparison using CaffeSCONE.	strength
2020-2192	- Implementation factors considered and analyzed such as tricks as using SGX-aware paging instead of naive Linux paging.	strength
2020-2192	- Strong experiments and benchmarks	strength
2020-2192	Cons: - Some sections are not explained well and unclear as mentioned earlier.	weakness
2020-2192	- How does the inference performance of Goten compare to Slalom given the same privacy and correctness guarantees?	weakness
2020-2192	This isn't clear from the experiments section.	weakness
2020-2192	Minor comments: - "Slalom" is mis-spelt in line 4 of the abstract.	weakness
2020-2192	- There appear to be typos and grammatical errors at many places in the paper.	weakness
2020-2192	Further proof-reading might be helpful.	weakness

2020-2194	This paper introduces a weakly supervised learning approach for trajectory segmentation, which relies on coarse labelling about the occurrence of a skill in a demonstration to segment trajectories.	abstract
2020-2194	This is accomplished through a recurrent model predicting skill categories for each step in a trajectory, and a trajectory level loss function that penalises the probability of seeing a given skill in a trajectory.	abstract
2020-2194	Overall, I like the idea of identifying skills in this manner, and think that this is an important problem to address.	strength
2020-2194	However, I have concerns about it's feasibility when a large number of skills are present.	weakness
2020-2194	It seems that there are certain requirements of skill occurrences in datasets that need to be met if this approach is to be feasible.	weakness
2020-2194	For example, consider the dataset of skill sequences: [111 222 333] [444 222 333] [222 333 555]	weakness
2020-2194	It seems that it will never be possible to learn to identify skills 2 and 3 from this dataset.	weakness
2020-2194	This paper would be greatly strengthened if the minimum dataset requirements to learn all skills were enumerated, or some theoretical bounds provided around when this loose labelling could possibly be successful provided.	suggestion
2020-2194	The paper glosses over this point by suggesting that "data" makes this a non-issue, but the paper would be much stronger if these limitations were confronted and some bounds on the chances of meeting the requirements needed for learning provided.	weakness
2020-2194	The classification results seem extremely poor, and it is hard to assess these on the basis of accuracy alone.	weakness
2020-2194	For example, in the Robosuit example, the test results could potentially have been obtained by simply making the same prediction throughout the test, and there is no indication that anything sensible was actually learned.	weakness
2020-2194	Confusion matrices, or precision and recall metrics, are required to avoid this.	weakness
2020-2194	At present it is impossible to know if these errors are due to noisy predictions, the dataset limitations described above, or simply a poor classifier.	weakness
2020-2194	Along these lines, qualitative results in the form of trajectory classification (say following the presentation conventions in	weakness
2020-2194	Bolanos, 15, https://arxiv.org/pdf/1505.01130.pdf Ranchod, 15, https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7353414&tag=1	misc
2020-2194	would also help to address these concerns.	suggestion
2020-2194	A question regarding the dial jaco videos experiments, why does the classifier not predict a 5 when moving from 4 to 6?	weakness
2020-2194	I would expect a very jumpy prediction here, but the prediction looks very smooth - is this a filtered result?	weakness
2020-2194	Finally, baseline experiments are limited to other weakly supervised learning segmentation approaches,  but I think comparisons with unsupervised clustering methods would also be useful.	weakness
2020-2194	Unfortunately, due to the lack of evidence that the proposed approach is able to learn effectively, I am inclined to reject this paper.	decision
2020-2194	Clarifying the bounds, and presenting stronger evidence (beyond accuracy) would make this paper stronger.	suggestion
2020-2194	This paper tackles the problem of learning to label individual timesteps of sequential data, when given labels only for the sequence as a whole.	abstract
2020-2194	The authors take an approach derived from the multiple-instance learning (MIL) literature that involves pooling the per-timestep predictions into a sequence-level prediction and to learn the per-timestep predictions without having explicit labels.	abstract
2020-2194	They evaluate several pooling techniques and conclude that the log-sum-exp pooling approach is superior.	abstract
2020-2194	The learned segmentations are used to train policies for multiple control skills, and these are used to solve hierarchical control tasks where the correct skill sequence is known.	abstract
2020-2194	This is a good application of the MIL approach.	abstract
2020-2194	However, I have settled on a weak reject because in my view, the novelty and results are minor.	decision
2020-2194	The main point of comparison is the log-sum-exp() pooling as compared to max() and neighborhood-max() pooling.	weakness
2020-2194	However, if I understand correctly, the log-sum-exp() approach has been used successfully in several other domains including its original domain of semantic image segmentation.	strength
2020-2194	So I view the novelty of the approach to be fairly low.	weakness
2020-2194	In addition, although the superior pooling method (which already exists in the literature) does outperform the alternatives evaluated here, the results are somewhat underwhelming, at only ~35-60% validation accuracy.	weakness
2020-2194	How does this compare to a fully-supervised oracle method trained with per-timestep labels?	weakness
2020-2194	The behavioral cloning results are also fairly underwhelming, and the experiments are not very clearly described.	weakness
2020-2194	Am I correct in my understanding that the learned skills are composed to solve a task where the correct sequence of skills is known, but is longer than the training sequences?	weakness
2020-2194	A success rate of 50% on this task seems rather low.	weakness
2020-2194	How does this compare, as above, to a fully-supervised oracle baseline?	weakness
2020-2194	Why is there no success rate reported for the CCNN baseline?	weakness
2020-2194	I think this is a good application of weakly-supervised MIL, but I find the specific contributions to be lacking in novelty and impressiveness of results.	weakness
2020-2194	There are several directions that I think could improve the work: - oracle fully-supervised results, to indicate the gap between the fully- and weakly-supervised case	suggestion
2020-2194	- more thorough baselines on the behavior task, such as Policy Sketches [1]	suggestion
2020-2194	- perhaps the temporal aspect of the problem could be incorporated into the pooling approach more directly to produce a more novel algorithmic contribution	suggestion
2020-2194	[1] Andreas, Jacob, Dan Klein, and Sergey Levine.	misc
2020-2194	"Modular multitask reinforcement learning with policy sketches." Proceedings of the 34th International Conference on Machine Learning-Volume 70.	misc
2020-2194	JMLR. org, 2017. The paper presents a weakly supervised method for segmentation of trajectories into sub-skills inspired by multi-instance learning (MIL) in image classification by Andrews et al. (2002).	abstract
2020-2194	This is done via training a classifier to label each observation per time-step with the probability of skills corresponding to that observation.	abstract
2020-2194	These predictions are then accumulated throughout the trajectory to compute the probability of the skill in that trajectory.	abstract
2020-2194	There is only a trajectory level supervision provided which specifies which skills are present with no specification of the order in which they appear.	abstract
2020-2194	They empirically show that their model can achieve decent skill level classification scores on multiple environments provided that there is a large variety of demonstrations provided.	abstract
2020-2194	In its current form, I would recommend this paper to be rejected because	decision
2020-2194	1) the framing and motivation of the paper does not correspond to the results and experiments reported and hence seems misleading	weakness
2020-2194	2) the paper is limited in scope	weakness
2020-2194	3) further experiments and comparisons to relevant baselines are needed to support the claims made in the paper.	weakness
2020-2194	The problem that they are proposing is interesting and is of clear value, however, the paper falls short in addressing this problem.	weakness
2020-2194	In particular, the paper is framed as a way to learn re-usable useful sub-skills that can help generalize to new situations in control.	weakness
2020-2194	However, the method presented provides a per time-step labelling of each observation with the associated most likely sub-skill.	weakness
2020-2194	Having the per time-step labelling of the trajectory provides no indication that the data could be useful for learning reusable skills for downstream tasks later.	weakness
2020-2194	One very basic experiment could be to train a behaviour cloning (BC) agent on the observation-action pairs conditioned on the sub-skill (or a separate network per sub-skill) and show that the learned policies can be leveraged in solving the tasks presented.	suggestion
2020-2194	For instance, one can train a meta-controller that can switch between these learned sub-skills to successfully perform the task.	suggestion
2020-2194	Training such sub-skills from weakly supervised skill annotations has been successfully done by Shiarlis et al. (2018).	suggestion
2020-2194	It should be noted that in their setting, the annotations are ordered which simplifies the problem to some extent.	strength
2020-2194	Ignoring the motivation and focusing only on the problem setting addressed which is annotation of trajectories with skill labels, the experiments seem very restrictive to me.	weakness
2020-2194	To my understanding there are at most 4-6 primitive skills present in each environment investigated.	weakness
2020-2194	Looking at the videos linked, it feels like there is some overfitting to the trajectories provided as for example in the case of the video with the red bowl (Reach and Stir inside Cup), the classifier is predicting 'Stirring' from the first frames where there is not much information present in the scene and 'reach to object' could also be plausible for example.	weakness
2020-2194	It would have been nice to see the logits of predictions per classes for these examples to understand the confidence of the model particularly when some of the skills could be equally likely (e.g. first few frames).	suggestion
2020-2194	I found the experimental setup unclear.	weakness
2020-2194	Particularly, details regarding the task setup, how many demonstrations are needed per task/skill, architectural choices and hyper-parameters are lacking and makes experiments hard to follow and understand.	weakness
2020-2194	I would have also liked to see more analysis regarding the segmented trajectories, particularly how consistent these predictions are through time.	suggestion
2020-2194	To my understanding there is nothing that keeps a skill annotation consistent over some period of time (e.g. the model could keep switching its prediction every time-step).	weakness
2020-2194	This would be quite unsatisfactory if one would like to use this to actually segment sub-trajectories associated with a given skill that could be useful for training policies.	weakness
2020-2194	They report applying Gaussian smoothing to filter out noisy predictions but there are no details provided on how this is tuned and how much this affects the quality of segmentations.	weakness
2020-2194	Overall, the paper seems to me very limited in its scope and experimental results.	weakness
2020-2194	The claims made throughout the paper are not supported empirically or theoretically.	weakness
2020-2194	There is not enough evidence for me to assess the significance of the proposed method and know whether this is indeed useful in practice.	weakness

2020-2209	Comments: -This paper considers codeswitched hate speech texts from an NLP perspective.	strength
2020-2209	The dataset considers mixed languages.	strength
2020-2209	-Focuses on kenyan presidential election.	strength
2020-2209	-Paper has severe formatting issues as well as simple issues like capitalization.	weakness
2020-2209	Additionally many plots are rather unattractive (seem to be produced using Excel or Google Sheets, whereas generally something like matplotlib or seaborn is preferred).	weakness
2020-2209	-The paper puts a lot of examples into the main text, whereas these are usually put into the appendix, or only a few examples are placed in the main text.	weakness
2020-2209	Usually the main text focuses more on higher level analysis.	weakness
2020-2209	-Figure 2 is formatted incorrectly (the caption runs on to the next page)	weakness
2020-2209	-I appreciate the effort that went into data annotation as well as the disclosure of the demographics of annotators.	weakness
2020-2209	-Table 1 should make the metric much clearer (it's mentioned in the main text, but it should be in the caption too, also the best performance usually should be bolded)!	weakness
2020-2209	Generally TF-idf features or PDC features seem to have the best performance.	weakness
2020-2209	The performance of the CNN does not seem very strong.	weakness
2020-2209	I think a simple RNN based approach might also be worth considering.	weakness
2020-2209	It would also be worth analyzing if the differences between the methods is attributable to underfitting or overfitting.	weakness
2020-2209	-If the paper is proposing a new task with many baselines, it's also important to release the dataset and code in my opinion (I believe *CONF* allows this to be done in a de-anonymized way).	weakness
2020-2209	Review: This paper deals with an important problem in social media analysis.	abstract
2020-2209	With the spread of hate speech and hate crimes by rioting separatists in Hong Kong as well as equally hateful attacks on Chinese people in the west, I think that this is an issue that deserves more attention in our community.	weakness
2020-2209	Unfortunately this paper needs more polish to be appropriate for *CONF*.	decision
2020-2209	It also might be better suited to an NLP focused conference (such as ACL, EMNLP, or NAACL) although I think if the technical contribution is clear enough it could be suitable for *CONF* as well.	decision
2020-2209	I think the big things to focus on would be including more baselines, improving polish in the paper, and providing a clearer high-level analysis of the dataset (with specific examples mostly left for the appendix).	suggestion
2020-2209	This paper compared several classification methods, including deep neural networks (DNN), to identify hate speech texts.	abstract
2020-2209	Mainly the data was corrected from twitter.	abstract
2020-2209	The data was prepossessed to deal with by popular classification methods.	abstract
2020-2209	The LDA and PDA are used to construct the identifier with high accuracy.	abstract
2020-2209	Finally, Practical data was used to assess the performance of several machine learning algorithms.	abstract
2020-2209	The research topic is important from the sociological viewpoint.	strength
2020-2209	I'm not sure whether this paper suits to the publication from ICRL.	decision
2020-2209	Besides that, the authors did not show any technical insight into the numerical results.	weakness
2020-2209	That is, can the authors explain the reason why the linear logistic regression with TF-IDF features outperformed all the other methods?	suggestion
2020-2209	Overall, this paper did not provide any useful knowledge, while this paper introduced some statistical methods and showed numerical results.	weakness
2020-2209	I recommend the authors to add more beneficial insight and to submit the paper to other conferences that deals with sociological issues.	decision
2020-2209	I'm sorry to say that this paper is not ready for publication.	decision
2020-2209	I think it's an important area and the dataset collected could be quite valuable for tackling hate speech.	strength
2020-2209	The paper does not follow the style guide, is full of typos or 'kkkkk' tokens indicating missing values.	weakness
2020-2209	The first sentence of the abstract is not grammatical.	weakness
2020-2209	Codeswitched needs to be mentioned more specifically in the introduction.	weakness
2020-2209	I couldn't easily find statistics about the dataset, especially in terms of language breakdown.	weakness
2020-2209	How many of the tweets were multi-lingual?	weakness
2020-2209	For pure-english tweets, I would be interested in this dataset being split out as a sub-dataset, as I would heavily bet the sota method for classifying hate-speech would be to fine-tune a BERT model on these labels.	weakness
2020-2209	We need a table of dataset statistics.	weakness
2020-2209	We need a mathematical definition of PDC that is made very explicit in the paper, there is too much prose, I did not have time to do the background reading of the linked papers to understand this sociological theory of hate speech.	weakness
2020-2209	The paper did not feel sufficiently anonymized.	weakness
2020-2209	I would anonymize the university used to create the dataset and the funding agencies that supported the research in subsequent submissions.	weakness

2021-1214	The paper proposes to theoretically analyze whether self-supervised learning can help FSL.	abstract
2021-1214	Under simplified assumptions (a simple mean classifier is used; training data is balanced; and a particular form of loss is used), the main result in Theorem 1 shows that self-supervised training loss is an upper bound of the supervised metric loss function.	abstract
2021-1214	The idea is interesting and inspiring.	strength
2021-1214	However, the analysis is less satisfactory.	weakness
2021-1214	The main concern is that Theorem 1 and 2 are quite loose.	weakness
2021-1214	They only apply for the so-called  supervised metric loss function.	weakness
2021-1214	Is it work for any fk and fq?	weakness
2021-1214	Can you provide more strict error bound to quantify the difference?	weakness
2021-1214	As said in the paper, "γ0, δ are constants depending on the class distribution ρ", then how to estimate γ0, δ?	weakness
2021-1214	If they cannot be estimated, why we need this theory?	weakness
2021-1214	How to link this theory to the success of self-supervised learning in solving FSL problem?	weakness
2021-1214	Or can this theory be validated empirically?	weakness
2021-1214	I think this paper indeed proposes an interesting direction to explore.	strength
2021-1214	But without answering the above questions, the current version is not complete enough to be published.	decision
2021-1214	=== During discussion period, I noticed import missing references of this paper as written by Nikunj Saunshi.	weakness
2021-1214	Besides, the authors do not respond to any of the reviewers' questions.	rebuttal_process
2021-1214	Hence I change my score to strong rejection.	rebuttal_process
2021-1214	* Key idea justification *	rebuttal_process
2021-1214	This work shows that contrastive loss (for self-supervised learning) is an upper bound of cross-entropy loss (for supervised learning) and leads to a conclusion that this is the underlying reason why self-supervised learning can help supervised learning in FSL.	abstract
2021-1214	This reasoning makes little sense with little logic.	weakness
2021-1214	Concretely, there exist a number of to-be-answered questions before connecting the two things and making theoretical conclusion: Why we need to know the upper bound of supervised learning loss given that we already have label data with the training data?	weakness
2021-1214	Decreasing SSL loss does not necessarily mean that supervised learning loss is also decreased, as it is just an upper bound.	weakness
2021-1214	No guarantee there. Assume SSL helps decrease the supervised learning loss, then why is this needed when we can simply use class labels to minimize it?	weakness
2021-1214	Intuitively, the two are overlapping and SSL should be not useful.	weakness
2021-1214	Besides, this paper only considers the case of contrastive loss which involves false negative samples.	weakness
2021-1214	What if applying other SSL loss function, for example rotation?	weakness
2021-1214	I do see the same analysis applies to that.	weakness
2021-1214	In conclusion, the proposed theory makes little sense and is also over-claimed.	weakness
2021-1214	The whole study is neither theoretical nor logical.	weakness
2021-1214	* Presentation clarity * In general, the presentation of this paper is poor.	weakness
2021-1214	One reason is using odd/strange terminologies and equation expressions.	weakness
2021-1214	For example, contrastive loss (Eq 1) and cross-entropy loss (Eq 3) both are not given in their common expression.	weakness
2021-1214	Other examples are "Supervised Metric for Representations" and "Self-Supervised Metric (SSM) for Representations", "a metric loss", etc.	weakness
2021-1214	Quite a few equations are hard to read and understand.	weakness
2021-1214	First, Eq (1) and (3) are not expressed in a standard way.	weakness
2021-1214	How are they derived? What is the difference between a class-wise prototype pc and an episodic mean of support samples (At the end of Sec 3).	weakness
2021-1214	What means by "the class distribution ρ is uniform" in the proof of Theorem 2?	weakness
2021-1214	What is implied by the last sentence of Sec 4: Theoretically, if given an unsupervised set with infinite classes and data, the performance achieved by SSM can be very close to that by supervised training?	weakness
2021-1214	* Grammatical errors * a episodic -> an episodic This paper performs theoretical analysis of the relationship between supervised learning (SL) and self-supervised learning (SSL) in the context of few-shot learning (FSL).	abstract
2021-1214	It aims to quantify the gap in training loss between SL and contrastive SSL on FSL tasks by casting SSL as an SL problem.	abstract
2021-1214	Using this formulation, the authors show that the self-supervised training loss is an upper bound of the supervised metric loss function, implying that if you reduce the self-supervision loss to be small enough, you can control the model's supervision loss on the training data, and thus improve results on the downstream FSL tasks.	abstract
2021-1214	The theoretical formulation also provides guidelines for the optimal values for the queue size in contrastive SSL, which the authors evaluate on omniglot and miniImageNet datasets, showing that the test performance varies with queue size.	abstract
2021-1214	Strengths: The motivation to perform theoretical analysis on the utility of SSL for few-shot learning is a good one.	strength
2021-1214	While I could not check the proofs thoroughly, they seem to provide a nice framework for explaining why SSL might provide good performance on few-shot learning.	strength
2021-1214	Weaknesses and suggestions: 1. The paper is very difficult to follow.	weakness
2021-1214	While the theory section (Section 4) is reasonably well-written, the rest of the paper needs a substantial rewrite to improve clarity and accessibility.	weakness
2021-1214	Unfortunately the writing quality makes it difficult  to make a strong case for the paper.	weakness
2021-1214	2. The experiments only touch upon one aspect of theory discussed in the paper -- the impact of N and M on test performance.	weakness
2021-1214	A more  thorough comparison with SL based few-shot learning and the impact of other factors like number of classes and class imbalance on test performance would make the paper stronger.	suggestion
2021-1214	The paper establishes a relationship between self-supervised learning (SSL) and supervised few-shot learning (FSL) method and shows that when both are equivalent.	abstract
2021-1214	The whole analysis and proof are based upon the two main assumptions: mean classifier and balanced class training data.	abstract
2021-1214	The paper shows that if we have a too large number of classes in the SSL, then it is equivalent to the supervised learning scenario and model enjoy the same generalization ability.	abstract
2021-1214	Always supervised loss is the upper bound by the SSL loss.	abstract
2021-1214	Comment: 1: The paper theoretically connects the SSL and FSL and shows when both will be equivalent.	strength
2021-1214	Theorem-1 shows that the supervised loss is upper bound by SSL loss by a linear relation (mostly scale+shift) when |C|-->infinity then both loss is equivalent.	abstract
2021-1214	It seems that Theorem-1 is trivial since it is obvious that for the large class there will be very less chance of the negative pair is incorrect (i.e. false negative).	weakness
2021-1214	If all the negative pair is correct, then it is same as we know the class label and we make the negative pair using the class information of all samples.	weakness
2021-1214	I believe this theorem provides less useful information for a practical perspective.	weakness
2021-1214	2: Theorem 2 provides the underlying factor between the L_sup and L_U, and shows that L_sup loss is upper bound by the loss of the true-negative and the intraclass variance.	weakness
2021-1214	For the small variance, we can reduce the gap between the supervised loss and SSL loss.	weakness
2021-1214	Once a trivial solution is when |C|--> infinity.	weakness
2021-1214	This theorem shows then when |C| is not large still we can still focus on reducing the intraclass variance and reduce the gap.	abstract
2021-1214	3: It is clear that if we have large number of class, we can reduce the gap between the supervised loss and self-supervised loss, but why the large batch size help in to get a practically better result?	weakness
2021-1214	In this case, the probability of the false-negative samples is the same, and it does not depend on the batch size.	weakness
2021-1214	Could you please explain that?	weakness
2021-1214	It is written that "We can increase N by increasing the total negative samples N_k", is true but in the total negative samples the probability of the false-negative will be same, and it depends on the number of class only.	weakness
2021-1214	Then how large batch size help?	weakness
2021-1214	4: In the N-way and M-shot, it is intuitive that when M increase the model performance will increase, but why with the increase of the N model performance will increase?	weakness
2021-1214	5: Omniglot dataset has 1623 classes, while in the paper it is written that "Omniglot involves up to 4800 classes" please check that.	weakness
2021-1214	https://github.com/brendenlake/omniglot Summary The authors analyze a self-supervised learning framework for downstream (supervised) few-shot classification.	abstract
2021-1214	The self-supervised stage is a simplified version of MoCo (He et al. 2019) and relies on class-invariant augmentation of unlabeled data to produce samples for a contrastive loss.	abstract
2021-1214	This produces two encoder networks that are used in the subsequent few-shot learning stage via a distance-based classification scheme similar to that used by Snell et al. (2017), [1], [2], and Chen et al. (2019).	abstract
2021-1214	The authors show that the method minimizes an upper bound on an oracle supervised distance-based classification loss.	abstract
2021-1214	They then further analyze the looseness by decomposing the self-supervised loss into contributions from false-negative and true-negative samples.	abstract
2021-1214	They relate these quantities to key methodological considerations, such as the level of diversity in the meta-training/base data and the number of negative samples to use during contrastive learning.	abstract
2021-1214	The authors assess this method on the Omniglot and miniImageNet few-shot datasets, following the setup proposed by Hsu et al. (2019) in which the meta-training (aka base) split is treated as unlabeled.	abstract
2021-1214	The results are strong, though are curiously relegated entirely to the Appendix.	abstract
2021-1214	Strengths The overall pipeline is to my knowledge novel, even though the authors are careful to state that the method is not a core contribution as it draws heavily from prior methods.	strength
2021-1214	Unlike previous works that consider unsupervised/self-supervised pre-training for few-shot learning, this work provides some theoretical justification for its method.	strength
2021-1214	Due to the judicious choice of considering contrastive learning and distance-based classification, the resulting analysis is relatively straightforward.	strength
2021-1214	Weaknesses This submission is overall poorly written.	weakness
2021-1214	It was very difficult to parse due to a copious number of grammatical errors.	weakness
2021-1214	In numerous instances, I can't quite discern what the authors mean.	weakness
2021-1214	Aside from this, there are many vague statements unsupported by reference or argument.	weakness
2021-1214	The organization leaves much to be desired.	weakness
2021-1214	For example, results of an ablation take center stage in the main text, while key experimental exposition and benchmark results are left entirely to the Appendix.	weakness
2021-1214	Comparison to CACTUs (Hsu et al., 2019) is not entirely fair as the method (like most modern contrastive learning methods) requires the specification of instance transformations that are class-invariant for test tasks.	weakness
2021-1214	This should be noted. (Though comparison to UMTRA (Khodadadeh et al., 2019) is fair.)	weakness
2021-1214	Recommendation I currently recommend rejection (3), as the submission's poor writing severely hampers clarity and thus prevents it from meeting publication standards.	decision
2021-1214	If the writing were fixed, I would probably rate it around a 6.	misc
2021-1214	References [1] Qi et al., Low-Shot Learning with Imprinted Weights, CVPR 2018	misc
2021-1214	[2] Gidaris et al., Dynamic Few-Shot Visual Learning without Forgetting, CVPR 2018	misc

