The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points. After rebuttal I think the authors' response and the revised paper address most of my concerns. -------------- Post rebuttal update: I think the authors have addressed my main concern points and I am updating my score accordingly. -----Post Rebuttal The authors have addressed my primary concerns and revised the text, I am thus increasing my score. Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks. ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. Finally, the reasoning to reach the conclusion "the distillation error could be seen as a quantification of uncertainty in predicting the constant zero function" seems somewhat unconvincing to me, considering the significant differences compared to Osband et al (2018), in particular: sharing weights among models in the ensemble, ignoring the specific regularization term R(theta), and not adding noise to the training data. * theoretically not very strong, the derivation of the bi-level optimization is interesting, but I believe it is not that clear why iterating between test and validation set is the right thing to do, although admittedly it leads to good results in the settings tested This paper proposes a novel way to formulate neural architecture search as a differentiable problem. Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
To be honest, I do not like the way the authors frame their work (e.g. the way the method is motivated in Section 2.3 or calling it a "unified framework"), but the actual method they propose does make sense, the experimental evaluation is solid, and the results are generally convincing. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points. Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that In some cases it is good to outline a powerful and generic framework (like the authors did here with defining "teaching" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points).
The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. Finally, the reasoning to reach the conclusion "the distillation error could be seen as a quantification of uncertainty in predicting the constant zero function" seems somewhat unconvincing to me, considering the significant differences compared to Osband et al (2018), in particular: sharing weights among models in the ensemble, ignoring the specific regularization term R(theta), and not adding noise to the training data.
The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks.
[Ref2] Soft-to-Hard Vector Quantization for End-to-End Learned Compression of Images and Neural Networks  (https://arxiv.org/abs/1704.00648) Authors propose a transform coding solution by extending the work in Balle 2016. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. [Ref2] Soft-to-Hard Vector Quantization for End-to-End Learned Compression of Images and Neural Networks  (https://arxiv.org/abs/1704.00648) Authors propose a transform coding solution by extending the work in Balle 2016.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. They apply the proposed method two well-known benchmark datasets under a fully connected and a convolutional neural network, and demonstrate that in the former case a slight improvement in accuracy can be achieved, while in the latter, the method performs similar to the group-lasso, but at a reduced computational cost for classifying new images due to increased compression of the network. ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. In some cases it is good to outline a powerful and generic framework (like the authors did here with defining "teaching" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points). The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. Finally, the reasoning to reach the conclusion "the distillation error could be seen as a quantification of uncertainty in predicting the constant zero function" seems somewhat unconvincing to me, considering the significant differences compared to Osband et al (2018), in particular: sharing weights among models in the ensemble, ignoring the specific regularization term R(theta), and not adding noise to the training data. Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that In some cases it is good to outline a powerful and generic framework (like the authors did here with defining "teaching" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points). [Ref2] Soft-to-Hard Vector Quantization for End-to-End Learned Compression of Images and Neural Networks  (https://arxiv.org/abs/1704.00648) Authors propose a transform coding solution by extending the work in Balle 2016. Relevant literature: [Ref1] Learning Convolutional Networks for Content-weighted Image Compression (https://arxiv.org/abs/1703.10553) [2] Huan Zhang, Hongge Chen, Chaowei Xiao, Bo Li, Duane Boning, and Cho-Jui Hsieh, "Towards Stable and Efficient Training of Verifiably Robust Neural Networks" (https://arxiv.org/abs/1906.06316) UPDATE: I would like to thank the authors for their detailed response and for adding additional experimental evaluation. (Disclaimers: I am not not active in the sub-field, just generally interested in the topic, it is easy however to find this paper in the wild and references to it, so I accidentally found out the name of the authors, but had not heard about them before reviewing this, so I do not think this biased my review). Jason D Lee, Ruoqi Shen, Zhao Song, Mengdi Wang, and Zheng Yu. Generalized leverage score sampling for neural networks.
The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks. Pros: - This work demonstrates, theoretically and empirically, a simple way to train generic models using only the known class balances of several sets of unlabeled data (having the same conditional distributions p(x|y))---a very interesting configuration of weak supervision, an increasingly popular and important area ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. They apply the proposed method two well-known benchmark datasets under a fully connected and a convolutional neural network, and demonstrate that in the former case a slight improvement in accuracy can be achieved, while in the latter, the method performs similar to the group-lasso, but at a reduced computational cost for classifying new images due to increased compression of the network. The authors derive different loss functions for such Time-Agnostic Prediction (TAP), including extensions to the Variational AutoEncoders (VAE) and Generative Adversarial Networks (GAN) frameworks, and conduct experiments that suggest that the frames predicted by TAP models correspond to 'subgoal' states useful for planning. Summary This paper presents Neural Process Networks, an architecture for capturing procedural knowledge stated in texts that makes use of a differentiable memory, a sentence and word attention mechanism, as well as learning action representations and their effect on entity representations.
The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. They apply the proposed method two well-known benchmark datasets under a fully connected and a convolutional neural network, and demonstrate that in the former case a slight improvement in accuracy can be achieved, while in the latter, the method performs similar to the group-lasso, but at a reduced computational cost for classifying new images due to increased compression of the network. ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks. Pros: - This work demonstrates, theoretically and empirically, a simple way to train generic models using only the known class balances of several sets of unlabeled data (having the same conditional distributions p(x|y))---a very interesting configuration of weak supervision, an increasingly popular and important area ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. In some cases it is good to outline a powerful and generic framework (like the authors did here with defining "teaching" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points). Finally, the reasoning to reach the conclusion "the distillation error could be seen as a quantification of uncertainty in predicting the constant zero function" seems somewhat unconvincing to me, considering the significant differences compared to Osband et al (2018), in particular: sharing weights among models in the ensemble, ignoring the specific regularization term R(theta), and not adding noise to the training data. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*. Despite my above questions/concerns, I think the proposed method or its predecessors could provide improvements across a variety of text generation tasks, so I overall highly recommend this paper for acceptance.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that In some cases it is good to outline a powerful and generic framework (like the authors did here with defining "teaching" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points).
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. They apply the proposed method two well-known benchmark datasets under a fully connected and a convolutional neural network, and demonstrate that in the former case a slight improvement in accuracy can be achieved, while in the latter, the method performs similar to the group-lasso, but at a reduced computational cost for classifying new images due to increased compression of the network. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks. ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. In some cases it is good to outline a powerful and generic framework (like the authors did here with defining "teaching" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points). Finally, the reasoning to reach the conclusion "the distillation error could be seen as a quantification of uncertainty in predicting the constant zero function" seems somewhat unconvincing to me, considering the significant differences compared to Osband et al (2018), in particular: sharing weights among models in the ensemble, ignoring the specific regularization term R(theta), and not adding noise to the training data. Given that the authors' method uses some extra "privileged" information (as described in point 2), it should far out-perform algorithms that train only on video data, and such a result would strengthen the paper a lot.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. They apply the proposed method two well-known benchmark datasets under a fully connected and a convolutional neural network, and demonstrate that in the former case a slight improvement in accuracy can be achieved, while in the latter, the method performs similar to the group-lasso, but at a reduced computational cost for classifying new images due to increased compression of the network. The authors derive different loss functions for such Time-Agnostic Prediction (TAP), including extensions to the Variational AutoEncoders (VAE) and Generative Adversarial Networks (GAN) frameworks, and conduct experiments that suggest that the frames predicted by TAP models correspond to 'subgoal' states useful for planning. Summary This paper presents Neural Process Networks, an architecture for capturing procedural knowledge stated in texts that makes use of a differentiable memory, a sentence and word attention mechanism, as well as learning action representations and their effect on entity representations. This paper considers learning informative priors for convolutional neural network models based on fits to data sets from similar problem domains. Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points. Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. They apply the proposed method two well-known benchmark datasets under a fully connected and a convolutional neural network, and demonstrate that in the former case a slight improvement in accuracy can be achieved, while in the latter, the method performs similar to the group-lasso, but at a reduced computational cost for classifying new images due to increased compression of the network. The authors derive different loss functions for such Time-Agnostic Prediction (TAP), including extensions to the Variational AutoEncoders (VAE) and Generative Adversarial Networks (GAN) frameworks, and conduct experiments that suggest that the frames predicted by TAP models correspond to 'subgoal' states useful for planning. ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points. Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. They apply the proposed method two well-known benchmark datasets under a fully connected and a convolutional neural network, and demonstrate that in the former case a slight improvement in accuracy can be achieved, while in the latter, the method performs similar to the group-lasso, but at a reduced computational cost for classifying new images due to increased compression of the network. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that In some cases it is good to outline a powerful and generic framework (like the authors did here with defining "teaching" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points). Given that the authors' method uses some extra "privileged" information (as described in point 2), it should far out-perform algorithms that train only on video data, and such a result would strengthen the paper a lot. I think it would strengthen the paper to optimize both the PG and DQN based methods and provide additional results to get a better idea of where things stand on these and/or possibly a more complicated set of tasks.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. They apply the proposed method two well-known benchmark datasets under a fully connected and a convolutional neural network, and demonstrate that in the former case a slight improvement in accuracy can be achieved, while in the latter, the method performs similar to the group-lasso, but at a reduced computational cost for classifying new images due to increased compression of the network. The authors derive different loss functions for such Time-Agnostic Prediction (TAP), including extensions to the Variational AutoEncoders (VAE) and Generative Adversarial Networks (GAN) frameworks, and conduct experiments that suggest that the frames predicted by TAP models correspond to 'subgoal' states useful for planning. Summary This paper presents Neural Process Networks, an architecture for capturing procedural knowledge stated in texts that makes use of a differentiable memory, a sentence and word attention mechanism, as well as learning action representations and their effect on entity representations. This paper considers learning informative priors for convolutional neural network models based on fits to data sets from similar problem domains. This paper proposes to apply a group ordered weighted l1 (GrOWL) regularization term to promote sparsity and parameter sharing in training deep neural networks and hence compress the model to a light version. Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points. After rebuttal I think the authors' response and the revised paper address most of my concerns. -------------- Post rebuttal update: I think the authors have addressed my main concern points and I am updating my score accordingly. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points. In some cases it is good to outline a powerful and generic framework (like the authors did here with defining "teaching" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points).
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. [Ref2] Soft-to-Hard Vector Quantization for End-to-End Learned Compression of Images and Neural Networks  (https://arxiv.org/abs/1704.00648) Authors propose a transform coding solution by extending the work in Balle 2016.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. They apply the proposed method two well-known benchmark datasets under a fully connected and a convolutional neural network, and demonstrate that in the former case a slight improvement in accuracy can be achieved, while in the latter, the method performs similar to the group-lasso, but at a reduced computational cost for classifying new images due to increased compression of the network. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points. However, due to the novelty of the algorithm, the reviewer is in favor of accepting the paper, provided the authors can address the comments above.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. In some cases it is good to outline a powerful and generic framework (like the authors did here with defining "teaching" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points). [Ref2] Soft-to-Hard Vector Quantization for End-to-End Learned Compression of Images and Neural Networks  (https://arxiv.org/abs/1704.00648) Authors propose a transform coding solution by extending the work in Balle 2016.
The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points. After rebuttal I think the authors' response and the revised paper address most of my concerns. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers.
Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers.
Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. They apply the proposed method two well-known benchmark datasets under a fully connected and a convolutional neural network, and demonstrate that in the former case a slight improvement in accuracy can be achieved, while in the latter, the method performs similar to the group-lasso, but at a reduced computational cost for classifying new images due to increased compression of the network. ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks. ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. However, due to the novelty of the algorithm, the reviewer is in favor of accepting the paper, provided the authors can address the comments above.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*. ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. In some cases it is good to outline a powerful and generic framework (like the authors did here with defining "teaching" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points).
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. They apply the proposed method two well-known benchmark datasets under a fully connected and a convolutional neural network, and demonstrate that in the former case a slight improvement in accuracy can be achieved, while in the latter, the method performs similar to the group-lasso, but at a reduced computational cost for classifying new images due to increased compression of the network. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. In some cases it is good to outline a powerful and generic framework (like the authors did here with defining "teaching" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points). Given that the authors' method uses some extra "privileged" information (as described in point 2), it should far out-perform algorithms that train only on video data, and such a result would strengthen the paper a lot. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*. I think it would strengthen the paper to optimize both the PG and DQN based methods and provide additional results to get a better idea of where things stand on these and/or possibly a more complicated set of tasks. The Office-31 dataset is still a good benchmark to compare different methods and for the study in Section 5.1, though it is not necessary to reach state-of-the-art results on this dataset because, as the authors noted, it is almost saturated.
The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. [Ref2] Soft-to-Hard Vector Quantization for End-to-End Learned Compression of Images and Neural Networks  (https://arxiv.org/abs/1704.00648) Authors propose a transform coding solution by extending the work in Balle 2016. ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. In some cases it is good to outline a powerful and generic framework (like the authors did here with defining "teaching" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points). Finally, the reasoning to reach the conclusion "the distillation error could be seen as a quantification of uncertainty in predicting the constant zero function" seems somewhat unconvincing to me, considering the significant differences compared to Osband et al (2018), in particular: sharing weights among models in the ensemble, ignoring the specific regularization term R(theta), and not adding noise to the training data. * theoretically not very strong, the derivation of the bi-level optimization is interesting, but I believe it is not that clear why iterating between test and validation set is the right thing to do, although admittedly it leads to good results in the settings tested This paper proposes a novel way to formulate neural architecture search as a differentiable problem.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. Overall, the paper is (a) well written, (b) proposes a new, interesting idea and (c) shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some standard benchmarks. Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that In some cases it is good to outline a powerful and generic framework (like the authors did here with defining "teaching" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points). Given that the authors' method uses some extra "privileged" information (as described in point 2), it should far out-perform algorithms that train only on video data, and such a result would strengthen the paper a lot. I think it would strengthen the paper to optimize both the PG and DQN based methods and provide additional results to get a better idea of where things stand on these and/or possibly a more complicated set of tasks. The Office-31 dataset is still a good benchmark to compare different methods and for the study in Section 5.1, though it is not necessary to reach state-of-the-art results on this dataset because, as the authors noted, it is almost saturated.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*. Despite my above questions/concerns, I think the proposed method or its predecessors could provide improvements across a variety of text generation tasks, so I overall highly recommend this paper for acceptance.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. They apply the proposed method two well-known benchmark datasets under a fully connected and a convolutional neural network, and demonstrate that in the former case a slight improvement in accuracy can be achieved, while in the latter, the method performs similar to the group-lasso, but at a reduced computational cost for classifying new images due to increased compression of the network. The authors derive different loss functions for such Time-Agnostic Prediction (TAP), including extensions to the Variational AutoEncoders (VAE) and Generative Adversarial Networks (GAN) frameworks, and conduct experiments that suggest that the frames predicted by TAP models correspond to 'subgoal' states useful for planning. Update following author and reviewer discussion: I agree with others regarding the weakness of the empirical comparison to pseudo-counts in particular, but still believe that the paper deserves to be accepted due to the fact that Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*. Despite my above questions/concerns, I think the proposed method or its predecessors could provide improvements across a variety of text generation tasks, so I overall highly recommend this paper for acceptance.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. ): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response]. [Ref2] Soft-to-Hard Vector Quantization for End-to-End Learned Compression of Images and Neural Networks  (https://arxiv.org/abs/1704.00648) Authors propose a transform coding solution by extending the work in Balle 2016. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
[Ref2] Soft-to-Hard Vector Quantization for End-to-End Learned Compression of Images and Neural Networks  (https://arxiv.org/abs/1704.00648) Authors propose a transform coding solution by extending the work in Balle 2016. Relevant literature: [Ref1] Learning Convolutional Networks for Content-weighted Image Compression (https://arxiv.org/abs/1703.10553) Post-rebuttal revision: After reading the authors' response to my review, I decided to increase the score by 2 points. Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for *CONF*.
Summary of the paper ------------------------------- The authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. The paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. In some cases it is good to outline a powerful and generic framework (like the authors did here with defining "teaching" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points).
