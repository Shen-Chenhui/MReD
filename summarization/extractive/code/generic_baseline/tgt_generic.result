There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. Reviewers largely agree that the paper proposes a novel and interesting idea for unsupervised learning through meta learning and the empirical evaluation does a convincing job in demonstrating its effectiveness. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. Reviewers largely agree that the paper proposes a novel and interesting idea for unsupervised learning through meta learning and the empirical evaluation does a convincing job in demonstrating its effectiveness. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. Reviewers largely agree that the paper proposes a novel and interesting idea for unsupervised learning through meta learning and the empirical evaluation does a convincing job in demonstrating its effectiveness. The paper addresess an important problem of neural net robustness verification, and presents a novel approach outperforming state of art; author provided details rebuttals which clarified their contributions over the state of art and highlighted scalability; this work appears to be a solid and useful contribution to the field. The reviewers agree that the proposed method is novel and interesting, that the paper addresses an important problem, and that it is well-written. Strengths: While combining deep learning methods with bundle adjustment is not new, reviewers generally agree that the particular way in which that is achieved in this paper is novel and interesting. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results.
After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results.
After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. The reviewers and the AC note the following as the primary concerns of the paper: (1) The primary concerned raised by the reviewers was that the evaluation is focused on whether KCLN can beat one with the knowledge, instead of measuring the efficacy of incorporating the knowledge itself (eg by comparing with other forms of incorporating knowledge, or by varying the quality of the rules that were introduced), (2) Even otherwise, the empirical results are not significant, offering slight improvements over the vanilla CLN (reviewer 1), (3) There are concerns that the rule-based gates are introduced but gradients are only computed on the final layer, which might lead to instability, and (4) There are a number of issues in the presentation, where the space is used on redundant information and description of datasets, instead of focusing on the proposed model.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided).
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3. There is plenty of discussion between the first reviewer and the authors regarding the novelty of the work as the former point out to several related papers;  however, the authors provide relatively convincing rebuttal of the concerns.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3. There is plenty of discussion between the first reviewer and the authors regarding the novelty of the work as the former point out to several related papers;  however, the authors provide relatively convincing rebuttal of the concerns.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided).
After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*.
However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. I agree with the reviewers' evaluation and encourage the authors to improve this paper before future submission. If the authors provide a rebuttal to a potential reviewer concern, it's a good idea to acknowledge this and note whether it influenced the final decision or not.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. Reviewers largely agree that the paper proposes a novel and interesting idea for unsupervised learning through meta learning and the empirical evaluation does a convincing job in demonstrating its effectiveness. I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs).
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology. the reviewers seem to agree that this submission could be much more strengthened if more investigation is done in two directions: (1) the effect of different, available resources (eg, in the comment, the authors mentioned WikiData didn't improve, and this raises a question of what kind of properties of external resources are necessary to help) and (2) alternatives to incorporating external knowledge (eg, as pointed out by one of the reviewers, this is certainly not the only way to do so, and external knowledge has been used by other approaches for RTE earlier.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. Reviewers largely agree that the paper proposes a novel and interesting idea for unsupervised learning through meta learning and the empirical evaluation does a convincing job in demonstrating its effectiveness. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The paper addresess an important problem of neural net robustness verification, and presents a novel approach outperforming state of art; author provided details rebuttals which clarified their contributions over the state of art and highlighted scalability; this work appears to be a solid and useful contribution to the field. The reviewers agree that the proposed method is novel and interesting, that the paper addresses an important problem, and that it is well-written. Strengths: While combining deep learning methods with bundle adjustment is not new, reviewers generally agree that the particular way in which that is achieved in this paper is novel and interesting.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). This paper presents experiments showing that a linear mapping existing between the hidden states of RNNs trained to recognise (rather than model) formal languages, in the hope of at least partially elucidating the sort of representations this class of network architectures learns. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. I agree with the reviewers' evaluation and encourage the authors to improve this paper before future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. The reviewers and the AC note the following as the primary concerns of the paper: (1) The primary concerned raised by the reviewers was that the evaluation is focused on whether KCLN can beat one with the knowledge, instead of measuring the efficacy of incorporating the knowledge itself (eg by comparing with other forms of incorporating knowledge, or by varying the quality of the rules that were introduced), (2) Even otherwise, the empirical results are not significant, offering slight improvements over the vanilla CLN (reviewer 1), (3) There are concerns that the rule-based gates are introduced but gradients are only computed on the final layer, which might lead to instability, and (4) There are a number of issues in the presentation, where the space is used on redundant information and description of datasets, instead of focusing on the proposed model. The reviewers thought that idea of trying to exploit low-rank structure in the loss gradients of a feedforward network to improve training was interesting; however they expressed many concerns about the clarity of the presentation, quality of the empirical evaluation, and significance of the result (since the tests were not done on an architecture anywhere near state-of-the-art). The reviewers and AC note the following potential weaknesses: (1) reviewer 4 brings up related approaches from automated program repair (APR), that are much more general than the VarMisuse bugs, and the paper lacks citation and comparison to them, (2) the baselines that were compared against are fairly weak, and some recent approaches like DeepBugs and Sk_p are ignored, (3) the approach is trained and evaluated only on synthetic bugs, which look very different from the realistic ones, and (4) the contributions were found to be restricted in novelty, just uses a pointer-based LSTM for locating and fixing bugs. It is not clear, however, whether the method works well in practice for multiple reasons: (i) the experiments are performed in a limited setting, and the rebuttal specifically declined to consider more realistic datasets, (ii) there is an open question about the stability of the resulting gradients, which has been pointed out both in the paper and the reviews. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). This paper presents experiments showing that a linear mapping existing between the hidden states of RNNs trained to recognise (rather than model) formal languages, in the hope of at least partially elucidating the sort of representations this class of network architectures learns. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3. There is plenty of discussion between the first reviewer and the authors regarding the novelty of the work as the former point out to several related papers;  however, the authors provide relatively convincing rebuttal of the concerns. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details). As such, and given the high quality bar of *CONF*, I can't recommend this paper be accepted at this time, but I encourage the authors to revise this explanation and re-submit a new version elsewhere.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). We hope that the detailed comments by the reviewers help improve your paper for potential future submission. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided).
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. One reviewer raised concerns about lack of theoretical guarantees but I do not agree with these concerns (the authors correctly point out in the rebuttal that this is not necessary for an attack-focused paper). The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology. the reviewers seem to agree that this submission could be much more strengthened if more investigation is done in two directions: (1) the effect of different, available resources (eg, in the comment, the authors mentioned WikiData didn't improve, and this raises a question of what kind of properties of external resources are necessary to help) and (2) alternatives to incorporating external knowledge (eg, as pointed out by one of the reviewers, this is certainly not the only way to do so, and external knowledge has been used by other approaches for RTE earlier. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). This paper presents experiments showing that a linear mapping existing between the hidden states of RNNs trained to recognise (rather than model) formal languages, in the hope of at least partially elucidating the sort of representations this class of network architectures learns. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper. Post rebuttal, the reviewers discussed extensively with each other and agreed that, given more work is done on a clear presentation and improving the experiments, this paper can be accepted. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. Reviewers largely agree that the paper proposes a novel and interesting idea for unsupervised learning through meta learning and the empirical evaluation does a convincing job in demonstrating its effectiveness. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). This paper presents experiments showing that a linear mapping existing between the hidden states of RNNs trained to recognise (rather than model) formal languages, in the hope of at least partially elucidating the sort of representations this class of network architectures learns. This paper introduces an approach for reducing the dimensionality of training data examples in a way that preserves information about soft target probabilistic representations provided by a teacher model, with applications such as zero-shot learning and distillation. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details). There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3. There is plenty of discussion between the first reviewer and the authors regarding the novelty of the work as the former point out to several related papers;  however, the authors provide relatively convincing rebuttal of the concerns. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper. Post rebuttal, the reviewers discussed extensively with each other and agreed that, given more work is done on a clear presentation and improving the experiments, this paper can be accepted. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. the reviewers seem to agree that this submission could be much more strengthened if more investigation is done in two directions: (1) the effect of different, available resources (eg, in the comment, the authors mentioned WikiData didn't improve, and this raises a question of what kind of properties of external resources are necessary to help) and (2) alternatives to incorporating external knowledge (eg, as pointed out by one of the reviewers, this is certainly not the only way to do so, and external knowledge has been used by other approaches for RTE earlier. I would recommend the authors to incorporate suggestions provided by reviewer #3 in the final version of the paper including expanding on the related work section. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. I agree with the reviewers' evaluation and encourage the authors to improve this paper before future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. We hope that the detailed comments by the reviewers help improve your paper for potential future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. The reviewers and the AC note the following as the primary concerns of the paper: (1) The primary concerned raised by the reviewers was that the evaluation is focused on whether KCLN can beat one with the knowledge, instead of measuring the efficacy of incorporating the knowledge itself (eg by comparing with other forms of incorporating knowledge, or by varying the quality of the rules that were introduced), (2) Even otherwise, the empirical results are not significant, offering slight improvements over the vanilla CLN (reviewer 1), (3) There are concerns that the rule-based gates are introduced but gradients are only computed on the final layer, which might lead to instability, and (4) There are a number of issues in the presentation, where the space is used on redundant information and description of datasets, instead of focusing on the proposed model. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. The reviewers and the AC note the following as the primary concerns of the paper: (1) The primary concerned raised by the reviewers was that the evaluation is focused on whether KCLN can beat one with the knowledge, instead of measuring the efficacy of incorporating the knowledge itself (eg by comparing with other forms of incorporating knowledge, or by varying the quality of the rules that were introduced), (2) Even otherwise, the empirical results are not significant, offering slight improvements over the vanilla CLN (reviewer 1), (3) There are concerns that the rule-based gates are introduced but gradients are only computed on the final layer, which might lead to instability, and (4) There are a number of issues in the presentation, where the space is used on redundant information and description of datasets, instead of focusing on the proposed model. The reviewers thought that idea of trying to exploit low-rank structure in the loss gradients of a feedforward network to improve training was interesting; however they expressed many concerns about the clarity of the presentation, quality of the empirical evaluation, and significance of the result (since the tests were not done on an architecture anywhere near state-of-the-art).
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. We hope that the detailed comments by the reviewers help improve your paper for potential future submission.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. We hope that the detailed comments by the reviewers help improve your paper for potential future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). We hope that the detailed comments by the reviewers help improve your paper for potential future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. I agree with the reviewers' evaluation and encourage the authors to improve this paper before future submission.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. We hope that the detailed comments by the reviewers help improve your paper for potential future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3. There is plenty of discussion between the first reviewer and the authors regarding the novelty of the work as the former point out to several related papers;  however, the authors provide relatively convincing rebuttal of the concerns. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. the reviewers seem to agree that this submission could be much more strengthened if more investigation is done in two directions: (1) the effect of different, available resources (eg, in the comment, the authors mentioned WikiData didn't improve, and this raises a question of what kind of properties of external resources are necessary to help) and (2) alternatives to incorporating external knowledge (eg, as pointed out by one of the reviewers, this is certainly not the only way to do so, and external knowledge has been used by other approaches for RTE earlier.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided).
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details). I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology. the reviewers seem to agree that this submission could be much more strengthened if more investigation is done in two directions: (1) the effect of different, available resources (eg, in the comment, the authors mentioned WikiData didn't improve, and this raises a question of what kind of properties of external resources are necessary to help) and (2) alternatives to incorporating external knowledge (eg, as pointed out by one of the reviewers, this is certainly not the only way to do so, and external knowledge has been used by other approaches for RTE earlier. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. I would recommend the authors to incorporate suggestions provided by reviewer #3 in the final version of the paper including expanding on the related work section.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. I agree with the reviewers' evaluation and encourage the authors to improve this paper before future submission. If the authors provide a rebuttal to a potential reviewer concern, it's a good idea to acknowledge this and note whether it influenced the final decision or not. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology. the reviewers seem to agree that this submission could be much more strengthened if more investigation is done in two directions: (1) the effect of different, available resources (eg, in the comment, the authors mentioned WikiData didn't improve, and this raises a question of what kind of properties of external resources are necessary to help) and (2) alternatives to incorporating external knowledge (eg, as pointed out by one of the reviewers, this is certainly not the only way to do so, and external knowledge has been used by other approaches for RTE earlier.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). This paper presents experiments showing that a linear mapping existing between the hidden states of RNNs trained to recognise (rather than model) formal languages, in the hope of at least partially elucidating the sort of representations this class of network architectures learns. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology. the reviewers seem to agree that this submission could be much more strengthened if more investigation is done in two directions: (1) the effect of different, available resources (eg, in the comment, the authors mentioned WikiData didn't improve, and this raises a question of what kind of properties of external resources are necessary to help) and (2) alternatives to incorporating external knowledge (eg, as pointed out by one of the reviewers, this is certainly not the only way to do so, and external knowledge has been used by other approaches for RTE earlier.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper. The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. Post rebuttal, the reviewers discussed extensively with each other and agreed that, given more work is done on a clear presentation and improving the experiments, this paper can be accepted. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology. the reviewers seem to agree that this submission could be much more strengthened if more investigation is done in two directions: (1) the effect of different, available resources (eg, in the comment, the authors mentioned WikiData didn't improve, and this raises a question of what kind of properties of external resources are necessary to help) and (2) alternatives to incorporating external knowledge (eg, as pointed out by one of the reviewers, this is certainly not the only way to do so, and external knowledge has been used by other approaches for RTE earlier.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*.
While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. The reviewers and the AC note the following as the primary concerns of the paper: (1) The primary concerned raised by the reviewers was that the evaluation is focused on whether KCLN can beat one with the knowledge, instead of measuring the efficacy of incorporating the knowledge itself (eg by comparing with other forms of incorporating knowledge, or by varying the quality of the rules that were introduced), (2) Even otherwise, the empirical results are not significant, offering slight improvements over the vanilla CLN (reviewer 1), (3) There are concerns that the rule-based gates are introduced but gradients are only computed on the final layer, which might lead to instability, and (4) There are a number of issues in the presentation, where the space is used on redundant information and description of datasets, instead of focusing on the proposed model. The reviewers thought that idea of trying to exploit low-rank structure in the loss gradients of a feedforward network to improve training was interesting; however they expressed many concerns about the clarity of the presentation, quality of the empirical evaluation, and significance of the result (since the tests were not done on an architecture anywhere near state-of-the-art). However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. Reviewers largely agree that the paper proposes a novel and interesting idea for unsupervised learning through meta learning and the empirical evaluation does a convincing job in demonstrating its effectiveness. The paper addresess an important problem of neural net robustness verification, and presents a novel approach outperforming state of art; author provided details rebuttals which clarified their contributions over the state of art and highlighted scalability; this work appears to be a solid and useful contribution to the field. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. Reviewers largely agree that the paper proposes a novel and interesting idea for unsupervised learning through meta learning and the empirical evaluation does a convincing job in demonstrating its effectiveness. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The paper addresess an important problem of neural net robustness verification, and presents a novel approach outperforming state of art; author provided details rebuttals which clarified their contributions over the state of art and highlighted scalability; this work appears to be a solid and useful contribution to the field.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. The reviewers and the AC note the following as the primary concerns of the paper: (1) The primary concerned raised by the reviewers was that the evaluation is focused on whether KCLN can beat one with the knowledge, instead of measuring the efficacy of incorporating the knowledge itself (eg by comparing with other forms of incorporating knowledge, or by varying the quality of the rules that were introduced), (2) Even otherwise, the empirical results are not significant, offering slight improvements over the vanilla CLN (reviewer 1), (3) There are concerns that the rule-based gates are introduced but gradients are only computed on the final layer, which might lead to instability, and (4) There are a number of issues in the presentation, where the space is used on redundant information and description of datasets, instead of focusing on the proposed model. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". The reviewers thought that idea of trying to exploit low-rank structure in the loss gradients of a feedforward network to improve training was interesting; however they expressed many concerns about the clarity of the presentation, quality of the empirical evaluation, and significance of the result (since the tests were not done on an architecture anywhere near state-of-the-art). I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology. the reviewers seem to agree that this submission could be much more strengthened if more investigation is done in two directions: (1) the effect of different, available resources (eg, in the comment, the authors mentioned WikiData didn't improve, and this raises a question of what kind of properties of external resources are necessary to help) and (2) alternatives to incorporating external knowledge (eg, as pointed out by one of the reviewers, this is certainly not the only way to do so, and external knowledge has been used by other approaches for RTE earlier. I would recommend the authors to incorporate suggestions provided by reviewer #3 in the final version of the paper including expanding on the related work section. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. We hope that the detailed comments by the reviewers help improve your paper for potential future submission.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3. There is plenty of discussion between the first reviewer and the authors regarding the novelty of the work as the former point out to several related papers;  however, the authors provide relatively convincing rebuttal of the concerns.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. Reviewers largely agree that the paper proposes a novel and interesting idea for unsupervised learning through meta learning and the empirical evaluation does a convincing job in demonstrating its effectiveness. The paper addresess an important problem of neural net robustness verification, and presents a novel approach outperforming state of art; author provided details rebuttals which clarified their contributions over the state of art and highlighted scalability; this work appears to be a solid and useful contribution to the field. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and the AC note the following as the primary concerns of the paper: (1) The primary concerned raised by the reviewers was that the evaluation is focused on whether KCLN can beat one with the knowledge, instead of measuring the efficacy of incorporating the knowledge itself (eg by comparing with other forms of incorporating knowledge, or by varying the quality of the rules that were introduced), (2) Even otherwise, the empirical results are not significant, offering slight improvements over the vanilla CLN (reviewer 1), (3) There are concerns that the rule-based gates are introduced but gradients are only computed on the final layer, which might lead to instability, and (4) There are a number of issues in the presentation, where the space is used on redundant information and description of datasets, instead of focusing on the proposed model. The reviewers thought that idea of trying to exploit low-rank structure in the loss gradients of a feedforward network to improve training was interesting; however they expressed many concerns about the clarity of the presentation, quality of the empirical evaluation, and significance of the result (since the tests were not done on an architecture anywhere near state-of-the-art). The reviewers and AC note the following potential weaknesses: (1) reviewer 4 brings up related approaches from automated program repair (APR), that are much more general than the VarMisuse bugs, and the paper lacks citation and comparison to them, (2) the baselines that were compared against are fairly weak, and some recent approaches like DeepBugs and Sk_p are ignored, (3) the approach is trained and evaluated only on synthetic bugs, which look very different from the realistic ones, and (4) the contributions were found to be restricted in novelty, just uses a pointer-based LSTM for locating and fixing bugs.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details). The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results.
While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers agree that the paper is well written and the proposed bandit optimization-based algorithm provides a nice framework in which to integrate priors, resulting in impressive empirical improvements. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. We hope that the detailed comments by the reviewers help improve your paper for potential future submission.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). This paper presents experiments showing that a linear mapping existing between the hidden states of RNNs trained to recognise (rather than model) formal languages, in the hope of at least partially elucidating the sort of representations this class of network architectures learns. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. We hope that the detailed comments by the reviewers help improve your paper for potential future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. The reviewers and the AC note the following as the primary concerns of the paper: (1) The primary concerned raised by the reviewers was that the evaluation is focused on whether KCLN can beat one with the knowledge, instead of measuring the efficacy of incorporating the knowledge itself (eg by comparing with other forms of incorporating knowledge, or by varying the quality of the rules that were introduced), (2) Even otherwise, the empirical results are not significant, offering slight improvements over the vanilla CLN (reviewer 1), (3) There are concerns that the rule-based gates are introduced but gradients are only computed on the final layer, which might lead to instability, and (4) There are a number of issues in the presentation, where the space is used on redundant information and description of datasets, instead of focusing on the proposed model.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. The reviewers and the AC note the following as the primary concerns of the paper: (1) The primary concerned raised by the reviewers was that the evaluation is focused on whether KCLN can beat one with the knowledge, instead of measuring the efficacy of incorporating the knowledge itself (eg by comparing with other forms of incorporating knowledge, or by varying the quality of the rules that were introduced), (2) Even otherwise, the empirical results are not significant, offering slight improvements over the vanilla CLN (reviewer 1), (3) There are concerns that the rule-based gates are introduced but gradients are only computed on the final layer, which might lead to instability, and (4) There are a number of issues in the presentation, where the space is used on redundant information and description of datasets, instead of focusing on the proposed model. The reviewers thought that idea of trying to exploit low-rank structure in the loss gradients of a feedforward network to improve training was interesting; however they expressed many concerns about the clarity of the presentation, quality of the empirical evaluation, and significance of the result (since the tests were not done on an architecture anywhere near state-of-the-art). The reviewers and AC note the following potential weaknesses: (1) reviewer 4 brings up related approaches from automated program repair (APR), that are much more general than the VarMisuse bugs, and the paper lacks citation and comparison to them, (2) the baselines that were compared against are fairly weak, and some recent approaches like DeepBugs and Sk_p are ignored, (3) the approach is trained and evaluated only on synthetic bugs, which look very different from the realistic ones, and (4) the contributions were found to be restricted in novelty, just uses a pointer-based LSTM for locating and fixing bugs. It is not clear, however, whether the method works well in practice for multiple reasons: (i) the experiments are performed in a limited setting, and the rebuttal specifically declined to consider more realistic datasets, (ii) there is an open question about the stability of the resulting gradients, which has been pointed out both in the paper and the reviews. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) more formal justifications are required to assess the scope and significance of this work contributions -- see very detailed comments by R2 about measuring networks capacity to memorize and the role of network weights and depth as studied in MacKay,2002. The paper is well written and makes an interesting contribution, but the reviewers expressed some criticisms, including technical novelty, unfinished experiments (and lack of experimental details), and somewhat weak experimental results, which suggest that the proposed ARNe model does not work well when training with weaker supervision without meta-targets. Also the reviewers address other potential weaknesses and give suggestions for improvement: (2) empirical evaluations can be substantially improved with sensitivity analysis of the hyper-parameters on the validation data (R3), indicating errors and error bars for all results (R3 and R2), using more challenging and realistic experimental setting where the data comes from different domains (R1), justifying the results better -- see R2's questions; (3) lack of clarity and motivation in Section 3.1 -- see R2's and R1's suggestions for how to improve clarity and potentially take advantage of the current task to probably correct the previous models prediction when it was wrong. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. The reviewers and the AC note the following as the primary concerns of the paper: (1) The primary concerned raised by the reviewers was that the evaluation is focused on whether KCLN can beat one with the knowledge, instead of measuring the efficacy of incorporating the knowledge itself (eg by comparing with other forms of incorporating knowledge, or by varying the quality of the rules that were introduced), (2) Even otherwise, the empirical results are not significant, offering slight improvements over the vanilla CLN (reviewer 1), (3) There are concerns that the rule-based gates are introduced but gradients are only computed on the final layer, which might lead to instability, and (4) There are a number of issues in the presentation, where the space is used on redundant information and description of datasets, instead of focusing on the proposed model. The reviewers thought that idea of trying to exploit low-rank structure in the loss gradients of a feedforward network to improve training was interesting; however they expressed many concerns about the clarity of the presentation, quality of the empirical evaluation, and significance of the result (since the tests were not done on an architecture anywhere near state-of-the-art). The reviewers and AC note the following potential weaknesses: (1) reviewer 4 brings up related approaches from automated program repair (APR), that are much more general than the VarMisuse bugs, and the paper lacks citation and comparison to them, (2) the baselines that were compared against are fairly weak, and some recent approaches like DeepBugs and Sk_p are ignored, (3) the approach is trained and evaluated only on synthetic bugs, which look very different from the realistic ones, and (4) the contributions were found to be restricted in novelty, just uses a pointer-based LSTM for locating and fixing bugs. It is not clear, however, whether the method works well in practice for multiple reasons: (i) the experiments are performed in a limited setting, and the rebuttal specifically declined to consider more realistic datasets, (ii) there is an open question about the stability of the resulting gradients, which has been pointed out both in the paper and the reviews. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) more formal justifications are required to assess the scope and significance of this work contributions -- see very detailed comments by R2 about measuring networks capacity to memorize and the role of network weights and depth as studied in MacKay,2002. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). This paper presents experiments showing that a linear mapping existing between the hidden states of RNNs trained to recognise (rather than model) formal languages, in the hope of at least partially elucidating the sort of representations this class of network architectures learns. This paper introduces an approach for reducing the dimensionality of training data examples in a way that preserves information about soft target probabilistic representations provided by a teacher model, with applications such as zero-shot learning and distillation. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). This paper presents experiments showing that a linear mapping existing between the hidden states of RNNs trained to recognise (rather than model) formal languages, in the hope of at least partially elucidating the sort of representations this class of network architectures learns. This paper introduces an approach for reducing the dimensionality of training data examples in a way that preserves information about soft target probabilistic representations provided by a teacher model, with applications such as zero-shot learning and distillation. For learning the current task, the authors propose to find an optimal structure of the neural network model first (select either to reuse, adapt previously learned layers or to train new layers) and then to learn its parameters. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper.
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3. There is plenty of discussion between the first reviewer and the authors regarding the novelty of the work as the former point out to several related papers;  however, the authors provide relatively convincing rebuttal of the concerns. Questions from reviewers were well addressed in the rebuttal and helped significantly clarify and improve the paper, in particular for delineating the novel contribution against prior related work. The paper did improve based on reviewer feedback, and while R3 was more convinced by the follow-up experiments (though remarked that requiring environment variations to obtain new skills was a "significant step backward from things like [Diversity is All You Need]"), the other reviewers remained unconvinced regarding domain knowledge and in particular how it interacts with the scalability of the proposed method to complex environments/robots. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers adjusted their scores upward after the rebuttal, but serious concerns remain, and the consensus is still to (borderline) reject the paper. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. The reviewers and the AC note the following as the primary concerns of the paper: (1) The primary concerned raised by the reviewers was that the evaluation is focused on whether KCLN can beat one with the knowledge, instead of measuring the efficacy of incorporating the knowledge itself (eg by comparing with other forms of incorporating knowledge, or by varying the quality of the rules that were introduced), (2) Even otherwise, the empirical results are not significant, offering slight improvements over the vanilla CLN (reviewer 1), (3) There are concerns that the rule-based gates are introduced but gradients are only computed on the final layer, which might lead to instability, and (4) There are a number of issues in the presentation, where the space is used on redundant information and description of datasets, instead of focusing on the proposed model. The reviewers thought that idea of trying to exploit low-rank structure in the loss gradients of a feedforward network to improve training was interesting; however they expressed many concerns about the clarity of the presentation, quality of the empirical evaluation, and significance of the result (since the tests were not done on an architecture anywhere near state-of-the-art). The reviewers and AC note the following potential weaknesses: (1) reviewer 4 brings up related approaches from automated program repair (APR), that are much more general than the VarMisuse bugs, and the paper lacks citation and comparison to them, (2) the baselines that were compared against are fairly weak, and some recent approaches like DeepBugs and Sk_p are ignored, (3) the approach is trained and evaluated only on synthetic bugs, which look very different from the realistic ones, and (4) the contributions were found to be restricted in novelty, just uses a pointer-based LSTM for locating and fixing bugs. It is not clear, however, whether the method works well in practice for multiple reasons: (i) the experiments are performed in a limited setting, and the rebuttal specifically declined to consider more realistic datasets, (ii) there is an open question about the stability of the resulting gradients, which has been pointed out both in the paper and the reviews. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) more formal justifications are required to assess the scope and significance of this work contributions -- see very detailed comments by R2 about measuring networks capacity to memorize and the role of network weights and depth as studied in MacKay,2002.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. The reviewers and the AC note the following as the primary concerns of the paper: (1) The primary concerned raised by the reviewers was that the evaluation is focused on whether KCLN can beat one with the knowledge, instead of measuring the efficacy of incorporating the knowledge itself (eg by comparing with other forms of incorporating knowledge, or by varying the quality of the rules that were introduced), (2) Even otherwise, the empirical results are not significant, offering slight improvements over the vanilla CLN (reviewer 1), (3) There are concerns that the rule-based gates are introduced but gradients are only computed on the final layer, which might lead to instability, and (4) There are a number of issues in the presentation, where the space is used on redundant information and description of datasets, instead of focusing on the proposed model. The reviewers thought that idea of trying to exploit low-rank structure in the loss gradients of a feedforward network to improve training was interesting; however they expressed many concerns about the clarity of the presentation, quality of the empirical evaluation, and significance of the result (since the tests were not done on an architecture anywhere near state-of-the-art). The reviewers and AC note the following potential weaknesses: (1) reviewer 4 brings up related approaches from automated program repair (APR), that are much more general than the VarMisuse bugs, and the paper lacks citation and comparison to them, (2) the baselines that were compared against are fairly weak, and some recent approaches like DeepBugs and Sk_p are ignored, (3) the approach is trained and evaluated only on synthetic bugs, which look very different from the realistic ones, and (4) the contributions were found to be restricted in novelty, just uses a pointer-based LSTM for locating and fixing bugs. It is not clear, however, whether the method works well in practice for multiple reasons: (i) the experiments are performed in a limited setting, and the rebuttal specifically declined to consider more realistic datasets, (ii) there is an open question about the stability of the resulting gradients, which has been pointed out both in the paper and the reviews. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) more formal justifications are required to assess the scope and significance of this work contributions -- see very detailed comments by R2 about measuring networks capacity to memorize and the role of network weights and depth as studied in MacKay,2002. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. As a result, while I think that dynamic evaluation itself is useful, given the limited novelty of the proposed method and the lack of comparison to the real baseline (the simpler strategy of Mikolov et al) in the majority of the experiments, I think this papers till falls short of the quality bar of *CONF*. The reviewers and the AC note the following as the primary concerns of the paper: (1) The primary concerned raised by the reviewers was that the evaluation is focused on whether KCLN can beat one with the knowledge, instead of measuring the efficacy of incorporating the knowledge itself (eg by comparing with other forms of incorporating knowledge, or by varying the quality of the rules that were introduced), (2) Even otherwise, the empirical results are not significant, offering slight improvements over the vanilla CLN (reviewer 1), (3) There are concerns that the rule-based gates are introduced but gradients are only computed on the final layer, which might lead to instability, and (4) There are a number of issues in the presentation, where the space is used on redundant information and description of datasets, instead of focusing on the proposed model. The reviewers thought that idea of trying to exploit low-rank structure in the loss gradients of a feedforward network to improve training was interesting; however they expressed many concerns about the clarity of the presentation, quality of the empirical evaluation, and significance of the result (since the tests were not done on an architecture anywhere near state-of-the-art). The reviewers and AC note the following potential weaknesses: (1) reviewer 4 brings up related approaches from automated program repair (APR), that are much more general than the VarMisuse bugs, and the paper lacks citation and comparison to them, (2) the baselines that were compared against are fairly weak, and some recent approaches like DeepBugs and Sk_p are ignored, (3) the approach is trained and evaluated only on synthetic bugs, which look very different from the realistic ones, and (4) the contributions were found to be restricted in novelty, just uses a pointer-based LSTM for locating and fixing bugs. It is not clear, however, whether the method works well in practice for multiple reasons: (i) the experiments are performed in a limited setting, and the rebuttal specifically declined to consider more realistic datasets, (ii) there is an open question about the stability of the resulting gradients, which has been pointed out both in the paper and the reviews. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. The idea, from my understanding, is interesting and would benefit from discussion at the workshop track, but the authors are investigated to make a stronger case for the novelty of this method in any further work and, in particular, to consider showing empirical improvement on "real" data where TT methods are currently applied. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. We hope that the detailed comments by the reviewers help improve your paper for potential future submission. I agree with the reviewers' evaluation and encourage the authors to improve this paper before future submission.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments". I encourage the authors to incorporate the reviewers' comments in a future revision, and explain why this proposed method bring significant contribution to either address a real problem or improve VI methodology. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. the reviewers seem to agree that this submission could be much more strengthened if more investigation is done in two directions: (1) the effect of different, available resources (eg, in the comment, the authors mentioned WikiData didn't improve, and this raises a question of what kind of properties of external resources are necessary to help) and (2) alternatives to incorporating external knowledge (eg, as pointed out by one of the reviewers, this is certainly not the only way to do so, and external knowledge has been used by other approaches for RTE earlier. I would recommend the authors to incorporate suggestions provided by reviewer #3 in the final version of the paper including expanding on the related work section. While this is an interesting direction and the presented experiments look quite encouraging, the paper would benefit from more evaluation, as suggested by reviewers, especially within state-of-the-art architecture search frameworks and/or large datasets. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. In particular, the paper should have an improved discussion of state-of-the-art work on exploration, compare the difference and benefits of the proposed approach, and then conduct proper experiments to validate the claims. The reviewers and AC note the following potential weaknesses: (1) low technical novelty in light of prior works "Demystifying Neural Style Transfer" by Li et al 2017 and "Deep Transfer Learning with Joint Adaptation Networks" by Long et al 2017 -- See R2's detailed explanations; (2) lack of empirical evidence that the proposed method is better than the seminal work on KD by Hinton et al, 2014; (3) important practical issues are not justified (eg kernel specifications as requested by R3 and R2; accuracy-efficiency trade-off as suggested by R1); (4) presentation clarity. I appreciate the changes made to address the comment, and I encourage the authors to continue improving the paper by simplifying the model and including a few baseline comparisons in the experiments. As pointed out by Reviewer 1, the paper could be made clearly more convincing by showing that these distribution preservation operations also help perform interpolation in the latent space of VAEs, and the AC strongly encourages the authors to add these results if possible. This is a borderline paper: the idea is valuable and I'd encourage the authors to develop it further, improving exposition and including additional experiments as suggested by the reviewers. As such, it is my suggestion that the authors revise the paper in its current form, and resubmit, addressing some of the first reviewers comments, such as discussion of utility of the methodology, and to improve the exposition such that less knowledgable reviewers understand the material presented better.
The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. I thank the authors for submitting this work to *CONF*, and I hope that the reviewers' comments are helpful in improving this research for future submission.
While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3. There is plenty of discussion between the first reviewer and the authors regarding the novelty of the work as the former point out to several related papers;  however, the authors provide relatively convincing rebuttal of the concerns. Questions from reviewers were well addressed in the rebuttal and helped significantly clarify and improve the paper, in particular for delineating the novel contribution against prior related work. The paper did improve based on reviewer feedback, and while R3 was more convinced by the follow-up experiments (though remarked that requiring environment variations to obtain new skills was a "significant step backward from things like [Diversity is All You Need]"), the other reviewers remained unconvinced regarding domain knowledge and in particular how it interacts with the scalability of the proposed method to complex environments/robots. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers agree that the paper addresses an important problem, brings clarity to existing methods, and proposes an interesting approach / algorithm, and is well-written. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The present work addresses the problem of opponent modeling in multi-agent learning settings, and propose an approach based on variational auto-encoders (VAEs). While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. Despite some positive experimental results, the contribution of the paper is not sufficient for publication at *CONF* due to several issues: similarity between the proposed method and existing method (eg, AMTL), unclear rationale/intuition of the proposed model, clarity of presentation, technical formulation, and limited empirical evaluations (see reviewer comments for details).
While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. The authors provided further experimental results during the discussion period and the reviewers agree that the paper is now acceptable for publication at *CONF*-2020. However, all reviewers agree that the paper could be improved by including more comparison with prior art and related work discussion, and strengthening empirical results by including real-life  data and more through evaluation; they also find the novelty and significance of the proposed approach somewhat limited. While the reviewers acknowledged the potential usefulness of the proposed approach, all of them agreed that the paper requires: (1) major improvement in clarifying important points related to the approach (see R3's detailed comments; R2's concern on using the double sampling method to train non-convex models; see R1's and R3's concerns regarding the double summation/integral terms and how this effects runtime), and (2) major improvement in justifying its application to fairness; as noted by R2, "there is no sufficient evidence why non-convex models are actually useful in the experiments".
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. The authors then propose an objective function, the conditional entropy bottleneck (CEB), to ensure that a learned representation satisfies the minimum necessary information criterion, and a variational approximation to the conditional entropy bottleneck that can be parameterized using deep networks and optimized with standard methods such as stochastic gradient descent. In this paper, the authors propose a novel approach for learning the structure of a directed acyclic graph from observational data that allows to flexibly model nonlinear relationships between variables using neural networks. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. However the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework â€“ see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (eg distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended â€“ see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. There is a general consensus that that the paper has good quality and clarity, is well motivated, is sufficiently novel, makes clear contributions for training deep neural networks, and provides convincing experimental results to show the advantages of the proposed SN. Pros: All reviews had positive sentiment: "very elegant and general idea" (Reviewer4); "idea is interesting and potentially very useful" (Reviewer2); "method is novel, the explanation is clear, and has good experimental results" (Reviewer3); "a good way to learn a policy for resetting while learning a policy for solving the problem. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). The reviewers point out the following potential weaknesses: (1) clarity issues in the writing and the presentation, (2) a lack of novelty in the proposed approach, given a number of recent work has shown the ability of language models to perform commonsense reasoning, and (3) critical methodological issues in the evaluation that raise questions about the significance of the results. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. The reviewers and the AC note the following as the primary concerns of the paper: (1) The novelty of this work is limited, since a number of approaches have recently combined CRFs and neural networks, and it is unclear whether the application of those ideas to GCNs is sufficiently interesting, (2) the losses, especially EBM, and the use of greedy/beam-search inference was found to be quite simple, especially given these have been studied extensively in the literature, and (3) analysis and adequate discussion of the results is missing (only a single table of numbers is provided). After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The authors have proposed an architecture that incorporates a VIN with a DNC to combine low level planning with high level memory-based optimization, resulting in a single policy for navigation and other similar problems that is trained end-to-end with sparse rewards. While the authors' response and revision have partially addressed some of the raised concerns on the technical analyses, the experimental evaluations presented in the paper do not appear adequate to justify the advantages of the proposed method over previously proposed ones, and the clarity (in particular, notation) needs further improvement. Reviewers initially had neutral to positive comments, and after the author rebuttal which addressed some of the major questions and concerns, their scores were raised to reflect their satisfaction with the response and the revised paper. The reviewers appreciated the author's comments and the revision, which addressed all of the concerns by including (1) additional experiments to performance with and without self-adversarial sampling, and comparisons to TorusE, (2) improved presentation. During the discussion phase, the authors clarified reviewer 1's concern regarding the difference in performance between HolE and ComplEx, along with providing a revision that addressed some of the clarity issues raised by reviewer 3. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. There is plenty of discussion between the first reviewer and the authors regarding the novelty of the work as the former point out to several related papers;  however, the authors provide relatively convincing rebuttal of the concerns. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. The reviewers and AC note the following potential weaknesses: (1) the paper does not propose a new model, but instead a different data generation strategy, somewhat limiting the novelty, (2) Salient variables that need to be uniformly sampled are still user specified, (3) there were a number of notation and clarity issues that make it difficult to understand the details of the approach, and finally, (4) there are concerns with the use of rejection sampling. While acknowledging that the proposed model is potentially useful, the reviewers raised several important concerns that were viewed by AC as critical issues: (1) poor presentation clarity of the manuscript and incremental technical contribution in light of prior work by Serra et al (2018); (2) rigorous experiments and in-depth analysis of the baseline models in terms of accuracy, number of parameters, memory demand and model complexity would significantly strengthen the evaluation â€“ see R1's and R3's suggestions how to improve; (3) simple strategies such as storing a number of examples and memory replay should not be neglected and evaluated to assess the scope of the contribution. After taking the reviewer discussion into account and making his/her own assessment, the AC recommends rejection at this time, but strongly encourages the authors to resubmit their work after improving their experimental setup, which will make the paper much stronger.
